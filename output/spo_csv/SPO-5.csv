input,subject,relation,object
表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。,OWL版本,被定义为,OWL2
表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。,OWL版本,由组成,OWL2
OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。,OWL2,被定义为,OWL的子语言
OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。,OWL2定义,由组成,一些OWL的子语言
OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。,OWL2定义,由组成,一些OWL的子语言
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2的三大子语言,被定义为,OWL_2_RL、OWL_2_QL和OWL_2_EL
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2的三大子语言,由组成,OWL_2_RL、OWL_2_QL和OWL_2_EL
OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。,OWL_2_QL,被定义为,专为基于本体的查询设计的
它的查询复杂度是AC0，非常适合大规模处理。,SPO,被定义为,大规模处理
它的查询复杂度是AC0，非常适合大规模处理。,SPO,由组成,ACO
它是基于描述逻辑DL-Lite定义的。,DL-Lite,被定义为,基于描述逻辑DL-Lite定义的
它是基于描述逻辑DL-Lite定义的。,基于描述逻辑的本体,由组成,DL-Lite
表2-6给出了OWL_2_QL词汇总结。,OWL_2_QL词汇,被定义为,OWL_2_QL词汇表
表2-6给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,由组成,表2-6给出了OWL_2_QL词汇总结。
表2-6给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,由组成,表2-6给出了OWL_2_QL词汇总结。
表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。,OWL_2_QL,被定义为,OWL_2_QL是OWL_2的一个子集，它只包含OWL_2中的一些基本概念
表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。,OWL_2_QL,由组成,OWL_2_QL词汇总结
表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。,OWL_2_QL,由组成,OWL_2_QL词汇总结
与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。,OWL_2_EL,被定义为,概念术语描述、本体的分类推理
与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。,OWL_2_EL,由组成,OWL_2_QL
与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。,OWL_2_EL,由组成,OWL_2_QL
OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。,OWL_2_EL,被定义为,基于描述逻辑语言EL++定义的
OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。,OWL_2_EL,由组成,基于描述逻辑语言EL++定义的
OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。,OWL_2_EL,由组成,基于描述逻辑语言EL++定义的
表2-7给出了OWL_2_QL词汇总结。,OWL_2_QL词汇,被定义为,OWL_2_QL词汇表
表2-7给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,由组成,表2-7给出了OWL_2_QL词汇总结。
表2-7给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,由组成,表2-7给出了OWL_2_QL词汇总结。
表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female??likes.Movie??hasSon.(Student??attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。,OWL_2_EL,被定义为,OWL_2_EL允许表达如下复杂的概念：Female??likes.Movie??hasSon.(Student??attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。
表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female??likes.Movie??hasSon.(Student??attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。,OWL_2_EL,由组成,Female??likes.Movie??hasSon.(Student??attends.CSCourse)
下面给出一个例子。,SPO,被定义为,三元组
下面给出一个例子。,SPO,由组成,由组成
下面给出一个例子。,知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
假设有一个本体，包含以下公理：公理1.Apple??beInvestedBy.(Fidelity?BlackStone)：苹果由富达和黑石投资。,苹果,被定义为,由富达和黑石投资
假设有一个本体，包含以下公理：公理1.Apple??beInvestedBy.(Fidelity?BlackStone)：苹果由富达和黑石投资。,苹果,由组成,富达和黑石投资
公理2.?beFundedBy.Fidelity?InnovativeCompanies：借助富达融资的公司都是创新企业。,Fidelity,被定义为,富达
公理2.?beFundedBy.Fidelity?InnovativeCompanies：借助富达融资的公司都是创新企业。,Fidelity,由组成,InnovativeCompanies
公理3.?beFundedBy.BlackStone?InnovativeCompanies：借助黑石融资的公司都是创新企业。,BlackStone,由组成,beFundedBy
公理4.beInvestedBy?beFundedBy：投资即是帮助融资。,投资,包含,帮助融资
公理4.beInvestedBy?beFundedBy：投资即是帮助融资。,投资,由组成,帮助融资
公理4.beInvestedBy?beFundedBy：投资即是帮助融资。,投资,由组成,帮助融资
由公理1可以推出公理5:Apple??beInvestedBy.Fidelity；由公理5和公理4可以推出公???beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,Apple,被定义为,Apple_InnovativeCompanies
由公理1可以推出公理5:Apple??beInvestedBy.Fidelity；由公理5和公理4可以推出公???beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,Apple,由组成,Fidelity
由公理1可以推出公理5:Apple??beInvestedBy.Fidelity；由公理5和公理4可以推出公???beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,Apple,由组成,Fidelity
还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。,OWL_2_RL,被定义为,OWL2子语言
还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。,OWL_2_RL,由组成,OWL2子语言
还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。,OWL_2_RL,属于,OWL2子语言
OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。,OWL_2_RL,被定义为,RDFS
OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。,OWL_2_RL,由组成,RDFS
OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。,OWL_2_RL,由组成,RDFS
OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。,OWL_2_RL_的推理,被定义为,前向链推理
OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。,OWL_2_RL_的推理,由组成,前向链推理
"下面给出两个OWL_2_RL上的推理规则：p_rdfs:domain_x,spo?s_rdf:type_xp_rdfs:range_x,spo?o_rdf:type_x其中，s、p、o、x为变量。",OWL_2_RL,被定义为,OWL_2_RL上的推理规则
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,第一条规则,被定义为,如果属性p的定义域是类x，而且实例s和o有关系p
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,第一条规则,由组成,如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,第一条规则,由组成,如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。
第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。,关系,被定义为,第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。
第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。,第二条规则,由组成,如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:hasChild_rdfs:domain_exp:Person,被定义为,exp:Helen_exp:hasChild_exp:Jack
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:hasChild_rdfs:domain_exp:Person,由组成,exp:Helen_exp:hasChild_exp:Jack
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:hasChild_rdfs:domain_exp:Person,由组成,exp:Helen_exp:hasChild_exp:Jack
OWL_2_RL允许的核心词汇有：●rdfs:subClassOf；●rdfs:subPropertyOf；●rdfs:domain；●rdfs:range；●owl:TransitiveProperty；●owl:FunctionalProperty；●owl:sameAs；●owl:equivalentClass；●owl:equivalentProperty；●owl:someValuesFrom；●owl:allValuesFrom。,OWL_2_RL,被定义为,核心词汇
OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。,OWL_2_RL,包含,PTIME完备
OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。,OWL_2_RL,由组成,PTIME
OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。,OWL_2_RL,由组成,PTIME
2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。,RDF,被定义为,SPARQL
2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。,SPARQL,由组成,SPARQL查询语言
1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。,SPARQL,被定义为,RDF中的资源，以“?”或者“$”指示
1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。,SPARQL,由组成,三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；SELECT子句中指示要查询的目标变量。
下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。,SPARQL查询,被定义为,查询所有选修CS328课程的学生
下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。,选修CS328课程的学生,由组成,PREFIX
下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。,选修CS328课程的学生,由组成,PREFIX
2.常见的SPARQL查询算子（1）OPTIONAL。,SPARQL查询算子,被定义为,OPTIONAL
可选算子，指的是在这个算子覆盖范围的查询语句是可选的。,可选算子,被定义为,可选查询语句
可选算子，指的是在这个算子覆盖范围的查询语句是可选的。,可选算子,由组成,可选查询语句
例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。,查询,被定义为,所有选修CS328课程的学生姓名，以及他们的邮箱。
例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。,查询所有选修CS328课程的学生姓名，以及他们的邮箱。,由组成,CS328
例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。,查询所有选修CS328课程的学生姓名，以及他们的邮箱。,属于,CS328
OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。,OPTIONAL关键字,被定义为,OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。
OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。,OPTIONAL关键字,由组成,如果没有邮箱，则依然返回学生姓名，邮箱处空缺。
OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。,OPTIONAL关键字,属于,OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。
（2）FILTER。,FILTER,被定义为,过滤掉不重要的信息
（2）FILTER。,FILTER,由组成,过滤
过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。,过滤算子,被定义为,过滤查询结果
过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。,过滤算子,由组成,过滤查询语句
过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。,过滤算子,属于,过滤查询结果
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,SPO查询,被定义为,查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,查询学生姓名,由组成,查询学生姓名
（3）UNION。,UNION,被定义为,将两个或多个关系合并成一个关系
（3）UNION。,UNION,由组成,UNION
（3）UNION。,UNION,由组成,UNION
并算子，指的是将两个查询的结果合并起来。,并算子,被定义为,将两个查询的结果合并起来
并算子，指的是将两个查询的结果合并起来。,并算子,由组成,将两个查询的结果合并起来
例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。,查询选修课程CS328或CS909的学生姓名以及邮件,被定义为,查询选修课程CS328或CS909的学生姓名以及邮件
例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。,查询选修课程CS328或CS909的学生姓名以及邮件,由组成,CS328或CS909
例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。,邮件,被定义为,邮件发送
注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。,邮件,由组成,邮件发送
需要注意UNION和OPTIONAL的区别。,UNION,被定义为,UNION和OPTIONAL的区别
需要注意UNION和OPTIONAL的区别。,UNION,由组成,UNION和OPTIONAL的区别
下面给出一个SPARQL查询的例子。,SPARQL查询,被定义为,SPARQL查询语言
给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。,收购,被定义为,收购关系
给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。,收购,由组成,收购关系
表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。,关联交易,被定义为,具备关联交易的公司
表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。,关联交易,由组成,具备关联交易的公司
表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。,关联交易,属于,具备关联交易的公司
通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。,SPARQL查询,被定义为,通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。
通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。,SPARQL查询,由组成,通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。
2.3.4语义Markup表示语言语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。,语义Markup表示语言,被定义为,语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。
被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5MicroData。,被谷歌知识图谱以及Schema.Org采用的语义Markup语言,由组成,JSON-LD、RDFa和HTML5MicroData
1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。,JSON-LD,被定义为,基于JSON表示和传输链接数据的方法
1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。,JSON-LD,由组成,JSON
1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。,JSON-LD,由组成,JSON
JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。,JSON-LD,被定义为,通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。
JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。,JSON-LD,由组成,JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。
JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。,JSON-LD,由组成,JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。
JSON-LD的语法和JSON兼容。,JSON-LD,被定义为,JSON的扩展
JSON-LD的语法和JSON兼容。,JSON-LD,由组成,JSON
JSON-LD的语法和JSON兼容。,JSON-LD,由组成,JSON
下面是一个简单的JSON例子：JSON文档表示一个人。,JSON文档,被定义为,一个人
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,name,被定义为,人的名字
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,name,由组成,人的名字
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,homepage,由组成,主页
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,image,由组成,某种照片
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,name,由组成,人的名字
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,homepage,由组成,主页
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,image,由组成,某种照片
当然，机器不理解“name”和“image”这样的术语。,机器理解,被定义为,知识图谱
当然，机器不理解“name”和“image”这样的术语。,机器理解,由组成,name和image
JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。,JSON-LD,被定义为,通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。
JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。,JSON-LD,由组成,统一化表示
JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。,JSON-LD,由组成,统一化表示
如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。,JSON-LD,被定义为,围绕某类知识提供共享的术语
如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。,JSON-LD,由组成,共享的术语
例如，每个数据集不应该围绕“name”重复发明概念。,数据集,被定义为,每个数据集不应该围绕“name”重复发明概念
例如，每个数据集不应该围绕“name”重复发明概念。,数据集,由组成,不应该围绕“name”重复发明概念
例如，每个数据集不应该围绕“name”重复发明概念。,每个数据集不应该围绕“name”重复发明概念,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。,JSON-LD,被定义为,JSON-LD的实现没有选择大部分语义网技术栈
但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。,JSON-LD,由组成,TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进
RDFa也是W3C推荐标准。,RDFa,被定义为,W3C推荐标准
RDFa也是W3C推荐标准。,RDFa,由组成,W3C推荐标准
它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。,XHTML,被定义为,网页制作者
它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。,XHTML,由组成,扩充了XHTML的几个属性
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,被定义为,RDF的三元组嵌入在XHTML文档中
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,由组成,RDF的三元组
RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。,RDFa,被定义为,在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。
RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。,RDFa,由组成,RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。
RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。,RDFa,由组成,RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。
上面的代码示例中用到了RDFa属性中的about属性和property属性。,RDFa,被定义为,RDF属性
上面的代码示例中用到了RDFa属性中的about属性和property属性。,RDFa,由组成,RDF
这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。,RDFa,被定义为,RDFa是一种用于在HTML文档中嵌入RDF数据的方法
这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。,这段代码示例说明了一篇文章,由组成,RDFa
RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。,RDFa,被定义为,从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联
RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。,RDFa,由组成,RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。
RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。,RDFa,实现,从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联
3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。,HTML5_Microdata,被定义为,微数据
3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。,HTML5_Microdata,由组成,微数据
3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。,HTML5_Microdata,由组成,微数据
微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。,微数据,包含,自定义词汇表、带作用域的键值对
微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。,微数据,被定义为,自定义词汇表、带作用域的键值对
微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。,微数据,由组成,自定义词汇表、带作用域的键值对
微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。,微数据,被定义为,给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。
微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。,微数据,由组成,给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。
微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。,微数据,由组成,给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。
下面是一个HTML5Microdata的示例。,HTML5Microdata,被定义为,HTML5Microdata是一个用于描述网页中数据结构的标记语言
下面是一个HTML5Microdata的示例。,HTML5Microdata,由组成,HTML5Microdata
这个例子给出了Person类下一个叫Andy的人的照片和URL地址。,Person,被定义为,Person类
这个例子给出了Person类下一个叫Andy的人的照片和URL地址。,Person,由组成,Andy
这个例子给出了Person类下一个叫Andy的人的照片和URL地址。,Person,由组成,Andy
通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。,HTML5Microdata,被定义为,通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。
通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。,通过HTML5Microdata,由组成,浏览器可以很方便地从网页上提取微数据实体、属性及属性值。
通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。,通过HTML5Microdata,由组成,浏览器可以很方便地从网页上提取微数据实体、属性及属性值。
2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。,开放域知识图谱,被定义为,知识表示方法
2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。,开放域知识图谱,由组成,知识表示方法
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,知识图谱框架,被定义为,知识图谱框架是用于描述知识图谱的框架
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,框架,由组成,描述术语、表达能力、数据格式
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,知识图谱框架,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,知识图谱框架,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这里以三个最典型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。,知识图谱,由组成,知识表示框架
为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。,RDF,被定义为,RDFS
为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。,RDF,由组成,RDFS
为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。,RDF,由组成,RDFS
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,Freebase,被定义为,MIDTypes
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,Freebase,由组成,MIDTypes
“Object”代表实体。,Object,被定义为,实体
“Object”代表实体。,Object,由组成,实体
每一个“Object”有唯一的（Machine_ID）。,Object,被定义为,每一个“Object”有唯一的（Machine_ID）。
每一个“Object”有唯一的（Machine_ID）。,每一个“Object”,由组成,（Machine_ID）
每一个“Object”有唯一的（Machine_ID）。,每一个“Object”,由组成,（Machine_ID）
一个“Object”可以有一个或多个“Types”。,Object,被定义为,一个“Object”可以有一个或多个“Types”。
一个“Object”可以有一个或多个“Types”。,Object,由组成,Types
一个“Object”可以有一个或多个“Types”。,Object,由组成,Types
“Properties”用来描述“Facts”。,Properties,被定义为,描述Facts
“Properties”用来描述“Facts”。,Properties,由组成,Facts
“Properties”用来描述“Facts”。,Properties,由组成,Facts
例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。,Barack_Obama,被定义为,/m/02mjmr
例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。,Barack_Obama,由组成,/m/02mjmr
例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。,Barack_Obama,由组成,/m/02mjmr
这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。,us_president,被定义为,政府/美国总统
这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。,us_president,被定义为,政府/美国总统
"Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。",Freebase,被定义为,复合值类型
"Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。",Freebase,由组成,复合值类型
type如图2-16所示，示例的CVT描述了关于Obama的任职期限的多元关系“government_position_held”。,government_position_held,被定义为,多元关系
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,被定义为,包含多个子二元关系：“office_holder”“office_position”“from”“to”等。
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,由组成,office_holder
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,由组成,office_position
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,由组成,from
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,由组成,to
一个CVT就是有唯一MID的Object，也可以有多个Types。,CVT,被定义为,一个Object
一个CVT就是有唯一MID的Object，也可以有多个Types。,一个CVT,由组成,Object
一个CVT就是有唯一MID的Object，也可以有多个Types。,多个Types,由组成,Types
为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。,Freebase,被定义为,Object
为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。,Freebase,由组成,Topic
为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。,Freebase,由组成,Topic
Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。,Wikidata,被定义为,Wikipedia
Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。,Wikidata,被定义为,Wikipedia
Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。,Wikidata,被定义为,Wikipedia
Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。,Wikidata,被定义为,Wikipedia
Entities类似于OWL:Things，代指最顶层的对象。,Entities,被定义为,最顶层的对象
Entities类似于OWL:Things，代指最顶层的对象。,Entities,由组成,OWL:Things
每一个Entity都有一个独立的维基页面。,Entity,被定义为,每一个Entity都有一个独立的维基页面。
每一个Entity都有一个独立的维基页面。,每一个Entity,由组成,独立的维基页面
每一个Entity都有一个独立的维基页面。,每一个Entity,由组成,独立的维基页面
Entities主要有两类：Items和Properties。,Entities,被定义为,Items和Properties
Entities主要有两类：Items和Properties。,Entities,由组成,Items和Properties
Items类似于RDF中的Instance，代指实例对象。,Items,被定义为,实例对象
Items类似于RDF中的Instance，代指实例对象。,Items,由组成,实例对象
Items类似于RDF中的Instance，代指实例对象。,Items,由组成,实例对象
Properties和Statements分别等价于RDF中的Property和Statement。,Properties,被定义为,RDF中的Property
Properties和Statements分别等价于RDF中的Property和Statement。,Properties,由组成,RDF中的Property
Properties和Statements分别等价于RDF中的Property和Statement。,Properties,由组成,RDF中的Property
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,包含,别名-aliases
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,包含,外部链接-Sitelinks
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,由组成,别名-aliases
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,由组成,外部链接-Sitelinks
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,Item,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。,Statement,被定义为,一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。
一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。,Statement,由组成,Property、Value、Qualifier、Reference、Rank
修饰-Qualifiers用于处理复杂的多元表示。,修饰,由组成,Qualifiers
修饰-Qualifiers用于处理复杂的多元表示。,修饰,由组成,Qualifiers
如一个陈述“spouse:Jane_Belson”描述了一个二元关系。,spouse,被定义为,二元关系
如一个陈述“spouse:Jane_Belson”描述了一个二元关系。,spouse,由组成,Jane_Belson
如一个陈述“spouse:Jane_Belson”描述了一个二元关系。,spouse,属于,二元关系
可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。,多元关系,被定义为,可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。
可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。,Qualifiers,由组成,可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。
可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。,Qualifiers,由组成,可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。
引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。,引用,被定义为,References
引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。,引用,由组成,References
引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。,引用,属于,References
引用也是一种Qualifiers，通常添加到Statements的附加信息中。,引用,被定义为,添加到Statements的附加信息中
引用也是一种Qualifiers，通常添加到Statements的附加信息中。,引用,由组成,Statements
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata支持多种数值类型,被定义为,Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata支持多种数值类型,被定义为,Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata支持多种数值类型,被定义为,Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata支持多种数值类型,被定义为,Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型
Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。,Wikidata,被定义为,Statement
Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。,Wikidata,由组成,Statement
Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。,Wikidata,由组成,Statement
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertyValueSnack,被定义为,声明一个属性值
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertyValueSnack,由组成,PropertyValue
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertyValueSnack,由组成,PropertyValue
PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。,PropertyValueSnack,由组成,PropertyValue
PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。,PropertyValueSnack,由组成,PropertyValue
"PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。",PropertySomeValueSnack,被定义为,"类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。"
"PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。",PropertySomeValueSnack,被定义为,"类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。"
of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。,of_England_had_no_I_Wikidata,被定义为,Item
of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。,of_England_had_no_I_Wikidata,由组成,Item
of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。,of_England_had_no_I_Wikidata,由组成,Item
其中，<id>可以是一个Property，如P234。,P234,被定义为,Property
其中，<id>可以是一个Property，如P234。,P234,由组成,由组成
其中，<id>可以是一个Property，如P234。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,P234
2.4.3ConceptNet5ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-Phrases、断言-Assertions、关系-Relations、边-Edges。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,P234
Concepts由Words或Phrases组成，构成了图谱中的节点。,Concepts,被定义为,由Words或Phrases组成，构成了图谱中的节点。
Concepts由Words或Phrases组成，构成了图谱中的节点。,Concepts,由组成,Words或Phrases
Concepts由Words或Phrases组成，构成了图谱中的节点。,Concepts,由组成,Words或Phrases
与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。,Concepts,被定义为,自然语言文本
与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。,Concepts,由组成,自然语言文本
与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。,Concepts,由组成,自然语言文本
Assertions描述了Concepts之间的关系，类似于RDF中的Statements。,Assertions,被定义为,Concepts之间的关系
Assertions描述了Concepts之间的关系，类似于RDF中的Statements。,Assertions,由组成,Concepts
Assertions描述了Concepts之间的关系，类似于RDF中的Statements。,Assertions,由组成,Concepts
Edges类似于RDF中的Property。,Edges,被定义为,RDF中的Property
Edges类似于RDF中的Property。,Edges,由组成,RDF中的Property
一个Concepts包含多条边，而一条边可能有多个产生来源。,Concepts,被定义为,多条边，一条边可能有多个产生来源
一个Concepts包含多条边，而一条边可能有多个产生来源。,Concepts,由组成,多条边
一个Concepts包含多条边，而一条边可能有多个产生来源。,一条边,由组成,多个产生来源
一个Concepts包含多条边，而一条边可能有多个产生来源。,Concepts,由组成,多条边
一个Concepts包含多条边，而一条边可能有多个产生来源。,一条边,由组成,多个产生来源
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,Concepts,由组成,多条边
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,一条边,由组成,多个产生来源
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,Concepts,由组成,多条边
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,一条边,由组成,多个产生来源
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,化妆,由组成,漂亮
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,化妆,由组成,漂亮
来源越多，该断言就越可靠。,断言,被定义为,来源越多，该断言就越可靠。
来源越多，该断言就越可靠。,断言,由组成,来源越多
来源越多，该断言就越可靠。,断言,来源,来源越多
ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。,ConceptNet5,包含,断言
ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。,ConceptNet5,被定义为,断言
ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。,ConceptNet5,由组成,根据来源的多少和可靠程度计算每个断言的置信度。
ConceptNet5示例如图2-17所示。,ConceptNet5,被定义为,知识图谱
ConceptNet5示例如图2-17所示。,ConceptNet5,由组成,由ConceptNet4和ConceptNet6组成
ConceptNet5示例如图2-17所示。,ConceptNet5,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。",ConceptNet5,被定义为,关系
"ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。",ConceptNet5,由组成,关系
on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。,ConceptNet5,被定义为,ConceptNet5对URI进行了精心的设计。
on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。,ConceptNet5,由组成,URI
on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。,ConceptNet5,由组成,URI
URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,URI,被定义为,考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。
URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,URI,由组成,同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。
URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,URI,由组成,同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。
其中，n代指这是一个名词，basement用于区分歧义。,n,被定义为,名词
其中，n代指这是一个名词，basement用于区分歧义。,n,由组成,basement
在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。,ConceptNet5,被定义为,把关于某条边的附加信息增加为边的属性
在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。,ConceptNet5,由组成,把关于某条边的附加信息增加为边的属性
图2-18ConceptNet5的知识表示结构2.5知识图谱的向量表示方法与前面所述的表示方法不同的是，本节要描述的方法是把知识图谱中的实体和关系映射到低维连续的向量空间，而不是使用基于离散符号的表达方式。,ConceptNet5,被定义为,知识图谱
2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。,知识图谱表示方法,被定义为,三元组方法
2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。,知识图谱表示,由组成,三元组
在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。,知识图谱,被定义为,三元组
在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。,知识图谱,由组成,三元组
在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。,离散的符号化的表达方式,被定义为,将数据结构化
虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。,离散的符号化的表达方式,由组成,可以非常有效地将数据结构化
知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。,知识,被定义为,基于离散符号的方法进行表达
知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。,知识表示,由组成,基于离散符号的方法
数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。,知识图谱,被定义为,知识表示
从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。,知识图谱,由组成,表示方法
在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。,词向量,被定义为,将词映射到向量空间
在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。,词向量,由组成,词映射到向量空间
在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
知识图谱中的向量表示方法也在此次有所借鉴。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
知识图谱中的向量表示方法也在此次有所借鉴。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
知识图谱中的向量表示方法也在此次有所借鉴。,知识图谱中的向量表示方法,由组成,此次
1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。,独热编码,被定义为,传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。
1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。,独热编码,由组成,传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。
对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。,独热表示,被定义为,表示该词编号的维度为1，其余都为0
对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。,独热表示,由组成,向量
如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。,词,包含,独热编码
如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。,词Rome,由组成,独热编码
这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。,稀疏编码,被定义为,稀疏性非常强
这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。,稀疏性,由组成,向量
"2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。",词袋模型,由组成,"词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"
"2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。",词袋模型,由组成,"词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"
该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。,词袋模型,由组成,"词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"
该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。,词袋模型,由组成,"词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"
该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。,词袋,由组成,词
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,词向量,被定义为,具体的方法
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,文本向量,方法,具体的方法
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,词向量,由组成,词典
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,词向量,由组成,词典
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,被定义为,文本doc1
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,Rome
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,Paris
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,France
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,Rome
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,Paris
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,doc1,由组成,France
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Rome
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Paris
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,France
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Rome
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Paris
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,France
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Rome
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Paris
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,France
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Rome
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,Paris
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,doc1,由组成,France
产生词向量的手段主要有三种：●Count-based。,doc1,由组成,Rome
产生词向量的手段主要有三种：●Count-based。,doc1,由组成,Paris
产生词向量的手段主要有三种：●Count-based。,doc1,由组成,France
基于计数的方法，简单说就是记录文本中词的出现次数。,基于计数的方法,被定义为,简单说就是记录文本中词的出现次数。
基于计数的方法，简单说就是记录文本中词的出现次数。,基于计数的方法,方法,记录文本中词的出现次数
基于计数的方法，简单说就是记录文本中词的出现次数。,基于计数的方法,由组成,简单说就是记录文本中词的出现次数。
●Predictive。,Predictive,包含,Predictive
●Predictive。,Predictive,被定义为,预测性
●Predictive。,Predictive,由组成,Predictive.js
●Predictive。,Predictive,由组成,Predictive.js
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,被定义为,通过上下文预测中心词，也可以通过中心词预测上下文
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,方法,通过上下文预测中心词
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,由组成,上下文预测中心词
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,实现,基于上下文预测中心词
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,来源,基于上下文预测中心词
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,属于,基于上下文预测中心词
●Task-based。,Task-based,被定义为,基于任务的
●Task-based。,Task-based,由组成,知识图谱
●Task-based。,Task-based,由组成,知识图谱
基于任务的，也就是通过任务驱动的方法。,基于任务的,被定义为,通过任务驱动的方法
基于任务的，也就是通过任务驱动的方法。,基于任务的,由组成,知识图谱
CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。,CBoW,被定义为,连续词袋模型
CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。,CBoW,由组成,连续词袋模型
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,被定义为,词向量
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,被定义为,词向量
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,由组成,词向量
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,由组成,词向量
"如图2-21（a）所示，其中wn是中心词，wn?2,wn?1,wn+1,wn+2为该中心词的上下文的词。",wn,被定义为,中心词
"如图2-21（a）所示，其中wn是中心词，wn?2,wn?1,wn+1,wn+2为该中心词的上下文的词。",中心词,由组成,wn
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,上下文词的独热表示,包含,词向量矩阵E
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,上下文词的独热表示,被定义为,将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,上下文词的独热表示,方法,词向量矩阵E
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,上下文词的独热表示,由组成,词向量矩阵E
整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。,连续词袋模型,被定义为,整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。
整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。,连续词袋模型,由组成,窗口
Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。,Skip-gram,被定义为,用中心词来预测上下文词
Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。,Skip-gram,由组成,CBoW
如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。,图2-21（b）所示,包含,中心词的独热表示
如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。,中心词的独热表示,被定义为,通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。
如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。,中心词的独热表示,由组成,词向量矩阵
图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。,CBoW模型,被定义为,词向量在连续空间中的一些关系
图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。,CBoW模型,由组成,词向量
vec（Rome）?vec（Italy）≈vec（Paris）?vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。,vec,被定义为,vec（Rome）?vec（Italy）≈vec（Paris）?vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。
通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。,Roma,被定义为,is-capital-of
这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。,空间平移性,被定义为,词向量
这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。,空间平移性,由组成,词向量
这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。,空间平移性,由组成,词向量
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",空间平移性,由组成,词向量
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",空间平移性,由组成,词向量
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",空间平移性,由组成,词向量
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",空间平移性,由组成,词向量
2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。,空间平移性,由组成,词向量
对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。,连续向量,被定义为,连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。
对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。,连续向量,由组成,连续向量的表达
把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph（Representation_Learning）、知识表示学习。,知识图谱嵌入,由组成,知识图谱
在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。,词向量,由组成,学习一定的语义层信息
在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。,词向量,由组成,学习一定的语义层信息
图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。,知识图谱嵌入,被定义为,将实体和关系用向量表示
图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。,图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点,实现,知识图谱嵌入
使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。,知识图谱,包含,向量的表达方式
使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。,使用向量的表达方式,由组成,提高应用时的计算效率
用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。,知识图谱,被定义为,用向量表示
用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。,知识图谱,被定义为,用向量表示
用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。,用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。,由组成,用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。
因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。,图算法,被定义为,下游应用
因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。,图算法,由组成,下游应用
因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。,图算法,由组成,下游应用
将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。,知识图谱嵌入,被定义为,下游应用的预训练向量输入
将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。,将知识图谱嵌入作为下游应用的预训练向量输入,由组成,使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量
将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。,将知识图谱嵌入作为下游应用的预训练向量输入,由组成,使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量
如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。,知识图谱的嵌入方法,被定义为,提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持
如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。,知识图谱的嵌入方法,由组成,提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持
2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。,知识图谱嵌入,被定义为,根据知识图谱中所有已知的三元组训练模型
2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。,知识图谱嵌入,由组成,多数知识图谱嵌入模型
2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。,知识图谱嵌入,属于,知识图谱嵌入模型
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,基于矩阵的表示方法,被定义为,被用来训练的三元组
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,方法,方法,训练实体表示和矩阵表示
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,实体表示,由组成,矩阵表示
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。,知识图谱嵌入,被定义为,利用一些除知识图谱之外的额外信息训练知识图谱嵌入
所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。,知识图谱嵌入,由组成,知识图谱
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,实体类型,被定义为,Entity_Types
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,实体类型,由组成,Entity_Types
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,关系路径,由组成,Relation_Paths
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,实体类型,由组成,Entity_Types
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,关系路径,由组成,Relation_Paths
根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。,知识图谱嵌入,被定义为,将知识图谱中的实体和关系进行嵌入
根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。,知识图谱嵌入,方法,将知识图谱嵌入到图结构中
根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。,知识图谱嵌入,由组成,知识图谱嵌入方法
根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。,知识图谱嵌入,实现,根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。
1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。,转移距离模型,被定义为,衡量向量化后的知识图谱中三元组的合理性问题
1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。,转移距离模型,由组成,Translational_Distance_Model
1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。,转移距离模型,由组成,Translational_Distance_Model
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,基于关系抽取的语义相似度,被定义为,利用关系把头实体转移到尾实体的合理性
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,基于关系抽取的语义相似度,由组成,得分函数
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,这一方法,实现,得分函数
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,这一方法,来源,得分函数
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,这一方法,属于,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,实现,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,来源,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,属于,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,实现,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,来源,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,属于,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,实现,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,来源,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,属于,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,实现,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,来源,得分函数
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,这一方法,属于,得分函数
也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。,知识图谱中的头实体,被定义为,向量空间
"TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。",TransE,被定义为,平移不变性
也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。,关系,被定义为,关系head+relation≈tail
2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。,语义匹配模型,被定义为,更注重挖掘向量化后的实体和关系的潜在语义
2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。,语义匹配模型,由组成,转移距离模型
2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。,语义匹配模型,由组成,转移距离模型
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,包含,RESCAL
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,被定义为,RESCAL
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,由组成,RESCAL
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,实现,RESCAL
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,来源,RESCAL
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。,RESCAL模型,被定义为,三维张量
RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。,RESCAL模型,由组成,由一个核心张量和因子矩阵组成
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,核心张量,包含,三元组成立的概率
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,核心张量,由组成,概率
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,因子矩阵,由组成,概率
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,实现,对应三元组正确
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,实现,对应三元组不正确
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,来源,对应三元组正确
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,来源,对应三元组不正确
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,属于,对应三元组正确
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率,属于,对应三元组不正确
其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。,DistMul,包含,RESCAL模型
其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。,DistMul,由组成,通过限制Mr为对角矩阵简化RESCAL模型
但因为是对角矩阵，所以存在h?diag（r）t=t?diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。,对角矩阵,被定义为,对称矩阵
但因为是对角矩阵，所以存在h?diag（r）t=t?diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。,对角矩阵,由组成,对称性
ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。,ComplEx[15]模型,被定义为,实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。
ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。,ComplEx[15]模型,由组成,实体和关系的向量表示不再依赖实数而是放在了复数域
也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。,非对称关系,被定义为,三元组中的头实体和尾实体调换位置后可以得到不同的分数
也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。,非对称关系,由组成,三元组
也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。,非对称关系,由组成,三元组
3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。,考虑附加信息的模型,被定义为,仅仅依靠知识库中的三元组构造知识图谱嵌入的模型
3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。,考虑附加信息的模型,由组成,仅仅依靠知识库中的三元组构造知识图谱嵌入的模型
3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。,考虑附加信息的模型,由组成,仅仅依靠知识库中的三元组构造知识图谱嵌入的模型
实体类型是一种容易考虑的额外信息。,实体类型,被定义为,一种容易考虑的额外信息
实体类型是一种容易考虑的额外信息。,实体类型,由组成,容易考虑的额外信息
在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。,Rome,被定义为,city
在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。,Rome,由组成,city
在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。,Rome,由组成,city
当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。,训练知识图谱嵌入,被定义为,三元组
当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。,训练知识图谱嵌入,由组成,三元组
也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。,向量表示,被定义为,向量表示方法
也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。,考虑相同类型的实体需要在向量表示上更加接近,方法,一些
也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。,考虑相同类型的实体需要在向量表示上更加接近,由组成,一些方法
也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。,考虑相同类型的实体需要在向量表示上更加接近,由组成,一些方法
"关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is?capital?of,Italy）（Italy,is?country?of,Europe）.从Rome到Europe的关系路径就是一条is?capital?of→is?country?of关系链。",关系路径,被定义为,实体之间的多跳关系
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,关系路径,被定义为,用相同的向量表达方式来表达路径
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,关系路径,方法,提升嵌入模型
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,当前很多方法也尝试考虑关系路径来提升嵌入模型,由组成,这里的关键问题是考虑如何用相同的向量表达方式来表达路径。
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,当前很多方法也尝试考虑关系路径来提升嵌入模型,实现,如何用相同的向量表达方式来表达路径
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+?+rlp=r1?r2???rlci=f（W[ci?1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,PTransE,被定义为,基于路径的TransE
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+?+rlp=r1?r2???rlci=f（W[ci?1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,PTransE,方法,r1+r2+?+rl
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+?+rlp=r1?r2???rlci=f（W[ci?1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,在基于路径的TransE,由组成,考虑了相加、相乘和RNN三种用关系表达关系路径的方法
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+?+rlp=r1?r2???rlci=f（W[ci?1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,在基于路径的TransE,由组成,考虑了相加、相乘和RNN三种用关系表达关系路径的方法
对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。,关系路径,被定义为,两个实体间关系的向量表示
文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。,文本描述,被定义为,对实体有一些简要的文本描述
文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。,文本描述,由组成,对实体有一些简要的文本描述
除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。,知识图谱,被定义为,知识库
除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。,知识图谱,由组成,文本信息和语料库
Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。,Wang,被定义为,Wang[18]
Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。,Wang,由组成,Wang[18]
Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。,Wang,由组成,Wang[18]
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识图谱中的实体和关系做嵌入,被定义为,TransE
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识图谱,由组成,TransE
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,TransE
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,TransE
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,TransE
联合模型在训练时降低来自三个子模型的损失之和。,联合模型,被定义为,训练时降低来自三个子模型的损失之和
联合模型在训练时降低来自三个子模型的损失之和。,联合模型,由组成,降低来自三个子模型的损失之和
联合模型在训练时降低来自三个子模型的损失之和。,联合模型,实现,降低来自三个子模型的损失之和
联合模型在训练时降低来自三个子模型的损失之和。,联合模型,属于,降低来自三个子模型的损失之和
"图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则?x,y:IsDirectorOf（x,y）?BeDirectedBy（y,x）说明了两个不同的关系之间的关系。",联合模型,实现,降低来自三个子模型的损失之和
"图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则?x,y:IsDirectorOf（x,y）?BeDirectedBy（y,x）说明了两个不同的关系之间的关系。",联合模型,属于,降低来自三个子模型的损失之和
Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。,Guo,被定义为,提出了一种以规则为指导的知识图谱嵌入方法
Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。,Guo,由组成,提出了一种以规则为指导的知识图谱嵌入方法
Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。,Guo,由组成,提出了一种以规则为指导的知识图谱嵌入方法
简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。,规则学习和知识图谱嵌入学习,被定义为,互相迭代
简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。,规则学习和知识图谱嵌入学习,由组成,互相迭代
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入,被定义为,知识图谱嵌入的发展
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入,由组成,相关应用
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入,实现,知识图谱嵌入的发展
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入,属于,知识图谱嵌入的发展
本小节将简单介绍一些典型的应用。,SPO,被定义为,知识图谱中的三元组
本小节将简单介绍一些典型的应用。,本小节将简单介绍一些典型的应用。,由组成,应用
本小节将简单介绍一些典型的应用。,本小节将简单介绍一些典型的应用。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。,链接预测,被定义为,通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系
1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。,链接预测,由组成,链接预测（Link_Prediction）
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,被定义为,排序
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,由组成,排序
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,实现,排序
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,属于,排序
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",链接预测,被定义为,将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",链接预测,由组成,Roma
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
链接预测也常被用于评测知识图谱嵌入。,链接预测,被定义为,评测知识图谱嵌入
链接预测也常被用于评测知识图谱嵌入。,链接预测,由组成,知识图谱嵌入
链接预测也常被用于评测知识图谱嵌入。,链接预测,实现,评测知识图谱嵌入
链接预测也常被用于评测知识图谱嵌入。,链接预测,属于,评测知识图谱嵌入
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,链接预测,包含,平均等级
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,链接预测,被定义为,平均等级
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,链接预测,由组成,平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,三元组分类,被定义为,判断三元组的真假
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,三元组分类,由组成,Triple_Classification
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,三元组分类
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,三元组分类
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱嵌入,被定义为,三元组得分
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱嵌入,由组成,训练过的知识图谱向量
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱嵌入,实现,知识图谱向量
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱向量,来源,知识图谱嵌入
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱嵌入,属于,知识图谱向量
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,被定义为,实体解析
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,由组成,实体解析
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,实现,实体解析
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,来源,实体解析
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,属于,实体解析
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,实体对齐,实现,实体解析
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,实体对齐,来源,实体解析
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,实体对齐,属于,实体解析
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,删除冗余的实体,由组成,该任务
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,删除冗余的实体,由组成,该任务
"一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。",知识图谱嵌入,被定义为,一种方法
"一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。",知识图谱嵌入,方法,"对三元组(x,EqualTo,y)打分"
也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。,实体对齐,包含,实体对齐方法
也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。,实体对齐,被定义为,实体对齐方法
也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。,实体对齐,由组成,相似度函数
简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。,知识图谱,被定义为,向量表示
简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。,向量表示,由组成,问题的向量表示
"S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））?（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。",S,被定义为,被设计出来的得分函数
简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。,Wφ,被定义为,问题和答案的向量表示
简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。,Wφ,由组成,Wψ
"当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。",得分函数S,被定义为,"当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。"
"当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。",得分函数S,由组成,"q,a"
5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。,推荐系统,被定义为,推荐用户没有接触过的、但有可能会感兴趣或者购买的服务或产品
5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。,推荐系统,由组成,用户
5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。,推荐系统,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。,协同过滤算法,被定义为,对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。
协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。,协同过滤算法,由组成,对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。
协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。,协同过滤算法,由组成,对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。
在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。,知识图谱嵌入,被定义为,推荐系统
在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。,知识图谱嵌入,由组成,推荐系统
在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。,知识图谱嵌入,属于,推荐系统
例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。,Zhang[20],包含,协同过滤算法
例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。,Zhang[20],被定义为,协同过滤算法
例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。,Zhang,由组成,尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。
例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。,Zhang,由组成,尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。
2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。,知识图谱,被定义为,知识表示、知识存储、知识抽取、知识融合、知识推理、语义搜索、知识问答、知识图谱
2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。,知识图谱,由组成,表示与建模方法
目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。,开放知识图谱,被定义为,RDF、RDFS和OWL
目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。,开放知识图谱,被定义为,RDF、RDFS和OWL
目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。,开放知识图谱,由组成,RDF、RDFS和OWL
目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。,开放知识图谱,由组成,RDF、RDFS和OWL
除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。,知识图谱的查询语言,被定义为,SPARQL
除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。,本章,由组成,除了标准语言
（4）插件管理器在Engine内起到插件管理作用，既包括GraphDB内部实现的插件，也包括各种外部工具连接器。,插件管理器,被定义为,GraphDB内部实现的插件，各种外部工具连接器
（4）插件管理器在Engine内起到插件管理作用，既包括GraphDB内部实现的插件，也包括各种外部工具连接器。,插件管理器,由组成,GraphDB
7.商业RDF三元组数据库BlazegraphBlazegraph在1.5版本之前叫作Bigdata，但众所周知的“大数据”的兴起使得这个不温不火的RDF三元组库软件被淹没其中。,Blazegraph,被定义为,商业RDF三元组数据库
7.商业RDF三元组数据库BlazegraphBlazegraph在1.5版本之前叫作Bigdata，但众所周知的“大数据”的兴起使得这个不温不火的RDF三元组库软件被淹没其中。,Blazegraph,由组成,Bigdata
但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。,Blazegraph,包含,大数据
但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。,Blazegraph,被定义为,大数据
但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。,Bigdata,由组成,Blazegraph
但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。,Bigdata,由组成,Blazegraph
原来仅仅是支持RDF三元组存储和SPARQL，现在已经定位为全面支持Blueprints标准的图数据库。,RDF三元组存储,被定义为,支持
原来仅仅是支持RDF三元组存储和SPARQL，现在已经定位为全面支持Blueprints标准的图数据库。,RDF,由组成,Blueprints
不过，其内部实现技术仍是面向RDF三元组和SPARQL的，因而可以理解为是“基于RDF三元组库的图数据库”。,RDF三元组库,被定义为,图数据库
不过，其内部实现技术仍是面向RDF三元组和SPARQL的，因而可以理解为是“基于RDF三元组库的图数据库”。,RDF三元组库,由组成,图数据库
从2006年发布至今，Blazegraph一直由SYSTAP公司开发，虽然它既不是最知名的RDF三元组库，也不是最流行的图数据库，但开发进展稳扎稳打，积累了相对全面的功能。,Blazegraph,被定义为,RDF三元组库
从2006年发布至今，Blazegraph一直由SYSTAP公司开发，虽然它既不是最知名的RDF三元组库，也不是最流行的图数据库，但开发进展稳扎稳打，积累了相对全面的功能。,Blazegraph,由组成,SYSTAP公司
Blazegraph可以通过其官方网站下载。,Blazegraph,被定义为,开源的图数据库
Blazegraph可以通过其官方网站下载。,Blazegraph,由组成,Blazegraph
Blazegraph可以通过其官方网站下载。,Blazegraph,由组成,Blazegraph
既可以将Blazegraph作为War包部署为Web程序，也可以将其配置为单机或分布式数据库服务器。,Blazegraph,被定义为,War包
既可以将Blazegraph作为War包部署为Web程序，也可以将其配置为单机或分布式数据库服务器。,Blazegraph,由组成,War包
既可以将Blazegraph作为War包部署为Web程序，也可以将其配置为单机或分布式数据库服务器。,Blazegraph,由组成,War包
图3-27Blazegraph的Web用户界面8.商业RDF三元组数据库StardogStardog是由美国Stardog_Union公司开发的RDF三元组数据库，其首个公开发布版本是2012年2月发布的Stardog_0.9。,Stardog,被定义为,RDF三元组数据库
图3-27Blazegraph的Web用户界面8.商业RDF三元组数据库StardogStardog是由美国Stardog_Union公司开发的RDF三元组数据库，其首个公开发布版本是2012年2月发布的Stardog_0.9。,Stardog,由组成,商业RDF三元组数据库
图3-27Blazegraph的Web用户界面8.商业RDF三元组数据库StardogStardog是由美国Stardog_Union公司开发的RDF三元组数据库，其首个公开发布版本是2012年2月发布的Stardog_0.9。,Stardog,由组成,商业RDF三元组数据库
Stardog分为企业版和社区版，社区版可以免费用于非商业用途。,Stardog,包含,企业版
Stardog分为企业版和社区版，社区版可以免费用于非商业用途。,Stardog,由组成,企业版
3.2.3原生图数据库1.最流行的图数据库Neo4jNeo4j的1.0版本发布于2010年。,Neo4j,被定义为,最流行的图数据库
Neo4j基于属性图模型，其存储管理层为属性图结构中的节点、节点属性、边、边属性等设计了专门的存储方案。,Neo4j,被定义为,属性图模型
Neo4j基于属性图模型，其存储管理层为属性图结构中的节点、节点属性、边、边属性等设计了专门的存储方案。,Neo4j,由组成,属性图模型
这使得Neo4j在存储层对于图数据的存取效率天生就优于关系数据库。,Neo4j,被定义为,图数据库
这使得Neo4j在存储层对于图数据的存取效率天生就优于关系数据库。,Neo4j,由组成,关系数据库
同时，Neo4j还具备OLTP数据库必需的ACID事务处理功能。,Neo4j,被定义为,OLTP数据库
同时，Neo4j还具备OLTP数据库必需的ACID事务处理功能。,Neo4j,由组成,OLTP数据库
如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。,图数据,被定义为,图数据规模
如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。,图数据,被定义为,图数据规模
如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。,图数据,由组成,系统性能
如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。,图数据,由组成,系统性能
Neo4j浏览器是功能完善的Neo4j可视化交互式客户端工具，可以用于执行Cypher语言。,Neo4j浏览器,被定义为,功能完善的Neo4j可视化交互式客户端工具，可以用于执行Cypher语言。
Neo4j浏览器是功能完善的Neo4j可视化交互式客户端工具，可以用于执行Cypher语言。,Neo4j浏览器,由组成,功能完善的Neo4j可视化交互式客户端工具
使用Neo4j内置的Movie图数据库执行Cypher查询，返回“TomHanks”所出演的全部电影，如图3-31所示。,TomHanks,由组成,出演的全部电影
使用Neo4j内置的Movie图数据库执行Cypher查询，返回“TomHanks”所出演的全部电影，如图3-31所示。,TomHanks,由组成,出演的全部电影
此外，成功启动Neo4j服务器之后，会在7474和7473端口分别开启HTTP和HTTPS服务。,Neo4j,包含,HTTP和HTTPS服务
此外，成功启动Neo4j服务器之后，会在7474和7473端口分别开启HTTP和HTTPS服务。,Neo4j,由组成,HTTP和HTTPS服务
此外，成功启动Neo4j服务器之后，会在7474和7473端口分别开启HTTP和HTTPS服务。,Neo4j,由组成,HTTP和HTTPS服务
例如，使用浏览器访问http://localhost:7474/进入Web界面，执行Cypher查询，其功能与Neo4j浏览器是一致的。,Cypher查询,被定义为,Neo4j浏览器
例如，使用浏览器访问http://localhost:7474/进入Web界面，执行Cypher查询，其功能与Neo4j浏览器是一致的。,Cypher,由组成,Neo4j浏览器
图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。,JanusGraph,被定义为,借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。
图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。,Neo4j,由组成,图数据库
图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。,图数据库,实现,JanusGraph
图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。,图数据库,来源,JanusGraph
图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。,图数据库,属于,JanusGraph
JanusGraph的前身Titan是由Aurelius公司开发的，而该公司的创始人Rodriguez博士恰恰就是Blueprints标准及Gremlin语言的主要开发者，Titan对于Blueprints标准和Gremlin语言的全面支持便不难理解，JanusGraph基本上继承了Titan的这一特性。,JanusGraph,被定义为,Titan
JanusGraph的前身Titan是由Aurelius公司开发的，而该公司的创始人Rodriguez博士恰恰就是Blueprints标准及Gremlin语言的主要开发者，Titan对于Blueprints标准和Gremlin语言的全面支持便不难理解，JanusGraph基本上继承了Titan的这一特性。,JanusGraph,由组成,Titan
JanusGraph的前身Titan是由Aurelius公司开发的，而该公司的创始人Rodriguez博士恰恰就是Blueprints标准及Gremlin语言的主要开发者，Titan对于Blueprints标准和Gremlin语言的全面支持便不难理解，JanusGraph基本上继承了Titan的这一特性。,JanusGraph,由组成,Titan
同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。,JanusGraph,被定义为,OLTP图数据库
同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。,JanusGraph,被定义为,OLTP图数据库
同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。,JanusGraph,由组成,OLTP图数据库
同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。,JanusGraph,由组成,OLTP图数据库
另一方面，JanusGraph还具备基于Hadoop_MapReduce的图分析引擎，其可以将Gremlin导航查询自动转化为MapReduce任务。,JanusGraph,包含,基于Hadoop_MapReduce的图分析引擎
另一方面，JanusGraph还具备基于Hadoop_MapReduce的图分析引擎，其可以将Gremlin导航查询自动转化为MapReduce任务。,JanusGraph,由组成,基于Hadoop_MapReduce的图分析引擎
从这个角度看，JanusGraph也可作为图计算引擎使用。,JanusGraph,被定义为,图计算引擎
从这个角度看，JanusGraph也可作为图计算引擎使用。,JanusGraph,被定义为,图计算引擎
从这个角度看，JanusGraph也可作为图计算引擎使用。,JanusGraph,由组成,图计算引擎
从这个角度看，JanusGraph也可作为图计算引擎使用。,JanusGraph,由组成,图计算引擎
3.图数据库OrientDBOrientDB对于数据模式的支持也相对灵活，可以管理无模式数据（Schema-less），也可以像关系数据库那样定义完整的模式（Schema-full），还可以适应介于两者之间的混合模式（Schema-mixed）数据。,OrientDB,被定义为,无模式数据
在查询语言方面，OrientDB支持扩展的SQL和Gremlin用于图上的导航式查询；值得注意的是，在2.2版本引入的MATCH语句实现了声明式的模式匹配，这类似于Cypher语言查询模式。,OrientDB,被定义为,Gremlin
在查询语言方面，OrientDB支持扩展的SQL和Gremlin用于图上的导航式查询；值得注意的是，在2.2版本引入的MATCH语句实现了声明式的模式匹配，这类似于Cypher语言查询模式。,OrientDB,由组成,Gremlin
在查询语言方面，OrientDB支持扩展的SQL和Gremlin用于图上的导航式查询；值得注意的是，在2.2版本引入的MATCH语句实现了声明式的模式匹配，这类似于Cypher语言查询模式。,OrientDB,由组成,Gremlin
需要指出的是，Cayley虽然可以存储N-Quads格式的RDF文件，但目前尚不支持SPARQL查询。,Cayley,被定义为,N-Quads格式的RDF文件
需要指出的是，Cayley虽然可以存储N-Quads格式的RDF文件，但目前尚不支持SPARQL查询。,Cayley,由组成,N-Quads格式的RDF文件
总体来讲，基于关系的存储系统继承了关系数据库的优势，成熟度较高，在硬件性能和存储容量满足的前提下，通常能够适应千万到十亿级三元组规模的管理。,基于关系的存储系统,被定义为,关系数据库
总体来讲，基于关系的存储系统继承了关系数据库的优势，成熟度较高，在硬件性能和存储容量满足的前提下，通常能够适应千万到十亿级三元组规模的管理。,基于关系的存储系统,由组成,关系数据库
对于一般在百万到上亿级三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。,RDF三元组数据库,被定义为,百万到上亿级
对于一般在百万到上亿级三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。,对于一般在百万到上亿级三元组的管理,由组成,使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。
对于一般在百万到上亿级三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。,对于一般在百万到上亿级三元组的管理,由组成,使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。
如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。,大规模RDF三元组,被定义为,分布式存储与查询能力的数据库系统
如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。,RDF三元组,由组成,分布式存储与查询能力的数据库系统
如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。,RDF三元组,由组成,分布式存储与查询能力的数据库系统
近年来，以Neo4j为代表的图数据库系统发展迅猛，使用图数据库管理RDF三元组也是一种很好的选择；但目前大部分图数据库还不能直接支持RDF三元组存储，对于这种情况，可采用数据转换方式，先将RDF预处理为图数据库支持的数据格式（如属性图模型），再进行后续管理操作。,RDF三元组,由组成,分布式存储与查询能力的数据库系统
本节首先以图数据库Neo4j为例介绍其内部存储方案，然后简要描述知识图谱数据库的两类索引技术。,Neo4j,被定义为,图数据库
本节首先以图数据库Neo4j为例介绍其内部存储方案，然后简要描述知识图谱数据库的两类索引技术。,Neo4j,由组成,图数据库
3.3.1知识图谱数据库的存储：以Neo4j为例这一节将深入Neo4j图数据库底层，探究其原生的图存储方案。,Neo4j,被定义为,图数据库
3.3.1知识图谱数据库的存储：以Neo4j为例这一节将深入Neo4j图数据库底层，探究其原生的图存储方案。,Neo4j,由组成,图数据库
3.3.1知识图谱数据库的存储：以Neo4j为例这一节将深入Neo4j图数据库底层，探究其原生的图存储方案。,Neo4j,由组成,图数据库
对于遵循属性图的图数据库，存储管理层的任务是将属性图编码表示为在磁盘上存储的数据格式。,遵循属性图的图数据库,被定义为,存储管理层的任务是将属性图编码表示为在磁盘上存储的数据格式。
对于遵循属性图的图数据库，存储管理层的任务是将属性图编码表示为在磁盘上存储的数据格式。,遵循属性图的图数据库,由组成,存储管理层的任务
虽然不同图数据库的具体存储方案各有差异，但一般认为具有“无索引邻接”特性（Index-FreeAdjacency）的图数据库才称为原生图数据库[35]。,原生图数据库,被定义为,具有“无索引邻接”特性（Index-FreeAdjacency）的图数据库
虽然不同图数据库的具体存储方案各有差异，但一般认为具有“无索引邻接”特性（Index-FreeAdjacency）的图数据库才称为原生图数据库[35]。,原生图数据库,由组成,无索引邻接
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,包含,图数据库
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,被定义为,每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,由组成,图数据库
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,实现,图数据库
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,来源,图数据库
在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。,无索引邻接,属于,图数据库
这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。,图导航操作,包含,图大小
这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。,图导航操作,被定义为,图遍历
这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。,图导航,由组成,图遍历
这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。,图导航操作,实现,图导航操作代价
这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。,图导航操作,属于,图导航操作代价
作为对比，来看看在非原生图数据库中使用全局索引关联邻接节点的情形。,非原生图数据库,被定义为,全局索引关联邻接节点
作为对比，来看看在非原生图数据库中使用全局索引关联邻接节点的情形。,非原生图数据库,由组成,全局索引关联邻接节点
作为对比，来看看在非原生图数据库中使用全局索引关联邻接节点的情形。,非原生图数据库,由组成,全局索引关联邻接节点
如果觉得这样的查找代价还是可以接受的话，那么换一个问题，“谁认识张三”的查找代价是多少？显然，对于这个查询，需要通过全局索引检查每个节点，看其认识的人中有没有张三，总代价为O(nlogn)，这样的复杂度对于大图数据的遍历操作是不可接受的。,全局索引,被定义为,通过全局索引查找一个节点的所有认识的人
有人说，可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。,被定义为,包含,图遍历操作代价与图规模无关
有人说，可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。,被认识关系,由组成,全局索引
有人说，可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。,有人说,实现,可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。
只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。,无索引邻接,包含,图数据的边表示的关系
只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。,无索引邻接,由组成,只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。
只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。,图数据库,属于,无索引邻接
图3-36邻接关系的全局索引示例图3-37将关系作为“一等公民”在Neo4j数据库中，属性图的不同部分是被分开存储在不同文件中的。,关系,被定义为,图3-36邻接关系的全局索引示例图3-37将关系作为“一等公民”在Neo4j数据库中，属性图的不同部分是被分开存储在不同文件中的。
图3-36邻接关系的全局索引示例图3-37将关系作为“一等公民”在Neo4j数据库中，属性图的不同部分是被分开存储在不同文件中的。,关系,由组成,属性图
正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。,Neo4j,被定义为,图遍历操作
正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。,Neo4j,被定义为,图遍历操作
正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。,Neo4j,由组成,图遍历操作
正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。,Neo4j,由组成,图遍历操作
首先，来看在Neo4j中是如何存储图节点和边的。,图节点,被定义为,图节点存储在Neo4j中，由节点属性、关系和关系属性组成。
首先，来看在Neo4j中是如何存储图节点和边的。,Neo4j,由组成,图数据库
首先，来看在Neo4j中是如何存储图节点和边的。,Neo4j,由组成,图数据库
节点记录存储在文件neostore.nodestore.db中。,节点记录,被定义为,文件neostore.nodestore.db
节点记录存储在文件neostore.nodestore.db中。,节点记录,由组成,文件neostore.nodestore.db
节点记录的第0字节inUse是记录使用标志字节的，告诉数据库该记录是否在使用中，还是已经删除并可回收用来装载新的记录；第1～4字节nextRelId是与节点相连的第1条边的id；第5～8字节nextPropId是节点的第1个属性的id。,节点记录,被定义为,记录使用标志字节、记录是否在使用中、还是已经删除并可回收用来装载新的记录、与节点相连的第1条边的id、节点的第1个属性的id
节点记录的第0字节inUse是记录使用标志字节的，告诉数据库该记录是否在使用中，还是已经删除并可回收用来装载新的记录；第1～4字节nextRelId是与节点相连的第1条边的id；第5～8字节nextPropId是节点的第1个属性的id。,节点记录,由组成,"第0字节inUse, 第1～4字节nextRelId, 第5～8字节nextPropId"
节点记录的第0字节inUse是记录使用标志字节的，告诉数据库该记录是否在使用中，还是已经删除并可回收用来装载新的记录；第1～4字节nextRelId是与节点相连的第1条边的id；第5～8字节nextPropId是节点的第1个属性的id。,节点记录,由组成,"第0字节inUse, 第1～4字节nextRelId, 第5～8字节nextPropId"
边记录存储在文件neostore.relationshipstore.db中。,边,被定义为,存储在文件neostore.relationshipstore.db中。
边记录存储在文件neostore.relationshipstore.db中。,边记录,由组成,文件neostore.relationshipstore.db
边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。,边记录,包含,节点记录
边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。,边记录,由组成,第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。
边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。,边记录,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。,边记录,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。,边记录,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
和第5～8字节firstNode图3-38Neo4j中节点和边记录的物理存储结构Neo4j实现节点和边快速定位的关键是“定长记录”的存储方案，将具有定长记录的图结构与具有变长记录的属性数据分开存储。,Neo4j,包含,节点和边
和第5～8字节firstNode图3-38Neo4j中节点和边记录的物理存储结构Neo4j实现节点和边快速定位的关键是“定长记录”的存储方案，将具有定长记录的图结构与具有变长记录的属性数据分开存储。,Neo4j,由组成,定长记录
例如，一个节点记录长度是9字节，如果要查找id为99的节点记录所在位置（id从0开始），则可直接到节点存储文件第891个字节处访问（存储文件从第0个字节开始）。,节点记录,被定义为,节点存储文件第891个字节
边记录也是“定长记录”，长度为33字节。,边记录,被定义为,定长记录
边记录也是“定长记录”，长度为33字节。,边记录,由组成,定长记录
这样，数据库已知记录id可以O(1)的代价直接计算其存储地址，而避免了全局索引中O(nlogn)的查找代价。,数据库,包含,全局索引
这样，数据库已知记录id可以O(1)的代价直接计算其存储地址，而避免了全局索引中O(nlogn)的查找代价。,数据库,由组成,全局索引
图3-39展示了Neo4j中各种存储文件之间是如何交互的。,存储文件,被定义为,存储文件之间的交互
图3-39展示了Neo4j中各种存储文件之间是如何交互的。,图3-39,由组成,存储文件
图3-39展示了Neo4j中各种存储文件之间是如何交互的。,图3-39,由组成,存储文件
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,节点文件,被定义为,存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,存储在节点文件中的节点1,由组成,存储在属性文件中各自的第1个属性记录
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,存储在节点文件中的节点1,属于,存储在属性文件中各自的第1个属性记录
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,存储在节点文件中的节点1,属于,存储在边文件中各自的第1条边
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,存储在节点文件中的节点4,属于,存储在属性文件中各自的第1个属性记录
存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。,存储在节点文件中的节点4,属于,存储在边文件中各自的第1条边
需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。,边记录,被定义为,双向链表
需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。,边记录,由组成,双向链表
需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。,边记录,实现,双向链表
需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。,边记录,属于,双向链表
这些操作除了记录字段的读取，就是定长记录地址的计算，均是O(1)时间的高效率操作。,定长记录地址的计算,包含,O(1)时间的高效率操作
这些操作除了记录字段的读取，就是定长记录地址的计算，均是O(1)时间的高效率操作。,定长记录地址的计算,由组成,O(1)时间的高效率操作
可见，正是由于将边作为“一等公民”，将图结构实现为定长记录的存储方案，赋予了Neo4j作为原生图数据库的“无索引邻接”特性。,Neo4j,包含,无索引邻接
可见，正是由于将边作为“一等公民”，将图结构实现为定长记录的存储方案，赋予了Neo4j作为原生图数据库的“无索引邻接”特性。,Neo4j,由组成,无索引邻接
3.3.2知识图谱数据库的索引图数据上的索引一种是对节点或边上属性数据的索引，一种是对图结构的索引；前者可应用关系数据库中已有的B+树索引技术直接实现，而后者仍是业界没有达成共识的、开放的研究问题。,知识图谱数据库的索引图数据上的索引,被定义为,关系数据库中已有的B+树索引技术
3.3.2知识图谱数据库的索引图数据上的索引一种是对节点或边上属性数据的索引，一种是对图结构的索引；前者可应用关系数据库中已有的B+树索引技术直接实现，而后者仍是业界没有达成共识的、开放的研究问题。,知识图谱数据库的索引图数据上的索引,由组成,一种是对节点或边上属性数据的索引，一种是对图结构的索引
1.属性数据索引Neo4j数据库在前述存储方案的基础上还支持用户对属性数据建立索引，目的是加速针对某属性的查询处理性能。,属性数据索引Neo4j数据库,包含,属性数据
1.属性数据索引Neo4j数据库在前述存储方案的基础上还支持用户对属性数据建立索引，目的是加速针对某属性的查询处理性能。,属性数据索引,由组成,Neo4j数据库
1.属性数据索引Neo4j数据库在前述存储方案的基础上还支持用户对属性数据建立索引，目的是加速针对某属性的查询处理性能。,属性数据索引,由组成,Neo4j数据库
Neo4j索引的定义通过Cypher语句完成，目前支持对于同一个类型节点的某个属性构建索引。,Neo4j索引,被定义为,Cypher语句
Neo4j索引的定义通过Cypher语句完成，目前支持对于同一个类型节点的某个属性构建索引。,Neo4j索引,由组成,Cypher语句
例如，对所有程序员节点的姓名属性构建索引。,对所有程序员节点的姓名属性构建索引,被定义为,索引
例如，对所有程序员节点的姓名属性构建索引。,对所有程序员节点的姓名属性构建索引,由组成,索引
例如，对所有程序员节点的姓名属性构建索引。,对所有程序员节点的姓名属性构建索引,属于,实现
在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。,查询优化器,包含,索引
在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。,在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。,由组成,在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。
例如，下面的查询查找姓名为张三的程序员，显然会用到刚刚建立的索引。,程序员,包含,索引
例如，下面的查询查找姓名为张三的程序员，显然会用到刚刚建立的索引。,张三,由组成,程序员
例如，下面的查询查找姓名为张三的程序员，显然会用到刚刚建立的索引。,张三,由组成,程序员
应用该索引无疑会根据姓名属性的值快速定位到姓名是“张三”的节点，而无须扫描程序员节点的全部属性。,应用该索引,包含,根据姓名属性的值快速定位到姓名是“张三”的节点
应用该索引无疑会根据姓名属性的值快速定位到姓名是“张三”的节点，而无须扫描程序员节点的全部属性。,应用该索引,由组成,根据姓名属性的值快速定位到姓名是“张三”的节点
删除索引的语句为：不难发现，为图节点或边的属性建立索引与为关系表的某一列建立索引在本质上并无不同之处，完全可以通过B+树或散列表实现。,索引,被定义为,为图节点或边的属性建立索引
删除索引的语句为：不难发现，为图节点或边的属性建立索引与为关系表的某一列建立索引在本质上并无不同之处，完全可以通过B+树或散列表实现。,删除索引的语句,由组成,为图节点或边的属性建立索引
这种索引并不涉及图数据上的任何图结构信息。,倒排索引,被定义为,图数据上的任何图结构信息
这种索引并不涉及图数据上的任何图结构信息。,倒排索引,由组成,图数据
2.图结构索引图结构索引是为图数据中的点边结构信息建立索引的方法。,图结构索引,被定义为,为图数据中的点边结构信息建立索引的方法
2.图结构索引图结构索引是为图数据中的点边结构信息建立索引的方法。,图结构索引,由组成,图数据中的点边结构信息
2.图结构索引图结构索引是为图数据中的点边结构信息建立索引的方法。,图结构索引,属于,图数据中的点边结构信息
利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。,图结构索引,被定义为,利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。
利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。,图结构索引,由组成,图查询
利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。,利用图结构索引可以对图查询中的结构信息进行快速匹配,实现,图结构索引
利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。,利用图结构索引可以对图查询中的结构信息进行快速匹配,来源,图结构索引
利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。,利用图结构索引可以对图查询中的结构信息进行快速匹配,属于,图结构索引
大体上，图结构索引分为“基于路径的”和“基于子图的”两种。,图结构索引,被定义为,基于路径的图结构索引
大体上，图结构索引分为“基于路径的”和“基于子图的”两种。,图结构索引,由组成,基于路径的
大体上，图结构索引分为“基于路径的”和“基于子图的”两种。,图结构索引,由组成,基于子图的
大体上，图结构索引分为“基于路径的”和“基于子图的”两种。,图结构索引,属于,基于路径的
（1）基于路径的图索引。,基于路径的图索引,被定义为,图索引
（1）基于路径的图索引。,基于路径的图索引,由组成,图索引
（1）基于路径的图索引。,基于路径的图索引,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（1）基于路径的图索引。,基于路径的图索引,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
一种典型的基于路径的图索引叫作GraphGrep[36]。,GraphGrep,包含,基于路径的图索引
一种典型的基于路径的图索引叫作GraphGrep[36]。,GraphGrep,被定义为,一种典型的基于路径的图索引
一种典型的基于路径的图索引叫作GraphGrep[36]。,GraphGrep,由组成,GraphGrep
一种典型的基于路径的图索引叫作GraphGrep[36]。,GraphGrep,实现,基于路径的图索引
一种典型的基于路径的图索引叫作GraphGrep[36]。,GraphGrep,来源,基于路径的图索引
一种典型的基于路径的图索引叫作GraphGrep[36]。,基于路径的图索引,属于,GraphGrep
这种索引将图中长度小于或等于一个固定长度的全部路径构建为索引结构。,短路径索引,被定义为,将图中长度小于或等于一个固定长度的全部路径构建为索引结构
这种索引将图中长度小于或等于一个固定长度的全部路径构建为索引结构。,索引,由组成,图中长度小于或等于一个固定长度的全部路径
索引的关键字可以是组成路径的节点或边上属性值或标签的序列。,索引,被定义为,组成路径的节点或边上属性值或标签的序列
索引的关键字可以是组成路径的节点或边上属性值或标签的序列。,索引,由组成,组成路径的节点或边上属性值或标签的序列
图3-40是在图3-3的属性图上构建的GraphGrep索引。,GraphGrep,包含,图3-40
图3-40是在图3-3的属性图上构建的GraphGrep索引。,GraphGrep,被定义为,图3-40
图3-40是在图3-3的属性图上构建的GraphGrep索引。,GraphGrep,由组成,图3-40是在图3-3的属性图上构建的GraphGrep索引。
图3-40是在图3-3的属性图上构建的GraphGrep索引。,GraphGrep,属于,图3-40是在图3-3的属性图上构建的GraphGrep索引。
这里构建的是长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。,路径索引,被定义为,长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。
这里构建的是长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。,路径索引,由组成,长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。
这里构建的是长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。,路径索引,由组成,长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。
"例如，索引将关键字“认识.参加”映射到节点id序列(1,4,3)和(1,4,5)。",索引,被定义为,将关键字映射到节点id序列
"例如，索引将关键字“认识.参加”映射到节点id序列(1,4,3)和(1,4,5)。",索引,由组成,关键字
"例如，索引将关键字“认识.参加”映射到节点id序列(1,4,3)和(1,4,5)。",索引,由组成,关键字
利用该路径索引，类似前面出现过的“查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目”的查询处理效率会大幅提高，因为由节点1出发，根据关键字“认识.参加”，可以快速找到满足条件的节点3和节点5。,路径索引,包含,节点1
利用该路径索引，类似前面出现过的“查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目”的查询处理效率会大幅提高，因为由节点1出发，根据关键字“认识.参加”，可以快速找到满足条件的节点3和节点5。,利用该路径索引,由组成,类似前面出现过的“查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目”的查询处理效率会大幅提高，因为由节点1出发，根据关键字“认识.参加”，可以快速找到满足条件的节点3和节点5。
（2）基于子图的索引。,基于子图的索引,被定义为,基于子图的索引是利用子图来存储知识图谱中实体和关系的一种索引方式
（2）基于子图的索引。,基于子图的索引,由组成,子图索引
基于子图的索引可以看作是基于路径索引的一般化形式，是将图数据中的某些子图结构信息作为关键字，将该子图的实例数据作为值而构建的索引结构。,基于子图的索引,包含,基于路径索引
基于子图的索引可以看作是基于路径索引的一般化形式，是将图数据中的某些子图结构信息作为关键字，将该子图的实例数据作为值而构建的索引结构。,基于子图的索引,由组成,基于路径索引
图3-41是在图3-3的属性图上构建的一种子图索引。,图3-41,包含,子图索引
图3-41是在图3-3的属性图上构建的一种子图索引。,图3-41,被定义为,子图索引
图3-41是在图3-3的属性图上构建的一种子图索引。,图3-41,由组成,子图索引
图3-41是在图3-3的属性图上构建的一种子图索引。,图3-41,实现,子图索引
图3-41是在图3-3的属性图上构建的一种子图索引。,图3-41,属于,子图索引
"满足第1个关键字子图的节点序列为(1,2,4)，满足第2个关键字子图的节点序列为(1,4,3)。",关键字子图,被定义为,"满足第1个关键字子图的节点序列为(1,2,4)，满足第2个关键字子图的节点序列为(1,4,3)。"
"满足第1个关键字子图的节点序列为(1,2,4)，满足第2个关键字子图的节点序列为(1,4,3)。","满足第1个关键字子图的节点序列为(1,2,4)",由组成,关键字子图
如果查询中包含某些作为关键字的子图结构，则可以利用该子图索引，快速找到与这些子图结构匹配的节点序列，这样可大幅度减小查询操作的搜索空间。,子图索引,被定义为,利用该子图索引，快速找到与这些子图结构匹配的节点序列
如果查询中包含某些作为关键字的子图结构，则可以利用该子图索引，快速找到与这些子图结构匹配的节点序列，这样可大幅度减小查询操作的搜索空间。,子图索引,由组成,快速找到与这些子图结构匹配的节点序列
图3-40基于路径的图索引示例图3-41基于子图的图索引示例不过，一个图数据的子图有指数个，将哪些子图作为关键字建立索引尚未得到很好的解决。,基于路径的图索引,被定义为,图索引
图3-40基于路径的图索引示例图3-41基于子图的图索引示例不过，一个图数据的子图有指数个，将哪些子图作为关键字建立索引尚未得到很好的解决。,图索引,由组成,图数据
一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。,gIndex,被定义为,一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。
一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。,gIndex,方法,利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。
一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。,gIndex,由组成,频繁子图
一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。,gIndex,由组成,频繁子图
但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。,gIndex,包含,建立索引的过程
但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。,gIndex,被定义为,建立索引的过程
但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。,gIndex,由组成,建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。
但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。,gIndex,由组成,建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。
一种更合理的方法是从用户的查询日志中挖掘频繁使用的子图模式，并以此作为关键字建立索引。,频繁使用的子图模式,被定义为,关键字
一种更合理的方法是从用户的查询日志中挖掘频繁使用的子图模式，并以此作为关键字建立索引。,一种更合理的方法,由组成,从用户的查询日志中挖掘频繁使用的子图模式，并以此作为关键字建立索引。
3.4开源工具实践3.4.1三元组数据库Apache_Jena1.开源工具简介Apache_Jena是Apache顶级项目，其前身为惠普实验室开发的Jena工具包。,Apache_Jena,被定义为,Apache顶级项目
3.4开源工具实践3.4.1三元组数据库Apache_Jena1.开源工具简介Apache_Jena是Apache顶级项目，其前身为惠普实验室开发的Jena工具包。,Apache_Jena,由组成,Apache顶级项目
3.4开源工具实践3.4.1三元组数据库Apache_Jena1.开源工具简介Apache_Jena是Apache顶级项目，其前身为惠普实验室开发的Jena工具包。,Apache_Jena,由组成,Apache顶级项目
Jena是语义Web领域主要的开源框架和RDF三元组库，较好地遵循W3C标准，其功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理等。,Jena,被定义为,语义Web领域主要的开源框架和RDF三元组库
Jena是语义Web领域主要的开源框架和RDF三元组库，较好地遵循W3C标准，其功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理等。,Jena,被定义为,语义Web领域主要的开源框架和RDF三元组库
Jena是语义Web领域主要的开源框架和RDF三元组库，较好地遵循W3C标准，其功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理等。,Jena,由组成,语义Web领域主要的开源框架和RDF三元组库
Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。,Jena,包含,一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理
Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。,Jena,包含,一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理
Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。,Jena,由组成,一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。
Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。,Jena,由组成,一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。
本实践相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,被定义为,OpenKG是一个开源的、基于知识图谱的、面向知识融合的、支持多种知识表示的、支持多种知识存储的、支持多种知识抽取的、支持多种知识推理的、支持多种知识融合的、支持多种知识问答的、支持多种知识图谱的、支持多种语义搜索的、支持多种知识图谱项目的开源项目。
本实践相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,由组成,OpenKG提供
本实践相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,属于,实践
2.开源工具的技术架构ApacheJena框架如图3-42所示。,ApacheJena框架,包含,开源工具
2.开源工具的技术架构ApacheJena框架如图3-42所示。,ApacheJena框架,被定义为,ApacheJena框架由ApacheJena和ApacheJenaTDB组成
2.开源工具的技术架构ApacheJena框架如图3-42所示。,ApacheJena框架,由组成,ApacheJena框架
2.开源工具的技术架构ApacheJena框架如图3-42所示。,ApacheJena框架,属于,开源工具的技术架构
推理API为上层提供本体推理服务，可以使用Jena内置基于规则的推理机进行RDFS和OWL本体上的推理任务，或者选择通过接口调用第三方外部推理机。,推理API,被定义为,推理服务
推理API为上层提供本体推理服务，可以使用Jena内置基于规则的推理机进行RDFS和OWL本体上的推理任务，或者选择通过接口调用第三方外部推理机。,推理API,由组成,推理服务
Jena对外界应用程序的API包括实现基本三元组管理功能的RDFAPI、实现RDFS和OWL本体推理功能的本体API和实现查询处理功能的SPARQL_API。,Jena,被定义为,对外界应用程序的API
Jena对外界应用程序的API包括实现基本三元组管理功能的RDFAPI、实现RDFS和OWL本体推理功能的本体API和实现查询处理功能的SPARQL_API。,Jena,由组成,实现基本三元组管理功能的RDFAPI、实现RDFS和OWL本体推理功能的本体API和实现查询处理功能的SPARQL_API。
Java应用程序代码可以通过导入类库的形式直接调用这些API。,Java应用程序代码,被定义为,导入类库的形式直接调用这些API
Java应用程序代码可以通过导入类库的形式直接调用这些API。,Java应用程序代码,由组成,导入类库的形式
Jena还提供了支持各种RDF三元组格式的解析器和编写器，支持的三元组格式包括：RDF/XML、Turtle、N-Triple和RDFa。,Jena,由组成,RDF/XML、Turtle、N-Triple和RDFa
Jena还提供了支持各种RDF三元组格式的解析器和编写器，支持的三元组格式包括：RDF/XML、Turtle、N-Triple和RDFa。,Jena,由组成,RDF/XML、Turtle、N-Triple和RDFa
图3-42Apache_Jena框架实质上，Jena是一个Java框架类库。,Apache_Jena框架,被定义为,Apache_Jena框架实质上，Jena是一个Java框架类库。
图3-42Apache_Jena框架实质上，Jena是一个Java框架类库。,Apache_Jena框架,由组成,Apache_Jena框架实质上，Jena是一个Java框架类库。
图3-42Apache_Jena框架实质上，Jena是一个Java框架类库。,Apache_Jena框架,由组成,Apache_Jena框架实质上，Jena是一个Java框架类库。
在一般情况下，上述功能需要在Java程序中进行调用。,SPO,被定义为,Java程序
在一般情况下，上述功能需要在Java程序中进行调用。,在一般情况下，上述功能需要在Java程序中进行调用。,由组成,Java程序
在一般情况下，上述功能需要在Java程序中进行调用。,在一般情况下，上述功能需要在Java程序中进行调用。,由组成,Java程序
Jena为了用户使用方便，提供了一个名为Fuseki的独立RDF数据库Web应用程序。,Jena,被定义为,Fuseki
Jena为了用户使用方便，提供了一个名为Fuseki的独立RDF数据库Web应用程序。,Jena,由组成,Fuseki
Jena为了用户使用方便，提供了一个名为Fuseki的独立RDF数据库Web应用程序。,Jena,由组成,Fuseki
本实践将使用Fuseki作为认识知识图谱数据库的入门工具。,Fuseki,被定义为,知识图谱数据库
本实践将使用Fuseki作为认识知识图谱数据库的入门工具。,Fuseki,由组成,知识图谱数据库
本实践将使用Fuseki作为认识知识图谱数据库的入门工具。,Fuseki,由组成,知识图谱数据库
Fuseki是基于Jena的SPARQL服务器，可以作为独立的服务由命令行启动，也可以作为操作系统服务或JavaWeb应用程序。,Fuseki,被定义为,基于Jena的SPARQL服务器
Fuseki是基于Jena的SPARQL服务器，可以作为独立的服务由命令行启动，也可以作为操作系统服务或JavaWeb应用程序。,Fuseki,由组成,基于Jena的SPARQL服务器
Fuseki是基于Jena的SPARQL服务器，可以作为独立的服务由命令行启动，也可以作为操作系统服务或JavaWeb应用程序。,Fuseki,由组成,基于Jena的SPARQL服务器
Fuseki底层存储基于TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。,Fuseki,被定义为,TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。
Fuseki底层存储基于TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。,Fuseki,由组成,TDB
Fuseki底层存储基于TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。,Fuseki,由组成,TDB
Fuseki支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。,Fuseki,被定义为,SPARQL图存储HTTP协议
Fuseki支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。,Fuseki,由组成,支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。
Fuseki支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。,Fuseki,由组成,支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。
访问OpenKG可以获取使用实例和整体配置细节。,OpenKG,被定义为,知识图谱构建平台
访问OpenKG可以获取使用实例和整体配置细节。,访问OpenKG,由组成,获取使用实例和整体配置细节
访问OpenKG可以获取使用实例和整体配置细节。,访问OpenKG,由组成,获取使用实例和整体配置细节
3.其他类似工具RDF4J是Eclipse基金会旗下的开源孵化项目，其前身是荷兰软件公司Aduna开发的Sesame框架，其功能包括：RDF数据的解析、存储、推理和查询等。,RDF4J,被定义为,Eclipse基金会旗下的开源孵化项目
3.其他类似工具RDF4J是Eclipse基金会旗下的开源孵化项目，其前身是荷兰软件公司Aduna开发的Sesame框架，其功能包括：RDF数据的解析、存储、推理和查询等。,3.其他类似工具,由组成,RDF4J
RDF4J提供内存和磁盘两种RDF存储机制，支持SPARQL1.1查询和更新语言。,RDF4J,由组成,内存和磁盘两种RDF存储机制，支持SPARQL1.1查询和更新语言
gStore是由北京大学开发的基于图的RDF三元组数据库。,gStore,被定义为,基于图的RDF三元组数据库
gStore是由北京大学开发的基于图的RDF三元组数据库。,gStore,由组成,基于图的RDF三元组数据库
gStore是由北京大学开发的基于图的RDF三元组数据库。,gStore,由组成,基于图的RDF三元组数据库
AllegroGraph是Franz公司开发的RDF三元组数据库。,AllegroGraph,被定义为,RDF三元组数据库
AllegroGraph是Franz公司开发的RDF三元组数据库。,AllegroGraph,由组成,Franz公司
AllegroGraph是Franz公司开发的RDF三元组数据库。,AllegroGraph,由组成,Franz公司
AllegroGraph对语义推理功能具有较为完善的支持。,AllegroGraph,由组成,Franz公司
AllegroGraph对语义推理功能具有较为完善的支持。,AllegroGraph,由组成,语义推理功能
AllegroGraph对语义推理功能具有较为完善的支持。,AllegroGraph,由组成,语义推理功能
除了三元组数据库的基本功能，AllegroGraph_RDFS++推理机、OWL2RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析还支持动态物化的库、可视化RDF图浏览器等。,AllegroGraph_RDFS++推理机,被定义为,RDFS++推理机
除了三元组数据库的基本功能，AllegroGraph_RDFS++推理机、OWL2RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析还支持动态物化的库、可视化RDF图浏览器等。,AllegroGraph_RDFS++推理机,由组成,动态物化的库
GraphDB是由Ontotext软件公司开发的RDF三元组数据库。,GraphDB,被定义为,RDF三元组数据库
GraphDB是由Ontotext软件公司开发的RDF三元组数据库。,GraphDB,由组成,Ontotext软件公司
GraphDB是由Ontotext软件公司开发的RDF三元组数据库。,GraphDB,由组成,Ontotext软件公司
GraphDB实现了RDF4J框架的SAIL层，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。,GraphDB,被定义为,RDF4J框架的SAIL层
GraphDB实现了RDF4J框架的SAIL层，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。,GraphDB,由组成,RDF4J框架的SAIL层
GraphDB实现了RDF4J框架的SAIL层，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。,GraphDB,由组成,RDF4J框架的SAIL层
GraphDB的特色是对于RDF推理功能的良好支持。,GraphDB,被定义为,RDF推理功能的良好支持
GraphDB的特色是对于RDF推理功能的良好支持。,GraphDB,由组成,RDF推理功能
GraphDB的特色是对于RDF推理功能的良好支持。,GraphDB,由组成,RDF推理功能
3.4.2面向RDF的三元组数据库gStore1.开源工具简介gStore是由北京大学计算机科学技术研究所数据管理实验室自2011年开始研发的面向RDF知识图谱的开源图数据库系统，遵循Apache开源协议。,gStore,被定义为,开源工具
3.4.2面向RDF的三元组数据库gStore1.开源工具简介gStore是由北京大学计算机科学技术研究所数据管理实验室自2011年开始研发的面向RDF知识图谱的开源图数据库系统，遵循Apache开源协议。,gStore,由组成,开源工具
不同于传统基于关系数据库的RDF数据管理方法，gStore原生基于图数据模型，在存储RDF数据时维持并根据其图结构构建了基于二进制位图索引的新型索引结构――VS树。,gStore,被定义为,基于图数据模型
不同于传统基于关系数据库的RDF数据管理方法，gStore原生基于图数据模型，在存储RDF数据时维持并根据其图结构构建了基于二进制位图索引的新型索引结构――VS树。,gStore,由组成,基于图数据模型
本实践相关工具、实验数据及操作说明由OpenKG提供，下载链接为http://openkg.cn/tool/gstore。,OpenKG,被定义为,OpenKG是一个开源的、基于知识图谱的语义搜索引擎
本实践相关工具、实验数据及操作说明由OpenKG提供，下载链接为http://openkg.cn/tool/gstore。,本实践相关工具、实验数据及操作说明,由组成,OpenKG
2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。,gStore,被定义为,开源工具
2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。,gStore,由组成,RDF数据管理
2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。,gStore,实现,开源工具
2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。,开源工具,来源,gStore
2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。,开源工具,属于,gStore
图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。,gStore,被定义为,图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。
图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。,gStore,由组成,图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。
图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。,gStore,由组成,图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。
同时，gStore将RDF数据上的所有点和边通过二进制编码的方式编码成若干位图索引，并将这些位图索引组织成VS树。,gStore,被定义为,将RDF数据上的所有点和边通过二进制编码的方式编码成若干位图索引，并将这些位图索引组织成VS树。
同时，gStore将RDF数据上的所有点和边通过二进制编码的方式编码成若干位图索引，并将这些位图索引组织成VS树。,gStore,由组成,VS树
在在线查询处理阶段，gStore也将SPARQL查询解析成查询图。,gStore,被定义为,SPARQL查询解析成查询图
在在线查询处理阶段，gStore也将SPARQL查询解析成查询图。,gStore,由组成,SPARQL查询图
然后，gStore按照对RDF数据图的编码方式，将SPARQL查询图进行编码以形成一个标签图，并在VS树和RDF数据图的邻接表上进行检索以得到每个查询变量的候选匹配。,gStore,被定义为,将SPARQL查询图进行编码以形成一个标签图，并在VS树和RDF数据图的邻接表上进行检索以得到每个查询变量的候选匹配。
然后，gStore按照对RDF数据图的编码方式，将SPARQL查询图进行编码以形成一个标签图，并在VS树和RDF数据图的邻接表上进行检索以得到每个查询变量的候选匹配。,gStore,由组成,编码方式
最后，gStore将所有查询变量的候选匹配连接成最终匹配。,gStore,被定义为,将查询变量的候选匹配连接成最终匹配
最后，gStore将所有查询变量的候选匹配连接成最终匹配。,gStore,由组成,所有查询变量的候选匹配连接成最终匹配
最后，gStore将所有查询变量的候选匹配连接成最终匹配。,gStore,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
目前，gStore只能在Linux系统上通过Shell命令编译、安装与运行。,gStore,被定义为,Linux系统
目前，gStore只能在Linux系统上通过Shell命令编译、安装与运行。,gStore,由组成,Linux系统
目前，gStore只能在Linux系统上通过Shell命令编译、安装与运行。,gStore,由组成,Linux系统
同时，gStore官网还提供了gStore_Workbench，方便用户操作RDF数据库。,gStore,被定义为,RDF数据库
同时，gStore官网还提供了gStore_Workbench，方便用户操作RDF数据库。,gStore,由组成,gStore_Workbench
同时，gStore官网还提供了gStore_Workbench，方便用户操作RDF数据库。,gStore,由组成,gStore_Workbench
具体包括：（1）环境配置。,具体包括,被定义为,环境配置
具体包括：（1）环境配置。,具体包括,由组成,环境配置
可以从OpenKG网站或gStore官网上下载gStore源代码，然后通过make来编译得到gStore运行程序。,gStore,被定义为,知识图谱存储系统
可以从OpenKG网站或gStore官网上下载gStore源代码，然后通过make来编译得到gStore运行程序。,gStore,由组成,OpenKG
可以从OpenKG网站或gStore官网上下载gStore源代码，然后通过make来编译得到gStore运行程序。,gStore,由组成,OpenKG
同时，通过OpenKG网站或gStore官网可以下载gStore_Workbench，进行编译安装后可以得到gStore_Workbench。,gStore,被定义为,知识图谱存储系统
同时，通过OpenKG网站或gStore官网可以下载gStore_Workbench，进行编译安装后可以得到gStore_Workbench。,gStore,由组成,gStore_Workbench
同时，通过OpenKG网站或gStore官网可以下载gStore_Workbench，进行编译安装后可以得到gStore_Workbench。,gStore,由组成,gStore_Workbench
（2）数据导入。,数据导入,被定义为,将数据导入到知识图谱中
（2）数据导入。,数据导入,由组成,数据导入工具
gStore目前支持NT格式的RDF数据，利用gStore安装路径下bin目录中gbuild或者gStore_Workbench中的数据库管理页面导入数据。,gStore,被定义为,NT格式的RDF数据
gStore目前支持NT格式的RDF数据，利用gStore安装路径下bin目录中gbuild或者gStore_Workbench中的数据库管理页面导入数据。,gStore,由组成,NT格式的RDF数据
gStore目前支持NT格式的RDF数据，利用gStore安装路径下bin目录中gbuild或者gStore_Workbench中的数据库管理页面导入数据。,gStore,由组成,NT格式的RDF数据
gStore_Workbench中的数据库管理页面还记录目前gStore包括的数据库统计信息。,gStore_Workbench,被定义为,数据库管理页面
gStore_Workbench中的数据库管理页面还记录目前gStore包括的数据库统计信息。,gStore_Workbench,由组成,数据库管理页面
gStore_Workbench中的数据库管理页面还记录目前gStore包括的数据库统计信息。,gStore_Workbench,由组成,数据库管理页面
（3）查询处理。,查询处理,被定义为,查询处理过程
（3）查询处理。,查询处理,由组成,查询处理引擎
（3）查询处理。,查询处理,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
gStore目前完全支持SPARQL1.0查询语法，利用gStore安装路径下bin目录中gquery或者gStoreWorkbench中的图数据库查询页面，就可以输入查询然后得到结果。,gStore,被定义为,SPARQL1.0查询语法
gStore目前完全支持SPARQL1.0查询语法，利用gStore安装路径下bin目录中gquery或者gStoreWorkbench中的图数据库查询页面，就可以输入查询然后得到结果。,gStore,由组成,SPARQL1.0查询语法
gStore目前完全支持SPARQL1.0查询语法，利用gStore安装路径下bin目录中gquery或者gStoreWorkbench中的图数据库查询页面，就可以输入查询然后得到结果。,gStore,由组成,SPARQL1.0查询语法
gStore同时还提供HTTP接口，可以利用gStore安装路径下bin目录中ghttp启动HTTP服务，进而接收其他机器远程通过HTTP发来的SPARQL查询请求。,gStore,被定义为,HTTP服务
gStore同时还提供HTTP接口，可以利用gStore安装路径下bin目录中ghttp启动HTTP服务，进而接收其他机器远程通过HTTP发来的SPARQL查询请求。,gStore,由组成,HTTP接口
gStore同时还提供HTTP接口，可以利用gStore安装路径下bin目录中ghttp启动HTTP服务，进而接收其他机器远程通过HTTP发来的SPARQL查询请求。,gStore,由组成,HTTP接口
访问OpenKG网站可以获取使用实例和整体配置细节。,OpenKG,被定义为,OpenKG是一个开源的、基于RDF的、可扩展的、可扩展的知识图谱平台
访问OpenKG网站可以获取使用实例和整体配置细节。,OpenKG,由组成,访问OpenKG网站可以获取使用实例和整体配置细节。
访问OpenKG网站可以获取使用实例和整体配置细节。,OpenKG,由组成,访问OpenKG网站可以获取使用实例和整体配置细节。
3.其他类似工具Jena的前身是惠普实验室（HP_Labs）2000年开发的工具包。,Jena,被定义为,惠普实验室（HP_Labs）2000年开发的工具包
3.其他类似工具Jena的前身是惠普实验室（HP_Labs）2000年开发的工具包。,Jena,由组成,HP_Labs
3.其他类似工具Jena的前身是惠普实验室（HP_Labs）2000年开发的工具包。,Jena,由组成,HP_Labs
Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。,Jena,被定义为,语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。
Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。,Jena,被定义为,语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。
Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。,Jena,由组成,RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理
Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。,Jena,由组成,RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理
针对RDF数据，Jena维护了一张大的三元组表和三种属性表，包括单值属性表、多值属性表和属性类表。,RDF数据,被定义为,Jena维护的三元组表
针对RDF数据，Jena维护了一张大的三元组表和三种属性表，包括单值属性表、多值属性表和属性类表。,Jena,由组成,RDF数据
针对RDF数据，Jena维护了一张大的三元组表和三种属性表，包括单值属性表、多值属性表和属性类表。,Jena,由组成,RDF数据
Virtuoso是OpenLink公司开发的知识图谱管理系统，有免费的社区版和收费的商业版。,Virtuoso,被定义为,OpenLink公司开发的知识图谱管理系统，有免费的社区版和收费的商业版。
Virtuoso是OpenLink公司开发的知识图谱管理系统，有免费的社区版和收费的商业版。,Virtuoso,由组成,OpenLink公司开发的知识图谱管理系统
Virtuoso是可以支持包括RDF在内的多种数据模型的混合数据库管理系统。,Virtuoso,被定义为,混合数据库管理系统
Virtuoso是可以支持包括RDF在内的多种数据模型的混合数据库管理系统。,Virtuoso,由组成,混合数据库管理系统
其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。,关系数据库管理系统,被定义为,事务管理、并发控制和完整性机制
其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。,关系型数据库管理系统,由组成,关系数据库
其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。,关系型数据库管理系统,由组成,关系数据库
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,被定义为,只利用少量的标注数据进行模型学习
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,由组成,少量的标注数据
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,由组成,少量的标注数据
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,被定义为,远程监督方法和Bootstrapping方法
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,方法,Bootstrapping方法
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,由组成,远程监督方法和Bootstrapping方法
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,实现,Bootstrapping方法
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,来源,Bootstrapping方法
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,属于,Bootstrapping方法
（1）远程监督方法。,远程监督方法,被定义为,通过监督学习，利用大量标注好的数据，训练出模型，然后利用模型对未知数据进行标注
（1）远程监督方法。,远程监督方法,由组成,知识图谱
（1）远程监督方法。,远程监督方法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督方法,被定义为,通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督方法,由组成,非结构化文本
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,被定义为,如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,由组成,基本假设
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,由组成,基本假设
例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。,远程监督方法,由组成,基本假设
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,由组成,一般步骤
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,由组成,一般步骤
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,被定义为,利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,由组成,丰富的知识图谱信息
但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。,基于远程监督的假设,由组成,大量噪声
为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。,远程监督实体关系抽取方法,被定义为,如何克服训练数据中的噪声问题
为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。,为了改进远程监督实体关系抽取方法,由组成,一些研究
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,被定义为,解决样例错误标注的问题
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,被定义为,解决样例错误标注的问题
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,由组成,样例错误标注
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,由组成,样例错误标注
下面介绍两个具有代表性的模型。,多示例学习,由组成,样例错误标注
下面介绍两个具有代表性的模型。,模型,由组成,知识图谱
下面介绍两个具有代表性的模型。,模型,由组成,知识图谱
Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。,Guoliang_Ji,被定义为,APCNNs
Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。,Guoliang_Ji,由组成,APCNNs
Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。,Guoliang_Ji,由组成,APCNNs
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,被定义为,Piecewise_Convolutional_Neural_Networks
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,由组成,卷积和池化操作
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,实现,卷积神经网络
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,来源,卷积神经网络
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,属于,卷积神经网络
关系的分类是基于包特征上的Softmax分类器实现的。,关系,被定义为,基于包特征上的Softmax分类器
关系的分类是基于包特征上的Softmax分类器实现的。,关系,由组成,基于包特征上的Softmax分类器
关系的分类是基于包特征上的Softmax分类器实现的。,关系,由组成,基于包特征上的Softmax分类器
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,APCNNs模型,被定义为,多示例学习策略
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,APCNNs模型,由组成,多示例学习的策略
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,APCNNs模型,由组成,多示例学习的策略
实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。,远程监督关系抽取,被定义为,实验结果
实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。,实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。,由组成,该模型
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,被定义为,在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,由组成,多示例学习策略
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,由组成,多示例学习策略
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,被定义为,基于强化学习的关系分类模型
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,由组成,基于强化学习的关系分类模型
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型框架,被定义为,如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型框架,由组成,样例选择器和关系分类器
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型框架,实现,样例选择器和关系分类器
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型框架,属于,样例选择器和关系分类器
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,被定义为,从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,由组成,关系分类器
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,由组成,关系分类器
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,被定义为,基于一个随机策略
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,由组成,强化学习
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,关系分类器,由组成,卷积神经网络
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,强化学习
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,强化学习
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,强化学习
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,关系分类模型,被定义为,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,由组成,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
图4-15CNN-RL模型[15]（2）Bootstrapping方法。,CNN-RL,被定义为,CNN和RL的结合
图4-15CNN-RL模型[15]（2）Bootstrapping方法。,CNN-RL,由组成,Bootstrapping方法
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping方法,包含,关系抽取的模板
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping方法,被定义为,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping方法,由组成,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping方法,被定义为,从文本中抽取关系的大量实例
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping方法,方法,从文本中抽取关系的大量实例
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping方法,由组成,文本
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping方法,实现,通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping方法,属于,通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。
有很多实体关系抽取系统都采用了Bootstrapping方法。,实体关系抽取系统,被定义为,Bootstrapping方法
有很多实体关系抽取系统都采用了Bootstrapping方法。,实体关系抽取系统,由组成,Bootstrapping方法
Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。,DIPER,被定义为,Bootstrapping方法
Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。,DIPER,由组成,Bootstrapping方法
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,被定义为,Snowball关系抽取系统
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,由组成,Snowball关系抽取系统
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,由组成,Snowball关系抽取系统
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,被定义为,关系抽取
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,由组成,关系抽取
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,属于,关系抽取
Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。,Etzioni等人,被定义为,构建KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。
Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。,KnowItAll,由组成,Etzioni等人
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,基于Bootstrapping的系统,被定义为,关系抽取
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,关系抽取,由组成,Bootstrapping
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,被定义为,初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,由组成,初始本体
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,由组成,初始本体
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法,被定义为,关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法,由组成,关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法,属于,关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping方法,被定义为,初始种子较为敏感、存在语义漂移问题、结果准确率较低
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping方法,由组成,不足之处
4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。,事件,被定义为,事件是指发生的事情，通常具有时间、地点、参与者等属性。
4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。,事件,由组成,事件抽取
事件的发生可能是因为一个动作的产生或者系统状态的改变。,事件的发生,被定义为,一个动作的产生或者系统状态的改变
事件的发生可能是因为一个动作的产生或者系统状态的改变。,事件的发生,由组成,一个动作的产生或者系统状态的改变
事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。,事件抽取,被定义为,从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。
事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。,事件抽取,由组成,事件信息
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,被定义为,识别事件触发词及事件类型；抽取事件元素的同时判断其角色；抽出描述事件的词组或句子；事件属性标注；事件共指消解。
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,由组成,事件触发词及事件类型；抽取事件元素的同时判断其角色；抽出描述事件的词组或句子；事件属性标注；事件共指消解
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取,被定义为,事件抽取方法
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取,由组成,流水线方法
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取,实现,流水线方法
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取,来源,流水线方法
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取,属于,流水线方法
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,被定义为,将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取,方法,流水线方法
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,由组成,事件识别、元素抽取、属性分类和可报告性判别
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,事件触发词分类器,被定义为,一个基本的事件抽取流水线需要的分类器
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,一个基本的事件抽取流水线,由组成,分类器
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,被定义为,基于触发词信息对事件类别进行分类
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,由组成,基于触发词信息对事件类别进行分类
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,实现,基于触发词信息对事件类别进行分类
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,属于,基于触发词信息对事件类别进行分类
（2）元素分类器。,元素分类器,被定义为,将元素分为不同类别的过程
（2）元素分类器。,元素分类器,由组成,元素分类器
（2）元素分类器。,元素分类器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判断词组是否为事件的元素。,判断词组是否为事件的元素,被定义为,判断词组是否为事件的元素
判断词组是否为事件的元素。,判断词组是否为事件的元素,由组成,判断词组是否为事件的元素
判断词组是否为事件的元素。,判断词组是否为事件的元素,由组成,判断词组是否为事件的元素
（3）元素角色分类器。,元素角色分类器,被定义为,将元素分为实体、属性、关系三类
（3）元素角色分类器。,元素角色分类器,由组成,元素角色分类器
（3）元素角色分类器。,元素角色分类器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判定事件元素的角色类别。,判定事件元素的角色类别,被定义为,判定事件元素的角色类别
判定事件元素的角色类别。,判定事件元素的角色类别,由组成,判定事件元素的角色类别
判定事件元素的角色类别。,判定事件元素的角色类别,属于,判定事件元素的角色类别
（4）属性分类器。,属性分类器,被定义为,将属性分为实体属性、关系属性和类型属性
（4）属性分类器。,属性分类器,由组成,属性识别
（4）属性分类器。,属性分类器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判定事件的属性。,判定事件的属性,被定义为,判定事件
判定事件的属性。,判定事件的属性,由组成,判定事件的属性
判定事件的属性。,判定事件的属性,属于,实现
（5）可报告性分类器。,可报告性分类器,被定义为,将可报告性分为可报告性、不可报告性和模糊性
（5）可报告性分类器。,可报告性分类器,由组成,可报告性分类器
（5）可报告性分类器。,可报告性分类器,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（5）可报告性分类器。,可报告性分类器,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（5）可报告性分类器。,可报告性分类器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判定是否存在值得报告的事件实例。,事件,被定义为,值得报告的事件实例
判定是否存在值得报告的事件实例。,值得报告的事件实例,由组成,判定
判定是否存在值得报告的事件实例。,值得报告的事件实例,由组成,判定
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类,被定义为,词性、词形、词义、词性组合、词形组合、词义组合、词性+词形+词义组合
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类,由组成,词性、词形、词义、词性组合、词形组合、词义组合
各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。,各个阶段的分类器,被定义为,最大熵模型、支持向量机等
各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。,各个阶段的分类器,由组成,最大熵模型、支持向量机等
表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。,事件抽取,被定义为,事件抽取流水线方法
表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。,事件抽取,由组成,流水线方法
为了解决这一问题，一些研究工作提出了事件的联合抽取方法。,事件的联合抽取方法,被定义为,为了解决这一问题
为了解决这一问题，一些研究工作提出了事件的联合抽取方法。,事件的联合抽取方法,由组成,一些研究工作
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,被定义为,事件的所有相关信息会通过一个模型同时抽取出来。
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,由组成,事件的所有相关信息
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,实现,事件的所有相关信息
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,属于,事件的所有相关信息
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取方法,被定义为,联合推断或联合建模的方法
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取方法,由组成,联合推断或联合建模的方法
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取方法,属于,联合推断
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,被定义为,首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,由组成,首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,实现,事件抽取
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,来源,事件抽取
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,属于,事件抽取
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模的方法,被定义为,充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模的方法,由组成,充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合事件抽取模型,被定义为,Qi_Li等人
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合事件抽取模型,由组成,Qi_Li等人
该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。,事件触发词,被定义为,事件触发词和元素抽取的局部特征
该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。,事件触发词,由组成,事件触发词
该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。,事件触发词,由组成,事件触发词
在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。,袭击,被定义为,fired
在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。,袭击,由组成,触发词
此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。,流水线方法,被定义为,局部的分类器
此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。,流水线方法,由组成,局部的分类器
为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。,联合抽取模型,被定义为,使用大量局部特征的基础上，增加了若干全局特征
为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。,联合抽取模型,由组成,大量局部特征
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,被定义为,从整体的结构中学习得到，从而使用全局的信息来提升局部的预测
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,由组成,全局的信息
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,联合抽取模型,被定义为,将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,联合抽取模型,由组成,集束搜索方法
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,联合抽取模型,由组成,集束搜索方法
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,基于动态多池化卷积神经网络的事件抽取模型,被定义为,图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,由组成,基于动态多池化卷积神经网络的事件抽取模型
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,基于动态多池化卷积神经网络的事件抽取模型,实现,图4-20
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,基于动态多池化卷积神经网络的事件抽取模型,属于,事件抽取
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,知识图谱,被定义为,知识图谱模型
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,该模型,由组成,YuboChen等人于2015年发表在ACL会议上[21]。
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,该模型,由组成,YuboChen等人于2015年发表在ACL会议上[21]。
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,该模型,由组成,YuboChen等人于2015年发表在ACL会议上[21]。
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,该模型,由组成,YuboChen等人于2015年发表在ACL会议上[21]。
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,由组成,词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,由组成,词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,模型总体,由组成,词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词向量学习,由组成,无监督方式学习词的向量表示
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词汇级特征抽取,由组成,基于词的向量表示获取事件抽取相关的词汇线索
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,句子级特征抽取,由组成,通过动态多池化卷积神经网络获取句子的语义组合特征
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,分类器输出,由组成,产生事件元素的角色类别
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词向量学习,由组成,无监督方式学习词的向量表示
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词汇级特征抽取,由组成,基于词的向量表示获取事件抽取相关的词汇线索
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,句子级特征抽取,由组成,通过动态多池化卷积神经网络获取句子的语义组合特征
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,分类器输出,由组成,产生事件元素的角色类别
在CNN方法的结果。,CNN方法,被定义为,CNN方法的结果
在CNN方法的结果。,CNN方法,由组成,CNN方法的结果
在CNN方法的结果。,CNN方法,属于,知识图谱项目
ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。,CNN方法,属于,知识图谱项目
在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。,数据库数据,被定义为,RDF数据、OWL本体
在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。,将数据库数据转化为RDF数据、OWL本体等,由组成,在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,R2RML,被定义为,RDB2RDF工作组于2012年发布的两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,W3C的RDB2RDF工作组,由组成,DM（Direct_Mapping，直接映射）和R2RML。
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,W3C的RDB2RDF工作组,由组成,DM（Direct_Mapping，直接映射）和R2RML。
DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。,DM和R2ML映射语言,被定义为,用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。
DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。,DM和R2ML映射语言,由组成,定义关系数据库中的数据如何转换为RDF数据的各种规则
DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。,DM和R2ML映射语言,由组成,定义关系数据库中的数据如何转换为RDF数据的各种规则
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,被定义为,规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,由组成,关系数据库
它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。,SPARQL,由组成,RDF图或定义虚拟图
它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。,SPARQL,由组成,RDF图或定义虚拟图
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,被定义为,将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,由组成,关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射,被定义为,将数据库表映射为RDF类，将数据库表的列映射为RDF属性，将数据库表中每一行映射为一个资源或实体，创建IRI，将数据库表中每个单元格的值映射为一个文字值（Literal_Value），如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射,由组成,●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
下面给出一个简单的例子，解释直接映射的基本思路。,直接映射,被定义为,将一个概念映射到另一个概念
下面给出一个简单的例子，解释直接映射的基本思路。,直接映射,由组成,直接映射
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL语句,被定义为,通过SQL语句创建图4-21中的两个数据库表
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL语句,由组成,图4-21中的两个数据库表
首先，假设通过SQL语句创建图4-21中的两个数据库表。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
"创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,被定义为,由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,由组成,由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,每列的谓词,被定义为,由IRI前缀和表名、列名连接形成的IRI。
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,每列的谓词,由组成,由IRI前缀和表名、列名连接形成的IRI。
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,实现,每列的谓词是由IRI前缀和表名、列名连接形成的IRI。
这些值是从列值的词汇形式形成的RDF文字。,RDF文字,被定义为,列值的词汇形式形成的RDF文字
这些值是从列值的词汇形式形成的RDF文字。,RDF文字,由组成,列值的词汇形式
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,外键,被定义为,每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,外键,由组成,每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,外键,由组成,每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,被引用三元组,被定义为,行标识符
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,缺点,由组成,没有提供对实体属性的支持
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,缺点,由组成,没有提供对实体属性的支持
直接映射不会为NULL值生成三元组。,直接映射,被定义为,不会为NULL值生成三元组
直接映射不会为NULL值生成三元组。,直接映射,由组成,不会为NULL值生成三元组。
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML映射语言,被定义为,一种用于表示从关系数据库到RDF数据集的自定义映射的语言。
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML映射语言,由组成,R2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML映射语言,由组成,R2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,R2RML,被定义为,RDF数据模型
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,R2RML,由组成,RDF
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,R2RML,由组成,RDF
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,数据库直接映射,被定义为,RDF图
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,在数据库的直接映射中,由组成,生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,在数据库的直接映射中,由组成,生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,被定义为,关系数据上的视图定制
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,由组成,关系数据
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,实现,关系数据
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,属于,关系数据
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,包含,数据库模式和目标词汇量身定制
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,被定义为,R2RML映射
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,由组成,R2RML映射
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,实现,R2RML映射
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,R2RML映射,属于,每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,被定义为,关系数据库
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,由组成,关系数据库
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,由组成,关系数据库
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,R2RML映射,被定义为,逻辑表
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,R2RML映射,由组成,逻辑表（Logic_Tables）
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,R2RML映射,由组成,逻辑表（Logic_Tables）
一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。,逻辑表,被定义为,数据库中的一个表、视图或有效的SQL语句查询
一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。,逻辑表,由组成,数据库中的一个表、视图或有效的SQL语句查询
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,逻辑表,被定义为,三元组映射
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,逻辑表,由组成,Triples_Map
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,逻辑表,被定义为,RDF数据
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,逻辑表,由组成,RDF数据
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,逻辑表,由组成,RDF数据
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射,被定义为,主语映射和多个谓词-宾语映射
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射,由组成,主语映射和多个谓词-宾语映射
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射,由组成,主语映射和多个谓词-宾语映射
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,被定义为,基于数据库表中的主键生成的IRI表示
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,由组成,基于数据库表中的主键生成的IRI表示
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,被定义为,谓词映射和宾语映射
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,由组成,谓词映射和宾语映射
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,雇用表,被定义为,表
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,雇用表,由组成,雇员
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,雇用表,由组成,部门
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,雇用表,属于,图4-22中给出的一个示例数据库
用于创建R2RML视图的SQL语句如下所示。,R2RML视图,被定义为,用于创建R2RML视图的SQL语句
用于创建R2RML视图的SQL语句如下所示。,R2RML,由组成,用于创建R2RML视图的SQL语句
用于创建R2RML视图的SQL语句如下所示。,R2RML,由组成,用于创建R2RML视图的SQL语句
用于DEPT表数据转换的R2RML映射文档如下所示。,R2RML映射文档,被定义为,R2RML映射文档用于DEPT表数据转换
用于DEPT表数据转换的R2RML映射文档如下所示。,R2RML映射文档,由组成,DEPT表数据转换
用于DEPT表数据转换的R2RML映射文档如下所示。,R2RML映射文档,属于,用于DEPT表数据转换的R2RML映射文档
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,EMP,被定义为,department
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,EMP,由组成,DEPT
"4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。",OBDA,被定义为,基于本体的数据库访问
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,被定义为,面向对象数据库
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,由组成,表4-3
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,包含,OBDA
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,被定义为,OBDA
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,由组成,D2RQ
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,由组成,D2RQ
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,被定义为,OBDA系统
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,由组成,RDF
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,被定义为,HTTP_Server
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,由组成,HTTP_Server
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,由组成,HTTP_Server
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,被定义为,D2RQ映射文件
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,由组成,D2RQ映射文件
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,由组成,D2RQ映射文件
基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。,基于D2RQ映射,被定义为,Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。
基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。,基于D2RQ映射,由组成,Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。
此外，D2RQ系统还部分支持R2RML映射。,D2RQ系统,被定义为,部分支持R2RML映射
此外，D2RQ系统还部分支持R2RML映射。,D2RQ系统,由组成,部分支持R2RML映射
（2）Mastro[23]。,Mastro,被定义为,知识图谱
（2）Mastro[23]。,Mastro,由组成,Mastro
（2）Mastro[23]。,Mastro,由组成,Mastro
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,包含,基于Java语言开发的OBDA系统
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,被定义为,基于Java语言开发的OBDA系统
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,由组成,基于Java语言开发的OBDA系统
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,属于,基于Java语言开发的OBDA系统
Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。,Mastro数据源管理器,被定义为,支持与最流行的商业和非商业DBMS的交互
Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。,Mastro数据源管理器,由组成,支持与最流行的商业和非商业DBMS的交互
Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。,Mastro数据源管理器,由组成,支持与最流行的商业和非商业DBMS的交互
除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。,Oracle,被定义为,Oracle数据库
除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。,Oracle,由组成,Oracle数据库
Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。,Ultrawrap,被定义为,商业化系统
Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。,Ultrawrap,由组成,编译器和服务器
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,SPARQL,被定义为,SPARQL查询语言
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,由组成,建立数据库到RDF和OWL的映射
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,由组成,建立数据库到RDF和OWL的映射
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,被定义为,执行SPARQL查询
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,由组成,执行SPARQL查询
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,由组成,执行SPARQL查询
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Ultrawrap,被定义为,Ultrawrap是一个基于RDF的图数据库，它使用RDFS和OWL来定义数据模型，使用SPARQL来查询数据。
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Ultrawrap,被定义为,Ultrawrap是一个基于RDF的图数据库，它使用RDFS和OWL来定义数据模型，使用SPARQL来查询数据。
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,由组成,Morph-RDB
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,由组成,Morph-RDB
Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。,Morph-RDB,被定义为,RDB2RDF引擎
Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。,Morph-RDB,由组成,马德里理工大学本体工程组
Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。,Morph-RDB,由组成,马德里理工大学本体工程组
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,被定义为,关系数据库中的数据生成RDF实例
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,由组成,数据升级
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,由组成,数据升级
Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。,Morph-RDB,包含,各种优化技术
Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。,Morph-RDB,由组成,各种优化技术
（5）Ontop[26]。,Ontop,被定义为,基于关系数据库的图数据库
（5）Ontop[26]。,Ontop,由组成,OntopQL
（5）Ontop[26]。,Ontop,由组成,OntopQL
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,被定义为,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,由组成,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,由组成,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具
Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。,Ontop,被定义为,基于Apache许可证的开源工具
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,被定义为,通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,由组成,关系数据库
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,由组成,关系数据库
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,被定义为,R2RML映射
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,由组成,R2RML映射
图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。,Ontop,被定义为,图4-26Ontop的系统结构[26]
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,半结构化数据,被定义为,知识获取的重要来源
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,半结构化数据,由组成,知识获取
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,实现,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,来源,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,属于,自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。
目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。,面向网页数据的知识抽取方法,被定义为,基于网页的语义特征
目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。,面向网页数据的知识抽取,由组成,基于网页的语义分析
4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。,面向百科类数据的知识抽取,被定义为,维基百科
4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。,面向百科类数据的知识抽取,由组成,维基百科
4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。,面向百科类数据的知识抽取,由组成,维基百科
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,面向百科类数据的知识抽取,由组成,维基百科
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,面向百科类数据的知识抽取,由组成,维基百科
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,词条页面,由组成,图4-27
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,词条页面,由组成,图4-27
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,词条页面,由组成,图4-27
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,词条页面,由组成,图4-27
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,维基百科词条页面结构,由组成,维基百科
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,维基百科词条页面结构,由组成,维基百科
目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。,维基百科词条页面结构,由组成,维基百科
目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。,DBpedia,由组成,维基百科
在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。,基于百科数据构建知识图谱,被定义为,结构化语义信息
在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。,基于百科数据构建知识图谱,由组成,结构化语义信息
在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。,基于百科数据构建知识图谱,属于,结构化语义信息抽取
DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。,DBpedia,被定义为,维基百科的机构化版本
DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。,DBpedia,由组成,维基百科的机构化版本
DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。,DBpedia,由组成,维基百科的机构化版本
得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。,DBpedia,被定义为,跨领域知识图谱
得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。,DBpedia,由组成,维基百科
得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。,DBpedia,由组成,维基百科
截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。,DBpedia,被定义为,知识图谱
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,被定义为,DBpedia数据集
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,由组成,DBpedia数据集
DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。,DBpedia,被定义为,LOD数据集
DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。,DBpedia,由组成,LOD数据集
DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。,DBpedia,由组成,LOD数据集
根据抽样评测，DBpedia中RDF三元组的正确率达88%。,DBpedia,被定义为,RDF三元组
根据抽样评测，DBpedia中RDF三元组的正确率达88%。,DBpedia,由组成,RDF三元组
根据抽样评测，DBpedia中RDF三元组的正确率达88%。,DBpedia,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
图4-28所示为DBpedia知识抽取的总体框架。,DBpedia,被定义为,DBpedia是德国弗劳恩霍夫协会(Fraunhofer-Gesellschaft)的一个研究项目，该项目旨在建立一个大型的开放知识库，以支持基于Web的搜索引擎。
图4-28所示为DBpedia知识抽取的总体框架。,DBpedia,由组成,DBpedia知识抽取
图4-28所示为DBpedia知识抽取的总体框架。,DBpedia知识抽取,属于,DBpedia
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架,由组成,页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架,实现,维基百科文章数据
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架,来源,维基百科文章数据
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架,属于,维基百科文章数据
图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。,DBpedia,被定义为,DBpedia是一个基于维基百科的开放知识库，它由来自维基百科的结构化数据组成，这些数据由DBpedia提取器从维基百科中抽取。
●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。,信息框,被定义为,从词条页面的信息框中抽取实体的结构化信息。
●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。,信息框,由组成,从词条页面的信息框中抽取实体的结构化信息。
●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。,信息框,由组成,从词条页面的信息框中抽取实体的结构化信息。
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,被定义为,一般抽取和基于映射的抽取
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,由组成,一般抽取
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,由组成,基于映射的抽取
信息框的一般抽取直接将信息框中的信息转换为RDF三元组。,信息框,被定义为,将信息框中的信息转换为RDF三元组
信息框的一般抽取直接将信息框中的信息转换为RDF三元组。,信息框,由组成,信息框的一般抽取
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,三元组,被定义为,由DBpedia的URI前缀和词条名称相连组成，由信息框属性URI前缀和属性名相连组成，基于属性值创建，可以是实体的URI或者数据类型的值。
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,三元组,由组成,由DBpedia的URI前缀和词条名称相连组成，由信息框的属性URI前缀和属性名相连组成，由基于属性值创建，可以是实体的URI或者数据类型的值。
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,三元组,由组成,由DBpedia的URI前缀和词条名称相连组成，由信息框的属性URI前缀和属性名相连组成，由基于属性值创建，可以是实体的URI或者数据类型的值。
然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。,维基百科信息框,被定义为,属性名和信息框模板同义异名
从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。,HTML,被定义为,HTML标记
从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。,产品,由组成,HTML代码
从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。,产品,由组成,HTML代码
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,被定义为,实现从网页中获取结构化信息
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,由组成,网页
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,实现,从网页中获取结构化信息
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,来源,从网页中获取结构化信息
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,属于,从网页中获取结构化信息
包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。,包装器,被定义为,能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。
包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。,包装器,由组成,能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器的生成方法,被定义为,手工方法、包装器归纳方法和自动抽取方法
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器的生成方法,由组成,三大类
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,基于包装器抽取网页信息的框架,被定义为,手工方法
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,网页信息抽取,由组成,包装器
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法,被定义为,查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法,由组成,查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,被定义为,XML路径语言
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,由组成,XML路径语言
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,由组成,XML路径语言
借助它可以获取网页中元素的位置，从而获取需要的信息。,网页元素定位,被定义为,获取网页中元素的位置
借助它可以获取网页中元素的位置，从而获取需要的信息。,网页元素定位,由组成,网页元素定位
借助它可以获取网页中元素的位置，从而获取需要的信息。,网页元素定位,由组成,网页元素定位
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,CSS选择器,被定义为,通过CSS元素实现对网页中元素的定位，并获取元素信息的。
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,产品价格信息,由组成,CSS选择器
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,价格信息,被定义为,CSS选择器表达式
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,分析图4-30中的搜索结果页面,实现,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则,来源,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则,属于,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,包装器归纳流程,被定义为,网页清洗、网页标注、包装器空间生成、包装器评估
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,网页清洗,由组成,网页标注
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,包装器归纳流程,实现,网页清洗、网页标注、包装器空间生成、包装器评估
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,包装器归纳流程,属于,网页清洗、网页标注、包装器空间生成、包装器评估
（1）网页清洗。,网页清洗,被定义为,将网页中的HTML代码转换为可被计算机识别的文本
（1）网页清洗。,网页清洗,由组成,网页清洗工具
（1）网页清洗。,网页清洗,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,TIDY类工具,包含,纠正和清理网页不规范的HTML、XML标记
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,TIDY类工具,由组成,纠正和清理网页不规范的HTML、XML标记
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,纠正和清理网页不规范的HTML、XML标记,实现,TIDY类工具
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,纠正和清理网页不规范的HTML、XML标记,属于,TIDY类工具
（2）网页标注。,网页标注,被定义为,网页标注器
（2）网页标注。,网页标注,由组成,网页标注系统
（2）网页标注。,网页标注,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。,网页标注,被定义为,标注过程
在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。,网页标注,由组成,标注过程
在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。,网页标注,属于,标注过程
（3）包装器空间生成。,包装器空间生成,被定义为,将知识图谱中的实体和关系映射为图数据库中的实体和关系
（3）包装器空间生成。,包装器空间生成,由组成,包装器
（3）包装器空间生成。,包装器空间生成,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,被定义为,对生成的集合进行归纳，从而形成若干个子集。
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,由组成,对生成的集合进行归纳，从而形成若干个子集
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,被定义为,使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,由组成,XPath
（4）包装器评估。,包装器评估,被定义为,评估包装器
（4）包装器评估。,包装器评估,由组成,包装器
（4）包装器评估。,包装器评估,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
包装器可以通过准确率和召回率进行评估。,包装器,包含,准确率和召回率
包装器可以通过准确率和召回率进行评估。,包装器,由组成,准确率和召回率
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,使用待评估包装器对训练数据中的网页进行标注,包含,准确率
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,由组成,N除以包装器输出标注的总数量
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,召回率,由组成,N除以人工标注数据项的总数量
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,由组成,N除以包装器输出标注的总数量
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,召回率,由组成,N除以人工标注数据项的总数量
准确率和召回率越高，表示包装器的质量越好。,包装器,包含,准确率和召回率
准确率和召回率越高，表示包装器的质量越好。,包装器,由组成,准确率和召回率
3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。,自动抽取方法包装器归纳方法,被定义为,大量的人工标注工作
3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。,自动抽取方法包装器归纳方法,由组成,大量的人工标注工作
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,包装器,被定义为,维护包装器的工作量
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,包装器,由组成,维护
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。,自动抽取方法,被定义为,不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。
自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。,自动抽取方法,由组成,不需要任何的先验知识和人工标注的数据
自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。,自动抽取方法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,自动抽取方法,包含,相似网页
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,自动抽取方法,被定义为,聚类
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,相似网页,由组成,聚类
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,自动抽取方法,属于,相似网页
在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。,应用包装器进行数据抽取,被定义为,将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。
在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。,应用包装器进行数据抽取,由组成,将需要抽取的页面划分到先前生成的网页组
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,基于规则的方法,被定义为,基于规则的方法是利用规则库对网页进行信息抽取，其优点是抽取速度快，缺点是规则库的维护比较困难，而且规则库的规模越大，维护的难度就越大。
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,基于规则的方法,由组成,基于规则的方法
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识挖掘,被定义为,从已有的实体及实体关系出发挖掘新的知识
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识挖掘,由组成,知识内容挖掘
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识图谱,实现,知识内容挖掘
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识内容挖掘,来源,知识内容挖掘
4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。,实体链接,被定义为,将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程
实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。,实体链接,由组成,文本数据
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,实体链接,被定义为,将文本中的实体指称与其在知识库中对应的实体建立链接
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,通过实体链接,由组成,文本中的实体指称
实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。,实体链接,被定义为,实体指称识别、候选实体生成和候选实体消歧
实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。,实体链接,由组成,实体指称识别、候选实体生成和候选实体消歧
该步骤主要通过命名实体识别技术或者词典匹配技术实现。,命名实体识别技术,被定义为,通过词典匹配技术实现
该步骤主要通过命名实体识别技术或者词典匹配技术实现。,命名实体识别技术,被定义为,通过词典匹配技术实现
该步骤主要通过命名实体识别技术或者词典匹配技术实现。,命名实体识别技术,由组成,该步骤
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,被定义为,通过直接与文本的匹配识别指称
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,由组成,词典匹配技术
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。,候选实体生成,被定义为,确定文本中的实体指称可能指向的实体集合
2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。,候选实体生成,由组成,候选实体生成是确定文本中的实体指称可能指向的实体集合。
2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。,候选实体生成,实现,候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,指称,被定义为,指代知识库中的多个实体
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,乔丹,由组成,迈克尔乔丹
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,乔丹,由组成,迈克尔乔丹
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,表层名字扩展,被定义为,通过实体表层名字扩展生成实体指称
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,表层名字扩展,方法,实体指称的候选实体
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,表层名字扩展,由组成,生成实体指称的候选实体
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,表层名字扩展,属于,生成实体指称的候选实体
某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,表层名字扩展,属于,生成实体指称的候选实体
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,实体提及,被定义为,实体提及的候选实体集合
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,实体提及,由组成,候选实体集合
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,实体提及,实现,实体提及的候选实体集合
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,实体提及,属于,实体提及的候选实体集合
表层名字扩展可以采用启发式的模式匹配方法实现。,表层名字扩展,被定义为,启发式的模式匹配方法实现
表层名字扩展可以采用启发式的模式匹配方法实现。,表层名字扩展,由组成,启发式的模式匹配方法
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,被定义为,提取实体提及邻近括号中的缩写作为扩展结果
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,由组成,提取实体提及邻近括号中的缩写作为扩展结果
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,由组成,提取实体提及邻近括号中的缩写作为扩展结果
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,模式匹配,被定义为,从文本中抽取复杂的实体名称缩写
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,模式匹配,方法,从文本中抽取复杂的实体名称缩写
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,模式匹配,由组成,使用模式匹配的方法
（2）基于搜索引擎的方法。,基于搜索引擎的方法,被定义为,基于搜索引擎的方法是利用搜索引擎对知识库进行搜索，然后根据搜索结果进行知识抽取的方法
（2）基于搜索引擎的方法。,基于搜索引擎的方法,方法,利用搜索引擎进行知识抽取
（2）基于搜索引擎的方法。,基于搜索引擎的方法,由组成,搜索引擎
将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。,实体提及,被定义为,检索结果
将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。,将实体提及和上下文文字提交至搜索引擎,由组成,检索结果生成候选实体
例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。,实体指称,被定义为,搜索关键词
例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。,实体指称,由组成,谷歌搜索引擎
例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。,实体指称,由组成,谷歌搜索引擎
此外，维基百科自有的搜索功能也可以用于生成候选实体。,维基百科,被定义为,维基百科搜索
此外，维基百科自有的搜索功能也可以用于生成候选实体。,维基百科,由组成,维基百科搜索
此外，维基百科自有的搜索功能也可以用于生成候选实体。,维基百科,属于,知识图谱
（3）构建查询实体引用表。,查询实体引用表,被定义为,查询实体引用表构建
（3）构建查询实体引用表。,查询实体引用表,由组成,构建
很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。,实体链接,被定义为,实体提及与候选实体的对应关系
很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。,很多实体链接系统,由组成,基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。
很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。,很多实体链接系统都基于维基百科数据构建查询实体引用表,实现,建立实体提及与候选实体的对应关系
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用表示,被定义为,键-值映射
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用表示,由组成,键-值映射
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用表示,由组成,键-值映射
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,实体提及,包含,实体提及
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,实体提及,被定义为,实体提及
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,完成引用表构建,由组成,实体提及
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,引用表,实现,实体提及
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,引用表,属于,实体提及
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,引用表,实现,实体提及
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,引用表,属于,实体提及
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象,由组成,实体
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象,由组成,重定向页面
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象,由组成,消歧页面
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象通常被当作知识库中的实体,实现,维基百科词条页面描述的对象通常被当作知识库中的实体
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象通常被当作知识库中的实体,来源,维基百科
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,维基百科词条页面描述的对象通常被当作知识库中的实体,属于,维基百科词条页面描述的对象通常被当作知识库中的实体
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,被定义为,实体提及
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,由组成,实体提及
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,实现,提取实体和实体提及的对应关系
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,来源,提取实体和实体提及的对应关系
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,属于,提取实体和实体提及的对应关系
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,实体链接,被定义为,实体链接系统
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,实体链接,由组成,候选实体消歧
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,包含,排序问题
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,由组成,排序问题
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,实现,排序问题
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,属于,排序问题
下面介绍每类方法中具有代表性的工作。,方法,被定义为,具有代表性的工作
下面介绍每类方法中具有代表性的工作。,知识图谱,方法,知识抽取
下面介绍每类方法中具有代表性的工作。,缺点,由组成,缺点
下面介绍每类方法中具有代表性的工作。,缺点,由组成,缺点
[32]（1）基于图的方法。,基于图的方法,由组成,图数据库
[32]（1）基于图的方法。,基于图的方法,由组成,图数据库
基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。,基于图的方法,被定义为,将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。
基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。,基于图的方法,由组成,实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图协同实体链接方法,被定义为,Han等人较早提出的基于参照图协同实体链接方法
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图协同实体链接方法,方法,Han等人
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图协同实体链接方法,由组成,Han等人
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,Han等人,被定义为,候选实体消歧
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,Han等人,由组成,候选实体消歧
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,Han等人,实现,候选实体消歧
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,Han等人,来源,候选实体消歧
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,候选实体消歧,属于,Han等人
在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。,Han_PageRank算法,被定义为,实体消歧
在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。,Han_PageRank算法,方法,将实体提及的初始重要性度量作为实体消歧的初始依据
在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。,Han_PageRank算法,由组成,实体消歧
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧,被定义为,局部相容度和全局依赖性
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧目标函数,目标,局部相容度
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧,由组成,局部相容度
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,基于图的方法进行候选实体消歧的实体链接系统,被定义为,文献[34]、文献[35]等
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,基于图的方法进行候选实体消歧的实体链接系统,由组成,文献[34]、文献[35]等
图4-34参照图[33]（2）基于概率生成模型的方法。,基于概率生成模型的方法,被定义为,基于概率生成模型的方法是利用概率生成模型来生成知识图谱的表示，从而实现知识图谱的构建。
图4-34参照图[33]（2）基于概率生成模型的方法。,基于概率生成模型的方法,由组成,图4-34参照图[33]
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型的实体消歧,被定义为,实体提及和实体的联合概率
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型对实体提及和实体的联合概率进行建模,由组成,实体消歧问题
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型对实体提及和实体的联合概率进行建模,实现,实体消歧问题
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型对实体提及和实体的联合概率进行建模,来源,实体消歧问题
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型对实体提及和实体的联合概率进行建模,属于,实体消歧问题
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,被定义为,实体提及被作为生成样本进行建模，其生成过程如图4-35所示。
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,由组成,Han等人[36]提出的实体-提及概率生成模型
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,实现,Han等人[36]提出的实体-提及概率生成模型
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,Han等人[36]提出的实体-提及概率生成模型,来源,实体-提及概率生成模型
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,属于,Han等人[36]提出的实体-提及概率生成模型
当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。,候选实体消歧,被定义为,基于主题模型的方法
当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。,候选实体消歧,由组成,基于主题模型的方法
当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。,候选实体消歧,由组成,基于主题模型的方法
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,被定义为,实体链接
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,由组成,实体链接
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,被定义为,给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,由组成,给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,主题,被定义为,基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,E维狄利克雷分布,由组成,每个主题z中实体的分布φz
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,K维狄利克雷分布,由组成,每个实体e名称的分布ψe
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,V维狄利克雷分布,由组成,实体e上下文词的分布ξe
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,吉布斯抽样算法,被定义为,实体-主题模型
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,吉布斯抽样算法,由组成,实体-主题模型
图4-36实体-主题模型[37]（4）基于深度学习的方法。,实体-主题模型,被定义为,图4-36实体-主题模型
图4-36实体-主题模型[37]（4）基于深度学习的方法。,实体-主题模型,由组成,基于深度学习的方法
图4-36实体-主题模型[37]（4）基于深度学习的方法。,图4-36实体-主题模型,实现,基于深度学习的方法
图4-36实体-主题模型[37]（4）基于深度学习的方法。,图4-36实体-主题模型,来源,图4-36实体-主题模型
图4-36实体-主题模型[37]（4）基于深度学习的方法。,图4-36实体-主题模型,属于,基于深度学习的方法
在候选实体消歧过程中，准确计算实体的相关度十分重要。,候选实体消歧,被定义为,准确计算实体的相关度
在候选实体消歧过程中，准确计算实体的相关度十分重要。,候选实体消歧,由组成,准确计算实体的相关度
在候选实体消歧过程中，准确计算实体的相关度十分重要。,候选实体消歧,实现,准确计算实体的相关度
在候选实体消歧过程中，准确计算实体的相关度十分重要。,候选实体消歧,属于,准确计算实体的相关度
因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,实体相关度评价,被定义为,利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。
因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,利用上下文中信息或进行协同实体消歧,由组成,评价实体与实体的相关度
Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。,Huang等人,被定义为,一个基于深度神经网络的实体语义相关度计算模型
Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。,Huang等人,由组成,一个基于深度神经网络的实体语义相关度计算模型
Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。,Huang等人[38]提出的一个基于深度神经网络的实体语义相关度计算模型,属于,基于深度神经网络的实体语义相关度计算模型
在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。,输入层,被定义为,实体E、实体拥有的关系R、实体类型ET和实体描述D
在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。,输入层,由组成,实体E、实体拥有的关系R、实体类型ET和实体描述D
在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,被定义为,语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,由组成,基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,知识图谱中的实体关系,被定义为,二元谓词描述的事实
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,知识图谱中的实体关系,实现,ILP方法
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,知识图谱中的实体关系,来源,ILP方法
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,知识图谱中的实体关系,属于,ILP方法
"给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。",ILP系统,被定义为,描述目标谓词的逻辑规则集合
FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。,FOIL,被定义为,早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则
FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。,FOIL,由组成,顺序覆盖的策略逐条学习逻辑规则
FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。,FOIL,由组成,顺序覆盖的策略逐条学习逻辑规则
下面通过一个例子介绍FOIL的规则学习过程。,FOIL,被定义为,通过一个例子介绍FOIL的规则学习过程。
下面通过一个例子介绍FOIL的规则学习过程。,FOIL,由组成,规则学习过程
下面通过一个例子介绍FOIL的规则学习过程。,FOIL,由组成,规则学习过程
设有规则学习问题如表4-6所示。,规则学习,被定义为,规则学习问题
设有规则学习问题如表4-6所示。,规则学习,由组成,表4-6
设有规则学习问题如表4-6所示。,规则学习问题,实现,表4-6
设有规则学习问题如表4-6所示。,规则学习问题,属于,表4-6
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,背景知识,被定义为,daughter
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,规则学习,目标,daughter
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,背景知识描述,由组成,规则学习的目标谓词为daughter
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,包含,规则学习
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,由组成,规则学习
表4-7列出了FOIL学习单个规则的过程。,FOIL,被定义为,使用FOIL进行规则学习
表4-7列出了FOIL学习单个规则的过程。,FOIL,由组成,FOIL学习单个规则的过程
表4-7列出了FOIL学习单个规则的过程。,FOIL,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
表4-7列出了FOIL学习单个规则的过程。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,FOIL
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,被定义为,基于正例和反例的规则覆盖
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,由组成,正例
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,FOIL,包含,规则学习问题
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,规则学习,方法,FOIL
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,规则学习,由组成,表4-6
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,被定义为,选择使得规则FOIL_Gain达到最大的谓词加入规则体
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,由组成,谓词
FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。,FOIL_Gain,被定义为,式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。
FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。,FOIL_Gain,由组成,由候选谓词构成的新文字
FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。,FOIL_Gain,由组成,由候选谓词构成的新文字
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL,包含,基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL,由组成,FOIL_Gain评价函数
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL,由组成,FOIL_Gain评价函数
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,ILP,被定义为,基于逆语义蕴涵的学习方法
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,在早期的ILP系统中,由组成,以Progol[41]为代表的基于逆语义蕴涵的学习方法
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,ILP系统,实现,基于逆语义蕴涵的学习方法
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,ILP系统,来源,基于逆语义蕴涵的学习方法
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,ILP系统,属于,基于逆语义蕴涵的学习方法
多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。,ILP系统,被定义为,仅适用于小规模的数据集
多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。,ILP系统,由组成,仅适用于小规模的数据集
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,ILP,被定义为,分布式并行的ILP系统
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,ILP系统,由组成,FOIL-D
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,ILP系统,由组成,FOIL-D
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,被定义为,AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,由组成,AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,由组成,AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE,包含,AMIE+
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE+,被定义为,AMIE
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE,由组成,Galarraga
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE,由组成,Galarraga
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",PRA,被定义为,将关系路径作为特征的知识图谱链接预测算法
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",PRA,由组成,"PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。"
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,PRA
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,PRA
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,PRA
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,被定义为,通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,由组成,实体间可能存在的某种特定关系
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,由组成,实体间可能存在的某种特定关系
"如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。",AlthletePlaysForLeague,被定义为,NFL
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,关系路径,被定义为,霍恩子句
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,霍恩子句,由组成,霍恩子句
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,被定义为,特征选择、特征计算和关系分类
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,由组成,特征选择、特征计算和关系分类
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,实现,特征选择
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,来源,特征计算
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,属于,关系分类
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,霍恩子句,被定义为,特征选择
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,霍恩子句,由组成,特征选择
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,霍恩子句,由组成,特征选择
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径数量,被定义为,连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径数量,由组成,可能会很多
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,被定义为,关系路径选择
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,由组成,关系路径选择
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,由组成,关系路径选择
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,被定义为,基于随机游走的特征选择方法
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,由组成,基于随机游走的特征选择方法
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,由组成,基于随机游走的特征选择方法
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）,包含,实体si
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）,包含,实体Gi
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）,包含,关系路径π
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中,由组成,P（si→Gi;π）
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,PRA,包含,准确度和覆盖度
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,PRA,由组成,阈值
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,PRA,由组成,阈值
（2）特征计算。,特征计算,被定义为,特征计算是利用机器学习算法，对特征进行计算，从而得到特征向量，特征向量是特征计算的结果
（2）特征计算。,特征计算,由组成,特征计算引擎
（2）特征计算。,特征计算,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,PRA,被定义为,选择有用的关系路径作为特征
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,PRA,由组成,特征值
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,PRA,由组成,特征值
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,包含,实体s为起点沿着关系路径π进行随机游走抵达实体t的概率
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,由组成,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,实现,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,来源,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,属于,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,特征关系路径,被定义为,实体对在每个特征关系路径上的可达概率
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,由组成,特征关系路径上的可达概率
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,实现,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,来源,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,属于,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。
（3）关系分类。,关系分类,被定义为,关系分类器
（3）关系分类。,关系分类,由组成,关系抽取
（3）关系分类。,关系分类,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,被定义为,基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,由组成,基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,知识图谱,被定义为,利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,利用训练完的模型,由组成,可以预测知识图谱中任意两个实体间是否存在某特定关系
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,关系分类,被定义为,逻辑回归分类模型
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,关系分类,由组成,逻辑回归分类模型
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,包含,关系路径的权重
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,由组成,关系路径的权重
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,实现,训练逻辑回归模型
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,来源,训练逻辑回归模型
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,属于,训练逻辑回归模型
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,DeepDive,被定义为,基于深度学习的开源关系抽取框架
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,DeepDive,实现,关系抽取
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,DeepDive,来源,关系抽取
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,DeepDive,属于,关系抽取
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,被定义为,OpenKG是一个开源的、基于知识图谱的开放知识库
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,由组成,OpenKG提供
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,OpenKG,属于,实践
该框架遵循Apache开源协议。,Apache开源框架,被定义为,遵循Apache开源协议
该框架遵循Apache开源协议。,Apache,由组成,Apache开源协议
该框架遵循Apache开源协议。,Apache,由组成,Apache开源协议
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,被定义为,开源工具
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,由组成,数据准备
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,由组成,因子图模型构建
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,由组成,数据准备
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,由组成,因子图模型构建
在具体应用中，可以选择使用因子图模型或神经网络模型。,知识图谱,被定义为,因子图模型
在具体应用中，可以选择使用因子图模型或神经网络模型。,因子图模型,由组成,神经网络模型
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,DeepDive,被定义为,图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,DeepDive,由组成,图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,DeepDive,由组成,图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。
根据使用技术的不同，下面分别介绍一些典型的本体映射工作。,本体映射,被定义为,根据使用技术的不同，下面分别介绍一些典型的本体映射工作。
根据使用技术的不同，下面分别介绍一些典型的本体映射工作。,使用技术的不同,由组成,一些典型的本体映射工作
根据使用技术的不同，下面分别介绍一些典型的本体映射工作。,本体映射,属于,使用技术的不同
很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。,映射发现技术,被定义为,综合方法
很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。,映射发现技术,由组成,综合方法
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语和基于结构的映射发现方法,被定义为,将基于术语和基于结构的映射发现方法放在一处进行讨论
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语和基于结构的映射发现方法,由组成,基于术语和基于结构的映射发现方法
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语和基于结构的映射发现方法,实现,基于术语和基于结构的映射发现方法
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语和基于结构的映射发现方法,属于,基于术语和基于结构的映射发现方法
1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。,基于术语和结构的本体映射,被定义为,从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。
1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。,基于术语和结构的本体映射,由组成,从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。
这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。,知识图谱,被定义为,一种基于语义的网络资源组织方式
这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。,方法,由组成,由组成
（1）技术综述1）基于术语的本体映射技术。,基于术语的本体映射技术,被定义为,术语映射
（1）技术综述1）基于术语的本体映射技术。,基于术语的本体映射技术,由组成,术语本体映射技术
这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。,本体映射方法,被定义为,从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。
这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。,本体映射方法,由组成,比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,被定义为,基于字符串的方法和基于语言的方法
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,方法,基于字符串的方法和基于语言的方法
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,由组成,基于字符串的方法和基于语言的方法
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,实现,基于字符串的方法
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,来源,基于字符串的方法
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,属于,基于字符串的方法
①基于字符串的方法。,基于字符串的方法,被定义为,基于字符串的方法
①基于字符串的方法。,基于字符串的方法,方法,将文本转化为三元组
①基于字符串的方法。,基于字符串的方法,由组成,基于字符串的方法
基于字符串的方法直接比较表示本体成分的术语的字符串结构。,基于字符串的方法,被定义为,直接比较表示本体成分的术语的字符串结构
基于字符串的方法直接比较表示本体成分的术语的字符串结构。,基于字符串的方法,方法,直接比较表示本体成分的术语的字符串结构
基于字符串的方法直接比较表示本体成分的术语的字符串结构。,基于字符串的方法,由组成,直接比较表示本体成分的术语的字符串结构
基于字符串的方法直接比较表示本体成分的术语的字符串结构。,基于字符串的方法,由组成,直接比较表示本体成分的术语的字符串结构
主要的字符串比较技术如下。,字符串比较,被定义为,字符串比较技术
主要的字符串比较技术如下。,字符串比较,方法,字符串比较技术
主要的字符串比较技术如下。,字符串比较技术,由组成,字符串比较技术
主要的字符串比较技术如下。,字符串比较技术,由组成,字符串比较技术
（a）规范化。,规范化,被定义为,将知识图谱中的实体和关系进行规范化，使其具有统一的形式
（a）规范化。,规范化,由组成,知识图谱
在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。,字符串比较,被定义为,字符串规范化
在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。,字符串比较,由组成,字符串规范化
这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。,规范化操作,被定义为,针对拉丁语系
这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。,规范化操作,由组成,拉丁语系
（b）相似度量方法。,相似度量方法,被定义为,相似度量方法有距离度量方法、相似度量方法、余弦相似度量方法
（b）相似度量方法。,相似度量方法,方法,基于知识图谱的相似度量方法
（b）相似度量方法。,相似度量方法,由组成,相似度量方法
（b）相似度量方法。,相似度量方法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在规范字符串的基础上，能进一步度量不同字符串间的相似程度。,字符串相似度,被定义为,在规范字符串的基础上，能进一步度量不同字符串间的相似程度。
在规范字符串的基础上，能进一步度量不同字符串间的相似程度。,规范字符串,由组成,度量不同字符串间的相似程度
在规范字符串的基础上，能进一步度量不同字符串间的相似程度。,规范字符串,实现,相似度
在规范字符串的基础上，能进一步度量不同字符串间的相似程度。,相似度,属于,规范字符串
常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。,字符串度量方法,被定义为,汉明距离、子串相似度、编辑距离和路径距离
常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。,字符串度量方法,由组成,汉明距离、子串相似度、编辑距离和路径距离等
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",相似度,被定义为,字符串间相似度的度量
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",相似度,方法,字符串
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",相似度,由组成,"区间(0,1)中的某个值"
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",字符串相似度,属于,字符串
一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。,汉明距离,被定义为,计算两个字符中字符出现位置的不同
一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。,汉明距离,被定义为,计算两个字符中字符出现位置的不同
一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。,汉明距离,由组成,两个字符中字符出现位置的不同
定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。,汉明距离相似度,被定义为,对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。
定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。,汉明距离相似度,被定义为,对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。
定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。,汉明距离相似度,由组成,定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。
定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。,字符串,被定义为,子串
定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。,子串,由组成,定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,子串相似度,被定义为,两字符串包含共同部分的比例
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,子串相似度,由组成,精确度量两字符串包含共同部分的比例
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,子串相似度
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,子串相似度
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,子串相似度
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,子串相似度度量,被定义为,任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,子串相似度度量,由组成,任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,定义5.3子串相似度度量,实现,任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,定义5.3子串相似度度量,来源,任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,定义5.3子串相似度度量,属于,任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,包含,修改
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,被定义为,修改其中一个使之与另一个相同所需要的最小操作代价
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,由组成,修改
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,两字符串之间的编辑距离,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这些编辑操作包括插入、删除和替代字符。,编辑操作,被定义为,插入、删除和替代字符
这些编辑操作包括插入、删除和替代字符。,编辑操作,由组成,插入、删除和替代字符
显然，编辑距离越大，表示两字符串的相似程度越小。,编辑距离,被定义为,两字符串的相似程度
显然，编辑距离越大，表示两字符串的相似程度越小。,编辑距离,由组成,字符串
显然，编辑距离越大，表示两字符串的相似程度越小。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,实现
显然，编辑距离越大，表示两字符串的相似程度越小。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,实现
显然，编辑距离越大，表示两字符串的相似程度越小。,实现,属于,实现
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,被定义为,字符串间相似度的指标
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,由组成,字符串
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,实现,最基础的判断字符串间相似度的指标
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,来源,最基础的判断字符串间相似度的指标
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,属于,最基础的判断字符串间相似度的指标
除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。,字符串比较,被定义为,比较两个字符串是否相似
除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。,比较单个术语的字符串相似,由组成,相关的一系列的字符串
路径比较便是这类方法中的一种。,路径比较,被定义为,路径比较方法
路径比较便是这类方法中的一种。,路径比较,方法,路径比较
路径比较便是这类方法中的一种。,路径比较,由组成,路径比较方法
路径比较便是这类方法中的一种。,路径比较,由组成,路径比较方法
"定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。",路径距离,被定义为,"给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"
"定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。",路径距离,由组成,"有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"
"定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。",路径距离,由组成,"有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"
②基于语言的方法。,基于语言的方法,被定义为,基于语言的方法是利用语言本身的特点，通过分析语言结构，利用语言规则，实现知识抽取的方法
②基于语言的方法。,基于语言的方法,方法,基于语言的方法
②基于语言的方法。,基于语言的方法,由组成,基于语言的方法
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,被定义为,寻找概念或关系之间的联系
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,方法,寻找概念或关系之间的联系
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,由组成,自然语言处理技术
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,实现,自然语言处理技术
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,来源,自然语言处理技术
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,属于,自然语言处理技术
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,内部方法,被定义为,使用语言的内部属性，如形态和语法特点
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,内部方法,方法,语言的内部属性
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,内部方法,由组成,语言的内部属性
内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。,内部方法,被定义为,利用词语形态和语法分析来保证术语的规范化
内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。,内部方法,由组成,词语形态和语法分析
它寻找同一字符串的不同语言形态，如Apple和Apples等。,SPO,被定义为,寻找同一字符串的不同语言形态，如Apple和Apples等。
它寻找同一字符串的不同语言形态，如Apple和Apples等。,SPO,由组成,SPO
它寻找同一字符串的不同语言形态，如Apple和Apples等。,它寻找同一字符串的不同语言形态,实现,Apple
它寻找同一字符串的不同语言形态，如Apple和Apples等。,它寻找同一字符串的不同语言形态,来源,Apple
它寻找同一字符串的不同语言形态，如Apple和Apples等。,它寻找同一字符串的不同语言形态,属于,Apple
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,它寻找同一字符串的不同语言形态,实现,Apple
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,它寻找同一字符串的不同语言形态,来源,Apple
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,它寻找同一字符串的不同语言形态,属于,Apple
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,寻找词形变化的算法,由组成,Porter_M_F提出的Stemming算法
外部方法利用词典等外部资源来寻找映射。,外部方法,被定义为,利用词典等外部资源来寻找映射
外部方法利用词典等外部资源来寻找映射。,外部方法,由组成,词典等外部资源
基于词典的方法使用外部词典匹配语义相关的术语。,基于词典的方法,被定义为,使用外部词典匹配语义相关的术语
基于词典的方法使用外部词典匹配语义相关的术语。,基于词典的方法,方法,使用外部词典匹配语义相关的术语
基于词典的方法使用外部词典匹配语义相关的术语。,基于词典的方法,由组成,使用外部词典匹配语义相关的术语
例如，使用WordNet能判断两个术语是否有同义或上下义关系。,WordNet,由组成,由WordNet和WordNet2.0组成
例如，使用WordNet能判断两个术语是否有同义或上下义关系。,WordNet,由组成,由WordNet和WordNet2.0组成
尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。,基于术语的相似度度量方法,被定义为,很难得到比较好的映射结果
尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。,基于术语的相似度度量方法,由组成,基于术语的相似度度量方法
2）基于结构的本体映射技术。,基于结构的本体映射技术,被定义为,将本体映射为结构化的形式
2）基于结构的本体映射技术。,基于结构的本体映射技术,由组成,基于结构的本体映射技术
在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。,本体映射,被定义为,同时考虑本体的结构
在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。,寻找映射,由组成,同时考虑本体的结构
在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。,基于结构的方法,被定义为,考虑本体的概念或关系的属性和属性值的数据类型等，考虑与其他成分间的联系
基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。,基于结构的方法,由组成,内部结构和外部结构
①内部结构。,内部结构,被定义为,知识图谱的内部结构
①内部结构。,内部结构,由组成,由组成
基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。,基于内部结构的方法,被定义为,利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。
基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。,基于内部结构的方法,方法,利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。
基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。,基于内部结构的方法,由组成,利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。
通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。,相似度,被定义为,具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。
通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。,相似度,由组成,属性或者属性的数据类型相同的概念
通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。,相似度,属于,具有相同属性或者属性的数据类型相同的概念
②外部结构。,外部结构,被定义为,知识图谱的存储结构
②外部结构。,外部结构,由组成,由组成
比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。,比较两本体的成分之间的相似,由组成,与它们相关的外部结构
比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。,比较两本体的成分之间的相似,由组成,与它们相关的外部结构
从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。,本体成分,被定义为,本体使用过程中所获得的一些经验
从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。,本体成分,由组成,人们在本体使用过程中所获得的一些经验
对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。,本体成分之间的关系,被定义为,比较特殊和常见
对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。,通过Part-of关系或Is-a关系构成的本体,由组成,结构上的相似
计算概念之间的相似也可以考虑它们之间的关系。,计算概念之间的相似,被定义为,关系
计算概念之间的相似也可以考虑它们之间的关系。,计算概念之间的相似,由组成,关系
计算概念之间的相似也可以考虑它们之间的关系。,计算概念之间的相似也可以考虑它们之间的关系。,实现,计算概念之间的相似也可以考虑它们之间的关系。
计算概念之间的相似也可以考虑它们之间的关系。,计算概念之间的相似也可以考虑它们之间的关系。,属于,计算概念之间的相似
如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。,概念A,被定义为,概念A’
然而，这种方法的问题在于如何判断关系的相似性。,关系抽取,被定义为,判断关系的相似性
然而，这种方法的问题在于如何判断关系的相似性。,关系抽取,由组成,关系相似性判断
然而，这种方法的问题在于如何判断关系的相似性。,关系抽取,属于,关系抽取方法
关系的相似性计算一直是一个很困难的问题。,关系的相似性计算,被定义为,一个困难的问题
关系的相似性计算一直是一个很困难的问题。,关系的相似性计算,由组成,困难的问题
关系的相似性计算一直是一个很困难的问题。,关系的相似性计算,由组成,困难的问题
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,外部结构的方法,被定义为,无法解决由于本体建模的观点不同而造成的异构
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,外部结构的方法,方法,无法解决由于本体建模的观点不同而造成的异构
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,外部结构的方法,由组成,无法解决由于本体建模的观点不同而造成的异构
基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。,基于结构的方法,被定义为,难以解决这种不同划分下的子类之间的相似度问题
基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。,基于结构的方法,由组成,难以解决这种不同划分下的子类之间的相似度问题
基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。,基于结构的方法,实现,难以解决这种不同划分下的子类之间的相似度问题
基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。,基于结构的方法,属于,难以解决这种不同划分下的子类之间的相似度问题
（2）方法和工具1）AnchorPROMPT。,AnchorPROMPT,被定义为,AnchorPROMPT是一种基于深度学习的知识图谱自动抽取方法。
（2）方法和工具1）AnchorPROMPT。,AnchorPROMPT,由组成,方法和工具
（2）方法和工具1）AnchorPROMPT。,AnchorPROMPT,实现,方法和工具
（2）方法和工具1）AnchorPROMPT。,方法和工具,属于,AnchorPROMPT
除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。,AnchorPROMPT,包含,本体映射
除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。,AnchorPROMPT,由组成,直接处理映射
PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。,PROMPT,被定义为,PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。
PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。,PROMPT,由组成,各个工具
目前，PROMPT的这些工具已集成到Protégé系统中。,PROMPT,被定义为,目前，PROMPT的这些工具已集成到Protégé系统中。
目前，PROMPT的这些工具已集成到Protégé系统中。,PROMPT,由组成,Protégé
本体映射是解决很多多本体问题的基础。,本体映射,被定义为,解决很多多本体问题的基础
本体映射是解决很多多本体问题的基础。,本体映射,由组成,解决很多多本体问题的基础
本体映射是解决很多多本体问题的基础。,本体映射,由组成,解决很多多本体问题的基础
"为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。",SMART算法,被定义为,通过比较概念名的相似性，识别异构本体间的等价概念
"为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。",SMART算法,由组成,Noy_N_F
"为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。",SMART算法,由组成,Noy_N_F
AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。,AnchorPROMPT算法,被定义为,SAMRT
AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。,AnchorPROMPT算法,由组成,SAMRT
AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。,AnchorPROMPT算法,由组成,SAMRT
①AnchorPROMPT的思想。,AnchorPROMPT,被定义为,基于文本的实体识别
①AnchorPROMPT的思想。,AnchorPROMPT,由组成,AnchorPROMPT的思想
①AnchorPROMPT的思想。,AnchorPROMPT,由组成,AnchorPROMPT的思想
AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。,AnchorPROMPT,被定义为,在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。
AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。,AnchorPROMPT,由组成,目标
AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。,AnchorPROMPT,由组成,目标
AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。,AnchorPROMPT,被定义为,相关术语对的集合
AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。,AnchorPROMPT,由组成,相关术语对的集合
AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。,AnchorPROMPT,由组成,相关术语对的集合
术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。,术语对,被定义为,术语比较算法
术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。,术语对,由组成,术语比较算法
AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。,AnchorPROMPT算法,被定义为,根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对
AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。,AnchorPROMPT算法,目标,进一步分析异构本体的结构，产生新的语义相关术语对
AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。,AnchorPROMPT算法,由组成,根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对
AnchorPROMPT将每个本体O视为一个带边有向图G。,AnchorPROMPT,被定义为,将每个本体O视为一个带边有向图G
AnchorPROMPT将每个本体O视为一个带边有向图G。,AnchorPROMPT,由组成,每个本体O视为一个带边有向图G
AnchorPROMPT将每个本体O视为一个带边有向图G。,AnchorPROMPT,由组成,每个本体O视为一个带边有向图G
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,O,被定义为,图
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,O,由组成,每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,O,实现,实现
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,实现,属于,实现
图中通过一条边连接的两节点称为相邻节点。,图,被定义为,图中通过一条边连接的两节点
图中通过一条边连接的两节点称为相邻节点。,图中通过一条边连接的两节点,由组成,相邻节点
如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。,路径,被定义为,从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。
如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。,路径,由组成,节点A和节点B
路径的长度是边的数目。,路径,被定义为,边的数目
路径的长度是边的数目。,路径的长度,由组成,边的数目
为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。,AnchorPROMPT,包含,异构本体
为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。,AnchorPROMPT,由组成,遍历异构本体中由“锚”限定的对应路径
为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。,AnchorPROMPT,由组成,遍历异构本体中由“锚”限定的对应路径
AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。,AnchorPROMPT,由组成,遍历异构本体中由“锚”限定的对应路径
AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。,AnchorPROMPT,由组成,沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。
AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。,AnchorPROMPT,由组成,沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。
因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。,AnchorPROMPT算法,被定义为,根据最初给定的相关术语对的小集合，产生本体间大量可能的语义相似术语对
因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。,AnchorPROMPT算法,由组成,相关术语对
因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。,AnchorPROMPT算法,由组成,相关术语对
②AnchorPROMPT算法。,AnchorPROMPT算法,被定义为,基于文本的实体识别
②AnchorPROMPT算法。,AnchorPROMPT算法,由组成,AnchorPROMPT
②AnchorPROMPT算法。,AnchorPROMPT算法,由组成,AnchorPROMPT
为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。,AnchorPROMPT算法,由组成,AnchorPROMPT
为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。,AnchorPROMPT算法,由组成,AnchorPROMPT
为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。,AnchorPROMPT,由组成,AnchorPROMPT
为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。,AnchorPROMPT,由组成,AnchorPROMPT
"对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。",TRIAL,被定义为,Trial
"对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。",TRIAL,由组成,Trial
这样的术语对利用基本的术语比较技术能很容易识别出来。,术语,被定义为,利用基本的术语比较技术能很容易识别出来
这样的术语对利用基本的术语比较技术能很容易识别出来。,术语,由组成,基本的术语比较技术
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,算法,包含,相关术语对
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,算法,由组成,相关术语对
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,相关术语对,实现,算法
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,相关术语对,属于,算法
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,由组成,PERSON
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,由组成,PERSON
在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。,路径长度限制,包含,路径长度限制
在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。,路径长度限制,被定义为,路径长度限制
在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。,路径长度限制,由组成,路径长度限制
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path1,被定义为,路径
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path1,由组成,PROTOCOL→STUDY-SITE→PERSON
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path1,由组成,PROTOCOL→STUDY-SITE→PERSON
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,包含,路径
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,被定义为,增加路径中同一位置的一对术语的相似度分数
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,由组成,增加路径中同一位置的一对术语的相似度分数
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,由组成,增加路径中同一位置的一对术语的相似度分数
"在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。",PROTOCOL,被定义为,Design
AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。,AnchorPROMPT算法,被定义为,重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。
AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。,AnchorPROMPT算法,由组成,AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,术语对间的相似度分数,被定义为,结果
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,结果,由组成,相似度分数
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,结果,实现,相似度分数
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,相似度分数,属于,术语对
（a）等价组。,等价组,被定义为,等价关系
（a）等价组。,等价组,由组成,等价类
（a）等价组。,等价组,由组成,等价类
在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。,AnchorPROMPT,包含,连接概念间的继关系和普通关系
在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。,AnchorPROMPT,由组成,区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。
与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。,Is-a关系,被定义为,连接着已经相似的概念
与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。,Is-a关系,由组成,PROTOCOL
AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。,AnchorPROMPT算法,被定义为,将这种通过Is-a关系连接的概念作为一个等价组看待
AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。,AnchorPROMPT算法,由组成,这种通过Is-a关系连接的概念
等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。,AnchorPROMPT算法,被定义为,概念
等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。,AnchorPROMPT算法,由组成,概念
图5-5路径中的等价组（b）相似度分数。,路径,被定义为,相似度分数
图5-5路径中的等价组（b）相似度分数。,图5-5路径中的等价组（b）相似度分数。,由组成,相似度分数
图5-5路径中的等价组（b）相似度分数。,图5-5路径中的等价组（b）相似度分数。,实现,实现
图5-5路径中的等价组（b）相似度分数。,实现,属于,实现
"给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。",来自本体O1中的概念C1,被定义为,来自本体O2中的概念C2
"给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。",给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2,由组成,"计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚"
"给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。",给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2,由组成,"计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚"
步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。,步骤2,被定义为,从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。
步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。,步骤2,由组成,从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。
步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。,相似度,被定义为,X
步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。,步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。,由组成,相似度分
"如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。",相似度分数,被定义为,"S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度"
"如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。",相似度分数,由组成,"S(C1,C2)"
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,比较的节点,包含,等价组
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,当进行比较的节点包含等价组时,由组成,增加相似度分数的情况有所不同
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,实现,当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,属于,当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。
这个问题在接下来的部分进行分析。,特点,被定义为,分析
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT算法,被定义为,生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT算法,由组成,很多可能的相似术语对
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT算法,实现,生成很多可能的相似术语对
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT算法,来源,生成很多可能的相似术语对
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT算法,属于,生成很多可能的相似术语对
③AnchorPROMPT评估。,AnchorPROMPT评估,被定义为,评估方法
③AnchorPROMPT评估。,AnchorPROMPT评估,由组成,AnchorPROMPT
③AnchorPROMPT评估。,AnchorPROMPT评估,由组成,AnchorPROMPT
Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。,Noy_N_F等人,被定义为,AnchorPROMPT
Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。,Noy_N_F,由组成,AnchorPROMPT
（a）等价组大小。,等价组大小,包含,等价组
（a）等价组大小。,等价组大小,由组成,等价组
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,等价组大小最大值,被定义为,0或1
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,等价组大小最大值,由组成,0或1
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
当等价组的最大尺寸为2时，只有12%的试验没有结果。,等价组,被定义为,最大尺寸为2的等价组
当等价组的最大尺寸为2时，只有12%的试验没有结果。,当等价组的最大尺寸为2时,由组成,只有12%的试验没有结果
当等价组的最大尺寸为2时，只有12%的试验没有结果。,当等价组的最大尺寸为2时,实现,只有12%的试验没有结果
当等价组的最大尺寸为2时，只有12%的试验没有结果。,当等价组的最大尺寸为2时,来源,只有12%的试验没有结果
当等价组的最大尺寸为2时，只有12%的试验没有结果。,当等价组的最大尺寸为2时,属于,只有12%的试验没有结果
因此，在随后的试验中设定等价组的最大尺寸大小为2。,等价组,被定义为,2
因此，在随后的试验中设定等价组的最大尺寸大小为2。,等价组,由组成,2
因此，在随后的试验中设定等价组的最大尺寸大小为2。,等价组,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（b）等价组成员的相似度分数。,等价组,被定义为,相似度分数
（b）等价组成员的相似度分数。,等价组成员的相似度分数,由组成,等价组
（b）等价组成员的相似度分数。,等价组成员的相似度分数,实现,等价组成员的相似度分数
（b）等价组成员的相似度分数。,等价组成员的相似度分数,属于,等价组
为评价等价组成员如何打分合理而做了两类试验。,等价组成员如何打分合理,被定义为,两类试验
为评价等价组成员如何打分合理而做了两类试验。,为评价等价组成员如何打分合理而做了两类试验。,由组成,试验
第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。,第二类试验,包含,第一类试验
第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。,第一类试验,由组成,第二类试验
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,对等价组成员打分不同,被定义为,结果的准确率提高14%
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,对等价组成员打分不同,由组成,结果的准确率
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,对等价组成员打分不同,实现,将结果的准确率提高14%
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,试验结果表明,来源,对等价组成员打分不同能将结果的准确率提高14%
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,对等价组成员打分不同能将结果的准确率提高14%,属于,对等价组成员打分不同
（c）锚的数目和路径最大长度。,锚,包含,锚的数目和路径最大长度
（c）锚的数目和路径最大长度。,锚,由组成,锚的数目和路径最大长度
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,知识图谱,包含,知识表示
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,知识图谱,被定义为,知识表示
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,输入的锚数量,由组成,运行时间
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
试验表明，当最大长度路径设为2时，能获得最好的正确率。,最大长度路径,包含,2
试验表明，当最大长度路径设为2时，能获得最好的正确率。,最大长度路径,由组成,2
试验表明，当最大长度路径设为2时，能获得最好的正确率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,实现
试验表明，当最大长度路径设为2时，能获得最好的正确率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,实现
试验表明，当最大长度路径设为2时，能获得最好的正确率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,限制路径最大长度,被定义为,平均正确率
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,限制路径最大长度,由组成,平均正确率
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
④AnchorPROMPT的讨论。,AnchorPROMPT,被定义为,AnchorPROMPT的讨论
④AnchorPROMPT的讨论。,AnchorPROMPT,由组成,由组成
④AnchorPROMPT的讨论。,AnchorPROMPT,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
④AnchorPROMPT的讨论。,AnchorPROMPT,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
④AnchorPROMPT的讨论。,AnchorPROMPT,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。,AnchorPROMPT算法,被定义为,考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似
当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。,AnchorPROMPT算法,由组成,考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似
以此类推，可以得到路径上更多的关系对也是相似的。,路径,被定义为,关系对
以此类推，可以得到路径上更多的关系对也是相似的。,路径,由组成,关系对
实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。,AnchorPROMPT算法,被定义为,基于这样的假设：本体中相似的术语通常也通过相似的关系连接
实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。,AnchorPROMPT算法,由组成,基于这样的假设
实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。,AnchorPROMPT算法,由组成,基于这样的假设
在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。,路径长度,被定义为,随着路径的过长
在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。,路径长度,由组成,生成结果的精度
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径长度,包含,路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径长度,由组成,路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径长度,由组成,路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。
AnchorPROMPT其他方面的讨论如下。,AnchorPROMPT,被定义为,其他方面的讨论
AnchorPROMPT其他方面的讨论如下。,AnchorPROMPT,由组成,其他方面的讨论如下。
AnchorPROMPT其他方面的讨论如下。,AnchorPROMPT其他方面的讨论如下。,实现,实现
AnchorPROMPT其他方面的讨论如下。,AnchorPROMPT其他方面的讨论如下。,属于,实现
（a）减少负面结果的影响。,减少负面结果的影响,被定义为,减少负面结果的影响
（a）减少负面结果的影响。,减少负面结果的影响。,由组成,缺点
概念间的相似度分数是一个累加值。,概念间的相似度分数,被定义为,累加值
概念间的相似度分数是一个累加值。,概念间的相似度分数,由组成,累加值
概念间的相似度分数是一个累加值。,概念间的相似度分数,由组成,累加值
两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。,两个不相关的术语,被定义为,出现在某一对路径的相同位置
两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。,两个不相关的术语可能出现在某一对路径的相同位置,由组成,概率很小
两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。,两个不相关的术语可能出现在某一对路径的相同位置,实现,对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小
AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。,AnchorPROMPT,包含,累加遍历所有路径过程中对应概念对的相似度分数
AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。,AnchorPROMPT,由组成,累加遍历所有路径过程中对应概念对的相似度分数
AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。,AnchorPROMPT,由组成,累加遍历所有路径过程中对应概念对的相似度分数
试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。,相似度分数,被定义为,阈值
试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。,相似度分数,由组成,阈值
试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。,AnchorPROMPT,包含,去除大多数的这类术语对
试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。,AnchorPROMPT,由组成,去除大多数的这类术语对
试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。,AnchorPROMPT,由组成,去除大多数的这类术语对
（b）执行本体映射。,本体映射,被定义为,将本体中的概念和属性映射到知识图谱中的实体和属性
（b）执行本体映射。,执行本体映射,由组成,本体映射
（b）执行本体映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,本体映射
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,本体映射
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,本体映射
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,AnchorPROMPT,由组成,建立术语之间的映射
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,AnchorPROMPT,由组成,建立术语之间的映射
（c）局限性。,局限性,被定义为,知识图谱的局限性
（c）局限性。,局限性,由组成,由组成
AnchorPROMPT的映射发现方法并非适用于所有的本体。,AnchorPROMPT的映射发现方法,被定义为,适用于所有的本体
AnchorPROMPT的映射发现方法并非适用于所有的本体。,AnchorPROMPT的映射发现方法,由组成,并非适用于所有的本体
AnchorPROMPT的映射发现方法并非适用于所有的本体。,AnchorPROMPT的映射发现方法,实现,适用于所有的本体
AnchorPROMPT的映射发现方法并非适用于所有的本体。,AnchorPROMPT的映射发现方法,属于,AnchorPROMPT
当两个本体间的结构差别很大时，该方法处理的效果并不好。,本体间结构差别,被定义为,该方法处理的效果并不好
当两个本体间的结构差别很大时，该方法处理的效果并不好。,当两个本体间的结构差别很大时,方法,该方法处理的效果并不好
当两个本体间的结构差别很大时，该方法处理的效果并不好。,当两个本体间的结构差别很大时,由组成,该方法处理的效果并不好
当两个本体间的结构差别很大时，该方法处理的效果并不好。,当两个本体间的结构差别很大时，该方法处理的效果并不好。,实现,当两个本体间的结构差别很大时，该方法处理的效果并不好。
当两个本体间的结构差别很大时，该方法处理的效果并不好。,当两个本体间的结构差别很大时，该方法处理的效果并不好。,属于,当两个本体间的结构差别很大时，该方法处理的效果并不好。
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,包含,领域描述
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,被定义为,当两个本体对领域描述得比较深入时
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,由组成,当两个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
⑤AnchorPROMPT的总结。,AnchorPROMPT,被定义为,AnchorPROMPT的总结
⑤AnchorPROMPT的总结。,AnchorPROMPT,由组成,由Anchor和PROMPT组成
⑤AnchorPROMPT的总结。,AnchorPROMPT,由组成,由Anchor和PROMPT组成
AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。,AnchorPROMPT,被定义为,基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。
AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。,AnchorPROMPT,由组成,基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。
由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。,AnchorPROMPT算法,被定义为,由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。
由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。,AnchorPROMPT算法,由组成,只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射
对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。,AnchorPROMPT,被定义为,复杂概念或复杂关系间的本体映射
对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。,AnchorPROMPT,由组成,无法处理复杂概念或复杂关系间的本体映射
对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。,AnchorPROMPT,由组成,无法处理复杂概念或复杂关系间的本体映射
从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。,AnchorPROMPT算法,被定义为,基于一种直观的经验，缺乏严格的理论依据
从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。,AnchorPROMPT算法,由组成,基于一种直观的经验，缺乏严格的理论依据
从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。,AnchorPROMPT算法,属于,基于一种直观的经验，缺乏严格的理论依据
2）iPROMPT。,iPROMPT,被定义为,知识图谱中用于表示实体和实体之间关系的三元组
2）iPROMPT。,iPROMPT,由组成,iPrompt
2）iPROMPT。,iPROMPT,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。,PROMPT工具,被定义为,iPROMPT
PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。,PROMPT工具,由组成,iPROMPT
iPROMPT从语言角度判断本体间概念或关系的相似。,iPROMPT,被定义为,从语言角度判断本体间概念或关系的相似。
iPROMPT从语言角度判断本体间概念或关系的相似。,iPROMPT,由组成,从语言角度判断本体间概念或关系的相似。
iPROMPT从语言角度判断本体间概念或关系的相似。,iPROMPT,实现,从语言角度判断本体间概念或关系的相似
iPROMPT从语言角度判断本体间概念或关系的相似。,iPROMPT,属于,从语言角度判断本体间概念或关系的相似
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,本体合并,包含,合并算法
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,本体合并,被定义为,以这些初始的术语相似为基础，执行合并算法完成本体合并的任务
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,合并算法,由组成,初始的术语相似
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,本体合并,实现,合并算法
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,本体合并,属于,本体合并
在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。,iPROMPT,被定义为,本体合并
在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。,iPROMPT,由组成,本体合并
图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,iPROMPT,被定义为,基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。
图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,iPROMPT,由组成,基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。
图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,iPROMPT,由组成,基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。
iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。,iPROMPT,被定义为,合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等
iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。,iPROMPT,由组成,合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等
步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。,步骤2,被定义为,从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。
步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。,步骤2,由组成,合并建议列表
当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。,iPROMPT,被定义为,检查合并后本体中的不一致性和潜在问题
当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。,iPROMPT,由组成,检查合并后本体中的不一致性和潜在问题
合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。,合并后的本体,被定义为,每个术语名字必须是唯一的
合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。,合并后的本体中的每个术语名字必须是唯一的,由组成,合并后的本体中的每个术语名字必须是唯一的
这样的冲突可以通过重命名来解决。,冲突,被定义为,重命名
这样的冲突可以通过重命名来解决。,重命名,由组成,冲突
②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。,属性,被定义为,拷贝属性
②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。,当在本体间拷贝属性时,由组成,不一致问题
②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。,当在本体间拷贝属性时,由组成,不一致问题
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,本体,被定义为,概念
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,删除这些概念,由组成,本体
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。
③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。,概念继承冗余,被定义为,本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。
③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。,概念继承冗余,由组成,本体合并
对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。,iPROMPT,被定义为,删除一些多余的概念
对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。,iPROMPT,由组成,删除一些多余的概念
对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。,iPROMPT,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。,iPROMPT算法,包含,准确率和召回率
Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。,Noy_N_F等人,由组成,iPROMPT算法
Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。,Noy_N_F等人,由组成,iPROMPT算法
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,iPROMPT,包含,准确率
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,准确率,由组成,用户遵循iPROMPT给出的建议占所有建议的比例
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,准确率,由组成,用户遵循iPROMPT给出的建议占所有建议的比例
试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。,iPROMPT算法,被定义为,试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。
试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。,iPROMPT算法,由组成,平均准确率
试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。,iPROMPT算法,由组成,平均准确率
总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。,iPROMPT,被定义为,利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射
总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。,iPROMPT,由组成,利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射
总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。,iPROMPT,由组成,利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射
3）MAFRA。,MAFRA,被定义为,知识图谱
3）MAFRA。,MAFRA,由组成,知识图谱
MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。,MAFRA,包含,处理语义Web上分布式本体间映射的一个框架
MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。,MAFRA,由组成,处理语义Web上分布式本体间映射的一个框架
MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。,MAFRA,由组成,处理语义Web上分布式本体间映射的一个框架
MAFRA引入了语义桥和以服务为中心的思想。,MAFRA,被定义为,语义桥和以服务为中心的思想
MAFRA引入了语义桥和以服务为中心的思想。,MAFRA,由组成,语义桥和以服务为中心的思想
语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。,语义桥,由组成,异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务
语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。,语义桥,由组成,异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务
MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。,MAFRA体系结构,被定义为,水平方向和垂直方向的两个模块组成
MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。,MAFRA体系结构,由组成,水平方向和垂直方向的两个模块组成
MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。,MAFRA体系结构,由组成,水平方向和垂直方向的两个模块组成
要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。,本体,被定义为,统一形式
要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。,要求各个本体必须表示为一个统一形式（如RDF、OWL等）,由组成,消除不同源本体之间语法和语言上的差异
要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。,要求各个本体必须表示为一个统一形式（如RDF、OWL等）,由组成,消除不同源本体之间语法和语言上的差异
MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。,MAFRA,被定义为,正规化过程
MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。,MAFRA,由组成,MAFRA的正规化过程
MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。,MAFRA,由组成,MAFRA的正规化过程
②相似度。,相似度,被定义为,相似度计算
②相似度。,相似度,由组成,相似度计算
②相似度。,相似度,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。,MAFRA,被定义为,利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。
MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。,MAFRA,由组成,多种基本的术语或结构相似度方法
在计算概念间关系的过程中还考虑了概念的属性。,计算概念间关系,被定义为,概念的属性
在计算概念间关系的过程中还考虑了概念的属性。,计算概念间关系,由组成,概念的属性
在计算概念间关系的过程中还考虑了概念的属性。,计算概念间关系,由组成,概念的属性
③语义桥。,计算概念间关系,由组成,概念的属性
③语义桥。,语义桥,由组成,语义网
③语义桥。,语义桥,由组成,语义网
根据本体成分间的相似度，利用语义桥来表示本体映射。,本体映射,被定义为,利用语义桥来表示本体映射。
根据本体成分间的相似度，利用语义桥来表示本体映射。,本体映射,由组成,语义桥
根据本体成分间的相似度，利用语义桥来表示本体映射。,根据本体成分间的相似度，利用语义桥来表示本体映射。,实现,根据本体成分间的相似度，利用语义桥来表示本体映射。
根据本体成分间的相似度，利用语义桥来表示本体映射。,根据本体成分间的相似度，利用语义桥来表示本体映射。,属于,根据本体成分间的相似度，利用语义桥来表示本体映射。
这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。,语义桥,被定义为,表示概念桥和属性桥
这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。,语义桥,由组成,表示概念桥和属性桥
还能利用推理建立一些隐含的语义桥。,知识图谱,被定义为,利用推理建立一些隐含的语义桥
还能利用推理建立一些隐含的语义桥。,推理,由组成,隐含的语义桥
还能利用推理建立一些隐含的语义桥。,知识图谱,实现,知识表示
还能利用推理建立一些隐含的语义桥。,知识图谱,来源,知识表示
还能利用推理建立一些隐含的语义桥。,知识图谱,属于,知识表示
④执行。,执行,被定义为,执行过程
④执行。,执行,由组成,执行器
在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。,语义桥,被定义为,利用语义桥中的映射规则完成实例转换或属性转换
在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。,语义桥,被定义为,利用语义桥中的映射规则完成实例转换或属性转换
在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。,语义桥,由组成,本体间交互
⑤后处理。,后处理,由组成,后处理算法
⑤后处理。,⑤后处理,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。,映射执行,被定义为,转换结果
映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。,映射执行产生的转换结果,由组成,需要进一步处理
映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。,映射执行产生的转换结果,由组成,需要进一步处理
垂直方向四个模块具体包括：①演化。,垂直方向,被定义为,演化
垂直方向四个模块具体包括：①演化。,垂直方向四个模块,由组成,演化
当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。,语义桥,被定义为,本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。
当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。,语义桥,由组成,本体
②协同创建。,协同创建,被定义为,知识图谱的创建方式
②协同创建。,协同创建,由组成,协同工作
②协同创建。,协同创建,由组成,协同工作
对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。,本体映射,被定义为,通过多个用户协商，选择一致的映射方案
对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。,本体映射,由组成,多个不同的映射建议
对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。,本体映射,由组成,多个不同的映射建议
③领域限制和背景知识。,领域限制和背景知识,被定义为,领域限制
③领域限制和背景知识。,领域限制和背景知识,由组成,领域限制
给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。,领域限制,由组成,避免生成不必要的映射
给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。,领域限制,由组成,避免生成不必要的映射
④用户界面交互。,用户界面交互,被定义为,用户界面交互是用户与系统之间进行信息交换的接口
④用户界面交互。,用户界面交互,由组成,缺点
给出图形化的操作界面能让本体建立的过程更容易。,本体建立,包含,图形化的操作界面
给出图形化的操作界面能让本体建立的过程更容易。,本体建立,被定义为,图形化的操作界面
给出图形化的操作界面能让本体建立的过程更容易。,图形化的操作界面,由组成,本体建立
给出图形化的操作界面能让本体建立的过程更容易。,给出图形化的操作界面,实现,本体建立的过程更容易
给出图形化的操作界面能让本体建立的过程更容易。,给出图形化的操作界面,属于,本体建立的过程更容易
图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。,MAFRA,被定义为,本体映射方法学
图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。,MAFRA,由组成,概念桥和属性桥
尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。,MAFRA,被定义为,通过手工建立一些复杂的映射
尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。,MAFRA,由组成,缺乏自己特有的映射发现技术
因此，MAFRA更多只是一个处理异构本体映射的框架。,MAFRA,被定义为,处理异构本体映射的框架
因此，MAFRA更多只是一个处理异构本体映射的框架。,MAFRA,由组成,处理异构本体映射的框架
因此，MAFRA更多只是一个处理异构本体映射的框架。,MAFRA,属于,处理异构本体映射的框架
4）ONION。,ONION,被定义为,洋葱
4）ONION。,ONION,由组成,ONION
4）ONION。,ONION,由组成,ONION
ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。,ONION,被定义为,Mitra_P等人设计的一个解决本体互操作的系统
ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。,ONION,由组成,Mitra_P等人设计的一个解决本体互操作的系统
该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。,本体互操作,被定义为,半自动算法
该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。,本体互操作,由组成,半自动算法
为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。,ONION,被定义为,图的形式表示本体
为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。,ONION,由组成,图的形式表示本体
为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。,ONION,由组成,图的形式表示本体
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,ONION,由组成,图的形式表示本体
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,ONION,由组成,图的形式表示本体
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,ONION,由组成,图的形式表示本体
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,ONION,由组成,图的形式表示本体
本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。,本体映射,包含,生成算法
本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。,本体映射,被定义为,生成算法
本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。,本体映射,由组成,生成算法
专家还可以添加新的映射，以补充算法无法生成的映射规则。,专家还可以添加新的映射,被定义为,补充算法无法生成的映射规则
专家还可以添加新的映射，以补充算法无法生成的映射规则。,专家,由组成,添加新的映射
专家还可以添加新的映射，以补充算法无法生成的映射规则。,专家还可以添加新的映射,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
ONION的映射生成过程同时使用了术语匹配和本体图匹配。,ONION映射生成过程,包含,术语匹配和本体图匹配
ONION的映射生成过程同时使用了术语匹配和本体图匹配。,ONION,由组成,术语匹配和本体图匹配
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,被定义为,几个算法结果的综合
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,由组成,置信度
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,实现,综合
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,来源,综合
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,属于,综合
在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,计算两个本体的映射,包含,比较两个本体之间所有可能的术语对
在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,由组成,在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。
在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,属于,在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。
为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。,ONION,被定义为,窗口算法
为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。,ONION,由组成,窗口算法
为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。,ONION,由组成,窗口算法
在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。,窗口对,被定义为,比较只在那些可能会有映射的窗口对之间进行
在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。,在发现映射的过程中,由组成,并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。
“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。,窗口算法,包含,比较过程的时间复杂度
“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。,窗口算法,被定义为,降低比较过程的时间复杂度
“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。,窗口算法,由组成,比较过程的时间复杂度
“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。,窗口算法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。,非迭代算法,被定义为,利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。
①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。,非迭代算法,由组成,利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。
在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。,相似度算法,被定义为,阈值
在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。,相似度,由组成,阈值
在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。,相似度算法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。,相似度算法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。,非迭代算法,由组成,词典
同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。,非迭代算法,由组成,词典
②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。,迭代算法,被定义为,迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。
②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。,迭代算法,由组成,迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。
Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。,Nexus,包含,子图比较技术
Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。,Nexus,被定义为,子图比较技术
Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。,Nexus,由组成,ONION
Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。,Nexus,由组成,ONION
因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。,迭代算法,被定义为,基本匹配器生成的结果
因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。,迭代算法,由组成,基本匹配器
因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。,迭代算法,属于,基本匹配器
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,ONION算法,包含,映射精度
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,ONION算法,被定义为,映射精度
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,ONION算法,由组成,映射精度
试验还表明，在映射发现过程中采用多种策略能提高精度。,映射发现,被定义为,在映射发现过程中采用多种策略能提高精度。
试验还表明，在映射发现过程中采用多种策略能提高精度。,映射发现,由组成,多种策略
试验还表明，在映射发现过程中采用多种策略能提高精度。,试验,实现,多种策略
试验还表明，在映射发现过程中采用多种策略能提高精度。,试验,属于,多种策略
ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。,ONION,被定义为,原子概念之间的等价关系
ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。,ONION,由组成,原子概念
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng和Xu_Baowen的方法,被定义为,基于知识图谱的语义搜索
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng,方法,Xu_Baowen
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng和Xu_Baowen的方法,由组成,Wang_Peng和Xu_Baowen
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng和Xu_Baowen的方法,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng和Xu_Baowen的方法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。,Wang_Peng,被定义为,Xu_Baowen
Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。,Wang_Peng,由组成,Xu_Baowen
该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。,本体概念相似度,被定义为,寻找异构本体概念间的关系
该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。,该方法,方法,借助各种本体概念相似度的度量
该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。,该方法,由组成,借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,概念间语义关系,被定义为,概念名、概念属性和概念在本体中的上下文
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,概念间语义关系,方法,概念名、概念属性和概念在本体中的上下文
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,该方法,由组成,概念间的语义关系
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,该方法,由组成,概念间的语义关系
这种方法认为不同本体间概念的相似度包括三个部分：①概念的同义词集相似度。,本体间概念的相似度,被定义为,概念的同义词集相似度
同义词集是语义相同或相近词的分组[38]。,同义词集,由组成,语义相同或相近词的分组
同义词集是语义相同或相近词的分组[38]。,同义词集,由组成,语义相同或相近词的分组
基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。,同义词集,由组成,语义相同或相近词的分组
基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。,基于同名或同义词集的概念,由组成,相似度
基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。,基于同名或同义词集的概念,由组成,相似度
②概念特征上的相似度。,概念特征上的相似度,被定义为,概念特征上的相似度
②概念特征上的相似度。,概念特征上的相似度,由组成,概念相似度
概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。,概念,包含,概念的属性、概念附带的关系以及属性和关系取值的限制
概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。,概念的特征,被定义为,概念的属性、概念附带的关系以及属性和关系取值的限制
概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。,概念的特征,由组成,概念的属性、概念附带的关系以及属性和关系取值的限制
③概念上下文上的相似度。,概念上下文上的相似度,被定义为,概念相似度
③概念上下文上的相似度。,概念上下文上的相似度,由组成,概念相似度
③概念上下文上的相似度。,概念上下文上的相似度,由组成,概念相似度
以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。,相似度,被定义为,基于概念自身的相似度
以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。,相似度,由组成,基于概念自身的相似度
以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。,相似度,属于,基于概念自身的相似度
以下定义概念的语义邻居概念集。,相似度,属于,基于概念自身的相似度
式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。,知识图谱,包含,概念间的距离
式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。,概念间的距离,被定义为,d
式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。,距离,由组成,d
这里的关系包含直接继承关系。,关系,被定义为,直接继承关系
这里的关系包含直接继承关系。,关系,由组成,直接继承关系
d≤r表明与当前的概念在语义距离上小于某一定常数。,d≤r,包含,与当前的概念在语义距离上小于某一定常数
d≤r表明与当前的概念在语义距离上小于某一定常数。,d≤r,由组成,与当前的概念在语义距离上小于某一定常数
"在以上分析的基础上，给出了本体间概念相似度的计算公式：S(Cp,Cq)=Ww×Sw(Cp,Cq)+Wu×Su(Cp,Cq)+Wn×Sn(Cp,Cq)式中，Ww、Wu和Wn是权重；Sw、Su和Sn分别代表概念名称、特征以及上下文三方面的相似性度量。",相似性度量,由组成,Sw、Su和Sn
"计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。",计算采用Tverski_A定义的非对称的相似度度量,包含,非对称的相似度度量
"计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。",计算采用Tverski_A定义的非对称的相似度度量,被定义为,非对称的相似度度量
"计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。",计算采用Tverski_A定义的非对称的相似度度量,由组成,"式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。"
"计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。",计算采用Tverski_A定义的非对称的相似度度量,由组成,"式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。"
该方法利用概念间的相似度辅助本体映射的生成。,本体映射,被定义为,概念间的相似度
该方法利用概念间的相似度辅助本体映射的生成。,概念间的相似度辅助本体映射的生成,方法,该方法
该方法利用概念间的相似度辅助本体映射的生成。,概念间的相似度,由组成,本体映射的生成
"①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。",概念,被定义为,相同名称、相同特征和相同上下文
通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。,相似度,被定义为,概念相似度
通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。,相似度,由组成,相似度
②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。,同一本体中父概念与子概念的相似度,被定义为,小于子概念与父概念的相似度
②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。,同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度,由组成,同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,等价关系,被定义为,概念上的等价关系和上/下义关系两种映射
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,等价关系,由组成,上/下义关系
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,等价关系,属于,上/下义关系
生成规则如下。,生成规则,被定义为,生成规则如下
生成规则如下。,生成规则,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",不同本体中两概念,被定义为,互相相似度
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",定义5.7,由组成,"(Oa:Ci,Ob:Cj))"
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",定义5.7,属于,等价
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,AddBridge,被定义为,添加一个映射的操作
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,AddBridge,由组成,添加一个映射的操作
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,BCequal,由组成,两个概念等价
式中，isa表示两概念具有上义和下义关系。,isa,被定义为,两概念具有上义和下义关系
式中，isa表示两概念具有上义和下义关系。,isa,由组成,上义和下义关系
式中，isa表示两概念具有上义和下义关系。,isa,属于,两概念具有上义和下义关系
从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。,概念映射,被定义为,从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系
从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。,概念映射,由组成,简单映射
6）S-Match。,S-Match,被定义为,基于图匹配的文本匹配方法
6）S-Match。,S-Match,由组成,S-Match
6）S-Match。,S-Match,由组成,S-Match
S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。,S-Match,被定义为,本体匹配系统
S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。,S-Match,由组成,本体匹配系统
S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。,S-Match,被定义为,基于本体抽象层的概念继承结构树，不考虑本体中的实例。
S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。,S-Match,由组成,基于本体抽象层的概念继承结构树，不考虑本体中的实例。
S-Match的核心是计算异构本体间的语义关系。,S-Match,被定义为,计算异构本体间的语义关系
S-Match的核心是计算异构本体间的语义关系。,S-Match,由组成,计算异构本体间的语义关系
输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。,本体树,被定义为,XML编码
输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。,输入的本体树结构,由组成,标准的XML格式编码
输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。,输入的本体树结构,由组成,标准的XML格式编码
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,包含,WordNet
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,方法,WordNet
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,由组成,WordNet
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,由组成,WordNet
执行结果的输出是一个被丰富的树。,执行结果的输出,被定义为,被丰富的树
执行结果的输出是一个被丰富的树。,执行结果的输出,由组成,被丰富的树
执行结果的输出是一个被丰富的树。,执行结果的输出,由组成,被丰富的树
然后，用户协调两本体的匹配过程，这种方法使用三个外部库。,用户协调两本体的匹配过程,被定义为,使用三个外部库
然后，用户协调两本体的匹配过程，这种方法使用三个外部库。,用户协调两本体的匹配过程,由组成,三个外部库
第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。,弱语义元素匹配器,包含,字符串操作
第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。,弱语义元素匹配器,由组成,字符串操作
目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。,S-Match,由组成,弱语义的元素层次匹配器
目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。,S-Match,由组成,弱语义的元素层次匹配器
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,包含,WordNet
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,由组成,强语义的元素层次匹配器
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,实现,WordNet
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,属于,WordNet
第三个库是由结构层次的强语义匹配器组成的。,第三个库,被定义为,由结构层次的强语义匹配器组成的
第三个库是由结构层次的强语义匹配器组成的。,第三个库,由组成,由结构层次的强语义匹配器组成的
第三个库是由结构层次的强语义匹配器组成的。,第三个库,由组成,由结构层次的强语义匹配器组成的
"输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。",S-Match算法,被定义为,"对给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。"
"输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。",S-Match算法,由组成,4步
"输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。",S-Match算法,由组成,4步
其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。,节点标签,被定义为,一种内部的形式化形式
其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。,节点标签,由组成,一种内部的形式化形式
"<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。",Wine,被定义为,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。
"<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。",Wine,由组成,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。
"<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。",Wine,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。,扩展节点标签的含义,被定义为,捕获树结构中的知识，定义节点中概念的上下文
扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。,扩展节点标签的含义,由组成,捕获树结构中的知识，定义节点中概念的上下文
扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。,扩展节点标签的含义,由组成,捕获树结构中的知识，定义节点中概念的上下文
步骤3：对所有T1和T2中的标签对，计算标签间的关系。,步骤3：对所有T1和T2中的标签对，计算标签间的关系。,被定义为,标签间的关系
步骤3：对所有T1和T2中的标签对，计算标签间的关系。,步骤3：对所有T1和T2中的标签对，计算标签间的关系。,由组成,标签间的关系
利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。,元素层次语义匹配器,被定义为,利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。
利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。,元素层次语义匹配器,由组成,概念间的关系
步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,被定义为,节点对
步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,由组成,计算节点上的概念间的关系
将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。,概念匹配,被定义为,将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。
将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。,概念间的关系,由组成,匹配问题
与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。,S-Match,包含,基于术语和结构的本体映射系统
与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。,S-Match,由组成,基于术语和结构的本体映射系统
与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。,S-Match,由组成,基于术语和结构的本体映射系统
7）Cupid。,Cupid,被定义为,爱情
7）Cupid。,Cupid,由组成,Cupid
7）Cupid。,Cupid,由组成,Cupid
Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。,Cupid系统,包含,通用的模式匹配算法
Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。,Cupid系统,由组成,一个通用的模式匹配算法
该方法输入图格式的模式，图节点表示模式中的元素。,图模式,被定义为,图格式的模式，图节点表示模式中的元素。
该方法输入图格式的模式，图节点表示模式中的元素。,该方法,方法,输入图格式的模式，图节点表示模式中的元素。
该方法输入图格式的模式，图节点表示模式中的元素。,该方法,由组成,输入图格式的模式，图节点表示模式中的元素。
该方法输入图格式的模式，图节点表示模式中的元素。,该方法,属于,图格式的模式
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,包含,混合方法
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,被定义为,混合方法
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,由组成,与其他的混合方法比较
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,实现,与其他的混合方法比较
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,来源,与其他的混合方法比较
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,属于,与其他的混合方法比较
发现模式匹配的算法包含三个阶段。,发现模式匹配的算法,包含,三个阶段
发现模式匹配的算法包含三个阶段。,发现模式匹配的算法,由组成,三个阶段
发现模式匹配的算法包含三个阶段。,发现模式匹配的算法,由组成,三个阶段
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,语言匹配,由组成,计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,结构匹配,由组成,计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,语言匹配,实现,计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,语言匹配,来源,计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,语言匹配,属于,计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法
Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。,Cupid,被定义为,针对数据库模式
Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。,Cupid,由组成,针对数据库模式
8）其他方法。,其他方法,被定义为,其他方法
8）其他方法。,其他方法,由组成,其他方法
8）其他方法。,其他方法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Chimaera是一个合并和测试大本体的环境[43]。,Chimaera,包含,合并和测试大本体的环境
Chimaera是一个合并和测试大本体的环境[43]。,Chimaera,被定义为,合并和测试大本体的环境
Chimaera是一个合并和测试大本体的环境[43]。,Chimaera,由组成,合并和测试大本体的环境
Chimaera是一个合并和测试大本体的环境[43]。,Chimaera,由组成,合并和测试大本体的环境
寻找本体映射是进行合并操作的一个主要任务。,本体映射,被定义为,寻找本体映射
寻找本体映射是进行合并操作的一个主要任务。,本体映射,由组成,本体映射
Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。,Chimaera,包含,术语对
Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。,Chimaera,由组成,术语对匹配
BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。,BUSTER,包含,改善信息检索的语义转换中间件
BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。,BUSTER,由组成,德国不来梅大学
BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。,BUSTER,由组成,德国不来梅大学
BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。,BUSTER,被定义为,异构信息源的集成
BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。,BUSTER,由组成,异构信息源的集成
BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。,BUSTER,由组成,异构信息源的集成
它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。,本体,被定义为,不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。
它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。,本体,由组成,词汇
它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。,本体,属于,本体间信息查询
因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。,BUSTER,被定义为,异构信息源查询
因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。,BUSTER,由组成,建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。
因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。,BUSTER,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,包含,模式匹配系统
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,被定义为,综合的通用匹配器
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,由组成,模式匹配系统
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,由组成,模式匹配系统
COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。,COMA,被定义为,一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台
COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。,COMA,由组成,一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。
COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。,COMA,由组成,一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。
它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。,SPO,包含,匹配库
它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。,SPO,由组成,匹配库
面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。,面向重用的匹配器,包含,其他匹配器得到的结果
面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。,面向重用的匹配器,被定义为,重用其他匹配器得到的结果来得到更好的映射
面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。,面向重用的匹配器,由组成,其他匹配器得到的结果
模式被编码为有向无环图。,模式,被定义为,有向无环图
模式被编码为有向无环图。,模式,由组成,有向无环图
模式被编码为有向无环图。,模式,由组成,有向无环图
COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。,COMA,被定义为,支持在匹配过程中与用户进行交互，提高匹配结果的准确率。
COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。,COMA,由组成,支持在匹配过程中与用户进行交互，提高匹配结果的准确率。
ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。,ASCO原型,被定义为,识别不同本体间相关元素对的算法
ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。,ASCO原型,由组成,识别不同本体间相关元素对的算法
ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。,ASCO,被定义为,使用本体中包含的可用信息来处理映射
ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。,ASCO,由组成,本体
ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。,ASCO,由组成,本体
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,概念相似度计算,被定义为,语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,该方法,方法,语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,该方法的匹配过程,由组成,几个阶段
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,该方法的匹配过程,实现,语言阶段
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,该方法的匹配过程,来源,语言阶段
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,该方法的匹配过程,属于,语言阶段
（3）基于术语和结构的本体映射总结。,该方法的匹配过程,实现,语言阶段
（3）基于术语和结构的本体映射总结。,该方法的匹配过程,来源,语言阶段
（3）基于术语和结构的本体映射总结。,该方法的匹配过程,属于,语言阶段
（3）基于术语和结构的本体映射总结。,基于术语和结构的本体映射,由组成,术语和结构的本体映射
（3）基于术语和结构的本体映射总结。,基于术语和结构的本体映射,实现,基于术语和结构的本体映射总结
（3）基于术语和结构的本体映射总结。,基于术语和结构的本体映射,属于,基于术语和结构的本体映射总结
这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。,基于直观的思想,被定义为,这一类方法
这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。,基于直观的思想,由组成,这一类方法
2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。,基于实例的本体映射,被定义为,通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。
2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。,基于实例的本体映射,由组成,发现方法
（1）技术综述。,技术综述,被定义为,技术综述是技术领域中的一种综述，它是对技术领域中某一主题的全面、系统、深入的分析。
（1）技术综述。,技术综述,由组成,由组成
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,被定义为,本体概念间存在共享实例和概念之间没有共享实例
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,由组成,两种情况
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,属于,基于实例的本体映射技术
①共享实例的方法。,共享实例的方法,被定义为,共享实例的方法
①共享实例的方法。,共享实例,方法,方法
①共享实例的方法。,共享实例的方法,由组成,共享实例
当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。,测试实例集合的交,被定义为,共享实例
当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。,来自不同本体的两概念,由组成,寻找它们之间关系最简单的方法是测试实例集合的交
当两概念等价时，显然有AB=A=B。,等价,被定义为,AB=A=B
当两概念等价时，显然有AB=A=B。,等价,由组成,AB=A=B
当两概念等价时，显然有AB=A=B。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。,概念,被定义为,对称差分
然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。,概念,由组成,对称差分
定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。,对称差分表示,包含,两集合的相似度
定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。,对称差分表示,被定义为,两集合的相似度
定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。,对称差分表示,由组成,两集合的相似度
此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。,实例集合的概率解释,被定义为,根据实例集合的概率解释来计算相似度
此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。,概率解释,由组成,实例集合
此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
②无共享实例的方法。,SPO,被定义为,无共享实例的方法
②无共享实例的方法。,无共享实例的方法,方法,无共享实例的方法
②无共享实例的方法。,无共享实例的方法,由组成,无共享实例的方法
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,被定义为,基于实例的方法
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,由组成,两概念没有共享实例
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,实现,无能为力
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,属于,基于共享实例的方法
事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。,异构本体,被定义为,共享实例
事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。,异构本体,由组成,共享实例
在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。,连接聚合,被定义为,数据分析方法
在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。,连接聚合,由组成,数据分析方法
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,被定义为,单连接、全连接、平均连接和Haussdorf距离
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,由组成,单连接、全连接、平均连接和Haussdorf距离
其中，Haussdorf距离度量两个集合之间的最大距离。,Haussdorf距离度量,被定义为,两个集合之间的最大距离
其中，Haussdorf距离度量两个集合之间的最大距离。,Haussdorf距离度量,实现,两个集合之间的最大距离
其中，Haussdorf距离度量两个集合之间的最大距离。,Haussdorf距离度量,属于,两个集合之间的最大距离
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,ValtchevP提出的匹配相似度,包含,建立实体间的对应关系
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,ValtchevP提出的匹配相似度,被定义为,通过建立实体间的对应关系来进一步计算集合之间的相似度
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,ValtchevP提出的匹配相似度,由组成,通过建立实体间的对应关系
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,被定义为,采用机器学习技术来发现异构本体间映射
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,方法,机器学习技术
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,由组成,机器学习技术
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,实现,机器学习技术
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,来源,机器学习技术
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,属于,机器学习技术
通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,有监督的学习方法,被定义为,算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）
通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,有监督的学习方法,由组成,算法
通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,有监督的学习方法,由组成,算法
训练完成后，训练结果用于发现异构本体间的映射。,训练完成后，训练结果用于发现异构本体间的映射。,被定义为,训练结果
训练完成后，训练结果用于发现异构本体间的映射。,训练完成后，训练结果用于发现异构本体间的映射。,由组成,训练完成后，训练结果用于发现异构本体间的映射。
训练完成后，训练结果用于发现异构本体间的映射。,训练完成后，训练结果用于发现异构本体间的映射。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,本体实例,被定义为,学习算法
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,本体实例,由组成,学习算法
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,学习算法,实现,利用这些信息能学习概念之间或关系之间的语义关系
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,大量的本体实例,来源,学习算法
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,学习算法,属于,利用这些信息能学习概念之间或关系之间的语义关系
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,机器学习算法,被定义为,形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,机器学习算法,被定义为,形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,机器学习算法,由组成,形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等
（2）方法和工具1）GLUE。,GLUE,被定义为,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（2）方法和工具1）GLUE。,GLUE,由组成,方法
（2）方法和工具1）GLUE。,GLUE,由组成,方法
"GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。",GLUE,被定义为,半自动的方法发现异构本体间的映射
"GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。",GLUE,由组成,半自动的方法发现异构本体间的映射
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,包含,LSD
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,被定义为,对半自动模式发现系统LSD的一个改进
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,由组成,LSD
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,实现,对半自动模式发现系统LSD的一个改进
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,属于,对半自动模式发现系统LSD的一个改进
GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。,GLUE,被定义为,概念分类
GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。,GLUE,由组成,概念分类
该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。,关系映射,由组成,该方法
该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。,关系映射,由组成,该方法
①GLUE的思想。,GLUE,被定义为,GLUE是谷歌提出的一个多任务学习框架
GLUE的目的是根据分类本体寻找本体间1∶1的映射。,GLUE,被定义为,根据分类本体寻找本体间1∶1的映射
GLUE的目的是根据分类本体寻找本体间1∶1的映射。,GLUE,由组成,根据分类本体寻找本体间1∶1的映射
GLUE的目的是根据分类本体寻找本体间1∶1的映射。,GLUE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
其中的主要思想包括：（a）相似度定义。,相似度定义,被定义为,相似度定义
其中的主要思想包括：（a）相似度定义。,相似度定义,由组成,知识图谱
其中的主要思想包括：（a）相似度定义。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,相似度定义
GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。,GLUE,被定义为,概念的联合概率分布
GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。,GLUE,由组成,联合概率分布
GLUE定义了4种概念的联合概率分布。,GLUE,被定义为,联合概率分布
GLUE定义了4种概念的联合概率分布。,GLUE,由组成,GLUE定义了4种概念的联合概率分布。
（b）计算相似度。,相似度,被定义为,计算相似度
（b）计算相似度。,计算相似度,由组成,相似度
（b）计算相似度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,计算相似度
由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。,GLUE,被定义为,机器学习技术
由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。,GLUE,由组成,机器学习技术
它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。,实例匹配,被定义为,实例匹配器
它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。,A,由组成,匹配器
（c）多策略学习。,多策略学习,被定义为,多策略学习是一种基于多策略的机器学习算法
（c）多策略学习。,多策略学习,由组成,多策略学习
使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。,机器学习技术,被定义为,一个特定的学习算法通常只适合解决一类特定问题
使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。,使用机器学习技术,由组成,一个特定的学习算法通常只适合解决一类特定问题
使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。,使用机器学习技术,属于,一个特定的学习算法通常只适合解决一类特定问题
然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。,本体学习,被定义为,本体中的信息类型
然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。,本体中的信息类型,由组成,单个学习器
然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。,GLUE,被定义为,多策略学习技术
为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。,GLUE,由组成,多策略学习技术
为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。,GLUE,由组成,多策略学习技术
（d）利用领域约束。,领域约束,被定义为,利用领域约束
（d）利用领域约束。,利用领域约束,由组成,d
GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。,GLUE,包含,领域约束条件和通用启发式规则
GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。,GLUE,由组成,领域约束条件和通用启发式规则
GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。,GLUE,实现,领域约束条件和通用启发式规则
GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。,GLUE,属于,领域约束条件和通用启发式规则
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,领域约束,被定义为,一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,领域约束,由组成,一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。
（e）处理复杂映射。,e,被定义为,处理复杂映射
（e）处理复杂映射。,e,由组成,处理复杂映射
为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。,GLUE,被定义为,CGLUE系统
为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。,GLUE,由组成,CGLUE
以下给出GLUE方法的详细介绍。,GLUE方法,被定义为,GLUE方法是一种基于文本的语义相似度计算任务
以下给出GLUE方法的详细介绍。,GLUE方法,方法,介绍GLUE方法
以下给出GLUE方法的详细介绍。,GLUE方法,由组成,GLUE方法介绍
以下给出GLUE方法的详细介绍。,GLUE方法,由组成,GLUE方法介绍
②相似度度量。,相似度度量,被定义为,相似度度量方法
②相似度度量。,相似度度量,由组成,相似度度量方法
②相似度度量。,相似度度量,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。,GLUE,被定义为,更精确的相似度表示
很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。,GLUE,由组成,更精确的相似度表示
GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。,GLUE,被定义为,概念
GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。,GLUE,由组成,概念
在此基础上，GLUE定义不同概念间的联合)和P(概率分布。,GLUE,被定义为,联合概率分布和概率分布
在此基础上，GLUE定义不同概念间的联合)和P(概率分布。,GLUE,由组成,联合和概率分布
在此基础上，GLUE定义不同概念间的联合)和P(概率分布。,GLUE,属于,联合和概率分布
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",GLUE,属于,联合和概率分布
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",GLUE,属于,联合和概率分布
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念A和B之间的联合概率分布,由组成,"P(A,B)、P(,B)、P(A,)。"
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念A和B之间的联合概率分布,由组成,"P(A,B)、P(,B)、P(A,)。"
"以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。",P,包含,概率
"以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。",P,由组成,属于A但不属于B的概率
"以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。",P,属于,属于
GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。,GLUE,被定义为,4种概念
GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。,GLUE,由组成,4种概念
第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。,相似度度量函数,被定义为,基于Jaccard系数
第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。,相似度度量函数,方法,基于Jaccard系数
第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。,相似度度量函数,由组成,Jaccard系数
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,最特化双亲,被定义为,概率P(A|B)和P(B|A)能用4种联合概率来表示
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,最特化双亲,由组成,概率P(A|B)和P(B|A)
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。",MSP,包含,"MSP(A,B)的值越大"
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。",MSP,由组成,"MSP(A,B)"
这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。,A,包含,A
这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。,A,由组成,包含A的最小集
类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。,最泛化孩子,被定义为,最特化双亲
类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。,最泛化孩子,由组成,最特化双亲
③GLUE体系结构。,GLUE体系结构,被定义为,GLUE体系结构由三个部分组成：一个基准测试集，一个评估框架，以及一个评估指标
③GLUE体系结构。,GLUE体系结构,由组成,GLUE体系结构由三个部分组成：GLUE数据集、GLUE基准测试和GLUE基准测试工具
③GLUE体系结构。,GLUE体系结构,由组成,GLUE体系结构由三个部分组成：GLUE数据集、GLUE基准测试和GLUE基准测试工具
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,被定义为,分布估计、相似度估计和放松标记
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,由组成,三个模块
图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。,GLUE体系结构,被定义为,GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。
图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。,GLUE,由组成,GLUE体系结构分布估计
图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。,图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。,属于,图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。
然后利用机器学习技术计算每对概念的联合概率分布。,概念,被定义为,联合概率分布
然后利用机器学习技术计算每对概念的联合概率分布。,机器学习技术,由组成,每对概念的联合概率分布
然后利用机器学习技术计算每对概念的联合概率分布。,知识图谱,实现,机器学习技术
然后利用机器学习技术计算每对概念的联合概率分布。,知识图谱,来源,机器学习技术
然后利用机器学习技术计算每对概念的联合概率分布。,知识图谱,属于,机器学习技术
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识表示
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识存储
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识抽取
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识融合
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识推理
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,语义搜索
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识问答
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,包含,知识图谱项目
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,知识图谱,被定义为,本体
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,联合概率分布,由组成,4种
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,联合概率分布,由组成,4种
分布评估使用一组基本学习器和一个元学习器。,分布评估,被定义为,使用一组基本学习器和一个元学习器。
分布评估使用一组基本学习器和一个元学习器。,分布评估,由组成,一组基本学习器和一个元学习器
相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。,相似度估计,被定义为,利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。
相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。,相似度估计,由组成,利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。
相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。,相似度估计,属于,概念对之间的相似度矩阵
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,包含,相似度矩阵以及领域特定的约束和启发式知识
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,被定义为,寻找满足领域约束和常识知识的映射，输出最终的映射结果
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,由组成,相似度矩阵以及领域特定的约束和启发式知识
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,由组成,相似度矩阵以及领域特定的约束和启发式知识
④分布估计。,分布估计,被定义为,分布估计是利用概率统计方法，对知识图谱中实体、关系、属性等概念的分布进行估计
④分布估计。,分布估计,由组成,分布估计
④分布估计。,④分布估计,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。",联合概率分布,包含,同时属于A和B的实例数与全体实例总数的比值
"考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。",联合概率分布,由组成,同时属于A和B的实例数与全体实例总数的比值
"考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。",联合概率分布,属于,同时属于A和B的实例数与全体实例总数的比值
通常这个比值是无法计算的，因为不可能知道全体实例。,知识图谱,被定义为,知识表示
通常这个比值是无法计算的，因为不可能知道全体实例。,缺点,由组成,无法计算
"因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。",基于本体的知识抽取,被定义为,"利用两个本体的输入实例来估计P(A,B)"
"因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。",基于本体的知识抽取,由组成,利用两个本体的输入实例
注意，两个本体的实例可以重叠，但没有必要必须那样。,本体,被定义为,本体实例
注意，两个本体的实例可以重叠，但没有必要必须那样。,本体,由组成,实例
注意，两个本体的实例可以重叠，但没有必要必须那样。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。,Ui,被定义为,本体Oi的实例集合
Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。,Ui,由组成,本体Oi
Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。,Ui,由组成,本体Oi
N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。,N,被定义为,Ui中实例的数目
N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。,N,由组成,同时属于A和B的实例数目
"这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。",P,被定义为,"P(A,B)的计算转化为计算和。"
"这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。","P(A,B)",由组成,计算和
"这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。","P(A,B)",由组成,计算和
为了达到这个目的，GLUE使用了机器学习方法。,GLUE,被定义为,机器学习方法
为了达到这个目的，GLUE使用了机器学习方法。,GLUE,由组成,机器学习方法
特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。,O1,被定义为,将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。
特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。,O1,由组成,U1
特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。,O1,属于,A
然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。,实例分类器,被定义为,关于A的实例分类器
然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。,A,由组成,B
然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。,A,由组成,B
最后，使用该分类器预测O2中的实例s是否属于A。,分类器,被定义为,使用该分类器预测O2中的实例s是否属于A
最后，使用该分类器预测O2中的实例s是否属于A。,O2,由组成,分类器
最后，使用该分类器预测O2中的实例s是否属于A。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。",分类器,被定义为,返回的结果
"通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。",分类器,由组成,置信度值
这个值反映了分类的不确定性。,分类的不确定性,被定义为,这个值
这个值反映了分类的不确定性。,这个值反映了分类的不确定性,由组成,分类的不确定性
这个值反映了分类的不确定性。,这个值反映了分类的不确定性,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这里规定置信度大于0.5就表示“是”。,SPO,被定义为,三元组
这里规定置信度大于0.5就表示“是”。,SPO,由组成,由组成
这里规定置信度大于0.5就表示“是”。,实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。,分类学习器,被定义为,GLUE
常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。,常用的分类学习器,由组成,GLUE
常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。,分类学习器,属于,GLUE
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,联合概率分布,被定义为,学习的方法得到和等参数
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,基于上述思想,由组成,学习的方法得到和等参数
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,基于上述思想,实现,学习的方法得到和等参数
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,基于上述思想,来源,学习的方法得到和等参数
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,基于上述思想,属于,学习的方法得到和等参数
具体的过程如图5-9所示。,SPO,被定义为,具体的过程
具体的过程如图5-9所示。,具体的过程,由组成,如图5-9所示
●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。,划分本体,被定义为,O1的实例集合U1
●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。,划分本体,由组成,O1的实例集合U1
●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。,划分本体O1的实例集合U1,属于,属于A的实例集合
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,正例和反例,被定义为,学习器L
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,使用和作为正例和反例分别训练学习器L,由组成,如图5-9（c）。
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,使用和作为正例和反例分别训练学习器L，如图5-9（c）。
●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。,划分本体O2的实例集合U2为和,被定义为,分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。
●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。,划分本体O2的实例集合U2为和,由组成,分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。
●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。,划分本体O2的实例集合U2,属于,属于B的实例集合
●对中的每个实例使用学习器L进行分类。,对中的每个实例使用学习器L进行分类,被定义为,分类
●对中的每个实例使用学习器L进行分类。,对中的每个实例使用学习器L进行分类,由组成,学习器L
将划分为两个集合和。,划分,被定义为,和
将划分为两个集合和。,将,由组成,划分为两个集合和。
将划分为两个集合和。,将划分为两个集合和。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,应用学习器L,被定义为,两个集合和，如图5-9（f）所示。
相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,相似地,由组成,对应用学习器L，得到两个集合和，如图5-9（f）所示。
相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,属于,相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。
●重复（a）～（d），得到集合和。,集合,被定义为,集合和
●重复（a）～（d），得到集合和。,由组成,由组成,重复（a）～（d），得到集合和。
●重复（a）～（d），得到集合和。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
●重复（a）～（d），得到集合和。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
●重复（a）～（d），得到集合和。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
"●使用公式计算P(A,B)。",公式计算,被定义为,"P(A,B)"
"●使用公式计算P(A,B)。","使用公式计算P(A,B)",由组成,"使用公式计算P(A,B)。"
"●使用公式计算P(A,B)。","使用公式计算P(A,B)",由组成,"使用公式计算P(A,B)。"
类似地，可以计算出其他3种联合概率分布。,联合概率分布,被定义为,联合分布
类似地，可以计算出其他3种联合概率分布。,联合概率分布,由组成,联合概率分布
图5-9估计概念A和B的概率分布⑤多策略学习。,图5-9估计概念A和B的概率分布⑤多策略学习。,被定义为,图5-9估计概念A和B的概率分布⑤多策略学习。
图5-9估计概念A和B的概率分布⑤多策略学习。,图5-9估计概念A和B的概率分布⑤,由组成,多策略学习。
图5-9估计概念A和B的概率分布⑤多策略学习。,图5-9估计概念A和B的概率分布⑤多策略学习。,实现,多策略学习
图5-9估计概念A和B的概率分布⑤多策略学习。,图5-9估计概念A和B的概率分布⑤多策略学习。,属于,图5-9估计概念A和B的概率分布⑤
训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。,训练实例分类器,被定义为,利用词语出现的频率、实例名和实例属性的赋值格式等
训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。,训练实例分类器的过程,由组成,可以利用词语出现的频率、实例名和实例属性的赋值格式等
为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。,GLUE,被定义为,多策略的学习方法
为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。,GLUE,由组成,多策略的学习方法
"在分布估计阶段，系统会训练多个基本学习器L1,�,Lk。",分布估计,被定义为,"系统会训练多个基本学习器L1,�,Lk。"
"在分布估计阶段，系统会训练多个基本学习器L1,�,Lk。","在分布估计阶段，系统会训练多个基本学习器L1,�,Lk。",由组成,"在分布估计阶段，系统会训练多个基本学习器L1,�,Lk。"
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,学习器,被定义为,利用来自实例数据中某种类型的信息进行分类学习训练
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,学习器,方法,利用来自实例数据中某种类型的信息进行分类学习训练
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,学习器,由组成,实例数据中某种类型的信息
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,每种学习器,实现,利用来自实例数据中某种类型的信息进行分类学习训练
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,每种学习器,属于,利用来自实例数据中某种类型的信息进行分类学习训练
训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。,元学习器,被定义为,训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。
训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。,训练完成后,由组成,当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。
与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。,多策略的学习方法,被定义为,采用多个学习器的方法
与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。,多策略的学习方法,由组成,较高的分类准确率，并可以得到较好的联合分布近似值
目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。,GLUE系统,被定义为,内容学习器和名字学习器
目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。,GLUE系统,由组成,2个基本分类学习器
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,包含,基本学习器
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,被定义为,将基本学习器的结果进行线性合并
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,由组成,基本学习器
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,实现,基本学习器
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,属于,基本学习器
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,被定义为,学习器
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,由组成,内容学习器
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
利用实例文本内容中的词频来进行分类预测。,实例文本内容,被定义为,词频
利用实例文本内容中的词频来进行分类预测。,实例文本内容,方法,分类预测
利用实例文本内容中的词频来进行分类预测。,实例文本内容,由组成,词频
利用实例文本内容中的词频来进行分类预测。,利用实例文本内容中的词频来进行分类预测。,实现,利用实例文本内容中的词频来进行分类预测。
利用实例文本内容中的词频来进行分类预测。,利用实例文本内容中的词频来进行分类预测。,属于,利用实例文本内容中的词频来进行分类预测。
一个实例通常由名将这些信息都作为实例的文本内容。,实例,被定义为,名、属性、值
一个实例通常由名将这些信息都作为实例的文本内容。,一个实例,由组成,名
例如，实字、属性集合以及属性值组成。,实字,被定义为,实字由实词和虚词组成
例如，实字、属性集合以及属性值组成。,实字,由组成,属性集合以及属性值
例如，实字、属性集合以及属性值组成。,实字,由组成,属性集合以及属性值
"GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。",Professor_Cook,被定义为,"R.Cook,Ph.D.,University_of_Sydney,Australia"
"GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。",Professor_Cook,由组成,"R.Cook,Ph.D.,University_of_Sydney,Australia"
内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。,内容学习器,被定义为,贝叶斯学习技术
内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。,内容学习器,由组成,贝叶斯学习技术
"它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,�,wk}，其中的wj是标记。",输入实例的内容表示,被定义为,"d={w1,�,wk}，其中的wj是标记。"
"它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,�,wk}，其中的wj是标记。",输入实例的内容表示,由组成,"{w1,�,wk}"
内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。,内容学习器,被定义为,计算输入的一个实例属于概念A的概率
内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。,内容学习器,由组成,P(A|d)
内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。,内容学习器,属于,概念A
根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。,P(d|A)P(A)/P(d),被定义为,P(A|d)
根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。,P(d|A)P(A)/P(d),被定义为,P(A|d)
根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。,P(d|A)P(A)/P(d),由组成,根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(d|A),由组成,P(d)
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(A),由组成,P(d|A)
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(d|A),由组成,P(d)
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(A),由组成,P(d|A)
特别地，P(A)被估计为属于A的实例占全部训练实例的比例。,P,被定义为,属于A的实例占全部训练实例的比例
特别地，P(A)被估计为属于A的实例占全部训练实例的比例。,P,由组成,P(A)被估计为属于A的实例占全部训练实例的比例。
特别地，P(A)被估计为属于A的实例占全部训练实例的比例。,P,属于,属于
因此，只需要计算P(d|A)就可以得到P(A|d)。,P(d|A),被定义为,P(A|d)
因此，只需要计算P(d|A)就可以得到P(A|d)。,P(d|A),由组成,P(A|d)
因此，只需要计算P(d|A)就可以得到P(A|d)。,P(d|A),由组成,P(A|d)
"为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。",P(d|A),被定义为,"P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。"
"为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
"为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,标记独立假设,被定义为,在很多时候并不成立
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,标记独立假设,由组成,贝叶斯学习技术
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,标记独立假设,实现,贝叶斯学习技术
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,标记独立假设,来源,贝叶斯学习技术
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,标记独立假设,属于,贝叶斯学习技术
P(|d)可通过相似的方法来计算。,P,被定义为,相似的方法
P(|d)可通过相似的方法来计算。,P,由组成,相似的方法
P(|d)可通过相似的方法来计算。,P,由组成,相似的方法
（b）名字学习器。,名字学习器,被定义为,通过名字学习器，可以学习出每个实体在知识图谱中的名字
（b）名字学习器。,名字学习器,由组成,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（b）名字学习器。,名字学习器,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（b）名字学习器。,名字学习器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,名字学习器,被定义为,内容学习器
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,名字学习器,由组成,内容学习器
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,相似于内容学习器,实现,名字学习器
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,相似于内容学习器,来源,名字学习器
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,相似于内容学习器,属于,名字学习器
这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。,实例全名,被定义为,从根节点直到实例所在位置的路径上所有概念名的连接
这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。,实例全名,由组成,从根节点直到实例所在位置的路径上所有概念名的连接
这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。,实例全名,属于,从根节点直到实例所在位置的路径上所有概念名的连接
（c）元学习器。,元学习器,被定义为,学习器
（c）元学习器。,元学习器,由组成,元学习
基本学习器的预测结果通过元学习器来合并。,基本学习器,被定义为,元学习器
基本学习器的预测结果通过元学习器来合并。,基本学习器,由组成,元学习器
基本学习器的预测结果通过元学习器来合并。,基本学习器的预测结果,实现,元学习器
基本学习器的预测结果通过元学习器来合并。,基本学习器的预测结果,来源,元学习器
基本学习器的预测结果通过元学习器来合并。,基本学习器的预测结果,属于,元学习器
元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。,元学习器,被定义为,将基本学习器的预测值合并
元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。,元学习器,由组成,基本学习器
这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。,基本学习器,被定义为,权重
这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。,基本学习器,由组成,机器学习的方法自动设置
⑥利用领域约束和启发式知识。,领域约束,被定义为,领域约束和启发式知识
⑥利用领域约束和启发式知识。,利用领域约束和启发式知识,由组成,⑥
经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。,相似估计,被定义为,概念之间的相似度矩阵
经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。,相似估计,由组成,最佳的正确映射
放松标记是一种解决图中节点的标签分配问题的有效技术。,放松标记,包含,解决图中节点的标签分配问题的有效技术
放松标记是一种解决图中节点的标签分配问题的有效技术。,放松标记,由组成,一种解决图中节点的标签分配问题的有效技术。
该方法的思想是节点的标签通常受其邻居的特征影响。,节点标签,被定义为,节点的标签通常受其邻居的特征影响
该方法的思想是节点的标签通常受其邻居的特征影响。,该方法,方法,节点的标签通常受其邻居的特征影响
该方法的思想是节点的标签通常受其邻居的特征影响。,该方法的思想是节点的标签通常受其邻居的特征影响,由组成,该方法
基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。,放松标记技术,被定义为,节点邻居对其标签的影响
基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。,基于这种观察,由组成,放松标记技术将节点邻居对其标签的影响用公式量化。
基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。,基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。,实现,基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。
放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。,放松标记技术,被定义为,相似匹配
放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。,放松标记技术,由组成,计算机视觉和自然语言处理等领域中的相似匹配
GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。,GLUE,被定义为,本体映射
GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。,GLUE,由组成,本体映射
考虑约束能提高映射的精度。,考虑约束能提高映射的精度。,包含,约束
考虑约束能提高映射的精度。,考虑约束能提高映射的精度。,由组成,约束
约束又可分为领域独立约束和领域依赖约束两种。,约束,被定义为,领域独立约束和领域依赖约束
约束又可分为领域独立约束和领域依赖约束两种。,约束,由组成,领域独立约束和领域依赖约束
领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。,领域独立约束,被定义为,相关节点间交互的通用知识
领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。,领域独立约束,由组成,相关节点间交互的通用知识
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,邻居约束,被定义为,“两节点的邻居匹配，则两节点也匹配”
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,邻居约束,由组成,“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。
领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。,领域依赖约束,由组成,特定节点间交互的用户知识
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,PROFESSOR,由组成,FACULTY
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,被定义为,利用这些限制进一步寻找正确的映射或去除不太可能的映射。
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,由组成,利用这些限制进一步寻找正确的映射或去除不太可能的映射。
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
⑦实验评估。,实验评估,被定义为,实验评估方法
⑦实验评估。,实验评估,由组成,实验评估
⑦实验评估。,⑦实验评估。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统,被定义为,GLUE系统的实验结果
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统,由组成,1∶1的映射
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统,实现,1∶1的映射
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统,来源,实验结果
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统,属于,1∶1的映射
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,内容学习器,包含,名字学习器
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,内容学习器,由组成,52%～83%
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,名字学习器,由组成,12%～15%
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,内容学习器,实现,52%～83%
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,基本学习器,来源,内容学习器
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,内容学习器,属于,52%～83%
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,名字学习器,属于,12%～15%
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,包含,少量提高正确率
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,由组成,少量提高正确率
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,实现,少量提高正确率
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,来源,少量提高正确率
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,属于,少量提高正确率
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,包含,提高3%～18%的正确率
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,由组成,能进一步提高3%～18%的正确率，只有一个实验例外。
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,实现,能进一步提高3%～18%的正确率
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,属于,能进一步提高3%～18%的正确率
由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。,GLUE,被定义为,概念间1∶1形式的映射结果
由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。,GLUE,由组成,实验
尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。,GLUE,被定义为,一个基准测试
尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。,GLUE,由组成,几个因素
首先，一些概念不能被匹配是因为缺少足够的训练数据。,匹配,被定义为,一些概念
首先，一些概念不能被匹配是因为缺少足够的训练数据。,一些概念,由组成,缺少足够的训练数据
首先，一些概念不能被匹配是因为缺少足够的训练数据。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,缺少足够的训练数据
其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。,放松标签优化,被定义为,利用放松标签进行优化
其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。,利用放松标签进行优化,由组成,可能没有考虑全局的知识
其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。,放松标签优化,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。,文本分类器,被定义为,实现中使用的两个基本学习器
第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。,实现,由组成,两个基本学习器
最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。,特点,被定义为,描述过于含糊，机器很难判断与之相关的映射
最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。,最后,由组成,有些节点的描述过于含糊，机器很难判断与之相关的映射。
最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
⑧扩充GLUE发现复杂映射。,GLUE,被定义为,复杂映射
⑧扩充GLUE发现复杂映射。,GLUE,由组成,复杂映射
GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。,GLUE,被定义为,寻找给定分类本体概念之间1∶1的简单映射
GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。,GLUE,由组成,寻找给定分类本体概念之间1∶1的简单映射
GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。,GLUE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。,GLUE,被定义为,复杂映射
为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。,GLUE,由组成,CGLUE
为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。,GLUE,由组成,CGLUE
目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。,CGLUE,被定义为,概念间复杂映射
目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。,CGLUE,由组成,概念间复杂映射
CGLUE中的复杂映射形式如A=X1op1X2op2�opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。,复杂映射,被定义为,A=X1op1X2op2�opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。
CGLUE中的复杂映射形式如A=X1op1X2op2�opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。,CGLUE,由组成,复杂映射形式
这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。,1∶n的映射,被定义为,m∶n的形式
这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。,1∶n的映射,由组成,m∶n的形式
由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。,opi,被定义为,并、差和补等集合运算符
由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。,opi,由组成,并、差和补等集合运算符
CGLUE将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。,CGLUE,被定义为,将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。
CGLUE将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。,CGLUE,被定义为,将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。
CGLUE将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。,CGLUE,由组成,将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象
"CGLUE还进一步假设概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。",CGLUE,包含,"概念D的孩子C1,C2,�,Ck"
"CGLUE还进一步假设概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。",CGLUE,由组成,"概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。"
"CGLUE还进一步假设概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。",CGLUE,由组成,"概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。"
CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。,CGLUE,被定义为,复合概念
CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。,CGLUE,由组成,将复合概念都可以重写为概念并的形式，便于统一处理。
"对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。",CGLUE,被定义为,"O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。"
"对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。",O1,由组成,CGLUE
"对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。",O1,由组成,CGLUE
比较的方法与GLUE中的相似。,比较的方法,被定义为,GLUE中的相似
比较的方法与GLUE中的相似。,比较的方法,方法,GLUE
比较的方法与GLUE中的相似。,比较的方法,由组成,GLUE中的相似
最后返回相似度最高的映射结果。,SPO,被定义为,相似度最高的映射结果
最后返回相似度最高的映射结果。,相似度,由组成,映射结果
最后返回相似度最高的映射结果。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。,概念并组合,被定义为,概念并组合的数目是指数级的
由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。,概念并组合,由组成,暴力方法
因此需要考虑从巨量的候选复合概念中搜索A的近似。,A,被定义为,从巨量的候选复合概念中搜索A的近似
因此需要考虑从巨量的候选复合概念中搜索A的近似。,A,由组成,巨量的候选复合概念
因此需要考虑从巨量的候选复合概念中搜索A的近似。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
因此需要考虑从巨量的候选复合概念中搜索A的近似。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。,CGLUE,被定义为,定向搜索技术
为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。,CGLUE,由组成,定向搜索技术
为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。,CGLUE,由组成,定向搜索技术
定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。,定向搜索算法,被定义为,寻找概念A的最佳映射
定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。,定向搜索算法,由组成,寻找概念A的最佳映射
设highest_sim=0。,highest_sim,被定义为,highest similarity
设highest_sim=0。,highest_sim,由组成,由组成
扩展这些候选创建新的候选对象。,扩展这些候选创建新的候选对象。,被定义为,扩展这些候选创建新的候选对象
扩展这些候选创建新的候选对象。,扩展这些候选创建新的候选对象。,由组成,候选对象
添加新候选对象到S。,S,被定义为,添加新候选对象到S。
添加新候选对象到S。,添加新候选对象到S,由组成,S
设置highest_sim=new_highest_sim。,highest_sim,被定义为,new_highest_sim
设置highest_sim=new_highest_sim。,设置highest_sim,由组成,new_highest_sim
算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,算法,被定义为,GLUE中的学习方法计算概念A和候选概念间的相似度分数
算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,算法的步骤2,由组成,采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。
算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,算法的步骤2,由组成,采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。
在步骤2（c）中，ε最初设置为0。,ε,被定义为,0
在步骤2（c）中，ε最初设置为0。,ε,由组成,0
在步骤2（c）中，ε最初设置为0。,ε,由组成,0
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,k-近邻算法,被定义为,在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,由组成,在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,由组成,在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。
因为每个候选对象只是O2概念的并，去除过程很快。,O2概念的并,被定义为,候选对象
因为每个候选对象只是O2概念的并，去除过程很快。,O2概念的并,由组成,候选对象
CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。,CGLUE,被定义为,GLUE不能发现的1∶n类型的概念映射
CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。,CGLUE,由组成,1∶n类型的概念映射
CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。,CGLUE,由组成,1∶n类型的概念映射
试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。,CGLUE,被定义为,知识图谱的语义搜索任务
试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。,CGLUE,由组成,实验
实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。,CGLUE,包含,实验
实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。,CGLUE,由组成,实验
实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。,CGLUE,创建时间,2019
⑨GLUE的总结。,GLUE,被定义为,GLUE是NLP领域的一个大型基准测试，它由10个任务组成，每个任务都使用不同的数据集和评估指标。
⑨GLUE的总结。,GLUE,由组成,GLUE的总结
GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。,GLUE,被定义为,早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。
GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。,GLUE,由组成,早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。
GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。,GLUE,被定义为,语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。
GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。,GLUE,被定义为,语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。
GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。,GLUE,由组成,机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。
试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。,GLUE,被定义为,概念之间1∶1的简单映射
试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。,GLUE,由组成,概念之间1∶1的简单映射
扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。,扩展后的CGLUE系统,包含,概念间1∶n类型的映射
扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。,扩展后的CGLUE系统,被定义为,概念间1∶n类型的映射
扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。,扩展后的CGLUE系统,由组成,发现概念间1∶n类型的映射
扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。,扩展后的CGLUE系统,由组成,发现概念间1∶n类型的映射
尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。,GLUE,被定义为,一个基准测试
尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。,GLUE,由组成,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。,尽管GLUE取得了很多不错的映射结果,属于,不足
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE,包含,复杂概念间的映射
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE,被定义为,复杂概念间的映射
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE,由组成,复杂概念间的映射
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
最后，GLUE无法处理关于异构本体的关系之间的映射。,GLUE,被定义为,无法处理关于异构本体的关系之间的映射
最后，GLUE无法处理关于异构本体的关系之间的映射。,GLUE,由组成,无法处理关于异构本体的关系之间的映射
最后，GLUE无法处理关于异构本体的关系之间的映射。,GLUE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
2）概念近似的方法。,概念近似,被定义为,概念相似度
2）概念近似的方法。,概念近似,方法,概念近似的方法
2）概念近似的方法。,概念近似的方法,由组成,概念近似的方法
2）概念近似的方法。,概念近似,属于,概念相似度
在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。,基于异构本体的信息检索,包含,原查询重写为近似的查询
在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。,基于异构本体的信息检索,被定义为,将原查询重写为近似的查询
在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。,基于异构本体的信息检索,由组成,重写为近似的查询
本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。,本体间概念的近似查询,被定义为,本体间概念的近似技术
本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。,本体间概念的近似查询,由组成,本体间概念的近似查询
①方法的思想。,方法,被定义为,将文本中的实体和关系抽取出来
①方法的思想。,方法的思想,方法,实现知识图谱的构建
①方法的思想。,方法的思想,由组成,实现
在本体查询系统中，信息源和查询都是针对特定本体的。,本体查询系统,被定义为,信息源和查询都是针对特定本体的
在本体查询系统中，信息源和查询都是针对特定本体的。,信息源,由组成,本体查询系统
不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。,查询,被定义为,本体
一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。,S,被定义为,基于本体O的信息源
一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。,S,由组成,只能回答关于O的查询
因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。,查询异构问题,由组成,用户（查询提出者）和系统（查询回答者）使用不同的本体
因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。,查询异构问题,由组成,用户（查询提出者）和系统（查询回答者）使用不同的本体
当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。,异构查询,被定义为,两个本体之间解决
当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。,异构查询,由组成,全局本体
当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。,异构查询问题,属于,全局本体
令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。,重写,被定义为,关于O2的查询
令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。,令用户本体,由组成,O1
令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。,系统本体,由组成,O2
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,查询重写,包含,关于O1的查询重写为关于O2的解释相同的查询
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,查询重写,由组成,关于O1的查询重写为关于O2的解释相同的查询
但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。,重写,被定义为,解释近似于原查询的查询
但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。,重写为解释近似于原查询的查询,由组成,O1
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R,包含,Q在T中的近似
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R作为Q在T中的近似,被定义为,查全率和查准率
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R作为Q在T中的近似,由组成,查全率和查准率
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R作为Q在T中的近似,由组成,查全率和查准率
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",近似查询结果,被定义为,所有原查询的结果
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,实现
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,实现
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,被定义为,用来寻找完备或正确的近似
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,由组成,QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,实现,寻找完备或正确的近似
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,来源,寻找完备或正确的近似
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,属于,寻找完备或正确的近似
本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。,本体间的概念近似技术,被定义为,通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果
本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。,本体间的概念近似技术,由组成,基于概念近似技术
这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。,本体映射发现方法,被定义为,基于实例的本体映射发现方法
这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。,本体映射发现方法,由组成,基于实例的本体映射发现方法
②Stuckenschmidt_H的概念近似。,Stuckenschmidt_H的概念近似,由组成,Stuckenschmidt_H的概念近似
寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。,近似查询,被定义为,寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。
寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。,近似查询,由组成,关键问题
Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。,Stuckenschmidt_H,由组成,利用概念的最小上界和最大下界计算概念近似的方法
Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。,Stuckenschmidt_H,由组成,利用概念的最小上界和最大下界计算概念近似的方法
该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。,概念,被定义为,最小上界和最大下界
该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。,概念的上下近似,方法,定义了概念的最小上界和最大下界
该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。,概念,由组成,上近似和下近似
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念,被定义为,最小上界
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念,由组成,最小上界
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念的蕴涵关系,实现,概念在另一本体中所有的直接父类
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念的蕴涵关系,属于,概念在另一本体中所有的直接子类
图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。,最小上界,被定义为,图5-10
图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。,最小上界,由组成,C
"定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。",lub,被定义为,T中概念的集合
"定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。",lub,由组成,T中概念的集合
"定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。",lub,由组成,T中概念的集合
"找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。",C,被定义为,C在T中的最小上界
"找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。",C,由组成,C在T中的最小上界
"找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。",C,由组成,C在T中的最小上界
定义5.11令C为O1中概念，T为O2中全部概念的集合。,定义5.11,被定义为,令C为O1中概念，T为O2中全部概念的集合。
定义5.11令C为O1中概念，T为O2中全部概念的集合。,定义5.11,由组成,C为O1中概念，T为O2中全部概念的集合
"定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。",glb,被定义为,"T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。"
"定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。",glb,由组成,C在T中的最大下界
"定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。",glb,由组成,C在T中的最大下界
"找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。",下近似,被定义为,"la(C,T)"
"找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。",下近似,由组成,C在T中的最大下界
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,上近似,被定义为,不包含非算子（）
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,上近似,由组成,不包含非算子（）
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,上近似,由组成,不包含非算子（）
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",非算子,包含,非正规形式
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",非算子,被定义为,非正规形式
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",非算子,由组成,"将查询化为否定正规形式（NegationNormal_Form,NNF）消去"
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,线性时间
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,等价的NNF
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,NNF
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,非算子
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,单个概念
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,包含,处理
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,任何查询,由组成,线性时间
这样概念数目最多翻倍，但所有非算子都被消去。,SPO三元组,包含,特点
这样概念数目最多翻倍，但所有非算子都被消去。,SPO三元组,被定义为,这样概念数目最多翻倍，但所有非算子都被消去。
这样概念数目最多翻倍，但所有非算子都被消去。,概念,由组成,算子
这样概念数目最多翻倍，但所有非算子都被消去。,这样概念数目最多翻倍,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。",Akahani_J等人对定义5.10和定义5.11进行了扩展,包含,"T中概念D属于O1中概念C在T中最小上界lub(C,T)"
"Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。",Akahani_J等人对定义5.10和定义5.11进行了扩展,被定义为,"T中概念D属于O1中概念C在T中最小上界lub(C,T)"
上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。,扩展定义,被定义为,去除了最小上界和最大下界中的大量冗余成员，提高了效率
上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。,最小上界,由组成,最大下界
但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。,最小上界,被定义为,T的子集
但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。,最小上界,由组成,T的子集
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,生成概念的近似,包含,概念的最小上界和最大下界
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,生成概念的近似,被定义为,找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,生成概念的近似,方法,找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,概念近似,由组成,概念的近似
但这种方法无法得到概念的最佳近似，近似的质量有时是不可接受的。,概念近似,被定义为,概念的近似
如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。,上近似,被定义为,如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。
如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。,上近似,由组成,概念
同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。,下近似,被定义为,概念的子类
异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。,异构本体,被定义为,全异的概念集合和概念层次
异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。,异构本体,由组成,全异的概念集合和概念层次
这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。,最佳近似,被定义为,概念的异构本体原子概念间的蕴涵关系
这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。,最佳近似,由组成,概念的超类和子类
实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。,概念的合取和析取,被定义为,蕴涵关系
实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。,复杂概念,由组成,蕴涵关系
实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。,复杂概念,属于,概念的合取和析取
如果考虑这些蕴涵关系，也许可以提高近似查询的质量。,近似查询,被定义为,蕴涵关系
如果考虑这些蕴涵关系，也许可以提高近似查询的质量。,近似查询,由组成,蕴涵关系
如果考虑这些蕴涵关系，也许可以提高近似查询的质量。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
如果考虑这些蕴涵关系，也许可以提高近似查询的质量。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。,复杂蕴涵关系,被定义为,TzitzikasY的概念近似
图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。,复杂蕴涵关系,由组成,TzitzikasY的概念近似
为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。,实例学习,被定义为,通过实例学习来进行近似查询的方法
为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。,实例学习,由组成,近似查询
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,包含,最小查询
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,被定义为,对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,方法,对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,由组成,对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例,实现,对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例,属于,对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询
该方法需要一个训练实例集合。,SPO,被定义为,训练实例集合
该方法需要一个训练实例集合。,该方法,由组成,需要一个训练实例集合
该方法需要一个训练实例集合。,该方法,由组成,需要一个训练实例集合
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,该方法,由组成,需要一个训练实例集合
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,该方法,由组成,需要一个训练实例集合
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,该方法,由组成,需要一个训练实例集合
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,该方法,由组成,需要一个训练实例集合
在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K_QI(S)};K-={Q|QI(S)_K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。,K+,包含,K-
在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K_QI(S)};K-={Q|QI(S)_K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。,K+,方法,{Q|K_QI(S)}
在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K_QI(S)};K-={Q|QI(S)_K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。,K+,由组成,{Q|K_QI(S)}
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,上界,包含,K+
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,上界,由组成,K+
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,上界,由组成,K+
为此，引入一个将对象映射到概念合取的函数：。,对象映射到概念合取的函数,被定义为,将对象映射到概念合取的函数
为此，引入一个将对象映射到概念合取的函数：。,将对象映射到概念合取的函数,由组成,概念合取
为此，引入一个将对象映射到概念合取的函数：。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,将对象映射到概念合取的函数
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,DI(o),被定义为,可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,可证明利用DI(o)能得到与上界和下界等价的近似表示形式,实现,可证明利用DI(o)能得到与上界和下界等价的近似表示形式
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,可证明利用DI(o)能得到与上界和下界等价的近似表示形式,来源,可证明利用DI(o)能得到与上界和下界等价的近似表示形式
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,可证明利用DI(o)能得到与上界和下界等价的近似表示形式,属于,可证明利用DI(o)能得到与上界和下界等价的近似表示形式
对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。,概念近似查询,被定义为,概念近似查询
对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。,概念近似查询,由组成,概念近似查询
遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。,Tzitzikas_Y,被定义为,概念近似
遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。,Tzitzikas_Y,由组成,没有提出有效发现这种概念近似的方法
与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。,Stuckenschmidt_H的方法,包含,Stuckenschmidt_H的方法
与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。,Stuckenschmidt_H的方法,被定义为,Stuckenschmidt_H的方法
第一是查询效率问题。,SPO,被定义为,查询效率
第一是查询效率问题。,查询效率问题,由组成,第一
第一是查询效率问题。,查询效率,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
该方法需要遍历所有实例计算概念近似。,查询效率,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
该方法需要遍历所有实例计算概念近似。,概念近似,方法,该方法需要遍历所有实例计算概念近似。
该方法需要遍历所有实例计算概念近似。,该方法需要遍历所有实例计算概念近似,由组成,该方法
该方法需要遍历所有实例计算概念近似。,该方法需要遍历所有实例计算概念近似,由组成,该方法
得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。,得到的近似查询,包含,很多小查询
得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。,得到的近似查询,由组成,很多小查询
得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。,得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。,属于,得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。
第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。,基于包含关系的本体融合,被定义为,完全基于从训练集合中学习概念间的包含关系
第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。,第二,由组成,该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。
第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。,基于实例的近似,被定义为,基于实例的近似
最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。,基于特征的近似方法,由组成,特征
最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。,基于特征的近似方法,由组成,特征
④基于多元界的概念近似。,基于多元界的概念近似,包含,基于多元界的概念近似
④基于多元界的概念近似。,基于多元界的概念近似,被定义为,基于多元界的概念近似
④基于多元界的概念近似。,基于多元界的概念近似,由组成,基于多元界的概念近似
Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。,Kang_Dazhou,被定义为,概念近似查询
Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。,Kang_Dazhou,由组成,Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。
Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。,Kang_Dazhou,由组成,Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。
这种方法能进一步推广到关系映射的发现。,关系映射,被定义为,关系映射的发现
这种方法能进一步推广到关系映射的发现。,关系映射的发现,方法,这种方法
这种方法能进一步推广到关系映射的发现。,关系映射,由组成,关系映射发现
这种方法能进一步推广到关系映射的发现。,关系映射,由组成,关系映射发现
由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。,关系映射,由组成,关系映射发现
由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。,最佳近似,由组成,概念间的最佳近似
基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。,基于多元界的概念近似方法,被定义为,考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似
基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。,基于多元界的概念近似方法,由组成,考虑概念合取和析取之间的蕴涵关系
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的析取定义,被定义为,概念的多元最小上界
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的最小上界,由组成,概念的析取定义
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的最大下界,由组成,概念的合取定义
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,概念的最小上近似,被定义为,多元最小上界
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,概念的多元最小上界,由组成,概念的最小上近似
通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。,多元界,被定义为,概念近似表达
通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。,多元界,由组成,冗余
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元界,包含,概念的最简多元最小上界
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元界,被定义为,概念的最简多元最小上界
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元最小上界,方法,算法
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元界,由组成,算法
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元界,由组成,算法
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似,包含,概念的最小上近似和最大下近似
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似,被定义为,概念的最小上近似和最大下近似
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似,由组成,概念的最小上近似和最大下近似
引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。,概念析取,被定义为,概念的上界
引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。,概念析取,由组成,概念的上界
由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。,多元界,被定义为,由多个概念组成的复杂概念
由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。,概念的多元界,由组成,上下界
证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。,多元界,由组成,概念的最佳近似
证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。,证明利用多元界可以求得概念的最佳近似,属于,提高近似查询的质量
这是该方法的理论基础。,SPO,被定义为,三元组抽取
这是该方法的理论基础。,该方法,方法,理论基础
这是该方法的理论基础。,该方法,由组成,理论基础
这是该方法的理论基础。,该方法,由组成,理论基础
3）FCA。,FCA,被定义为,Fuzzy概念分析
3）FCA。,FCA,由组成,FuzzyC-Means
3）FCA。,FCA,由组成,FuzzyC-Means
"Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。","Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]",包含,FCA-Merge
"Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。","Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]",被定义为,FCA-Merge
"Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。","Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]",由组成,FCA-Merge
"Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。","Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]",由组成,FCA-Merge
该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。,合并,被定义为,合并后的本体
该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。,该方法,由组成,合并后的本体
该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。,该方法,由组成,合并后的本体
当然，这些概念分别来自两个不同的初始本体。,概念,被定义为,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
当然，这些概念分别来自两个不同的初始本体。,概念,由组成,知识图谱
①形式化概念分析基础。,形式化概念分析基础,被定义为,形式化概念分析
①形式化概念分析基础。,形式化概念分析基础,由组成,形式化概念分析
①形式化概念分析基础。,形式化概念分析基础,由组成,形式化概念分析
首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。,形式化概念分析基础,由组成,形式化概念分析
首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。,FCA-Merge方法,由组成,形式概念分析
首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。,FCA-Merge方法,由组成,形式概念分析
形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。,形式概念分析,被定义为,Wille_R于1982年首先提出的
形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。,形式概念分析,由组成,Wille_R
概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。,概念格,被定义为,形式概念
概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。,概念格,由组成,外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。
概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。,概念格,由组成,外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。
另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。,概念格,被定义为,概念之间的泛化和特化关系
另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。,概念格,由组成,Hasse图
另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。,概念格,由组成,Hasse图
因此，概念格被认为是进行数据分析的有力工具。,概念格,由组成,Hasse图
因此，概念格被认为是进行数据分析的有力工具。,概念格,由组成,数据分析
从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。,概念格,属于,概念聚类过程
"形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。",形式背景,被定义为,"三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。"
"形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。",形式背景,由组成,"三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。"
"(s,d)∈R表示实例s有属性d。",R,被定义为,实例有属性
"(s,d)∈R表示实例s有属性d。",缺点,由组成,属性
"(s,d)∈R表示实例s有属性d。",R,属于,实例
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,形式背景,被定义为,偏序集合
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,形式背景,由组成,唯一的一个偏序集合
"这种由背景(S,D,R)导出的格L就称为一个概念格。",概念格,被定义为,"由背景(S,D,R)导出的格L"
"这种由背景(S,D,R)导出的格L就称为一个概念格。",概念格,由组成,"由背景(S,D,R)导出的格L"
"这种由背景(S,D,R)导出的格L就称为一个概念格。",概念格,由组成,"由背景(S,D,R)导出的格L"
"格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。",格,被定义为,序偶
"格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。",格,被定义为,序偶
"格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。",格,被定义为,序偶
"格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。",格,被定义为,序偶
"每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|_y∈Y,xRy}2）Y={y∈D|_x∈X,xRy}在概念格节点间能够建立起一种偏序关系。",完备性,被定义为,"每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|_y∈Y,xRy}2）Y={y∈D|_x∈X,xRy}在概念格节点间能够建立起一种偏序关系。"
"每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|_y∈Y,xRy}2）Y={y∈D|_x∈X,xRy}在概念格节点间能够建立起一种偏序关系。",每一个序偶,由组成,关于关系R是完备的
"每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|_y∈Y,xRy}2）Y={y∈D|_x∈X,xRy}在概念格节点间能够建立起一种偏序关系。",每一个序偶关于关系R是完备的,实现,性质
"给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1_Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。",领先次序,被定义为,H2<H1_Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。
"给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1_Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。",H1,由组成,H2
根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。,偏序关系,包含,Hasse图
根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。,偏序关系,被定义为,Hasse图
根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。,Hasse图,由组成,偏序关系
②自底向上的FCA-Merge本体合并。,自底向上的FCA-Merge本体合并,被定义为,自底向上的FCA-Merge本体合并算法
②自底向上的FCA-Merge本体合并。,自底向上的FCA-Merge本体合并,由组成,自底向上的FCA-Merge本体合并
该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。,形式化概念分析技术,被定义为,一种自底向上的方式来合并两个共享相同实例集的本体
该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。,形式化概念分析技术,方法,以一种自底向上的方式来合并两个共享相同实例集的本体
该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。,该方法并不直接处理本体映射,由组成,形式化概念分析技术
整个本体合并的过程分三步。,本体合并,被定义为,本体合并的过程
整个本体合并的过程分三步。,整个本体合并的过程,由组成,分三步
整个本体合并的过程分三步。,本体合并,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（a）实例提取。,实例提取,被定义为,从文本中抽取实体和关系的过程
（a）实例提取。,实例提取,由组成,实例抽取
（a）实例提取。,实例提取,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。,FCA-Merge方法,被定义为,要求两个本体具有相同的实例集合
由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。,FCA-Merge方法,由组成,两个本体
从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。,从相同的文本集合为两个本体提取实例,被定义为,两本体相关的概念具有相近的共享实例集合
从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。,从相同的文本集合为两个本体提取实例,由组成,能够保证两本体相关的概念具有相近的共享实例集合
从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。,从相同的文本集合为两个本体提取实例,由组成,能够保证两本体相关的概念具有相近的共享实例集合
而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。,共享实例,被定义为,用来识别相似概念的基础
而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。,共享实例,由组成,识别相似概念
而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。,共享实例,属于,提取共享实例
这一步采用自然语言处理技术，得到两本体的形式背景。,形式背景,被定义为,自然语言处理技术
这一步采用自然语言处理技术，得到两本体的形式背景。,两本体的形式背景,由组成,自然语言处理技术
每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。,FCA-Merge,被定义为,将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真
每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。,FCA-Merge,由组成,每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真
显然，一个文档可能是多个概念的实例。,文档,被定义为,多个概念的实例
显然，一个文档可能是多个概念的实例。,文档,由组成,多个概念
显然，一个文档可能是多个概念的实例。,文档,由组成,多个概念
（b）概念格计算。,概念格计算,被定义为,概念格计算是概念格的实现方法
（b）概念格计算。,概念格计算,由组成,概念格
（b）概念格计算。,概念格计算,由组成,概念格
输入第一步中得到的两张布尔表来计算概念格。,概念格计算,由组成,概念格
输入第一步中得到的两张布尔表来计算概念格。,概念格,由组成,布尔表
"FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。",FCA-Merge,包含,经典的形式化概念分析理论提供的算法
"FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。",FCA-Merge,被定义为,根据两张形式化背景的布尔表自动生成一个剪枝的概念格
"FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。",FCA-Merge,由组成,"采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。"
（c）交互生成合并的本体。,交互生成合并的本体,被定义为,本体合并
（c）交互生成合并的本体。,交互生成合并的本体,由组成,本体
生成的概念格已经将独立的两个本体合并在一起。,生成的概念格,由组成,独立的两个本体
生成的概念格已经将独立的两个本体合并在一起。,生成的概念格,由组成,独立的两个本体
本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。,本体工程师,被定义为,根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。
本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。,本体工程师,由组成,生成的概念格
本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。,本体工程师,由组成,生成的概念格
显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。,合并的本体,被定义为,本体概念间的映射关系
显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。,合并的本体,由组成,两个初始本体概念间的映射关系
显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。,合并的本体,属于,本体概念间的映射关系
②FCA总结。,FCA,被定义为,FCA总结
②FCA总结。,FCA,由组成,总结
形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。,形式化概念分析技术,被定义为,基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。
形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。,形式化概念分析技术,由组成,基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。
这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。,本体概念间的等价和包含映射,被定义为,1∶1的简单类型
这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。,异构本体概念间的等价和包含映射,由组成,1∶1的简单类型
这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。,异构本体概念间的等价和包含映射,由组成,1∶1的简单类型
FCA具有一些不足。,FCA,被定义为,基于图模型的语义分析方法
首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。,关系映射,被定义为,基于概念的映射
首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。,复杂概念间的映射,由组成,该方法
其次，映射结果质量受提取共享实例过程的影响。,映射结果质量,被定义为,提取共享实例过程
其次，映射结果质量受提取共享实例过程的影响。,映射结果质量,由组成,提取共享实例过程
其次，映射结果质量受提取共享实例过程的影响。,映射结果质量,属于,提取共享实例过程
最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。,概念格生成合并本体,被定义为,概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。
最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。,由概念格生成合并本体的工作,由组成,可能产生错误的映射结果
4）IF-Map。,IF-Map,被定义为,一种基于图表示的推理方法
4）IF-Map。,IF-Map,由组成,IF-Map
4）IF-Map。,IF-Map,由组成,IF-Map
该方法是一种自动的本体映射发现技术，基于信息流理论[71]。,本体映射发现技术,被定义为,信息流理论
该方法是一种自动的本体映射发现技术，基于信息流理论[71]。,基于信息流理论的本体映射发现技术,方法,基于信息流理论
该方法是一种自动的本体映射发现技术，基于信息流理论[71]。,基于信息流理论的本体映射发现技术,由组成,信息流理论
IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。,IF-Map,被定义为,寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射
IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。,IF-Map,由组成,寻找两个局部本体间的等价
IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。,IF-Map,由组成,寻找两个局部本体间的等价
那样的参考本体没有实例，而实例只在局部本体中才考虑。,参考本体,被定义为,没有实例
那样的参考本体没有实例，而实例只在局部本体中才考虑。,那样的参考本体没有实例,由组成,局部本体
那样的参考本体没有实例，而实例只在局部本体中才考虑。,那样的参考本体,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。,IF-Map方法,被定义为,生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系
因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。,IF-Map方法,由组成,生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。
映射生成的过程包括4个阶段：①采集，即收集不同的本体；②转换，即将待映射本体转换为特定格式；③信息映射生成，即利用信息流理论生成本体间的映射；④映射投影，将生成的概念间等价映射用本体语言表示出来，如owl:sameAs等。,映射生成的过程,由组成,4个阶段
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,被定义为,异构本体概念间的简单等价映射
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,由组成,异构本体概念间的简单等价映射
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（3）基于实例的本体映射总结。,基于实例的本体映射,被定义为,基于实例的本体映射是本体映射的一种，它通过实例来描述本体映射。
（3）基于实例的本体映射总结。,基于实例的本体映射,由组成,基于实例的本体映射
（3）基于实例的本体映射总结。,基于实例的本体映射,属于,基于实例的本体映射总结
与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。,基于实例的本体映射发现方法,包含,基于术语和结构的映射发现方法
与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。,基于实例的本体映射发现方法,被定义为,基于实例的本体映射发现方法
与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。,基于实例的本体映射发现方法,由组成,基于术语和结构的映射发现方法
一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。,基于实例的方法,被定义为,能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现
一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。,基于实例的方法,由组成,能较好地解决异构本体概念间的映射问题
此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。,基于实例的方法,被定义为,要求异构本体具有相同的实例集合
此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。,基于实例的方法,方法,采用机器学习技术
3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。,综合方法,被定义为,综合方法是将多种映射方法结合在一起，以解决映射问题
3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。,综合方法,方法,不同的映射方法
3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。,综合方法,由组成,不同的映射方法
因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。,本体映射,被定义为,综合使用
因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。,本体映射,由组成,多种映射方法
（1）方法和工具1）QOM。,QOM,被定义为,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
（1）方法和工具1）QOM。,QOM,由组成,方法和工具
QOM是采用综合方法发现本体映射的典型工作[72-75]。,QOM,包含,采用综合方法发现本体映射的典型工作
QOM是采用综合方法发现本体映射的典型工作[72-75]。,QOM,被定义为,采用综合方法发现本体映射的典型工作
QOM是采用综合方法发现本体映射的典型工作[72-75]。,QOM,由组成,采用综合方法发现本体映射的典型工作
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,知识图谱,包含,知识表示
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,知识图谱,被定义为,知识表示
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,该方法,方法,寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,该方法,由组成,同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,该方法,由组成,同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。
QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。,QOM,包含,映射发现算法
QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。,QOM,被定义为,合理组织各种映射发现算法
QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。,QOM,由组成,通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。
①QOM的思路。,QOM,被定义为,知识图谱的查询优化方法
①QOM的思路。,QOM,由组成,QOM的思路
大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。,本体映射发现算法,被定义为,过于强调映射结果的质量，而往往忽略发现映射的效率
大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。,大多数本体映射发现算法,由组成,过于强调映射结果的质量
大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。,大多数本体映射发现算法,实现,过于强调映射结果的质量
"目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。",映射对象,被定义为,O(n2)
"目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。",方法,方法,O(n2)
"目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。",目前，绝大多数方法的时间复杂度为O(n2),由组成,n
对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。,大本体间的映射需求,被定义为,UMLS
与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。,QOM,被定义为,QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。
与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。,QOM,方法,同时考虑映射质量和运行时间复杂度
与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。,QOM,由组成,同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果
QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。,QOM,被定义为,只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。
QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。,QOM,由组成,异构本体间1∶1等价映射
QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。,QOM,由组成,异构本体间1∶1等价映射
②QOM方法的过程。,QOM方法,被定义为,知识图谱的查询优化方法
②QOM方法的过程。,QOM方法,方法,QOM方法的过程
②QOM方法的过程。,QOM方法,由组成,QOM方法的过程
QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。,QOM处理本体映射的过程,被定义为,六步
QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。,QOM处理本体映射的过程,由组成,六步
特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。,特征工程,被定义为,将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。
特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。,特征工程,由组成,将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,QOM,由组成,RDF三元组
搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。,QOM,被定义为,启发式方法
搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。,搜索步骤的选择,由组成,启发式方法
相似度计算：对每一对候选映射对象，判断它们之间的相似度值。,相似度计算,被定义为,对每一对候选映射对象，判断它们之间的相似度值。
相似度计算：对每一对候选映射对象，判断它们之间的相似度值。,相似度计算,由组成,对每一对候选映射对象，判断它们之间的相似度值。
一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。,一个对象,被定义为,URIs的标识和RDF(S)原语
一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。,一个对象,由组成,URIs的标识和RDF(S)原语等
一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。,一个对象,由组成,URIs的标识和RDF(S)原语等
QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。,QOM,被定义为,多种关于对象特征（包括概念、关系和实例）的相似度量公式
QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。,QOM,由组成,多种关于对象特征（包括概念、关系和实例）的相似度量公式
为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。,选择度量公式,被定义为,忽略那些复杂度过高的度量公式
为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。,选择度量公式,由组成,忽略那些复杂度过高的度量公式
相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。,相似度累加,被定义为,由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。
相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。,相似度累加,由组成,同时采用多种度量方法
这些不同的相似度值需要累加，成为单个的相似度值。,相似度值,被定义为,累加
这些不同的相似度值需要累加，成为单个的相似度值。,相似度值,由组成,累加
这些不同的相似度值需要累加，成为单个的相似度值。,这些不同的相似度值需要累加,实现,单个的相似度值
QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。,QOM,被定义为,QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。
QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。,QOM,由组成,不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度
QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。,QOM,由组成,不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度
解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。,去除一些不正确的映射结果,被定义为,解释
解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。,去除一些不正确的映射结果,由组成,解释
解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。,去除一些不正确的映射结果,由组成,解释
根据处理后的最终相似度值判断本体之间的映射。,本体映射,被定义为,根据处理后的最终相似度值判断本体之间的映射。
根据处理后的最终相似度值判断本体之间的映射。,相似度,由组成,相似度计算
根据处理后的最终相似度值判断本体之间的映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
根据处理后的最终相似度值判断本体之间的映射。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。,迭代,被定义为,算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。
迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。,迭代,由组成,算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。
每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,贪婪策略,包含,每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。
每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,贪婪策略,被定义为,每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。
每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,由组成,贪婪策略
每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,由组成,贪婪策略
③实验评估和结果。,实验评估和结果,被定义为,实验评估
③实验评估和结果。,实验评估和结果,由组成,实验评估
③实验评估和结果。,③实验评估和结果。,属于,实验评估
QOM分析了几种典型的本体映射方法的时间复杂度。,QOM分析,被定义为,几种典型的本体映射方法的时间复杂度
QOM分析了几种典型的本体映射方法的时间复杂度。,QOM,方法,时间复杂度
QOM分析了几种典型的本体映射方法的时间复杂度。,QOM分析了几种典型的本体映射方法的时间复杂度。,由组成,时间复杂度
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",iPROMPT,包含,AnchorPROMPT
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",iPROMPT,方法,O(n・log(n))
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",iPROMPT,由组成,O(n・log(n))
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",AnchorPROMPT,由组成,O(n2・log2(n))
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",GLUE,由组成,O(2n)
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",iPROMPT,由组成,O(n・log(n))
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",AnchorPROMPT,由组成,O(n2・log2(n))
"iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。",GLUE,由组成,O(2n)
与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n・og(n))。,QOM,包含,映射发现的时间复杂度控制为O(n・og(n))
与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n・og(n))。,QOM,方法,O(n・og(n))
与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n・og(n))。,QOM,由组成,O(n・og(n))
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,被定义为,映射结果质量不尽如人意
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,方法,GLUE
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,由组成,GLUE
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,由组成,GLUE
试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。,QOM,包含,试验结果
试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。,QOM,由组成,QOM-based mapping
2）OLA。,OLA,被定义为,知识图谱
2）OLA。,OLA,由组成,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
2）OLA。,OLA,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。",OLA,被定义为,本体映射发现综合方法
"OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。",OLA,由组成,本体映射发现综合方法
"OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。",OLA,由组成,本体映射发现综合方法
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,由组成,本体映射发现综合方法
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,由组成,本体映射发现综合方法
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,由组成,OWL-Lite描述的本体间的映射
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,由组成,OWL-Lite描述的本体间的映射
OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。,OLA算法,被定义为,将OWL本体编码为图，图中的边为概念之间的关系。
OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。,OLA算法,由组成,将OWL本体编码为图，图中的边为概念之间的关系。
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,包含,根据类和它的属性将节点进行分类；考虑分类后节点中的所有特征，如父类和属性等。
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,由组成,根据类和它的属性将节点进行分类；考虑分类后节点中的所有特征，如父类和属性等。
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,由组成,根据类和它的属性将节点进行分类；考虑分类后节点中的所有特征，如父类和属性等。
实体之间的相似度被赋予权重并线性累加。,实体之间的相似度,包含,权重
实体之间的相似度被赋予权重并线性累加。,实体之间的相似度,被定义为,线性累加
实体之间的相似度被赋予权重并线性累加。,实体之间的相似度,方法,被赋予权重并线性累加
实体之间的相似度被赋予权重并线性累加。,实体之间的相似度,由组成,被赋予权重并线性累加
实体之间的相似度被赋予权重并线性累加。,实体之间的相似度被赋予权重并线性累加。,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
OLA能发现本体概念间的等价映射。,OLA,被定义为,本体概念间的等价映射
OLA能发现本体概念间的等价映射。,OLA,由组成,本体概念间的等价映射
OLA能发现本体概念间的等价映射。,OLA,由组成,本体概念间的等价映射
3）KRAFT。,KRAFT,被定义为,知识图谱的构建框架
3）KRAFT。,KRAFT,由组成,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。",KRAFT,包含,本体映射的体系结构
"KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。",KRAFT,被定义为,本体映射的体系结构
KRAFT并没有给出映射发现的方法。,KRAFT,被定义为,知识图谱的映射发现方法
KRAFT并没有给出映射发现的方法。,KRAFT,由组成,没有给出映射发现的方法
KRAFT并没有给出映射发现的方法。,KRAFT,由组成,没有给出映射发现的方法
4）OntoMap。,OntoMap,被定义为,知识图谱的构建工具
4）OntoMap。,OntoMap,由组成,OntoMap是由美国斯坦福大学于2004年开发的一个知识图谱构建工具
4）OntoMap。,OntoMap,由组成,OntoMap是由美国斯坦福大学于2004年开发的一个知识图谱构建工具
OntoMap是一个知识表示的形式化、推理和Web接口。,OntoMap,被定义为,知识表示的形式化、推理和Web接口
OntoMap是一个知识表示的形式化、推理和Web接口。,OntoMap,由组成,知识表示的形式化、推理和Web接口
OntoMap是一个知识表示的形式化、推理和Web接口。,OntoMap,由组成,知识表示的形式化、推理和Web接口
它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。,SPO,被定义为,访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。
它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。,SPO,由组成,SPO接口
为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。,OntoMap,被定义为,OntoMapO
为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。,OntoMap,由组成,OntoMapO
这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。,OWL_Lite,被定义为,描述本体映射的特定原语
这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。,OWL_Lite,由组成,描述本体映射的特定原语
这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。,OWL_Lite,由组成,描述本体映射的特定原语
OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。,OntoMapO,被定义为,考虑的上层本体包括Cyc、WordNet和SENSUS等。
OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。,OntoMapO,由组成,Cyc、WordNet和SENSUS等
OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。,OntoMapO,由组成,Cyc、WordNet和SENSUS等
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射原语,被定义为,①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言,由组成,映射原语
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言,由组成,映射原语
这些原语表明了OntoMapO支持的映射类型。,映射类型,被定义为,OntoMapO支持的映射类型
这些原语表明了OntoMapO支持的映射类型。,映射类型,由组成,OntoMapO支持的映射类型
这些原语表明了OntoMapO支持的映射类型。,映射类型,由组成,OntoMapO支持的映射类型
但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。,OntoMap,被定义为,OntoMap是一个基于Ontology的映射工具
但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。,OntoMap,由组成,OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。
但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。,OntoMap,由组成,OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。
因此，OntoMap更多只是提供了一个映射的表示框架。,OntoMap,被定义为,映射框架
因此，OntoMap更多只是提供了一个映射的表示框架。,OntoMap,由组成,Ontology Mapping Framework
和5）OBSERVER。,OBSERVER,被定义为,观察者
和5）OBSERVER。,OBSERVER,由组成,5）
和5）OBSERVER。,知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。,OBSERVER系统,被定义为,解决分布式数据库的异构问题
OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。,OBSERVER系统,由组成,组件本体
OBSERVER使用基于组件的方法发现本体映射。,OBSERVER,包含,基于组件的方法发现本体映射
OBSERVER使用基于组件的方法发现本体映射。,OBSERVER,方法,基于组件的方法发现本体映射
OBSERVER使用基于组件的方法发现本体映射。,OBSERVER,由组成,基于组件的方法发现本体映射
它使用多个预先定义的本体来表示异构数据库的模式。,异构数据库模式,被定义为,多个预先定义的本体
它使用多个预先定义的本体来表示异构数据库的模式。,异构数据库模式,由组成,多个预先定义的本体
映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。,映射,被定义为,这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。
映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。,映射,被定义为,这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。
映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。,映射,由组成,这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。
映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。,映射,由组成,这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。
OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。,OBSERVER,包含,两个组件本体之间的1∶1映射
OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。,OBSERVER,由组成,两个组件本体之间的1∶1映射
OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。,OBSERVER,由组成,两个组件本体之间的1∶1映射
但是，该方法的本体映射依靠手工建立。,本体映射,被定义为,本体映射方法
但是，该方法的本体映射依靠手工建立。,本体映射,方法,手工建立
但是，该方法的本体映射依靠手工建立。,本体映射,由组成,手工建立
但是，该方法的本体映射依靠手工建立。,本体映射,由组成,手工建立
6）InfoSleuth。,InfoSleuth,被定义为,知识图谱中用于查询和检索的系统
6）InfoSleuth。,InfoSleuth,由组成,信息侦察
6）InfoSleuth。,InfoSleuth,由组成,信息侦察
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,包含,基于主体的系统
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,被定义为,基于主体的系统
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,由组成,基于主体的系统
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,由组成,基于主体的系统
本体间的映射是概念间的关系。,本体间的映射,被定义为,概念间的关系
本体间的映射是概念间的关系。,本体间的映射,由组成,概念间的关系
本体间的映射是概念间的关系。,本体间的映射,由组成,概念间的关系
本体的映射由一个特殊的被称为“资源主体”的类完成。,映射,被定义为,一个特殊的被称为“资源主体”的类
本体的映射由一个特殊的被称为“资源主体”的类完成。,本体的映射,由组成,一个特殊的被称为“资源主体”的类
本体的映射由一个特殊的被称为“资源主体”的类完成。,本体的映射,由组成,一个特殊的被称为“资源主体”的类
一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。,资源主体,被定义为,一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。
一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。,资源主体,被定义为,一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。
一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。,资源主体,由组成,本体映射的规则集
一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。,资源主体,由组成,本体映射的规则集
7）基于虚拟文档的本体匹配。,基于虚拟文档的本体匹配,被定义为,基于虚拟文档的本体匹配是利用虚拟文档来表示本体，然后利用本体匹配算法来匹配虚拟文档和本体。
7）基于虚拟文档的本体匹配。,基于虚拟文档的本体匹配,由组成,基于虚拟文档的本体匹配
7）基于虚拟文档的本体匹配。,基于虚拟文档的本体匹配,由组成,基于虚拟文档的本体匹配
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,基于虚拟文档的本体匹配,由组成,基于虚拟文档的本体匹配
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,基于虚拟文档的本体匹配,由组成,基于虚拟文档的本体匹配
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,本体元素,由组成,词汇
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,本体元素,由组成,词汇
元素还可以通过自身注释中的简单语句，对其含义进行补充说明。,元素,被定义为,通过自身注释中的简单语句，对其含义进行补充说明
元素还可以通过自身注释中的简单语句，对其含义进行补充说明。,元素,由组成,简单语句
此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。,语义描述,被定义为,文本形式
此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。,文本形式,由组成,语义描述
因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。,虚拟文档,被定义为,本体中元素相关的文本
因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。,虚拟文档,由组成,本体中元素
因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。,虚拟文档,由组成,本体中元素
一个元素的虚拟文档包含3种。,虚拟文档,被定义为,一个元素的虚拟文档包含3种
一个元素的虚拟文档包含3种。,一个元素的虚拟文档,由组成,3种
一个元素的虚拟文档包含3种。,一个元素的虚拟文档,由组成,3种
"①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。",元素自身的描述文本,被定义为,"Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。"
"①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。",元素自身的描述文本Des（e）,由组成,"包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。"
②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,空节点,被定义为,对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。
②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,空节点,由组成,Des（e）
②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,空节点,由组成,Des（e）
在此过程中，越远的元素会被赋予越小的描述权重。,描述权重,被定义为,描述越远的元素
在此过程中，越远的元素会被赋予越小的描述权重。,描述权重,由组成,越远的元素
③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。,元素邻居,被定义为,根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。
③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。,元素,由组成,三元组
注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。,SPO三元组,被定义为,SPO三元组是一种基于三元组的知识表示方式
注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。,注意,由组成,如果这些邻居存在空节点，则采用空节点的描述方式进行描述。
注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。,注意,由组成,如果这些邻居存在空节点，则采用空节点的描述方式进行描述。
在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。,虚拟文档,被定义为,构造虚拟文档
在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。,虚拟文档,由组成,构造虚拟文档
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,两元素的语义描述文档相似度,被定义为,它们相匹配的可能性
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,两元素的语义描述文档相似度,由组成,它们相匹配的可能性
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,两元素的语义描述文档相似度,实现,匹配可能性
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,两元素的语义描述文档相似度,属于,匹配可能性
描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。,描述文档,被定义为,根据本体对元素描述的语义特点被划分为不同的类型
描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。,描述文档,由组成,根据本体对元素描述的语义特点被划分为不同的类型
描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。,描述文档,由组成,根据本体对元素描述的语义特点被划分为不同的类型
"虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,�,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。",虚拟文档,包含,带权重的词汇集合
"虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,�,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。",虚拟文档的表示形式,被定义为,带权重的词汇集合
基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。,基于虚拟文档的方法,被定义为,思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形
基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。,基于虚拟文档的方法,由组成,思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形
（2）本体映射的综合方法总结。,本体映射的综合方法,由组成,总结
（2）本体映射的综合方法总结。,本体映射的综合方法,由组成,总结
考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。,多种映射方法综合使用,包含,吸收每种方法的优点
考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。,多种映射方法,由组成,综合使用
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,综合使用多种方法,被定义为,这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,综合使用多种方法,方法,要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,综合使用多种方法,由组成,这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
此外，将各种映射方法的结果进行综合也很重要。,知识图谱,被定义为,将各种映射方法的结果进行综合
此外，将各种映射方法的结果进行综合也很重要。,将各种映射方法的结果进行综合,由组成,也很重要
此外，将各种映射方法的结果进行综合也很重要。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
此外，将各种映射方法的结果进行综合也很重要。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。,本体映射管理,被定义为,映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。
5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。,本体映射管理,由组成,映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。
要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。,多本体管理,被定义为,对多本体进行有效的管理
要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。,多本体环境,由组成,多本体管理
管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。,管理多个本体,被定义为,方便处理多个本体的维护和演化问题；合理组织本体间的映射，方便查询、数据转移和推理等应用；将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。
管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。,管理多个本体,被定义为,方便处理多个本体的维护和演化问题；合理组织本体间的映射，方便查询、数据转移和推理等应用；将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。
管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。,管理多个本体,由组成,好处
这里讨论如何通过组织映射来达到管理异构的多本体的目的。,组织映射,被定义为,通过组织映射来达到管理异构的多本体的目的
这里讨论如何通过组织映射来达到管理异构的多本体的目的。,组织映射,由组成,多本体
实际上，在数据库等领域中就有针对模式或模型管理的研究。,模式管理,被定义为,模式管理
实际上，在数据库等领域中就有针对模式或模型管理的研究。,模式管理,由组成,模式管理
实际上，在数据库等领域中就有针对模式或模型管理的研究。,模式或模型管理,属于,数据库
他们指出，模型间的映射和操作是模型管理的核心问题。,模型间的映射和操作,被定义为,模型管理的核心问题
他们指出，模型间的映射和操作是模型管理的核心问题。,模型间的映射和操作,由组成,模型管理的核心问题
他们指出，模型间的映射和操作是模型管理的核心问题。,模型间的映射和操作,实现,模型管理
他们指出，模型间的映射和操作是模型管理的核心问题。,模型间的映射和操作,属于,模型管理
"在本体研究领域，一些工作分析了本体管理的挑战[87,88]。",本体管理,被定义为,本体管理研究
"在本体研究领域，一些工作分析了本体管理的挑战[87,88]。","在本体研究领域，一些工作分析了本体管理的挑战[87,88]。",由组成,"在本体研究领域，一些工作分析了本体管理的挑战[87,88]。"
"在本体研究领域，一些工作分析了本体管理的挑战[87,88]。",在本体研究领域，一些工作分析了本体管理的挑战,属于,在本体研究领域，一些工作分析了本体管理的挑战
这些研究将本体管理的任务分为两方面。,本体管理,被定义为,本体管理的任务
这些研究将本体管理的任务分为两方面。,本体管理,由组成,本体管理研究
这些研究将本体管理的任务分为两方面。,本体管理,由组成,本体管理研究
一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。,本体库系统,被定义为,增强本体管理
一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。,设计本体库系统,由组成,增强本体管理
另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。,本体版本或演化,被定义为,研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。
另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。,本体版本或演化,由组成,研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。
Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。,Stoffel_K等人设计了一个处理大规模本体的系统,被定义为,高效内存管理、关系数据库二级存储，以及并行处理
Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。,Stoffel_K等人设计了一个处理大规模本体的系统,由组成,高效内存管理、关系数据库二级存储，以及并行处理
Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。,Stoffel_K等人设计了一个处理大规模本体的系统,由组成,高效内存管理、关系数据库二级存储，以及并行处理
Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。,Lee_J等人描述了一个企业级的本体管理系统,被定义为,它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。
Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。,Lee_J等人描述了一个企业级的本体管理系统,由组成,它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。
Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。,OntoManager,被定义为,本体管理系统
Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。,OntoManager,由组成,Stojanovic_L等人
Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。,OntoManager,由组成,Stojanovic_L等人
显然，这些工作都关注本体的表示、存储和维护。,本体,被定义为,本体表示、存储和维护
显然，这些工作都关注本体的表示、存储和维护。,本体,由组成,本体表示、存储和维护
显然，这些工作都关注本体的表示、存储和维护。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,本体
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,本体映射,被定义为,处理多个本体之间映射的方法
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,本体映射,方法,处理多个本体
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,本体映射,由组成,本体演化
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
但这些工作为管理多个本体打下了基础。,管理多个本体,被定义为,本体管理
但这些工作为管理多个本体打下了基础。,管理多个本体,由组成,为管理多个本体打下了基础
但这些工作为管理多个本体打下了基础。,管理多个本体,由组成,为管理多个本体打下了基础
Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。,PROMPTDiff算法,包含,Noy_N_F和Musen_M提出一个处理版本管理框架
Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。,Noy_N_F,由组成,PROMPTDiff算法
Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。,Noy_N_F,由组成,PROMPTDiff算法
PROMPTDiff只使用结构不同检测两个版本的不同。,PROMPTDiff,被定义为,只使用结构不同检测两个版本的不同。
PROMPTDiff只使用结构不同检测两个版本的不同。,PROMPT,由组成,Diff
PROMPTDiff只使用结构不同检测两个版本的不同。,PROMPT,由组成,Diff
而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。,Klein_M的方法,被定义为,日志的变化、概念化关系和传递集合等
而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。,Klein_M的方法,由组成,更多的选择
Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。,Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架,由组成,单个本体演化、多个相互依赖的本体演化和分布式本体演化
Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。,Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架,由组成,单个本体演化、多个相互依赖的本体演化和分布式本体演化
Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。,Klein_M分析本体演化管理的需求和问题,被定义为,本体演化的框架
Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。,Klein_M分析本体演化管理的需求和问题,由组成,提出了本体演化的框架
从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。,本体管理工作,被定义为,关注本体演化或本体版本变化问题
从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。,本体管理工作,由组成,关注本体演化或本体版本变化问题
从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。,本体管理工作,属于,本体演化或本体版本变化问题
这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。,多本体,被定义为,利用多本体实现更强大、灵活的、单本体无法提供的服务
这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。,多本体,由组成,利用多本体实现更强大、灵活的、单本体无法提供的服务
与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。,Xu_Baowen等人,被定义为,从功能角度来探讨多本体管理
与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。,Xu_Baowen,由组成,多本体管理
传统的本体管理通常是二层结构：本体存储层和应用层。,传统的本体管理,被定义为,二层结构
传统的本体管理通常是二层结构：本体存储层和应用层。,传统的本体管理,由组成,二层结构：本体存储层和应用层
二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。,二层架构的多本体管理,被定义为,针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复
二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。,二层架构的多本体管理,由组成,过于粗糙
Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。,Xu_Baowen等人,被定义为,从管理多本体的映射来处理这些问题
Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。,Xu_Baowen,由组成,从管理多本体的映射来处理这些问题
Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。,Xu_Baowen,由组成,从管理多本体的映射来处理这些问题
这样的管理方式具有灵活的特点，适应动态Web环境。,这样的管理方式,被定义为,具有灵活的特点，适应动态Web环境
这样的管理方式具有灵活的特点，适应动态Web环境。,这样的管理方式,由组成,具有灵活的特点，适应动态Web环境
然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。,多本体,被定义为,将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。
然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。,多本体,由组成,面向应用的通用功能
Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,被定义为,多本体管理框架
Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,由组成,多本体管理框架
Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,由组成,多本体管理框架
框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。,框架,被定义为,本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层
框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。,框架,由组成,本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层
框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。,框架,由组成,本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层
五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。,五层的多本体管理体系结构,被定义为,面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。
五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。,五层的多本体管理体系结构,由组成,面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。
五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。,五层的多本体管理体系结构,由组成,面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。
各层的具体功能如下：①本体库层。,本体库层,被定义为,各层的具体功能
各层的具体功能如下：①本体库层。,各层的具体功能,由组成,本体库层
本体库层存放不同渠道获得的本体。,本体库层,被定义为,存放不同渠道获得的本体
本体库层存放不同渠道获得的本体。,本体库层,由组成,不同渠道获得的本体
本体库层存放不同渠道获得的本体。,本体库层,由组成,不同渠道获得的本体
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体库层,由组成,不同渠道获得的本体
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体,由组成,创建者与创建时间
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体,由组成,创建者与创建时间
②本体表示层。,本体表示层,被定义为,本体表示层是知识图谱的核心，是知识图谱的底层，是知识图谱的基石
②本体表示层。,本体表示层,由组成,本体表示层
②本体表示层。,本体表示层,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,本体语言,被定义为,将不同本体语言的语法、逻辑模型和表达能力转换到统一的表示形式
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,不同本体语言的语法,由组成,转换到统一的表示形式
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,不同本体语言的语法、逻辑模型和表达能力都必然存在差异,实现,将本体转换到统一的表示形式
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,不同本体语言的语法、逻辑模型和表达能力都必然存在差异,来源,将本体转换到统一的表示形式
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,不同本体语言的语法、逻辑模型和表达能力都必然存在差异,属于,将本体转换到统一的表示形式
这种转换会造成一些信息的损失。,知识图谱,被定义为,知识表示
这种转换会造成一些信息的损失。,转换,由组成,一些信息的损失
这种转换会造成一些信息的损失。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
通常少许的非关键本体信息在转换中丢失是可容忍的。,非关键本体信息,被定义为,在转换中丢失是可容忍的
通常少许的非关键本体信息在转换中丢失是可容忍的。,非关键本体信息,由组成,转换
③桥本体层。,桥本体层,被定义为,桥本体层是桥本体中用于描述桥梁结构特征的本体层
③桥本体层。,桥本体层,由组成,桥本体层
多本体间常常重叠，其间往往有关联。,多本体,被定义为,多本体间常常重叠，其间往往有关联。
多本体间常常重叠，其间往往有关联。,多本体,由组成,多本体间常常重叠，其间往往有关联。
多本体间常常重叠，其间往往有关联。,多本体,由组成,多本体间常常重叠，其间往往有关联。
为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。,生成的桥本体,被定义为,描述多本体间的沟通
为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。,多本体,由组成,生成的桥本体
为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。,多本体,由组成,生成的桥本体
桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。,桥本体,被定义为,可表示本体间概念和关系的12种不同映射
桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。,桥本体,由组成,概念和关系的12种不同映射
桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。,桥本体,由组成,概念和关系的12种不同映射
"在这层中，利用文献[62,36]的方法生成本体间的映射。",本体映射,被定义为,"利用文献[62,36]的方法生成本体间的映射。"
"在这层中，利用文献[62,36]的方法生成本体间的映射。",本体间的映射,由组成,"文献[62,36]的方法"
"在这层中，利用文献[62,36]的方法生成本体间的映射。",本体间的映射,由组成,"文献[62,36]的方法"
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,包含,半自动化的
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,包含,半自动化的
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,由组成,半自动化的
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,实现,半自动化的
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,属于,半自动化的
本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。,本体间映射生成过程,被定义为,语义冗余和冲突
本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。,本体间映射生成过程,由组成,语义冗余和冲突
本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。,本体间映射生成过程,由组成,语义冗余和冲突
Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。,Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。,包含,Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法
Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。,Xu_Baowen,由组成,多本体环境的语义一致性检查问题和冗余化简算法
Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。,Xu_Baowen,由组成,多本体环境的语义一致性检查问题和冗余化简算法
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,语义一致性问题,被定义为,良性回路和恶性回路
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,语义一致性问题,由组成,良性回路和恶性回路
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,语义一致性问题,实现,将引入桥后的多本体中的回路分为两种类型
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,语义一致性问题,属于,将引入桥后的多本体中的回路分为两种类型
前者是由于引入等价桥后造成的，通过算法可消除。,等价桥,被定义为,通过引入等价桥消除等价关系
前者是由于引入等价桥后造成的，通过算法可消除。,等价桥,由组成,引入等价桥后造成的
前者是由于引入等价桥后造成的，通过算法可消除。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
前者是由于引入等价桥后造成的，通过算法可消除。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,被定义为,原始本体中的错误或引入不当的桥
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,由组成,前者
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,实现,引入不当的桥
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,来源,原始本体中的错误
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,属于,引入不当的桥
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法,包含,环路
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法,由组成,能够找到环路
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法,实现,能够找到环路
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法能够找到环路,来源,但区分恶性和良性环路需要人工参与
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法能够找到环路,属于,但区分恶性和良性环路需要人工参与
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法,实现,能够找到环路
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法能够找到环路,来源,但区分恶性和良性环路需要人工参与
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法能够找到环路,属于,但区分恶性和良性环路需要人工参与
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法,实现,能够找到环路
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法能够找到环路,来源,但区分恶性和良性环路需要人工参与
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,算法能够找到环路,属于,但区分恶性和良性环路需要人工参与
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,由组成,多本体环境
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,由组成,多本体环境
本体间映射抽取出来，可通过桥本体进行管理。,本体间映射,被定义为,本体间映射抽取出来，可通过桥本体进行管理。
本体间映射抽取出来，可通过桥本体进行管理。,本体间映射,由组成,桥本体
本体间映射抽取出来，可通过桥本体进行管理。,本体间映射,由组成,桥本体
当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。,增量更新算法,包含,映射同步更新
当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。,增量更新算法,由组成,映射同步更新
④多本体功能层。,多本体功能层,被定义为,实现多本体功能
④多本体功能层。,多本体功能层,由组成,多本体功能层
④多本体功能层。,多本体功能层,由组成,多本体功能层
多本体的管理能提供满足应用需求的一些主要功能。,多本体的管理,被定义为,满足应用需求的一些主要功能
多本体的管理能提供满足应用需求的一些主要功能。,多本体的管理,由组成,提供满足应用需求的一些主要功能
多本体的管理能提供满足应用需求的一些主要功能。,多本体的管理,由组成,提供满足应用需求的一些主要功能
第一，桥本体中的桥提供了大量的简单和复杂的本体映射。,桥本体,被定义为,桥本体中的桥提供了大量的简单和复杂的本体映射。
第一，桥本体中的桥提供了大量的简单和复杂的本体映射。,桥本体,由组成,桥
通过这些映射，很容易实现异构本体间的互操作问题。,映射,被定义为,实现异构本体间的互操作问题
通过这些映射，很容易实现异构本体间的互操作问题。,映射,由组成,异构本体间的互操作问题
第二，利用多本体间的桥，能实现跨不同本体的推理。,跨不同本体的推理,被定义为,利用多本体间的桥
第二，利用多本体间的桥，能实现跨不同本体的推理。,跨不同本体的推理,由组成,多本体间的桥
第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。,桥本体,被定义为,利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索
第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。,第三,由组成,能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。
第四，还可以从多本体中抽取满足需求的子本体。,多本体,被定义为,从多本体中抽取满足需求的子本体
第四，还可以从多本体中抽取满足需求的子本体。,多本体,由组成,子本体
第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。,多本体,被定义为,利用多本体进行语义标注，提供比单本体更丰富的语义数据
第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。,多本体,由组成,语义标注
⑤多本体应用层。,多本体应用层,被定义为,多本体应用层的特点
⑤多本体应用层。,多本体应用层,由组成,多本体应用层
⑤多本体应用层。,⑤多本体应用层,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。,多本体,被定义为,利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。
在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。,多本体,由组成,利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,本体映射,被定义为,基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,本体映射,由组成,子本体抽取
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,本体映射
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,本体映射
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,本体映射
大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。,大本体,被定义为,大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。
大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。,大本体,由组成,难以驾驭
使用整个本体会大大增加系统的复杂性和降低效率。,使用整个本体会大大增加系统的复杂性和降低效率。,包含,使用整个本体会大大增加系统的复杂性和降低效率
使用整个本体会大大增加系统的复杂性和降低效率。,使用整个本体会大大增加系统的复杂性和降低效率。,由组成,使用整个本体会大大增加系统的复杂性和降低效率。
因此，从源本体中抽取一个小的子本体能让系统更有效。,源本体,被定义为,子本体
因此，从源本体中抽取一个小的子本体能让系统更有效。,源本体,由组成,一个小的子本体
因此，从源本体中抽取一个小的子本体能让系统更有效。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
因此，从源本体中抽取一个小的子本体能让系统更有效。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识抽取
子本体抽取是一个新的研究领域。,子本体抽取,被定义为,一个全新的研究领域
子本体抽取是一个新的研究领域。,子本体抽取,由组成,一个新的研究领域
Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。,物化本体视图抽取,包含,顺序抽取过程
Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。,Wouters_C等人提出物化本体视图抽取的顺序抽取过程,由组成,通过优化模式来保证抽取质量
随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。,分布式方法,包含,从大的复杂本体中抽取子本体的代价
随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。,分布式方法,被定义为,降低从大的复杂本体中抽取子本体的代价
随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。,分布式方法,方法,降低从大的复杂本体中抽取子本体的代价
随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。,分布式方法,由组成,降低从大的复杂本体中抽取子本体的代价
Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。,Bhatt_M等人进一步分析了这种方法的语义完整性问题,被定义为,语义完整性
Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。,Bhatt_M等人进一步分析了这种方法的语义完整性问题,由组成,Bhatt_M等人进一步分析了这种方法的语义完整性问题
Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。,Noy_N_F,被定义为,PROMPTFactor
Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。,Noy_N_F,由组成,PROMPTFactor
Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。,Noy_N_F,由组成,PROMPTFactor
当前的方法都是从单个本体中抽取子本体。,当前的方法,被定义为,从单个本体中抽取子本体
当前的方法都是从单个本体中抽取子本体。,当前的方法,方法,从单个本体中抽取子本体
当前的方法都是从单个本体中抽取子本体。,当前的方法,由组成,从单个本体中抽取子本体
当前的方法都是从单个本体中抽取子本体。,当前的方法,由组成,从单个本体中抽取子本体
但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。,多本体环境下的应用,被定义为,多个本体的不同部分都可能是子本体需要的
但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。,多本体环境下的应用,由组成,多个本体的不同部分
从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。,从多本体中抽取子本体,被定义为,知识重用
从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。,从多本体中抽取子本体,由组成,相关的工作和工具并不多见
Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。,Kang_Dazhou等人,被定义为,从多本体中抽取子本体的方法
Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。,Kang_Dazhou等人,由组成,从多本体中抽取子本体的方法
Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。,Kang_Dazhou等人,由组成,从多本体中抽取子本体的方法
抽取子本体是一种重要的知识重用手段。,抽取子本体,被定义为,一种重要的知识重用手段
抽取子本体是一种重要的知识重用手段。,抽取子本体,由组成,知识重用
本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。,本体映射,被定义为,多本体间的联系
本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。,本体映射,由组成,多本体间的联系
本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。,本体映射,由组成,多本体间的联系
在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。,语义搜索,包含,本体映射和匹配结果
在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。,语义搜索,由组成,本体映射和匹配结果
5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。,实例层的融合与匹配,被定义为,针对实例层的匹配
5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。,实例层的融合与匹配,由组成,针对实例层的匹配
实例匹配的过程虽然与本体匹配有相似之处，但实例匹配通常是一个大规模数据处理问题，需要在匹配过程中解决其中的时间复杂度和空间复杂度问题，其难度和挑战更大。,实例匹配,被定义为,大规模数据处理问题
5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。,知识图谱中的实例匹配问题分析,被定义为,本体
5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。,知识图谱中的实例匹配问题分析,由组成,本体
5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。,知识图谱中的实例匹配问题分析,属于,本体
人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。,本体,被定义为,描述通用知识的大规模本体
人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。,描述通用知识的大规模本体,由组成,机器翻译、信息检索和知识推理
人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。,描述通用知识的大规模本体,由组成,机器翻译、信息检索和知识推理
与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。,领域本体,被定义为,领域内的专业知识
与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。,领域本体,由组成,领域内的研究人员
与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。,领域本体,属于,领域知识
这些本体的规模正随着人类知识的增长而变得越来越大。,本体,被定义为,人类知识的增长
这些本体的规模正随着人类知识的增长而变得越来越大。,本体,由组成,规模
这些本体的规模正随着人类知识的增长而变得越来越大。,本体,由组成,规模
近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。,大规模本体间映射,被定义为,建立不同领域知识的交叉和基于不同大本体的系统间的交互
近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。,不同领域知识的交叉和基于不同大本体的系统间的交互,由组成,建立大规模本体间映射的需求
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,知识图谱,包含,映射系统
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,知识图谱,被定义为,映射系统
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,映射系统,由组成,无法在用户可接受的时间内给出满意的映射结果
因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。,大规模本体映射问题,被定义为,对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。
因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。,大规模本体映射问题,由组成,对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。
本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。,大规模本体映射方法,被定义为,本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。
本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。,大规模本体映射方法,由组成,分析现有几种大规模本体映射方法
本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。,大规模本体映射方法,由组成,分析现有几种大规模本体映射方法
从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。,本体,被定义为,概念和关系规模
从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。,本体,由组成,概念和关系
从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。,本体,由组成,概念和关系
出于商业保密的目的，这些企业本体通常并不公开。,企业本体,被定义为,企业知识图谱
出于商业保密的目的，这些企业本体通常并不公开。,企业本体,由组成,商业保密
大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。,大规模本体,被定义为,机器翻译、信息检索和集成、决策支持、知识发现等领域
大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。,大规模本体,由组成,机器翻译、信息检索和集成、决策支持、知识发现
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,知识图谱,被定义为,知识表示、知识存储、知识抽取、知识融合、知识推理、语义搜索、知识问答、知识图谱
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,知识图谱,由组成,本体模型
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,知识图谱,实现,知识表示
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,知识图谱,来源,知识表示
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,知识图谱,属于,知识表示
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,包含,元素数
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,被定义为,实例数据
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,由组成,元素数庞大，尤其是实例数据较多
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,属于,实例数据
基于不同大规模知识图谱的系统间可能需要进行交互。,基于不同大规模知识图谱的系统间交互,被定义为,基于不同大规模知识图谱的系统间交互
基于不同大规模知识图谱的系统间可能需要进行交互。,基于不同大规模知识图谱的系统间交互,由组成,基于不同大规模知识图谱的系统间交互
一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。,一些应用需要借助映射对多个知识图谱进行集成,由组成,Yahoo_Directory和GoogleDirectory
一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。,一些应用需要借助映射对多个知识图谱进行集成,由组成,Yahoo_Directory和GoogleDirectory
随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。,不同领域知识图谱中的知识,被定义为,UMLS本体中的语义信息
随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。,不同领域知识图谱,由组成,UMLS本体中的语义信息
随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。,不同领域知识图谱,由组成,UMLS本体中的语义信息
总之，大规模知识图谱间的异构现象依然普遍存在。,大规模知识图谱间的异构现象,被定义为,普遍存在
总之，大规模知识图谱间的异构现象依然普遍存在。,大规模知识图谱间的异构现象,由组成,普遍存在
总之，大规模知识图谱间的异构现象依然普遍存在。,大规模知识图谱间的异构现象,属于,知识图谱项目
在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。,大规模知识图谱间的异构现象,属于,知识图谱项目
在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。,大规模知识图谱间的异构现象,属于,知识图谱项目
在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。,大规模知识图谱间的匹配,由组成,大规模知识图谱
大规模知识图谱匹配是极具挑战性的任务。,大规模知识图谱匹配,被定义为,极具挑战性的任务
大规模知识图谱匹配是极具挑战性的任务。,大规模知识图谱匹配,由组成,极具挑战性的任务
大规模知识图谱匹配是极具挑战性的任务。,大规模知识图谱匹配,由组成,极具挑战性的任务
Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。,本体映射,被定义为,Reed和Lenat
Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。,Reed,由组成,Cyc
显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。,大规模知识图谱匹配,被定义为,自动化方法
"传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。",模式匹配,被定义为,分治法
"传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。",模式匹配,由组成,分治法
然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。,知识图谱匹配,被定义为,分治方法
然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。,知识图谱匹配,由组成,传统模式匹配的分治方法
在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。,大规模知识图谱匹配任务,被定义为,2007年的OAEI
在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。,在2007年的OAEI中，参与评估的18个映射系统,由组成,2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务
2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。,2008年参与OAEI评估的13个映射系统,被定义为,只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。
2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。,2008年参与OAEI评估的13个映射系统,由组成,只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。
2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。,2008年参与OAEI评估的13个映射系统,由组成,只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。
由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。,大规模知识图谱匹配问题,被定义为,大规模知识图谱匹配问题
由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。,大多数公开的系统,由组成,不能处理大规模知识图谱匹配问题
由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。,知识图谱匹配问题,属于,大多数公开的系统
大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。,大规模知识图谱匹配问题,被定义为,空间复杂度、时间复杂度和匹配结果质量
大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。,大规模知识图谱匹配问题,由组成,空间复杂度、时间复杂度和匹配结果质量
1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。,空间复杂度挑战,被定义为,在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。
1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。,空间复杂度挑战,由组成,在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配,包含,相似矩阵
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配,被定义为,相似矩阵
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配,由组成,空间复杂度
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配,属于,知识图谱
当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。,知识图谱匹配,属于,知识图谱
当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。,知识图谱匹配,属于,知识图谱
当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。,操作系统,由组成,内存不足
当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。,操作系统,由组成,内存不足
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,知识图谱,包含,相似矩阵
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,相似矩阵,被定义为,二维数组
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,相似矩阵,由组成,双精度类型
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,匹配系统,属于,二维数组
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,大规模知识图谱匹配,被定义为,数据结构
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,大规模知识图谱匹配,被定义为,数据结构
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,大规模知识图谱匹配,由组成,数据结构
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,大规模知识图谱匹配,由组成,数据结构
目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。,知识图谱匹配,被定义为,合理的数据结构
目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。,知识图谱匹配,由组成,合理的数据结构
因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。,大规模知识图谱匹配,被定义为,空间复杂度
因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。,空间复杂度,由组成,大规模知识图谱匹配
2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。,知识图谱匹配系统,被定义为,匹配计算过程
2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。,知识图谱匹配系统,由组成,预处理过程和映射结果后处理过程
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,知识图谱匹配,被定义为,计算异构实例间的相似度
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,知识图谱匹配系统,由组成,O(n2)
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,知识图谱匹配系统,实现,O(n2)
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,知识图谱匹配系统,来源,知识图谱匹配系统
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,知识图谱匹配系统,属于,知识图谱匹配系统
虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。,O(nlog(n))复杂度的匹配方法,包含,匹配方法
虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。,O(nlog(n))复杂度的匹配方法,被定义为,匹配方法
虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。,匹配方法,由组成,O(nlog(n))复杂度的匹配方法
此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,匹配系统,由组成,O(n2t)
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,匹配系统,实现,O(n2t)
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,令计算两元素相似度过程的时间复杂度为t,来源,匹配系统
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,匹配系统,属于,O(n2t)
因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。,大规模知识图谱匹配问题,被定义为,降低匹配元素对的相似度计算次数
因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。,降低大规模知识图谱匹配问题的时间复杂度,由组成,减少匹配元素对的相似度计算次数
3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。,匹配方法,被定义为,匹配结果质量
3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。,匹配方法,由组成,时间复杂度和空间复杂度
此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。,知识图谱匹配,被定义为,全局分析和整理
此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。,知识图谱,由组成,全局分析和整理
然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。,知识图谱,被定义为,大规模知识图谱
然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。,知识图谱,由组成,简化或近似处理
然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。,知识图谱,由组成,简化或近似处理
最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。,分治策略,被定义为,将大规模知识图谱匹配问题转换为多个小规模匹配问题
最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。,分治策略,由组成,大规模知识图谱匹配问题
最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。,分治策略,由组成,大规模知识图谱匹配问题
最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。,大规模知识图谱匹配任务,被定义为,OAEI评估
最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。,OAEI,由组成,知识图谱匹配
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,大规模知识图谱匹配方法,被定义为,基于快速相似度计算的方法、基于规则的方法和基于分治的方法
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,基于快速相似度计算的方法,由组成,基于规则的方法
就目前来看，现有的大规模知识图谱匹配系统都能克服空间复杂度问题，因为匹配过程中需要的大量空间可以借助数据压缩技术（如将稀疏矩阵压缩存储）、外部数据库或临时文件等方式解决。,大规模知识图谱匹配系统,被定义为,克服空间复杂度问题
因此，下面着重分析三类方法的时间复杂度。,方法,被定义为,时间复杂度
因此，下面着重分析三类方法的时间复杂度。,方法,方法,O(n^2)
因此，下面着重分析三类方法的时间复杂度。,方法,由组成,时间复杂度
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,被定义为,降低每次相似度计算的时间复杂度
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,方法,尽量降低每次相似度计算的时间复杂度
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,由组成,降低每次相似度计算的时间复杂度
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,实现,基于快速相似度计算的实例匹配方法
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,来源,基于快速相似度计算的实例匹配方法
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,属于,基于快速相似度计算的实例匹配方法
基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。,基于快速相似度计算的方法,包含,文本匹配器、结构匹配器和基于实例的匹配器等
基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。,基于快速相似度计算的方法,方法,文本匹配器、结构匹配器和基于实例的匹配器等
基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。,基于快速相似度计算的方法,由组成,文本匹配器、结构匹配器和基于实例的匹配器等
很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。,文本匹配器,被定义为,避免构造复杂的映射线索
很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。,基于文本相似的匹配算法,由组成,构造复杂的映射线索
很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。,基于文本相似的匹配算法,由组成,构造复杂的映射线索
大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。,大规模知识图谱匹配,被定义为,结构匹配器
大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。,大规模知识图谱匹配中的结构匹配器,由组成,概念层次或元素邻居文本相似的启发式规则
采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。,大规模知识图谱匹配问题,被定义为,采用上述思想的系统
采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。,采用上述思想的系统,由组成,能勉强处理一些大规模知识图谱匹配问题
首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。,匹配器,被定义为,利用知识图谱中少量的信息构造匹配线索
首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。,匹配器,由组成,知识图谱
首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。,匹配器,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。,知识图谱,包含,相似度计算方法
其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。,系统效率,由组成,相似度计算方法
Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。,Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配,被定义为,文本匹配器和结构匹配器
Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。,Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配,由组成,匹配过程采用了一些通用的文本匹配器和结构匹配器
Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。,Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配,由组成,匹配过程采用了一些通用的文本匹配器和结构匹配器
Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。,Ichise,被定义为,Web_Directory
Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。,Ichise,由组成,Web_Directory
Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。,Ichise,由组成,Web_Directory
此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。,相似度计算,包含,相似函数
此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。,相似度计算,由组成,寻找最佳的相似函数和阈值
此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。,基于规则的实例匹配方法,被定义为,寻找匹配规则
5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。,基于规则的实例匹配方法,由组成,大规模知识图谱
5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。,基于规则的实例匹配方法,由组成,大规模知识图谱
但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。,规则匹配方法,被定义为,规则匹配方法往往需要人类手工构建的规则来保证结果质量。
但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。,规则匹配方法,由组成,规则匹配方法往往需要人类手工构建的规则来保证结果质量。
基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。,基于规则的方法,被定义为,易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法
基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。,基于规则的方法,由组成,处理大规模知识图谱中的实例匹配
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,实例匹配,被定义为,EM算法
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则,由组成,EM算法
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则,实现,基于EM算法的半监督学习框架
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,基于EM算法的半监督学习框架,属于,半监督学习框架
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,知识图谱,包含,匹配规则
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,该框架,由组成,迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,该框架,实现,迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,该框架,属于,迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对
具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。,匹配规则,被定义为,似然函数中需要被估计的参数
具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。,数据集中少量具有owl:sameAs属性的现存匹配对,由组成,似然函数中需要被估计的参数
具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。,数据集中少量具有owl:sameAs属性的现存匹配对,由组成,似然函数中需要被估计的参数
该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。,基于图的指标,被定义为,EM算法的目标似然函数
该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。,基于图的指标,方法,EM算法的目标似然函数
该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。,EM算法,由组成,基于图的指标
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,匹配规则,被定义为,如何集成不同规则的置信度
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,匹配规则,由组成,匹配对的匹配置信度
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,不同的匹配规则,实现,同一个匹配对的匹配置信度
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,不同的匹配规则,来源,同一个匹配对的匹配置信度
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,不同的匹配规则,属于,同一个匹配对的匹配置信度
该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。,Dempster's_rule,被定义为,将多个匹配对的不同置信度进行加权平均
该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。,Dempster's_rule,被定义为,将多个匹配对的不同置信度进行加权平均
该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。,该方法,由组成,Dempster's_rule
定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。,实例等价,被定义为,两个实例在现实世界中为同一个物体
定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。,实例等价,由组成,～I
定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。,实例等价,由组成,～I
"URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。",URI不同的两个实例,被定义为,等价的
"URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。","URI不同的两个实例e1,e2",由组成,等价的
"定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。",匹配,包含,匹配器
"定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。",匹配,由组成,匹配器发现的一个匹配
如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。,属性-值对,被定义为,预处理
如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。,预处理,由组成,实例
然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。,种子匹配对,包含,高质量的新匹配对
然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。,种子匹配对,由组成,用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。
重复迭代步骤直至满足终止条件。,重复迭代,被定义为,重复迭代步骤直至满足终止条件。
重复迭代步骤直至满足终止条件。,重复迭代,由组成,步骤
重复迭代步骤直至满足终止条件。,重复迭代步骤直至满足终止条件。,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
前面提到，该框架通过学习规则来推导实例之间的等价关系。,SPO,被定义为,通过实例学习规则来推导实例之间的等价关系
前面提到，该框架通过学习规则来推导实例之间的等价关系。,实例,由组成,等价关系
前面提到，该框架通过学习规则来推导实例之间的等价关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱框架
首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。,匹配对中的属性等价关系,被定义为,Property_Equivalence
"实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。",实例等价,由组成,～I
"（p（e,o）是三元组＜e,p,o＞的函数式表示，o1_o2表示o1和o2指向同一实例或者字面值相等）。",p,被定义为,"三元组＜e,p,o＞的函数式表示"
"（p（e,o）是三元组＜e,p,o＞的函数式表示，o1_o2表示o1和o2指向同一实例或者字面值相等）。",p,由组成,三元组
这样的规则可以推导出大量的等价实例，从而完成实例匹配。,实例匹配,被定义为,这样的规则可以推导出大量的等价实例，从而完成实例匹配。
这样的规则可以推导出大量的等价实例，从而完成实例匹配。,实例匹配,由组成,等价实例
这样的规则可以推导出大量的等价实例，从而完成实例匹配。,规则,属于,实例匹配
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",属性-值对集,被定义为,"给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。"
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",属性-值对集,由组成,"PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}"
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。",等价属性对集,由组成,逆功能属性集
"定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。",等价属性对集,由组成,逆功能属性集
定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。,逆功能属性集规则,被定义为,基于逆功能属性集eps。
定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。,逆功能属性集规则,由组成,IFPS_Rule
"对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。",扩展的逆功能属性集规则,被定义为,IFPS规则
"对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。",IFPS规则,由组成,扩展的逆功能属性集规则
"对于所有eps里的属性对＜pi1,pi2＞,EIFPS规则有如下形式：根据以上定义，该方法实现了一个基于EM算法的实例匹配框架，输入为待匹配三元组、初始匹配对阈值，输出为匹配结果集与IFPS规则集。",EIFPS,方法,基于EM算法的实例匹配框架
该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,EM算法,被定义为,EIFPS规则
该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,EIFPS,由组成,EM算法
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,匹配图,被定义为,无向带权图
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,匹配图,由组成,无向带权图
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。,匹配图,被定义为,根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。
根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。,EIPFS,由组成,规则集合
根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。,EIPFS规则集合,属于,匹配图
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EIPFS规则集合,属于,匹配图
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EIPFS规则集合,属于,匹配图
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EIPFS规则集合,属于,匹配图
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EIPFS规则集合,属于,匹配图
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,传统上会选择取两者之间的较大值,包含,利用了两次匹配的信息得出的结果更为准确
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,传统上会选择取两者之间的较大值,由组成,利用了一次匹配的信息
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,这种集成方式,由组成,利用了两次匹配的信息得出的结果更为准确
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。,实例匹配,被定义为,该方法
该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。,zhishi.me,方法,实例匹配问题
该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。,zhishi.me,由组成,实例匹配问题
5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。,基于分治的实例匹配方法,被定义为,分治处理方法
5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。,基于分治的实例匹配方法,由组成,分治
5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。,基于分治的实例匹配方法,由组成,分治
采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。,分治,被定义为,将大规模知识图谱匹配划分为k个小规模的知识图谱匹配
采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。,分治策略,由组成,大规模知识图谱匹配
由此可见，系统效率取决于能将原有问题划分为多少个小规模。,系统效率,被定义为,将原有问题划分为多少个小规模
由此可见，系统效率取决于能将原有问题划分为多少个小规模。,系统效率,由组成,将原有问题划分为多少个小规模
由此可见，系统效率取决于能将原有问题划分为多少个小规模。,系统效率,属于,将原有问题划分为多少个小规模
最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。,分治策略,被定义为,将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配
最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。,分治策略,由组成,将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配
最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。,分治策略,由组成,将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配
"分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。",分治法,被定义为,"分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。"
"分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。",分治法,由组成,大规模数据库模式和XML模式匹配问题
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,Rahm和Do提出的基于模式片段的大规模模式匹配分治解决方法,被定义为,将大模式分解为多个片段，每个片段为模式树中的一个带根节点的子树
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,Rahm和Do,由组成,基于模式片段（fragment）的大规模模式匹配分治解决方法
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,Rahm和Do,实现,基于模式片段（fragment）的大规模模式匹配分治解决方法
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,Rahm和Do,来源,基于模式片段（fragment）的大规模模式匹配分治解决方法
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,基于模式片段（fragment）的大规模模式匹配分治解决方法,属于,基于模式片段（fragment）的大规模模式匹配分治解决方法
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,Rahm和Do,实现,基于模式片段（fragment）的大规模模式匹配分治解决方法
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,Rahm和Do,来源,基于模式片段（fragment）的大规模模式匹配分治解决方法
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,基于模式片段（fragment）的大规模模式匹配分治解决方法,属于,基于模式片段（fragment）的大规模模式匹配分治解决方法
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,片段分解方法,由组成,大规模知识图谱
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,片段分解方法,由组成,大规模知识图谱
本体模块化方法是对大规模本体进行划分的一种直观手段。,本体模块化方法,被定义为,对大规模本体进行划分的一种直观手段
本体模块化方法是对大规模本体进行划分的一种直观手段。,本体模块化方法,由组成,对大规模本体进行划分的一种直观手段
已有多种本体模块化方法被提出。,本体模块化方法,被定义为,多种
已有多种本体模块化方法被提出。,本体模块化方法,方法,将本体模块化
已有多种本体模块化方法被提出。,已有多种本体模块化方法被提出。,由组成,本体模块化方法
已有多种本体模块化方法被提出。,已有多种本体模块化方法被提出。,由组成,本体模块化方法
Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。,Grau等人,被定义为,语义封装
Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。,Grau等人通过引入语义封装的概念,由组成,将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。
Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。,Grau等人通过引入语义封装的概念,由组成,将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。
然而，这种方法在实际应用中效果并不好。,SPO,被定义为,三元组抽取方法
然而，这种方法在实际应用中效果并不好。,基于知识图谱的问答系统,由组成,基于知识图谱的问答系统
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,GALEN,被定义为,将GALEN划分为2个模块
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,GALEN,由组成,将GALEN划分为2个模块
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,NCI,由组成,将NCI划分为17个模块
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,GALEN,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。,模块化算法,被定义为,Grau等人
Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。,模块化算法,由组成,Grau等人
"此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。",本体模块化,被定义为,获得描述特定元素集含义的模块
"此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。",本体模块化,由组成,描述特定元素集含义的模块
Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。,Stuckenschmidt和Klein,被定义为,利用概念层次结构和属性约束，给出一种本体模块化方法
Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。,Stuckenschmidt和Klein,由组成,利用概念层次结构和属性约束
Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。,Stuckenschmidt和Klein,由组成,利用概念层次结构和属性约束
总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。,模块化工作,被定义为,以服务大规模本体映射为目的
总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。,模块化工作,由组成,以服务大规模本体映射为目的
特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。,知识图谱,被定义为,实例划分
特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。,知识图谱,由组成,实例划分
特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。,知识图谱中存在大量的实例,属于,上述模块化方法难以对大量的实例进行有效的划分
目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。,知识图谱中存在大量的实例,属于,上述模块化方法难以对大量的实例进行有效的划分
目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。,Malasco,由组成,分治思想
目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。,Malasco,由组成,分治思想
Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。,Malasco,被定义为,Paulheim提出的一种基于分治思想的大规模OWL本体映射系统
Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。,Malasco,由组成,Paulheim
Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。,Malasco,由组成,Paulheim
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,由组成,Paulheim
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,由组成,基于RDF声明
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,由组成,基于RDF声明
Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。,覆盖模块化,包含,模块化处理
Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。,覆盖模块化,被定义为,模块化处理
Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。,覆盖模块化,由组成,覆盖模块化方法
Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。,Paulheim的工作,被定义为,模块化方法
Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。,Paulheim的工作,由组成,模块化方法
Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。,Falcon-AO,包含,基于结构的本体划分方法
Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。,Falcon-AO,由组成,基于结构的本体划分方法
该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。,本体划分,被定义为,聚类方法
该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。,该方法,由组成,聚类方法
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,基于参照点的本体块匹配,被定义为,基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,基于预先计算的参照点,由组成,不同的本体块
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,基于预先计算的参照点,实现,对不同的本体块进行匹配
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,基于预先计算的参照点,属于,对不同的本体块进行匹配
该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。,划分算法,被定义为,将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射
该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。,该方法,方法,划分算法
该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。,该方法的划分算法,由组成,合适大小的集合
Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。,Falcon-AO,包含,映射结果质量
Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。,Falcon-AO,由组成,结果
Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。,Falcon-AO,由组成,结果
基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。,基于本体划分的分治处理方法,被定义为,较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失
基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。,基于本体划分的分治处理方法,由组成,存在的主要缺点
一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。,划分得到的块,由组成,边界语义信息损失
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,Malasco中的覆盖模块优化方法,包含,对该缺点的补救处理
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,Malasco中的覆盖模块优化方法,被定义为,对该缺点的补救处理
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,Malasco中的覆盖模块优化方法,由组成,对该缺点的补救处理
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,Malasco中的覆盖模块优化方法,实现,对该缺点的补救处理
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,Malasco中的覆盖模块优化方法,属于,对该缺点的补救处理
Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。,Lily,被定义为,利用大规模知识图谱匹配中的匹配局部性特点
Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。,Lily,被定义为,利用大规模知识图谱匹配中的匹配局部性特点
Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。,Lily,被定义为,利用大规模知识图谱匹配中的匹配局部性特点
该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。,划分方法,被定义为,实现过程简单，同时避免了划分知识图谱造成的语义信息损失
该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。,实现过程简单,方法,该方法
该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。,实现过程简单,由组成,该方法
1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。,基于属性规则的分块方法,被定义为,根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率
1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。,基于属性规则的分块方法,由组成,减少实例匹配中的匹配次数
1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。,基于属性规则的分块方法,属于,知识图谱
类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。,实体消解,被定义为,关系数据库领域和自然语言处理领域
类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。,实体消解,方法,关系数据库领域
类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。,实体消解,由组成,关系数据库领域
类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。,实体消解,由组成,关系数据库领域
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,被定义为,知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,被定义为,知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,由组成,漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,实现,漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,来源,漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学
第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。,知识图谱推理,属于,知识图谱推理
本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。,知识图谱推理,被定义为,知识图谱推理是知识图谱中的一种推理任务
本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。,知识图谱推理,由组成,知识图谱推理的定义及包含的任务
本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。,知识图谱推理,由组成,知识图谱推理的定义及包含的任务
6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。,基于演绎的知识图谱推理,由组成,基于演绎的知识图谱推理
6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。,知识图谱推理,属于,基于演绎的知识图谱推理
6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。,知识图谱推理,属于,基于归纳的知识图谱推理
6.5节将介绍知识图谱开源工具并提供实践建议。,6.5节将介绍知识图谱开源工具并提供实践建议。,被定义为,知识图谱开源工具
6.5节将介绍知识图谱开源工具并提供实践建议。,6.5节将介绍知识图谱开源工具并提供实践建议。,由组成,知识图谱开源工具
6.5节将介绍知识图谱开源工具并提供实践建议。,知识图谱开源工具,属于,6.5节
6.6节将对本章进行总结。,6.6节,被定义为,总结
6.6节将对本章进行总结。,6.6节,由组成,总结
希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。,知识图谱推理,由组成,知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向
希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。,知识图谱推理,实现,知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向
希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。,知识图谱推理,属于,知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向
推理的方法大致可以分为逻辑推理和非逻辑推理，其中逻辑推理的过程包含了严格的约束和推理过程，而非逻辑推理的过程相对模糊。,推理的方法,被定义为,逻辑推理和非逻辑推理
推理的方法大致可以分为逻辑推理和非逻辑推理，其中逻辑推理的过程包含了严格的约束和推理过程，而非逻辑推理的过程相对模糊。,推理的方法,由组成,逻辑推理和非逻辑推理
逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。,逻辑推理,被定义为,逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。
逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。,逻辑推理,由组成,逻辑推理
逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。,逻辑推理,由组成,逻辑推理
其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。,逻辑推理,由组成,逻辑推理
其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。,逻辑推理,由组成,逻辑推理
其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。,归纳推理,由组成,溯因推理
其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。,归纳推理,由组成,溯因推理
下面先介绍这四种基本的推理。,推理,被定义为,推理机
下面先介绍这四种基本的推理。,推理,由组成,四种基本的推理
下面先介绍这四种基本的推理。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。,演绎推理,包含,自上而下（top-down_logic）的逻辑推理
演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。,演绎推理,被定义为,自上而下（top-down_logic）的逻辑推理
演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。,演绎推理,由组成,自上而下（top-down_logic）的逻辑推理
典型的演绎推理有肯定前件假言推理、否定后件假言推理（Modus_Tollens）以及三段论（Law_of_Syllogism）。,肯定前件假言推理,由组成,三段论
典型的演绎推理有肯定前件假言推理、否定后件假言推理（Modus_Tollens）以及三段论（Law_of_Syllogism）。,肯定前件假言推理,由组成,三段论
在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。,肯定前件假言推理,由组成,三段论
在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。,肯定前件假言推理,由组成,三段论
在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。,假言推理,由组成,前提
在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。,假言推理,由组成,前提
其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。,假言推理,由组成,前提
其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。,肯定前件假言推理,由组成,性质命题
其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。,肯定前件假言推理,属于,性质命题
例如，通过假言命题“如果今天是星期二（前件）。,假言命题,被定义为,如果今天是星期二
例如，通过假言命题“如果今天是星期二（前件）。,通过假言命题,由组成,如果今天是星期二
那么小明会去上班（后件）”以及性质命题“今天是星期二”，能推理出“小明会去上班”。,小明,由组成,上班
而否定后件假言推理是指性质命题否定了假言命题的后件，从而推理出否定的假言前件。,否定后件假言推理,由组成,性质命题
例如，通过前文的假言命题和性质命题“小明不会去上班”，能推出“今天不是星期二”。,假言命题,由组成,性质命题
例如，通过前文的假言命题和性质命题“小明不会去上班”，能推出“今天不是星期二”。,假言命题,由组成,性质命题
在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。,假言三段论,被定义为,给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。
在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。,假言三段论,被定义为,给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。
在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。,假言三段论,由组成,两个假言命题
在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。,假言三段论,实现,给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。
从以上的例子可以看出，演绎推理是一种形式化的逻辑推理。,演绎推理,被定义为,形式化的逻辑推理
从以上的例子可以看出，演绎推理是一种形式化的逻辑推理。,演绎推理,由组成,形式化的逻辑推理
归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。,归纳推理,被定义为,自下而上的推理
归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。,归纳推理,由组成,自下而上的推理
归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。,归纳推理,由组成,自下而上的推理
例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。,归纳推理,被定义为,如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。
例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。,归纳推理,由组成,天鹅
例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。,归纳推理,由组成,天鹅
例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。,估计黑球和白球大概的个数,被定义为,概率
例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。,黑球,由组成,20个球
例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。,归纳泛化推理,包含,20个球
可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。,归纳泛化推理,由组成,20个球
可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。,归纳泛化推理,由组成,20个球
例如，经统计，90%就读于某高中的同学都上了大学，如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。,统计推理,被定义为,如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。
例如，经统计，90%就读于某高中的同学都上了大学，如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。,统计推理,由组成,90%就读于某高中的同学都上了大学
它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。,归纳推理,被定义为,演绎推理
它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。,归纳推理,由组成,演绎推理
它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。,归纳推理,属于,演绎推理
溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。,溯因推理,被定义为,给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程
溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。,溯因推理,由组成,给定一个或多个已有观察事实O，并根据已有的知识T推断出对已有观察最简单且最有可能的解释的过程
溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。,溯因推理,由组成,给定一个或多个已有观察事实O，并根据已有的知识T推断出对已有观察最简单且最有可能的解释的过程
例如，当一个病人显示出某种病症，而造成这个病症的原因可能有很多时，寻找在这个病人例子里最可能的原因的过程就是溯因推理。,溯因推理,被定义为,寻找在这个病人例子里最可能的原因的过程
例如，当一个病人显示出某种病症，而造成这个病症的原因可能有很多时，寻找在这个病人例子里最可能的原因的过程就是溯因推理。,溯因推理,由组成,溯因推理
在溯因推理中，要使基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。,溯因推理,被定义为,基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。
在溯因推理中，要使基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。,溯因推理,由组成,两个条件
类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。,类比推理,被定义为,只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。
类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。,类比推理,由组成,只基于对一个事物的观察而进行的对另一个事物的归纳推理
类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。,类比推理,由组成,只基于对一个事物的观察而进行的对另一个事物的归纳推理
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,类比推理,被定义为,通过类比推理可以得出小红也喜欢歌手C
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,小明,属于,同龄人
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,小红,属于,同龄人
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,小明,属于,歌手A
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,小明,属于,歌手B
例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。,小明,属于,歌手C
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,同龄人
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小红,属于,同龄人
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手A
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手B
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手C
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,同龄人
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小红,属于,同龄人
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手A
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手B
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,小明,属于,歌手C
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,不当类比,实现,类比推理
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,类比推理,来源,不当类比
由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。,不当类比,属于,类比推理
例如在上例中，如果歌手C和歌手A、歌手B完全不是一种类型或一个领域的歌手，那么小明喜欢歌手C与他喜欢歌手A和歌手B是完全无关的，所以将“喜欢歌手C”的结论应用到小红身上不合适。,喜欢歌手C,被定义为,歌手C
例如在上例中，如果歌手C和歌手A、歌手B完全不是一种类型或一个领域的歌手，那么小明喜欢歌手C与他喜欢歌手A和歌手B是完全无关的，所以将“喜欢歌手C”的结论应用到小红身上不合适。,喜欢歌手C,由组成,歌手A和歌手B
造成不当类比的原因有很多，包括类比事物不相干、类比理由不充分以及类比预设不当等。,不当类比,被定义为,类比事物不相干、类比理由不充分以及类比预设不当
造成不当类比的原因有很多，包括类比事物不相干、类比理由不充分以及类比预设不当等。,不当类比,由组成,类比事物不相干、类比理由不充分以及类比预设不当
尽管类比推理的结论相较于前面介绍的三种推理得到的结论错误率更高，但类比推理依然是一种普遍存在的推理方式。,类比推理,被定义为,普遍存在的推理方式
尽管类比推理的结论相较于前面介绍的三种推理得到的结论错误率更高，但类比推理依然是一种普遍存在的推理方式。,类比推理,由组成,错误率
除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。,逻辑推理,被定义为,逻辑推理的四种类型
除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。,逻辑推理,由组成,四种常见的逻辑推理
除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。,逻辑推理,由组成,四种常见的逻辑推理
例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。,不确定性推理,被定义为,根据不确定的观察信息以及不确定性的知识进行推理
例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。,不确定性推理,由组成,不确定性推理
例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。,不确定性推理,属于,推理方式
又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。,知识演变,包含,单调推理
又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。,知识演变,由组成,根据原有的推论可否被推翻
又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。,知识演变,由组成,根据原有的推论可否被推翻
从推理过程精确性来看，又可分为精确推理和模糊推理。,推理,被定义为,精确推理
从推理过程精确性来看，又可分为精确推理和模糊推理。,推理过程,由组成,精确推理和模糊推理
从推理过程精确性来看，又可分为精确推理和模糊推理。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
从推理过程精确性来看，又可分为精确推理和模糊推理。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
不同的研究领域也有各自的推理问题。,不同的研究领域,被定义为,推理问题
不同的研究领域也有各自的推理问题。,不同的研究领域,由组成,各自的推理问题
不同的研究领域也有各自的推理问题。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
例如，在自然语言处理领域，典型的问题是自然语言推理（Natutal_Language_Inference)，其任务判断两个给定句子的蕴涵关系，给定的两个句子一个前提（Premise），一个是假设结论（Hypothsis），目标是判断在给定前提句子的情况下是否可以推理出假设结论的句子。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。,视觉推理,被定义为,根据给定的图片回答特定的需要推理的问题
在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。,视觉推理,由组成,视觉推理
在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。,视觉推理,由组成,视觉推理
例如，给定一个包含多个不同色彩、不同形状的几何体图片，回答问题“图中最小的正方体右边的几何体是什么颜色”。,几何体,被定义为,正方体
在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。,面向知识图谱的推理,被定义为,知识图谱推理
在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。,面向知识图谱的推理,由组成,知识图谱
在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。,面向知识图谱的推理,属于,知识图谱
6.1.2面向知识图谱的推理面向知识图谱的推理主要围绕关系的推理展开，即基于图谱中已有的事实或关系推断出未知的事实或关系[5]，一般着重考察实体、关系和图谱结构三个方面的特征信息。,面向知识图谱的推理,被定义为,基于图谱中已有的事实或关系推断出未知的事实或关系
"如图6-1所示为人物关系图推理，利用推理可以得到新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。",人物关系图推理,由组成,"新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。"
"如图6-1所示为人物关系图推理，利用推理可以得到新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。",人物关系图推理,由组成,"新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。"
具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。,知识图谱推理,被定义为,能够辅助推理出新的事实、新的关系、新的公理以及新的规则等
具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。,知识图谱推理,被定义为,能够辅助推理出新的事实、新的关系、新的公理以及新的规则等
具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。,知识图谱推理,由组成,新的事实
具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。,知识图谱推理,属于,知识图谱
图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。,知识图谱补全,被定义为,知识图谱的生命周期
图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。,知识图谱,由组成,知识图谱补全
图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。,知识图谱融合,由组成,实体对齐
即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。,实体对齐,被定义为,实体识别
即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。,实体对齐,由组成,实体识别
即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。,知识图谱,包含,链接预测
由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。,知识图谱,由组成,链接预测
由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,链接预测
由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。,链接预测,属于,知识图谱补全
存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。,知识图谱,被定义为,提供知识服务
存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。,知识图谱,由组成,知识服务
存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。,知识图谱,属于,知识服务
知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。,知识图谱的推理,被定义为,基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。
知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。,知识图谱的推理,由组成,基于演绎的知识图谱推理
知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。,知识图谱的推理,由组成,基于归纳的知识图谱推理
以演绎推理为核心的知识图谱推理主要是基于描述逻辑、DataLog等进行的，而以归纳推理为核心的知识图谱推理主要是围绕对知识图谱图结构的分析、对知识图谱中元素的表示学习、利用图上搜索和分析进行规则学习以及应用强化学习方法等进行的。,演绎推理,被定义为,基于描述逻辑、DataLog等
以演绎推理为核心的知识图谱推理主要是基于描述逻辑、DataLog等进行的，而以归纳推理为核心的知识图谱推理主要是围绕对知识图谱图结构的分析、对知识图谱中元素的表示学习、利用图上搜索和分析进行规则学习以及应用强化学习方法等进行的。,演绎推理,由组成,基于描述逻辑、DataLog等
下面分别从这两类展开，介绍不同的推理实现方法。,知识图谱,被定义为,知识表示
下面分别从这两类展开，介绍不同的推理实现方法。,推理实现方法,由组成,知识图谱
下面分别从这两类展开，介绍不同的推理实现方法。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
下面分别从这两类展开，介绍不同的推理实现方法。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识表示
6.2基于演绎的知识图谱推理6.2.1本体推理1.本体与描述逻辑概述演绎推理的过程需要明确定义的先验信息，所以基于演绎的知识图谱推理多围绕本体展开。,本体推理,被定义为,本体与描述逻辑概述
本体的一般定义为概念化的显示规约，它给不同的领域提供共享的词汇。,本体,被定义为,概念化的显示规约
本体的一般定义为概念化的显示规约，它给不同的领域提供共享的词汇。,本体,由组成,概念化的显示规约
对于逻辑描述的规范，W3C提出了OWL。,逻辑描述的规范,被定义为,OWL
对于逻辑描述的规范，W3C提出了OWL。,逻辑描述的规范,由组成,OWL
2009年，为了适应更多应用的需求，W3C组织又提出了OWL的新版本OWL_2[15]。,OWL_2,被定义为,OWL_2是W3C组织在OWL的基础上提出的
2009年，为了适应更多应用的需求，W3C组织又提出了OWL的新版本OWL_2[15]。,OWL,由组成,OWL_2
OWL_2_Full比OWL_Full的表达能力更强，同样没有对应的描述逻辑。,OWL_2_Full,被定义为,OWL_Full
OWL_2_Full比OWL_Full的表达能力更强，同样没有对应的描述逻辑。,OWL_2_Full,由组成,OWL_Full
而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。,OWL_2_DL,被定义为,描述逻辑
而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。,OWL_2_DL,由组成,描述逻辑
而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。,OWL_2_DL,实现,描述逻辑
而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。,OWL_2_DL,属于,OWL_DL
为了适应高效的应用需求，W3C组织从OWL_2中分裂出三种易处理的剖面OWL_2_EL、OWL_2_QL和OWL_2RL。,OWL_2,被定义为,OWL_2_EL、OWL_2_QL和OWL_2RL
为了适应高效的应用需求，W3C组织从OWL_2中分裂出三种易处理的剖面OWL_2_EL、OWL_2_QL和OWL_2RL。,OWL_2,由组成,OWL_2_EL、OWL_2_QL和OWL_2RL
这些剖面都有对应的描述逻辑。,描述逻辑,被定义为,描述逻辑的语义表示
这些剖面都有对应的描述逻辑。,这些剖面,由组成,对应的描述逻辑
表6-1总结了OWL成员与描述逻辑之间的对应关系。,OWL成员,被定义为,描述逻辑
表6-1总结了OWL成员与描述逻辑之间的对应关系。,OWL成员,由组成,描述逻辑
目前，OWL是知识图谱语言中最规范、最严谨、表达能力最强的语言，而且OWL基于RDF语法，使表示出来的文档具有语义理解的结构基础，OWL的另外一个作用是促进了统一词汇表的使用，定义了丰富的语义词汇。,OWL,被定义为,目前，OWL是知识图谱语言中最规范、最严谨、表达能力最强的语言，而且OWL基于RDF语法，使表示出来的文档具有语义理解的结构基础，OWL的另外一个作用是促进了统一词汇表的使用，定义了丰富的语义词汇。
表6-1OWL成员与描述逻辑之间的对应关系基于OWL的模型论语义，在丰富逻辑描述的知识图谱中，除了包含实体和二元关系，还包含了许多更抽象的信息，例如描述实体类别的概念以及关系之间的从属信息等。,OWL成员,被定义为,描述逻辑
表6-1OWL成员与描述逻辑之间的对应关系基于OWL的模型论语义，在丰富逻辑描述的知识图谱中，除了包含实体和二元关系，还包含了许多更抽象的信息，例如描述实体类别的概念以及关系之间的从属信息等。,OWL成员,由组成,描述逻辑
从而有一系列实用有趣的推理问题，包括：（1）概念包含。,概念包含,被定义为,概念之间的包含关系
从而有一系列实用有趣的推理问题，包括：（1）概念包含。,概念包含,由组成,概念推理
从而有一系列实用有趣的推理问题，包括：（1）概念包含。,概念包含,属于,概念包含
判定概念C是否为D的子概念，即C是否被D包含。,判定概念,被定义为,判定概念是否为D的子概念
判定概念C是否为D的子概念，即C是否被D包含。,判定概念C是否为D的子概念,由组成,判定概念C是否为D的子概念
判定概念C是否为D的子概念，即C是否被D包含。,判定概念C是否为D的子概念,由组成,判定概念C是否为D的子概念
例如，在包含公理Mother_Women和Women_Person的本体中，可以判定Mother_Person成立。,Mother_Person,被定义为,Mother_Women
例如，在包含公理Mother_Women和Women_Person的本体中，可以判定Mother_Person成立。,Mother_Person,由组成,Mother_Women
例如，在包含公理Mother_Women和Women_Person的本体中，可以判定Mother_Person成立。,Mother_Person,由组成,Mother_Women
（2）概念互斥。,概念互斥,被定义为,概念之间不能同时属于
（2）概念互斥。,概念互斥,由组成,概念冲突
（2）概念互斥。,概念互斥,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判定两个概念C和D是否互斥，即不相交。,判定两个概念C和D是否互斥,被定义为,不相交
判定两个概念C和D是否互斥，即不相交。,判定两个概念C和D是否互斥,由组成,不相交
判定两个概念C和D是否互斥，即不相交。,判定两个概念C和D是否互斥,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
需要判定C_D_⊥是否为给定知识库的逻辑结论。,C_D_⊥,被定义为,逻辑结论
需要判定C_D_⊥是否为给定知识库的逻辑结论。,C_D_⊥,由组成,判定
需要判定C_D_⊥是否为给定知识库的逻辑结论。,C_D_⊥,属于,给定知识库的逻辑结论
例如，在包含Man_Women_⊥的本体中，概念Man和Women是互斥的。,Man,被定义为,互斥
例如，在包含Man_Women_⊥的本体中，概念Man和Women是互斥的。,Man,由组成,Women_⊥
（3）概念可满足。,概念,被定义为,概念可满足
（3）概念可满足。,概念可满足,由组成,概念可满足性
（3）概念可满足。,概念可满足,由组成,概念可满足性
判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。,判定概念C是否可满足,被定义为,找到该知识库的一个模型，使C的解释非空。
判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。,判定概念C是否可满足,由组成,找到该知识库的一个模型，使C的解释非空
判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。,判定概念C是否可满足,由组成,找到该知识库的一个模型，使C的解释非空
例如，包含公理Eternity_⊥的本体中，概念Eternity是不可满足概念。,包含公理Eternity_⊥的本体,被定义为,概念Eternity是不可满足概念
（4）全局一致。,全局一致,被定义为,知识图谱中所有实体和关系的全局一致性
（4）全局一致。,全局一致,由组成,知识图谱
判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。,判定给定的知识库是否全局一致,被定义为,找到该知识库的一个模型
判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。,判定给定的知识库是否全局一致,由组成,模型
判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。,判定给定的知识库是否全局一致,由组成,模型
例如，包含公理Man_Women_⊥、Man（Allen）和Women（Allen）的本体是不一致的。,判定给定的知识库是否全局一致,由组成,模型
例如，包含公理Man_Women_⊥、Man（Allen）和Women（Allen）的本体是不一致的。,包含公理Man_Women_⊥、Man（Allen）和Women（Allen）的本体,由组成,不一致
例如，包含公理Man_Women_⊥、Man（Allen）和Women（Allen）的本体是不一致的。,Man_Women_⊥,属于,公理
（5）TBox一致。,TBox一致,被定义为,TBox中所有概念和关系的定义必须满足一致性的要求
（5）TBox一致。,TBox一致,由组成,TBox一致性
（5）TBox一致。,TBox一致,由组成,TBox一致性
判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。,判定给定知识库的TBox是否一致,被定义为,判定TBox中的所有原子概念是否都满足
判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。,判定给定知识库的TBox是否一致,由组成,判定TBox中的所有原子概念是否都满足
判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。,判定给定知识库的TBox是否一致,由组成,判定TBox中的所有原子概念是否都满足
例如，包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox是不一致的。,判定给定知识库的TBox是否一致,由组成,判定TBox中的所有原子概念是否都满足
例如，包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox是不一致的。,包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox,由组成,不一致
例如，包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox是不一致的。,包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox,由组成,不一致
（6）实例测试。,实例测试,被定义为,知识图谱
（6）实例测试。,实例测试,由组成,由组成
（6）实例测试。,实例测试,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。,判定个体a是否是概念C的实例,被定义为,判定C(a)是否为给定知识库的逻辑结论
判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。,判定个体a是否是概念C的实例,由组成,判定C(a)是否为给定知识库的逻辑结论
判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。,判定个体a是否是概念C的实例,由组成,判定C(a)是否为给定知识库的逻辑结论
（7）实例检索。,实例检索,被定义为,通过实例来检索知识图谱中实体和关系
（7）实例检索。,实例检索,由组成,实例检索系统
（7）实例检索。,实例检索,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。,C,被定义为,C(a)是给定知识库的逻辑结论
找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。,C,由组成,C(a)
找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。,C,属于,C(a)
2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。,基于Tableaux的本体推理方法,被定义为,基于表运算（Tableaux）的本体推理方法
2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。,基于Tableaux的本体推理方法,由组成,基于表运算（Tableaux）的本体推理方法
2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。,基于Tableaux的本体推理方法,由组成,基于表运算（Tableaux）的本体推理方法
基于表运算的推理方法通过一系列规则构建Abox，以检测可满足性，或者检测某一实例是否存在某概念，基本思想类似于一阶逻辑的归结反驳。,基于表运算的推理方法,包含,Abox
基于表运算的推理方法通过一系列规则构建Abox，以检测可满足性，或者检测某一实例是否存在某概念，基本思想类似于一阶逻辑的归结反驳。,基于表运算的推理方法,由组成,Abox
以一个例子阐述该方法的基本思想。,SPO,被定义为,以一个例子阐述该方法的基本思想。
以一个例子阐述该方法的基本思想。,知识图谱项目,方法,以一个例子阐述该方法的基本思想。
以一个例子阐述该方法的基本思想。,以一个例子阐述该方法的基本思想。,由组成,该方法
假设知识库K由以下三个声明构成：将以a作为实例的所有概念的集合记作L(a)。,L,被定义为,"{a, b, c}"
假设知识库K由以下三个声明构成：将以a作为实例的所有概念的集合记作L(a)。,L(a),由组成,以a作为实例的所有概念的集合
我们使用L←C表示通过加入C进行更新。,L,被定义为,通过加入C进行更新
我们使用L←C表示通过加入C进行更新。,L,由组成,C
我们使用L←C表示通过加入C进行更新。,L←C,实现,通过加入C进行更新
我们使用L←C表示通过加入C进行更新。,L←C,属于,通过加入C进行更新
"例如，如果=｛D｝而且通过←C来对进行更新，那么将变成{C,D}。",L←C,实现,通过加入C进行更新
"例如，如果=｛D｝而且通过←C来对进行更新，那么将变成{C,D}。",L←C,属于,通过加入C进行更新
在给出的例子中，不经推导可以得到。,SPO,被定义为,三元组
在给出的例子中，不经推导可以得到。,SPO,由组成,SPO
TBox声明C_D与等价。,TBox声明,由组成,C_D与等价
因此，通过，得到，得到了矛盾，这表明K是不一致的。,K,被定义为,矛盾
因此，通过，得到，得到了矛盾，这表明K是不一致的。,K,由组成,矛盾
在上面例子中构建的东西实质上是表的一部分。,表,被定义为,关系三元组
在上面例子中构建的东西实质上是表的一部分。,表,由组成,表结构
如果在表构建过程中出现矛盾，那么知识库是不一致的。,知识库,被定义为,不一致
如果在表构建过程中出现矛盾，那么知识库是不一致的。,知识库,由组成,不一致
如果在表构建过程中出现矛盾，那么知识库是不一致的。,知识库,属于,不一致
以描述逻辑为例，在初始情况下，是原始的Abox，迭代运用如下规则：其中，y是新加进来的个体。,Abox,被定义为,描述逻辑
以描述逻辑为例，在初始情况下，是原始的Abox，迭代运用如下规则：其中，y是新加进来的个体。,描述逻辑,由组成,Abox
"给定包含如下公理和断言的本体：Man_Women_⊥,Man(Allen)，检测实例Allen是否Woman_Woman(Allen)，根据___规则，在Man_Women（Allen）加入中，再通过__规则得到⊥(Allen)，这样就得到了一个矛盾，中。",Man_Women,包含,Man_Women_⊥
首先，加入待反驳的结论所以拒绝现在的，即Allen不在Woman中。,Allen,被定义为,Woman
首先，加入待反驳的结论所以拒绝现在的，即Allen不在Woman中。,Allen,由组成,Woman
目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。,Tableaux算法,被定义为,前沿的超表运算（Hypertableau）技术
目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。,Tableaux算法,由组成,前沿的超表运算（Hypertableau）技术
目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。,Tableaux算法,由组成,前沿的超表运算（Hypertableau）技术
目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。,OWL推理系统,被定义为,Hypertableaux算法
目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。,OWL推理系统,由组成,FaCT++
目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。,OWL推理系统,由组成,RacerPro
目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。,OWL推理系统,由组成,Pellet
目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。,OWL推理系统,由组成,HermiT
虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。,Tableaux算法,包含,最通用的描述逻辑知识库一致性的检测方法
虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。,Tableaux算法,被定义为,最通用的描述逻辑知识库一致性的检测方法
虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。,Tableaux算法,由组成,最通用的描述逻辑知识库一致性的检测方法
例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。,一致性检测,被定义为,NExpTime-完全问题
例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。,SHOIN知识库,由组成,NExpTime-完全问题
例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,实现
例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,实现
例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
因此，如何为SHOIN等强表达力的描述逻辑设计最优组合复杂度的Tableaux算法仍有待研究。,SHOIN,被定义为,Tableaux算法
因此，如何为SHOIN等强表达力的描述逻辑设计最优组合复杂度的Tableaux算法仍有待研究。,SHOIN等强表达力的描述逻辑,由组成,Tableaux算法
3.常用本体推理工具简介（1）FaCT++。,FaCT++,被定义为,本体推理工具
3.常用本体推理工具简介（1）FaCT++。,FaCT++,由组成,本体推理工具
3.常用本体推理工具简介（1）FaCT++。,FaCT++,实现,知识推理
3.常用本体推理工具简介（1）FaCT++。,FaCT++,来源,知识推理
3.常用本体推理工具简介（1）FaCT++。,知识推理工具,属于,FaCT++
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,实现,知识推理
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,来源,知识推理
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,知识推理工具,属于,FaCT++
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,实现,知识推理
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,来源,知识推理
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,知识推理工具,属于,FaCT++
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,由组成,描述逻辑推理机
FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。,FaCT++,由组成,描述逻辑推理机
Java版本名为Jfact，基于OWL_API。,Java版本,被定义为,Jfact
Java版本名为Jfact，基于OWL_API。,Java版本,由组成,Jfact
Java版本名为Jfact，基于OWL_API。,Java版本,由组成,Jfact
构建推理机采用下面的代码：采用以下代码对本体进行分类：（2）Racer。,推理机,被定义为,采用下面的代码：采用以下代码对本体进行分类：（2）Racer。
构建推理机采用下面的代码：采用以下代码对本体进行分类：（2）Racer。,构建推理机,由组成,采用下面的代码：采用以下代码对本体进行分类：（2）Racer。
Racer是美国Franz_Inc.公司开发的以描述逻辑为基础的本体推理机，也可以用作语义知识库，支持OWL_DL，支持部分OWL_2_DL并且支持单机和客户端/服务器两种模式，用Allegro_Common_Lisp实现。,Racer,被定义为,以描述逻辑为基础的本体推理机
Racer是美国Franz_Inc.公司开发的以描述逻辑为基础的本体推理机，也可以用作语义知识库，支持OWL_DL，支持部分OWL_2_DL并且支持单机和客户端/服务器两种模式，用Allegro_Common_Lisp实现。,Racer,由组成,Franz_Inc.公司
以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。,Pellet,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。,Pellet,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。,Pellet,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,由组成,OWL_DL
Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。,Pellet,由组成,OWL_DL
构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。,推理机,被定义为,通过查询接口进行推理，采用下面的代码：（4）HermiT。
构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。,构建推理机,由组成,通过查询接口进行推理，采用下面的代码：（4）HermiT。
构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。,构建推理机,实现,HermiT
构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。,构建推理机,来源,HermiT
构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。,构建推理机,属于,HermiT
HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。,HermiT,包含,本体推理机
HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。,HermiT,由组成,牛津大学
HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。,HermiT,由组成,牛津大学
构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。,不一致推理,被定义为,采用以下代码：
构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。,不一致推理,由组成,不一致推理机
构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。,不一致推理,由组成,不一致推理机
与本体推理相比，规则推理有更大的灵活性。,规则推理,被定义为,与本体推理相比，规则推理有更大的灵活性。
与本体推理相比，规则推理有更大的灵活性。,规则推理,由组成,与本体推理相比，规则推理有更大的灵活性。
与本体推理相比，规则推理有更大的灵活性。,规则推理,属于,本体推理
本体推理通常仅支持预定义的本体公理上的推理，而规则推理可以根据特定的场景定制规则，以实现用户自定义的推理过程。,本体推理,被定义为,预定义的本体公理上的推理
本体推理通常仅支持预定义的本体公理上的推理，而规则推理可以根据特定的场景定制规则，以实现用户自定义的推理过程。,本体推理,由组成,规则推理
逻辑编程是一个很大的研究领域，在工业界应用广泛。,逻辑编程,被定义为,一个很大的研究领域，在工业界应用广泛
逻辑编程是一个很大的研究领域，在工业界应用广泛。,逻辑编程,由组成,逻辑编程语言
逻辑编程是一个很大的研究领域，在工业界应用广泛。,逻辑编程,由组成,逻辑编程语言
逻辑编程也可以与本体推理相结合，集合两者的优点。,逻辑编程,被定义为,集合两者的优点
逻辑编程也可以与本体推理相结合，集合两者的优点。,逻辑编程,由组成,本体推理
逻辑编程也可以与本体推理相结合，集合两者的优点。,逻辑编程,由组成,本体推理
"逻辑编程的研究始于Prolog语言[24,25]，后来由ISO标准化。",逻辑编程,被定义为,Prolog语言
"逻辑编程的研究始于Prolog语言[24,25]，后来由ISO标准化。",逻辑编程,由组成,Prolog语言
Prolog在多种系统中被实现，例如SWI-Prolog、Sicstus_Prolog、GNU_Prolog和XSB。,Prolog,被定义为,Prolog语言
Prolog在多种系统中被实现，例如SWI-Prolog、Sicstus_Prolog、GNU_Prolog和XSB。,Prolog,由组成,多种系统
Prolog在早期的人工智能研究中应用广泛，多用于实现专家系统。,Prolog,被定义为,实现专家系统
Prolog在早期的人工智能研究中应用广泛，多用于实现专家系统。,Prolog,由组成,Prolog语言
在通常情况下，Prolog程序是通过SLD消解和回溯来执行的[25]。,Prolog程序,包含,SLD消解和回溯
在通常情况下，Prolog程序是通过SLD消解和回溯来执行的[25]。,Prolog程序,由组成,SLD消解和回溯
运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。,运行结果依赖对规则内部的原子顺序和规则之间的顺序,被定义为,声明式的
运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。,运行结果依赖对规则内部的原子顺序和规则之间的顺序,由组成,声明式的
运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。,运行结果依赖对规则内部的原子顺序和规则之间的顺序,实现,声明式的
运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。,运行结果依赖对规则内部的原子顺序和规则之间的顺序,属于,声明式的
在程序存在递归的情况下，有可能出现运行无法终止的情况。,递归,被定义为,运行无法终止
在程序存在递归的情况下，有可能出现运行无法终止的情况。,递归,由组成,递归调用
在程序存在递归的情况下，有可能出现运行无法终止的情况。,程序存在递归的情况,属于,运行无法终止的情况
为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。,Datalog语言,被定义为,为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。
为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。,Datalog语言,由组成,一系列Datalog语言
为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。,Datalog语言,实现,为了得到完全的声明式规则语言
为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。,Datalog语言,属于,为了得到完全的声明式规则语言
从语法上来说，Datalog程序基本上是Prolog的一个子集。,Datalog,被定义为,Prolog的一个子集
从语法上来说，Datalog程序基本上是Prolog的一个子集。,Datalog,由组成,Prolog
它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。,Datalog,被定义为,基于完全声明式的模型论的语义，并保证可终止性
它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。,Datalog,由组成,完全声明式的模型论的语义，并保证可终止性
它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。,Datalog,实现,基于完全声明式的模型论的语义，并保证可终止性
它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。,Datalog,属于,基于完全声明式的模型论的语义，并保证可终止性
在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。,Datalog,被定义为,一种用于描述知识库的编程语言
在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。,Datalog,由组成,Datalog语言
在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。,Datalog,由组成,Datalog语言
读者可参考文献[26]获得更多关于逻辑程序的相关介绍。,逻辑程序,被定义为,逻辑程序的定义
读者可参考文献[26]获得更多关于逻辑程序的相关介绍。,逻辑程序,由组成,参考文献[26]
读者可参考文献[26]获得更多关于逻辑程序的相关介绍。,逻辑程序,实现,参考文献[26]
读者可参考文献[26]获得更多关于逻辑程序的相关介绍。,逻辑程序,来源,参考文献[26]
读者可参考文献[26]获得更多关于逻辑程序的相关介绍。,逻辑程序,属于,参考文献[26]
便于撰写规则，实现推理。,SPO,被定义为,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
便于撰写规则，实现推理。,SPO,由组成,实现推理
Datalog与OWL的关系如图6-2所示，其中OWL_RL和RDFS处于OWL和Datalog的交集之中。,Datalog,被定义为,Datalog是一种基于逻辑的描述语言，它由一组规则组成，这些规则描述了事实和规则之间的关系。
Datalog与OWL的关系如图6-2所示，其中OWL_RL和RDFS处于OWL和Datalog的交集之中。,Datalog,由组成,OWL_RL
OWL_RL的设计目标之一就是找出可以用规则推理来实现的一个OWL的片段。,OWL_RL,被定义为,找出可以用规则推理来实现的一个OWL的片段
OWL_RL的设计目标之一就是找出可以用规则推理来实现的一个OWL的片段。,OWL_RL,由组成,找出可以用规则推理来实现的一个OWL的片段
图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。,Datalog,被定义为,Datalog是一种基于逻辑的描述语言，它由一组规则组成，这些规则描述了如何从一组初始事实中产生新的事实。
图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。,Datalog,由组成,常量、变量和谓词
图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。,Datalog,由组成,常量、变量和谓词
常量通常用小写字母a、b、c表示一个具体的实例。,常量,被定义为,常量通常用小写字母a、b、c表示一个具体的实例。
常量通常用小写字母a、b、c表示一个具体的实例。,常量,由组成,小写字母a、b、c
变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。,变量,被定义为,用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、？y。
变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。,变量,由组成,大写字母X、Y、Z
变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。,变量,由组成,大写字母X、Y、Z
"原子（atom）形如p(t1,�,tn），其中p是一个谓词，t1,�,tn为项，n被称为p的元数。",原子,被定义为,"p(t1,�,tn），其中p是一个谓词，t1,�,tn为项，n被称为p的元数。"
"原子（atom）形如p(t1,�,tn），其中p是一个谓词，t1,�,tn为项，n被称为p的元数。",原子,由组成,谓词，项，元数
"例如，假定has_child为一个二元谓词，原子has_child(X,Y)表示变量X和Y有has_child的关系，而原子has_child(jim,bob)表示常量jim和bob有has_child的关系。",has_child,被定义为,二元谓词
"Datalog规则形如H:-B1,B2,�,Bm.其中，H,B1,B2,�,Bm为原子。",Datalog,被定义为,"Datalog规则形如H:-B1,B2,�,Bm.其中，H,B1,B2,�,Bm为原子。"
"H称为此规则的头部原子，B1,B2,�,Bm称为体部原子。",H,被定义为,此规则的头部原子
"例如，规则has_child(Y,X):-has_son(X,Y)表示当X和Y有has_son的关系时，则Y与X有has_child的关系。",has_child,由组成,has_son
"例如，规则has_child(Y,X):-has_son(X,Y)表示当X和Y有has_son的关系时，则Y与X有has_child的关系。",has_child,由组成,has_son
"Datalog事实（fact）是形如F(c1,c2,�,cn):-的没有体部且没有变量的规则。",Datalog事实,被定义为,"形如F(c1,c2,�,cn):-的没有体部且没有变量的规则"
"Datalog事实（fact）是形如F(c1,c2,�,cn):-的没有体部且没有变量的规则。",Datalog事实,由组成,规则
"Datalog事实（fact）是形如F(c1,c2,�,cn):-的没有体部且没有变量的规则。",Datalog事实,由组成,规则
"事实也常写成“F(c1,c2,�,cn).”的形式。",事实,被定义为,"F(c1,c2,�,cn)."
"事实也常写成“F(c1,c2,�,cn).”的形式。",事实,由组成,"F(c1,c2,�,cn)."
"事实也常写成“F(c1,c2,�,cn).”的形式。",事实,由组成,"F(c1,c2,�,cn)."
"例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。",事实,由组成,"F(c1,c2,�,cn)."
"例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。",has_child,由组成,"alice,bob"
"例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。",has_child,由组成,"alice,bob"
"例如，下面的两条规则构成了一个Datalog程序：has_child(X,Y):-has_son(X,Y).has_child(Alice,Bob).3.Datalog推理举例下面的规则集表达了给定一个图，计算所有的路径关系，即节点X、Y之间是否联通：path(X,Y):-edge(X,Y).①path(X,Y):-path(X,Z),path(Z,Y).②节点X和Y联通有两种情况：①X、Y之间通过一条边（edge）直接连接；②存在一个节点Z，使得X、Z联通并且Z、Y联通。",Datalog,被定义为,Datalog是一种基于逻辑的推理语言，它由一组规则组成，这些规则描述了推理过程。
"例如，下面的两条规则构成了一个Datalog程序：has_child(X,Y):-has_son(X,Y).has_child(Alice,Bob).3.Datalog推理举例下面的规则集表达了给定一个图，计算所有的路径关系，即节点X、Y之间是否联通：path(X,Y):-edge(X,Y).①path(X,Y):-path(X,Z),path(Z,Y).②节点X和Y联通有两种情况：①X、Y之间通过一条边（edge）直接连接；②存在一个节点Z，使得X、Z联通并且Z、Y联通。",has_child,由组成,path
下面的三个事实表示了一个图中的三条边。,图,被定义为,边
下面的三个事实表示了一个图中的三条边。,图,被定义为,边
下面的三个事实表示了一个图中的三条边。,图,被定义为,边
"edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。",Datalog,被定义为,一个结果集是Datalog程序可以推导出的所有原子的集合。
"edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。",Datalog,由组成,结果集
"edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。",Datalog,由组成,结果集
"例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。",path,被定义为,图联通
"例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。",path,由组成,"{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。"
"例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,图联通
"例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,图连通
"例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,图连通
图6-3Datalog推理举例4.Datalog与知识图谱Datalog程序可以应用在知识图谱中进行规则推理。,Datalog,被定义为,Datalog程序可以应用在知识图谱中进行规则推理。
图6-3Datalog推理举例4.Datalog与知识图谱Datalog程序可以应用在知识图谱中进行规则推理。,Datalog,由组成,知识图谱
一个知识图谱可以自然地被看作一个事实集。,知识图谱,被定义为,事实集
一个知识图谱可以自然地被看作一个事实集。,知识图谱,被定义为,事实集
一个知识图谱可以自然地被看作一个事实集。,一个知识图谱,由组成,事实集
一个知识图谱可以自然地被看作一个事实集。,一个知识图谱,由组成,事实集
"只需人为引入一个特殊的谓词triple，每一个三元组(subject,property,object)便可以作为一个事实triple(subject,property,object)。",SPO,被定义为,三元组
"另一种方法是按照描述逻辑ABox的方式来看待，即三元组(s,rdf:type,C)看作C(s)，其他的三元组(s,p,o)看作p(s,o)。",描述逻辑,被定义为,"三元组(s,rdf:type,C)看作C(s)，其他的三元组(s,p,o)看作p(s,o)。"
这样一来，Datalog规则就可以作用于知识图谱上。,Datalog规则,被定义为,知识图谱
这样一来，Datalog规则就可以作用于知识图谱上。,Datalog规则,由组成,知识图谱
这样一来，Datalog规则就可以作用于知识图谱上。,Datalog规则,由组成,知识图谱
下面介绍的三种语言SWRL、OWL_RL、RDFS与Datalog密切相关。,SWRL,被定义为,SWRL是SWRL语言，是SWRL语言的一种实现。
下面介绍的三种语言SWRL、OWL_RL、RDFS与Datalog密切相关。,SWRL,由组成,Datalog
（1）SWRL（Semantic_Web_Rule_Language）。,SWRL,被定义为,Semantic_Web_Rule_Language
（1）SWRL（Semantic_Web_Rule_Language）。,SWRL,由组成,Semantic_Web_Rule_Language
（1）SWRL（Semantic_Web_Rule_Language）。,SWRL,属于,Semantic_Web_Rule_Language
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,包含,Datalog
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,被定义为,2004年提出的一个完全基于Datalog的规则语言。
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,由组成,Datalog
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,实现,2004
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,来源,Datalog
SWRL是2004年提出的一个完全基于Datalog的规则语言。,SWRL,属于,规则语言
SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。,SWRL规则,被定义为,Datalog
SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。,SWRL规则,由组成,Datalog
SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。,SWRL规则,实现,Datalog
SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。,SWRL规则,来源,SWRL
SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。,SWRL规则,属于,知识表示
SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。,SWRL,被定义为,W3C的推荐标准
SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。,SWRL,由组成,W3C
SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。,SWRL,由组成,W3C
（2）OWL_RL。,OWL_RL,被定义为,基于OWL的推理规则语言
（2）OWL_RL。,OWL_RL,由组成,OWL_RL_2004
（2）OWL_RL。,OWL_RL,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。,OWL_RL,包含,Datalog程序
OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。,OWL_RL,由组成,Datalog
OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。,OWL_RL,由组成,Datalog
（3）RDFS（RDF_Schema）。,RDFS,被定义为,RDF_Schema
（3）RDFS（RDF_Schema）。,RDFS,由组成,RDF_Schema
RDFS的推理也可以用Datalog程序表示。,RDFS,被定义为,Datalog程序表示
RDFS的推理也可以用Datalog程序表示。,RDFS,由组成,Datalog程序表示
RDFS的推理也可以用Datalog程序表示。,RDFS,由组成,Datalog程序表示
5.基于Datalog的推理工具RDFox介绍目前，最主要的Datalog工具包括DLV[5]和Clingo[6]。,基于Datalog的推理工具,被定义为,DLV
5.基于Datalog的推理工具RDFox介绍目前，最主要的Datalog工具包括DLV[5]和Clingo[6]。,基于Datalog的推理工具,由组成,RDFox
这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。,Datalog推理机,被定义为,一般性的Datalog推理机
这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。,Datalog推理机,由组成,Datalog推理机
这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。,Datalog推理机,属于,一般性
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱领域,被定义为,多个系统
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱,由组成,KAON2
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱,由组成,HermiT
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱,由组成,Pellet
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱,由组成,Stardog
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱,由组成,RDFox
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱领域,实现,KAON2
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱领域,来源,KAON2
知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。,知识图谱领域,属于,KAON2
Datalog相关工具总结如表6-3所示。,Datalog相关工具,被定义为,表6-3
Datalog相关工具总结如表6-3所示。,Datalog相关工具,由组成,表6-3
下面简要介绍一下RDFox。,RDFox,被定义为,RDFox是一个开源的RDF数据存储引擎
下面简要介绍一下RDFox。,RDFox,由组成,RDFox是一个开源的RDF数据存储引擎
表6-3Datalog相关工具总结RDFox是由牛津大学开发的可扩展、跨平台、基于内存的RDF三元组存储系统。,RDFox,被定义为,RDF三元组存储系统
表6-3Datalog相关工具总结RDFox是由牛津大学开发的可扩展、跨平台、基于内存的RDF三元组存储系统。,RDFox,由组成,牛津大学
其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。,基于内存的高效并行Datalog推理,包含,SPARQL查询
其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。,基于内存的并行Datalog推理,由组成,SPARQL查询
其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。,基于内存的高效并行Datalog推理,属于,SPARQL查询
RDFox的架构如图6-4所示。,RDFox,被定义为,RDFox是一个开源的RDF存储引擎
RDFox的架构如图6-4所示。,RDFox,由组成,RDFox架构
RDFox的架构如图6-4所示。,RDFox,由组成,RDFox架构
其核心为RDFox推理机，支持增量更新。,RDFox,被定义为,RDFox推理机
其核心为RDFox推理机，支持增量更新。,RDFox,由组成,RDFox推理机
图6-4RDFox的架构1.RDFox_Java_API使用方法（1）创建本体与存储（2）导入本体进行推理2.RDFox_Java_API使用举例下面用一个具体的例子介绍RDFox。,RDFox,被定义为,RDFox_Java_API
假定有如图6-5所示的某金融领域相关的图。,金融领域,被定义为,金融领域相关的图
假定有如图6-5所示的某金融领域相关的图。,金融领域,由组成,金融领域相关的图
假定有如图6-5所示的某金融领域相关的图。,知识图谱,实现,知识表示
假定有如图6-5所示的某金融领域相关的图。,知识图谱,来源,知识表示
假定有如图6-5所示的某金融领域相关的图。,知识图谱,属于,知识表示
首先把它转换成一个知识图谱。,知识图谱,被定义为,知识图谱项目
首先把它转换成一个知识图谱。,知识图谱,由组成,知识表示
对每一个实体，要创建一个IRI。,实体,被定义为,IRI
对每一个实体，要创建一个IRI。,对每一个实体,由组成,创建一个IRI
为此引入命名空间finance：来表示http://www.example.org/kse/finance#。,命名空间,被定义为,命名空间finance：
为此引入命名空间finance：来表示http://www.example.org/kse/finance#。,命名空间,由组成,finance：
为此引入命名空间finance：来表示http://www.example.org/kse/finance#。,命名空间,由组成,finance：
<http://www.example.org/kse/finance#孙宏斌>这个IRI就可以使用命名空间简写为“finance：孙宏斌”。,孙宏斌,被定义为,IRI
自定义规则如下：1）执掌一家公司就一定是这家公司的股东。,执掌一家公司,被定义为,股东
自定义规则如下：1）执掌一家公司就一定是这家公司的股东。,执掌一家公司,由组成,股东
自定义规则如下：1）执掌一家公司就一定是这家公司的股东。,执掌一家公司,属于,股东
2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。,关联交易,被定义为,如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。
2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。,如果某人同时是两家公司的股东,由组成,这两家公司一定有关联交易
2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。,如果某人同时是两家公司的股东,由组成,这两家公司一定有关联交易
读取本体、数据，声明规则。,读取本体、数据，声明规则。,被定义为,本体、数据、规则
读取本体、数据，声明规则。,读取本体、数据，声明规则。,由组成,读取本体、数据，声明规则。
读取本体、数据，声明规则。,读取本体、数据，声明规则。,实现,声明规则
读取本体、数据，声明规则。,声明规则,属于,读取本体、数据，声明规则。
推理，定义命名空间与查询操作（用于输出当前三元组）。,推理,被定义为,定义命名空间与查询操作（用于输出当前三元组）。
推理，定义命名空间与查询操作（用于输出当前三元组）。,推理,由组成,定义命名空间与查询操作（用于输出当前三元组）。
将结果输出为结合规则推理的所有三元组实例化。,结合规则推理,被定义为,将结果输出为结合规则推理的所有三元组实例化。
将结果输出为结合规则推理的所有三元组实例化。,结合规则推理,由组成,结合规则推理
将结果输出为结合规则推理的所有三元组实例化。,结合规则推理,属于,所有三元组
6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。,基于查询重写的方法,被定义为,实现知识图谱的查询
6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。,查询重写的方法,由组成,基于查询重写的方法实现知识图谱的查询
6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。,基于查询重写的方法,实现,实现知识图谱的查询
考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。,知识图谱,被定义为,知识图谱项目
考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。,知识图谱,由组成,知识表示
考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。,知识图谱,由组成,知识表示
"第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。",知识图谱,由组成,知识表示
"第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。",本体介导的查询回答,由组成,OMQ
"第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。",本体介导的查询回答,由组成,OMQ
"在OMQ下，查询重写的任务是将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。",查询重写,被定义为,"将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。"
"在OMQ下，查询重写的任务是将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。",查询重写,由组成,查询q
"第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。",基于本体的数据访问,包含,OBDA
"第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。",基于本体的数据访问,被定义为,OBDA
"第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。",基于本体的数据访问,由组成,OBDA
"第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。",基于本体的数据访问,由组成,OBDA
在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。,OBDA,被定义为,OBDA是一种基于数据库的语义网实现方法
在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。,OBDA,由组成,映射
在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。,OBDA,由组成,映射
映射的标准语言为W3C的R2RML语言。,映射,被定义为,W3C的R2RML语言
映射的标准语言为W3C的R2RML语言。,映射的标准语言,由组成,W3C的R2RML语言
OMQ可以看作OBDA的特殊情况，即每个本体中谓词的实例都存储在一个特定的对应表中，而映射只是一个简单的同构关系。,OMQ,包含,OBDA
OMQ可以看作OBDA的特殊情况，即每个本体中谓词的实例都存储在一个特定的对应表中，而映射只是一个简单的同构关系。,OMQ,由组成,OBDA
以下着重介绍OBDA。,OBDA,被定义为,面向对象数据库
以下着重介绍OBDA。,OBDA,由组成,知识图谱
以下着重介绍OBDA。,OBDA,由组成,知识图谱
"这样OBDA的实例定义为外延层和内涵层的一个对I=(P,D)，其中P=(T,M,S)，且D符合S。",OBDA,被定义为,外延层和内涵层的一个对
"这样OBDA的实例定义为外延层和内涵层的一个对I=(P,D)，其中P=(T,M,S)，且D符合S。",OBDA,由组成,外延层和内涵层的一个对
用M(D)表示将映射M作用于数据库D上生成的知识图谱。,M(D),被定义为,将映射M作用于数据库D上生成的知识图谱
用M(D)表示将映射M作用于数据库D上生成的知识图谱。,用M(D)表示将映射M作用于数据库D上生成的知识图谱。,由组成,用M(D)表示将映射M作用于数据库D上生成的知识图谱。
用M(D)表示将映射M作用于数据库D上生成的知识图谱。,用M(D)表示将映射M作用于数据库D上生成的知识图谱。,实现,用M(D)表示将映射M作用于数据库D上生成的知识图谱。
用M(D)表示将映射M作用于数据库D上生成的知识图谱。,用M(D)表示将映射M作用于数据库D上生成的知识图谱。,属于,用M(D)表示将映射M作用于数据库D上生成的知识图谱。
"给定这样一个OBDA实例I,OBDA的语义即定义为一个知识库(T,M(D))。",OBDA,被定义为,"给定这样一个OBDA实例I,OBDA的语义即定义为一个知识库(T,M(D))。"
当查询时，本体T为用户提供了一个高级概念视图数据和方便的查询词汇，用户只针对T查询，而数据库存储层和映射层对用户完全透明。,T,包含,数据库存储层和映射层
当查询时，本体T为用户提供了一个高级概念视图数据和方便的查询词汇，用户只针对T查询，而数据库存储层和映射层对用户完全透明。,当查询时,由组成,本体T
这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。,OBDA,被定义为,将底层的数据库呈现为一个知识图谱
这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。,OBDA,由组成,将底层的数据库呈现为一个知识图谱
这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。,OBDA,由组成,将底层的数据库呈现为一个知识图谱
OBDA有多种实现方式，最直接的方式是生成映射得到的知识图谱M(D)，然后保存到一个三元组存储库中，这种方式也称作ETL（Extract_Transform_Load)，优点是实现简单直接。,OBDA,由组成,ETL
但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。,ETL,包含,ETL
但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。,ETL,由组成,ETL工具
但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。,ETL,由组成,ETL工具
在此，我们更感兴趣的是虚拟OBDA的方式，此方式下的三元组并不需要被真正生成，而通过查询重写的方式来实现，OBDA将在本体层面的SPARQL查询重写为在原始数据库上的SQL查询。,虚拟OBDA,被定义为,查询重写
在此，我们更感兴趣的是虚拟OBDA的方式，此方式下的三元组并不需要被真正生成，而通过查询重写的方式来实现，OBDA将在本体层面的SPARQL查询重写为在原始数据库上的SQL查询。,虚拟OBDA,由组成,查询重写
相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。,虚拟OBDA方式,包含,ELT的方式
相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。,虚拟OBDA方式,被定义为,轻量化、更灵活，也不需要额外的硬件
相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。,虚拟OBDA方式,由组成,更轻量化、更灵活，也不需要额外的硬件
相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。,虚拟OBDA方式,由组成,更轻量化、更灵活，也不需要额外的硬件
为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。,本体语言,被定义为,DL-Lite
为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。,本体语言,由组成,DL-Lite
为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。,本体语言,由组成,DL-Lite
OBDA查询重写的流程如图6-6所示。,OBDA查询重写,被定义为,OBDA查询重写流程
OBDA查询重写的流程如图6-6所示。,OBDA查询重写,由组成,OBDA查询重写流程
对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。,OMQ,被定义为,利用本体T将输入的SPARQLq重写为另一个SPARQL
对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。,OMQ,由组成,利用本体T将输入的SPARQLq重写为另一个SPARQL
对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。,OMQ,由组成,利用本体T将输入的SPARQLq重写为另一个SPARQL
（2）查询展开。,查询展开,被定义为,查询扩展
（2）查询展开。,查询展开,由组成,查询展开
（2）查询展开。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,SPARQL,包含,利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,SPARQL,被定义为,利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,SPARQL,由组成,利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,将SPARQL利用映射M展开,实现,将SPARQL利用映射M展开
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,将SPARQL利用映射M展开,来源,将SPARQL利用映射M展开
将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。,将SPARQL利用映射M展开,属于,将SPARQL利用映射M展开
（3）查询执行。,查询执行,被定义为,查询执行过程
（3）查询执行。,查询执行,由组成,查询语句
（3）查询执行。,查询执行,属于,查询
将生成的SQL语句交给数据库引擎并执行。,SQL语句,被定义为,将生成的SQL语句交给数据库引擎并执行。
将生成的SQL语句交给数据库引擎并执行。,将生成的SQL语句交给数据库引擎并执行。,由组成,将生成的SQL语句交给数据库引擎并执行。
（4）结果转换。,结果转换,被定义为,将结果转换为文本
（4）结果转换。,结果转换,由组成,结果转换器
（4）结果转换。,结果转换,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。,SQL语句查询的结果,被定义为,SPARQL查询结果
SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。,SQL语句查询的结果,由组成,SPARQL查询结果
SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。,SQL语句查询的结果,属于,SPARQL查询结果
为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂[29]。,OBDA,被定义为,为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂
为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂[29]。,OBDA,由组成,实际使用的OBDA系统
图6-6OBDA查询重写的流程2.查询重写举例（OMQ）假定有如下一个关于学校信息系统的本体T：查询q1=SELECT?teacherWHERE{?teacheraTeacher}试图查询所有的教师。,查询重写,被定义为,查询重写举例
通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。,q1,被定义为,通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。
通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。,通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。,由组成,通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。
查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。,查询q2,被定义为,SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。
查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。,查询q2,由组成,SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。
查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。,查询q2,由组成,SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。
可以先利用teaches的定义域和值域将q2优化为SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。,q2,被定义为,SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。
可以先利用teaches的定义域和值域将q2优化为SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。,teaches,由组成,?teacher?course
可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。,查询重写,被定义为,3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。
可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。,查询重写,由组成,OBDA
可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。,查询重写,由组成,OBDA
4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。,基于查询重写的推理机,被定义为,Ontop
4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。,基于查询重写的推理机,由组成,Ontop
4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。,Ontop,实现,基于查询重写的推理机
4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。,Ontop,来源,基于查询重写的推理机
4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。,基于查询重写的推理机,属于,Ontop
这些工具的功能对比如表6-4所示。,知识图谱,被定义为,知识图谱工具
这些工具的功能对比如表6-4所示。,SPO,方法,将三元组转换为关系图
这些工具的功能对比如表6-4所示。,SPO,由组成,SPO工具
这些工具的功能对比如表6-4所示。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
这些工具的功能对比如表6-4所示。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。,Ontop,被定义为,一个开源的OBDA系统
表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。,Ontop,由组成,Ontopic公司
表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。,Ontop,属于,OBDA系统
Ontop的Protégé插件可以用于编辑映射和测试查询。,Ontop的Protégé插件,包含,映射和测试查询
Ontop的Protégé插件可以用于编辑映射和测试查询。,Ontop的Protégé插件,由组成,编辑映射和测试查询
Ontop的Protégé插件可以用于编辑映射和测试查询。,Ontop的Protégé插件,由组成,编辑映射和测试查询
RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。,RDF4J插件,被定义为,将编辑好的OBDA系统发布为一个SPARQL_endpoint。
RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。,RDF4J插件,由组成,将编辑好的OBDA系统发布为一个SPARQL_endpoint
RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。,RDF4J插件,由组成,将编辑好的OBDA系统发布为一个SPARQL_endpoint
Ontop也提供Java_API。,Ontop,被定义为,Java_API
Ontop也提供Java_API。,Ontop,由组成,Java_API
Ontop也提供Java_API。,Ontop,由组成,Java_API
此系统支持对OWL2_QL本体的推理。,Ontop,由组成,Java_API
此系统支持对OWL2_QL本体的推理。,Ontop,由组成,Java_API
此系统支持对OWL2_QL本体的推理。,OWL2_QL推理系统,由组成,OWL2_QL本体的推理
此系统支持对OWL2_QL本体的推理。,OWL2_QL推理系统,由组成,OWL2_QL本体的推理
与此处提到的其他OBDA系统不同，它仅支持与合取查询相对应的SPARQL的受限片段。,OBDA,被定义为,SPARQL的受限片段
与此处提到的其他OBDA系统不同，它仅支持与合取查询相对应的SPARQL的受限片段。,OBDA,由组成,SPARQL
Ultrawrap是由Capsenta公司商业化的OBDA系统。,Ultrawrap,被定义为,OBDA系统
Ultrawrap是由Capsenta公司商业化的OBDA系统。,Ultrawrap,由组成,Capsenta公司商业化的OBDA系统
Ultrawrap是由Capsenta公司商业化的OBDA系统。,Ultrawrap,由组成,Capsenta公司商业化的OBDA系统
它被扩展为支持对具有反向和传递属性的RDFS扩展的推断。,RDFS,被定义为,支持对具有反向和传递属性的RDFS扩展的推断
它被扩展为支持对具有反向和传递属性的RDFS扩展的推断。,RDFS,由组成,支持对具有反向和传递属性的RDFS扩展的推断
Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。,Morph-RDB,被定义为,OBDA系统
Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。,Morph-RDB,由组成,西班牙马德里工业大学开发的开源OBDA系统
Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。,Morph-RDB,由组成,西班牙马德里工业大学开发的开源OBDA系统
Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。,Stardog,被定义为,Triple存储工具
Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。,Stardog,由组成,Stardog_Union
Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。,Stardog,由组成,Stardog_Union
Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。,Stardogv4版,被定义为,Ontop代码
Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。,Stardogv4版,由组成,Ontop代码
Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。,Stardogv4版,由组成,Ontop代码
因此，它现在也可以归为OBDA系统。,OBDA,被定义为,知识库
因此，它现在也可以归为OBDA系统。,OBDA,由组成,OBDA系统
因此，它现在也可以归为OBDA系统。,OBDA,由组成,OBDA系统
在v5版本中有了自己的OBDA实现。,OBDA,被定义为,v5版本
在v5版本中有了自己的OBDA实现。,v5版本,由组成,OBDA实现
在v5版本中有了自己的OBDA实现。,v5版本,由组成,OBDA实现
限于篇幅，不展开讲解，有兴趣的读者可以查阅参考文献[41]。,SPO,被定义为,三元组
限于篇幅，不展开讲解，有兴趣的读者可以查阅参考文献[41]。,SPO,由组成,SPO三元组
6.2.4基于产生式规则的方法1.产生式系统产生式系统是一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。,产生式系统,被定义为,一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。
6.2.4基于产生式规则的方法1.产生式系统产生式系统是一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。,产生式系统,由组成,一阶逻辑
产生式系统可以应用于自动规划和专家系统等领域。,产生式系统,被定义为,自动规划和专家系统
产生式系统可以应用于自动规划和专家系统等领域。,产生式系统,由组成,自动规划和专家系统
产生式系统可以应用于自动规划和专家系统等领域。,产生式系统,由组成,自动规划和专家系统
（1）事实集合。,事实集合,被定义为,事实的集合
（1）事实集合。,事实集合,由组成,事实
（1）事实集合。,事实集合,由组成,事实
"事实集合是运行内存（Working_Memory,WM）为事实（WME）的集合，用于存储当前系统中的所有事实。",事实集合,被定义为,运行内存
"事实集合是运行内存（Working_Memory,WM）为事实（WME）的集合，用于存储当前系统中的所有事实。",事实集合,由组成,运行内存
事实可描述对象，形如(typeattr_1:val_1attr_2:val_2�attr_n:val_n），其中type、attr_i、val_i均为原子（常量）。,事实,被定义为,事实可描述对象
例如，(studentage:24)表示一个学生，姓名为Alice，年龄为24。,studentage,被定义为,24
例如，(studentage:24)表示一个学生，姓名为Alice，年龄为24。,studentage,由组成,24
"事实也可描述关系name:""Alice""（Refication）。",事实,被定义为,关系
"事实也可描述关系name:""Alice""（Refication）。",事实,由组成,关系
"事实也可描述关系name:""Alice""（Refication）。",事实,属于,Refication
例如，(basicFactrelation:olderThanfirstArg:JohnsecondArg:Alice)表示John比Alice的年纪大，此事实也可简记为(olderThanJohnAlice)。,olderThan,被定义为,表示John比Alice的年纪大
（2）产生式集合。,产生式集合,被定义为,由一组产生式组成的集合
（2）产生式集合。,产生式集合,由组成,产生式
LHS是conditions的集合，各条件之间为且的关系。,LHS,被定义为,conditions的集合，各条件之间为且的关系。
LHS是conditions的集合，各条件之间为且的关系。,LHS,由组成,conditions
当LHS中所有条件均被满足时，触发规则。,触发规则,被定义为,当LHS中所有条件均被满足时，触发规则。
当LHS中所有条件均被满足时，触发规则。,触发规则,由组成,当LHS中所有条件均被满足时，触发规则。
当LHS中所有条件均被满足时，触发规则。,触发规则,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,SPO,包含,条件
每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,SPO,由组成,每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。
每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,实现,实现
每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,来源,实现
每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。,属于,实现
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识表示
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识存储
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识抽取
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识融合
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识推理
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,语义搜索
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识问答
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,包含,知识图谱项目
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,知识图谱,被定义为,知识表示
其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。,约束,由组成,RHS
动作的种类有如下三种：●ADDpattern。,动作,包含,ADDpattern
动作的种类有如下三种：●ADDpattern。,动作,由组成,ADDpattern
动作的种类有如下三种：●ADDpattern。,动作的种类,实现,ADDpattern
动作的种类有如下三种：●ADDpattern。,动作的种类,来源,ADDpattern
动作的种类有如下三种：●ADDpattern。,动作的种类,属于,ADDpattern
向WM中加入形如pattern的WME。,WM,被定义为,向WM中加入形如pattern的WME
向WM中加入形如pattern的WME。,WM,由组成,WME
●REMOVEi。,REMOVE,包含,i
●REMOVEi。,REMOVEi,由组成,由组成
●REMOVEi。,REMOVEi,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
从WM中移除当前规则第i个条件匹配的WME。,WM,包含,当前规则第i个条件匹配的WME
从WM中移除当前规则第i个条件匹配的WME。,WM,被定义为,当前规则第i个条件匹配的WME
从WM中移除当前规则第i个条件匹配的WME。,移除当前规则第i个条件匹配的WME,由组成,WM
●MODIFYi(attrspec)。,MODIFYi,被定义为,修改属性
●MODIFYi(attrspec)。,MODIFYi,由组成,attrspec
对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。,WME,被定义为,attr
对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。,当前规则第i个条件匹配的WME,由组成,attr
对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。,当前规则第i个条件匹配的WME,由组成,attr
例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。,产生式,被定义为,IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。
例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。,产生式,由组成,IF(Studentname:)ThenADD(Personname:)
例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。,产生式,由组成,IF(Studentname:)ThenADD(Personname:)
产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。,产生式具体语法,被定义为,(Studentname:x)_ADD(Personname:x)。
产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。,产生式具体语法,由组成,因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。
产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。,产生式具体语法,由组成,因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。
（3）推理引擎。,推理引擎,被定义为,知识图谱推理引擎
（3）推理引擎。,推理引擎,由组成,知识图谱
产生式系统执行流程如图6-7所示。,产生式系统,被定义为,图6-7
产生式系统执行流程如图6-7所示。,产生式系统,由组成,执行流程
产生式系统执行流程如图6-7所示。,产生式系统,由组成,执行流程
图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。,产生式系统,包含,模式匹配
图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。,产生式系统,由组成,模式匹配
图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。,产生式系统,实现,模式匹配
图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。,产生式系统,属于,模式匹配
图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。,产生式系统,来源,模式匹配
用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。,规则,被定义为,用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。
用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。,规则,由组成,条件
●选择规则。,选择规则,被定义为,选择规则是选择项与选择项之间的关系
●选择规则。,选择规则,由组成,选择规则
●选择规则。,选择规则,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
按一定的策略从被触发的多条规则中选择一条。,规则触发,被定义为,从被触发的多条规则中选择一条
按一定的策略从被触发的多条规则中选择一条。,按一定的策略从被触发的多条规则中选择一条,由组成,触发器
按一定的策略从被触发的多条规则中选择一条。,按一定的策略从被触发的多条规则中选择一条。,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
●执行规则。,执行规则,被定义为,规则执行
●执行规则。,执行规则,由组成,规则
●执行规则。,执行规则,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
执行被选择出来的规则的RHS，从而操作WM。,执行被选择出来的规则的RHS,包含,操作WM
执行被选择出来的规则的RHS，从而操作WM。,执行被选择出来的规则的RHS,由组成,WM
模式匹配用每条规则的条件部分匹配当前的WM，如图6-8所示为匹配规则过程。,模式匹配,被定义为,每条规则的条件部分匹配当前的WM
模式匹配用每条规则的条件部分匹配当前的WM，如图6-8所示为匹配规则过程。,模式匹配,由组成,每条规则的条件部分
"规则为：（typexy）,(subClassOfyz)_ADD(typexz)。",type,由组成,subClassOf
"规则为：（typexy）,(subClassOfyz)_ADD(typexz)。",type,由组成,subClassOf
图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。,模式匹配,被定义为,图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。
图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。,图6-8匹配规则过程,由组成,高效的模式匹配算法是产生式规则引擎的核心。
图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。,图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。,属于,图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。
目前，最流行的算法是Rete算法，在1979年由CharlesForgy提出[42]。,Rete算法,被定义为,Rete算法
目前，最流行的算法是Rete算法，在1979年由CharlesForgy提出[42]。,Rete算法,由组成,Rete算法
其主要的想法为将产生式的LHS组织成判别网络形式，以实现用空间换时间的效果。,产生式判别网络,被定义为,将产生式的LHS组织成判别网络形式
其主要的想法为将产生式的LHS组织成判别网络形式，以实现用空间换时间的效果。,产生式的LHS,由组成,判别网络形式
下面用图6-9和图6-10解释Rete算法的形状。,Rete算法,被定义为,图6-9和图6-10
下面用图6-9和图6-10解释Rete算法的形状。,Rete算法,由组成,Rete算法
最主要的部分为α网络和β网络。,知识图谱,被定义为,知识表示
最主要的部分为α网络和β网络。,知识图谱,由组成,α网络和β网络
α和β的名字来源于产生式规则常写成α_β的形式。,α和β的名字来源于产生式规则,被定义为,α_β的形式
α和β的名字来源于产生式规则常写成α_β的形式。,α和β的名字来源于产生式规则,由组成,α_β的形式
α和β的名字来源于产生式规则常写成α_β的形式。,α和β的名字来源于产生式规则,实现,α_β的形式
α网络对应条件，检验并保存各个条件对应的WME集合。,α网络对应条件,被定义为,检验并保存各个条件对应的WME集合。
α网络对应条件，检验并保存各个条件对应的WME集合。,α网络对应条件,由组成,检验并保存各个条件对应的WME集合
β网络对应结果，用于保存join的中间结果。,β网络对应结果,被定义为,用于保存join的中间结果。
β网络对应结果，用于保存join的中间结果。,β网络对应结果,由组成,用于保存join的中间结果。
β网络对应结果，用于保存join的中间结果。,β网络对应结果,由组成,用于保存join的中间结果。
图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。,Rete,包含,网络图
图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。,Rete,包含,算法的匹配过程
图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。,Rete,由组成,规则库
从被触发的规则中随机选择一条执行。,SPO,被定义为,三元组抽取
从被触发的规则中随机选择一条执行。,SPO,由组成,触发规则
从被触发的规则中随机选择一条执行。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
从被触发的规则中随机选择一条执行。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
注意在推理的场景下，被触发的多条规则可全被执行。,推理,被定义为,规则
注意在推理的场景下，被触发的多条规则可全被执行。,推理,由组成,多条规则
注意在推理的场景下，被触发的多条规则可全被执行。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
注意在推理的场景下，被触发的多条规则可全被执行。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
注意在推理的场景下，被触发的多条规则可全被执行。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
●具体性（specificity）。,具体性,被定义为,具体性是指知识图谱中实体和关系的描述越具体越好
●具体性（specificity）。,具体性,由组成,具体性
●具体性（specificity）。,具体性,由组成,具体性
选择最具体的规则，例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)_�(Studentname:age:20)_�●新近程度（recency）。,新近程度,被定义为,规则
选择最具体的规则，例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)_�(Studentname:age:20)_�●新近程度（recency）。,选择最具体的规则,由组成,例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)_�(Studentname:age:20)_�●新近程度（recency）。
选择最近没有被触发的规则执行动作。,规则,被定义为,选择最近没有被触发的规则执行动作。
选择最近没有被触发的规则执行动作。,选择最近没有被触发的规则执行动作,由组成,选择最近没有被触发的规则执行动作
选择最近没有被触发的规则执行动作。,选择最近没有被触发的规则执行动作,属于,选择最近没有被触发的规则执行动作
4.相关工具介绍表6-5为三个基于产生式规则的系统，它们都是基于Rete算法或其改进的。,Rete算法,被定义为,基于产生式规则的系统
4.相关工具介绍表6-5为三个基于产生式规则的系统，它们都是基于Rete算法或其改进的。,基于产生式规则的系统,由组成,Rete算法或其改进的
表6-5三个基于产生式规则的系统（1）Drools。,基于产生式规则的系统,被定义为,Drools
表6-5三个基于产生式规则的系统（1）Drools。,Drools,由组成,基于产生式规则的系统
表6-5三个基于产生式规则的系统（1）Drools。,Drools,由组成,基于产生式规则的系统
Drools是一个商用规则管理系统，提供了一个规则推理引擎。,Drools,被定义为,商用规则管理系统
Drools是一个商用规则管理系统，提供了一个规则推理引擎。,Drools,由组成,一个商用规则管理系统，提供了一个规则推理引擎。
Drools是一个商用规则管理系统，提供了一个规则推理引擎。,Drools,由组成,一个商用规则管理系统，提供了一个规则推理引擎。
核心算法是基于Rete算法的改进。,核心算法,被定义为,基于Rete算法的改进
核心算法是基于Rete算法的改进。,核心算法,由组成,基于Rete算法的改进
提供规则定义语言，支持嵌入Java代码。,SPO,被定义为,提供规则定义语言，支持嵌入Java代码。
提供规则定义语言，支持嵌入Java代码。,SPO,由组成,提供规则定义语言，支持嵌入Java代码。
提供规则定义语言，支持嵌入Java代码。,SPO,由组成,提供规则定义语言，支持嵌入Java代码。
Jena是一个用于构建语义网应用的Java框架。,Jena,被定义为,一个用于构建语义网应用的Java框架。
Jena是一个用于构建语义网应用的Java框架。,Jena,由组成,Java框架
Jena是一个用于构建语义网应用的Java框架。,Jena,由组成,Java框架
提供了处理RDF、RDFS、OWL数据的接口，还提供了一个规则引擎。,RDFS,被定义为,RDFS语言
提供了处理RDF、RDFS、OWL数据的接口，还提供了一个规则引擎。,RDF,由组成,RDFS
提供三元组的内存存储于SPARQL、查询。,SPO,被定义为,三元组存储
提供三元组的内存存储于SPARQL、查询。,SPARQL,由组成,SPARQL查询语言
提供三元组的内存存储于SPARQL、查询。,提供三元组的内存存储于SPARQL、查询。,实现,提供三元组的内存存储于SPARQL、查询。
提供三元组的内存存储于SPARQL、查询。,提供三元组的内存存储于SPARQL、查询。,属于,提供三元组的内存存储于SPARQL、查询。
6.3基于归纳的知识图谱推理随着技术的发展，越来越多的知识图谱自动化构建方法被提出来，例如利用算法对文本进行三元组抽取，这使得大规模知识图谱能够迅速被建立起来，例如NELL。,知识图谱,被定义为,利用算法对文本进行三元组抽取
6.3基于归纳的知识图谱推理随着技术的发展，越来越多的知识图谱自动化构建方法被提出来，例如利用算法对文本进行三元组抽取，这使得大规模知识图谱能够迅速被建立起来，例如NELL。,基于归纳的知识图谱推理,由组成,NELL
但这类知识图谱的信息准确度稍差于利用专家知识人工构建的知识图谱，且冗余度较大。,基于知识图谱构建的知识库,被定义为,利用专家知识人工构建的知识图谱
但这类知识图谱的信息准确度稍差于利用专家知识人工构建的知识图谱，且冗余度较大。,知识图谱,由组成,利用专家知识人工构建的知识图谱
在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。,知识图谱,被定义为,大规模知识图谱
在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。,知识图谱,由组成,归纳推理
在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。,知识图谱,由组成,归纳推理
基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。,基于归纳的知识图谱推理,被定义为,对知识图谱已有信息的分析和挖掘
基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。,基于归纳的知识图谱推理,由组成,三元组
基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。,基于归纳的知识图谱推理,由组成,三元组
按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。,基于图结构的推理,被定义为,基于图结构的推理
按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。,基于图结构的推理,由组成,基于图结构的推理
按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。,基于图结构的推理,由组成,基于图结构的推理
下面分别介绍这三类推理的主要方法和现有进展。,推理,被定义为,下面分别介绍这三类推理的主要方法和现有进展。
下面分别介绍这三类推理的主要方法和现有进展。,知识图谱,方法,知识推理
下面分别介绍这三类推理的主要方法和现有进展。,下面分别介绍这三类推理的主要方法和现有进展。,由组成,三类推理
6.3.1基于图结构的推理1.方法概述对于那些自底向上构建的知识图谱，图谱中大部分信息都是表示两个实体之间拥有某种关系的事实三元组。,基于图结构的推理,被定义为,自底向上构建的知识图谱
6.3.1基于图结构的推理1.方法概述对于那些自底向上构建的知识图谱，图谱中大部分信息都是表示两个实体之间拥有某种关系的事实三元组。,基于图结构的推理,由组成,自底向上构建的知识图谱
对于这些三元组，从图的角度来看，可以看作是标签的有向图，有向图以实体为节点，以关系为有向边，并且每个关系边从头实体的节点指向尾实体的节点，如图6-11所示。,三元组,被定义为,标签的有向图
对于这些三元组，从图的角度来看，可以看作是标签的有向图，有向图以实体为节点，以关系为有向边，并且每个关系边从头实体的节点指向尾实体的节点，如图6-11所示。,关系,由组成,三元组
例如，上面的示例中描述了不同人物之间的关系以及人物的职业信息，包含了如下的路径：这是一条从实体小明到实体小小的路径，表述的信息是小明的妻子是小红，小红的孩子有小小。,小明,被定义为,小红
例如，上面的示例中描述了不同人物之间的关系以及人物的职业信息，包含了如下的路径：这是一条从实体小明到实体小小的路径，表述的信息是小明的妻子是小红，小红的孩子有小小。,小红,被定义为,小小
其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。,关系,被定义为,由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。
其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。,关系,由组成,由组成
其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。,妻子是,属于,关系
这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。,路径,被定义为,一种重要的进行关系推理的信息，也是一种重要的图结构
这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。,路径,由组成,关系推理
这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。,路径,属于,关系推理
除了路径，实体的邻居节点以及它们之间的关系也是刻画和描述一个实体的重要信息，例如在上例中的关于“小明”的7个三元组鲜明地描述了小明这个人物，包括（小明，父亲是，建国）、（小明，获得奖项，最佳男主角）以及（小明，妻子是，小红）等。,小明,被定义为,小明，父亲是，建国
一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。,知识图谱,包含,实体
一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。,实体一跳和两跳范围内的节点和关系,由组成,知识图谱推理
一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。,实体一跳和两跳范围内的节点和关系,由组成,知识图谱推理
当把知识图谱看作是有向图时，往往强调的是在知识图谱中的事实三元组，即表示两个实体之间拥有某种关系的三元组，而对于知识图谱的本体和上层的schema则关注较少，因为本体中许多含有丰富逻辑描述的信息并不能简单地转化为图的结构。,知识图谱,被定义为,有向图
当把知识图谱看作是有向图时，往往强调的是在知识图谱中的事实三元组，即表示两个实体之间拥有某种关系的三元组，而对于知识图谱的本体和上层的schema则关注较少，因为本体中许多含有丰富逻辑描述的信息并不能简单地转化为图的结构。,知识图谱,由组成,本体
下面将介绍常见的基于图结构的知识图谱推理算法。,基于图结构的知识图谱推理算法,被定义为,基于图结构的知识图谱推理算法
下面将介绍常见的基于图结构的知识图谱推理算法。,基于图结构的知识图谱推理算法,由组成,基于图结构的知识图谱推理算法
2.常见算法简介典型的基于图结构的推理方法有PRA（Path_Ranking_Algorithm）[10]利用了实体节点之间的路径当作特征从而进行链接预测推理。,PRA,被定义为,基于图结构的推理方法
2.常见算法简介典型的基于图结构的推理方法有PRA（Path_Ranking_Algorithm）[10]利用了实体节点之间的路径当作特征从而进行链接预测推理。,PRA,由组成,基于图结构的推理方法
（1）基于知识图谱路径特征的PRA算法。,基于知识图谱路径特征的PRA算法,被定义为,PRA算法
（1）基于知识图谱路径特征的PRA算法。,基于知识图谱路径特征的PRA算法,由组成,PRA算法
（1）基于知识图谱路径特征的PRA算法。,基于知识图谱路径特征的PRA算法,实现,基于知识图谱路径特征的PRA算法
（1）基于知识图谱路径特征的PRA算法。,基于知识图谱路径特征的PRA算法,属于,基于知识图谱路径特征的PRA算法
PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。,PRA,被定义为,自底向上自动化构建的含有较多噪声的图谱
PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。,PRA,由组成,NELL
PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。,PRA,由组成,NELL
PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。,PRA,被定义为,将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。
PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。,PRA,由组成,逻辑斯蒂回归分类器
PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。,PRA,由组成,逻辑斯蒂回归分类器
在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。,PRA,被定义为,路径推理算法
在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。,PRA,由组成,路径
在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。,PRA,属于,路径推理算法
在PRA中，利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn_1的值域（domian)，即Tn=range（rn）=domain（rn_1），关系的值域和作用域通常指的是实体的类型。,PRA,被定义为,利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn_1的值域（domian)，即Tn=range（rn）=domain（rn_1），关系的值域和作用域通常指的是实体的类型。
在PRA中，利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn_1的值域（domian)，即Tn=range（rn）=domain（rn_1），关系的值域和作用域通常指的是实体的类型。,PRA,由组成,利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn_1的值域（domian)，即Tn=range（rn）=domain（rn_1），关系的值域和作用域通常指的是实体的类型。
"基于路径的随机游走定义了一个关系路径的分布，并得到每条路径的特征值s_,P（t）,s_,P（t）可以理解为沿着路径P从h开始能够到达t的概率。",基于路径的随机游走,被定义为,路径的分布
"基于路径的随机游走定义了一个关系路径的分布，并得到每条路径的特征值s_,P（t）,s_,P（t）可以理解为沿着路径P从h开始能够到达t的概率。",基于路径的随机游走,由组成,路径的分布
"具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。",s_,被定义为,s_，P（e）
"具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。",具体操作为,由组成,"在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。"
"具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。","具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。",实现,"具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。"
"在随机游走的过程中，s_,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。",随机游走,包含,式
"在随机游走的过程中，s_,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。",s_,由组成,P（e）
"在随机游走的过程中，s_,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。",在随机游走的过程中,实现,s_，P（e）的更新原则
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",PRA,包含,关系r
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",PRA,被定义为,利用随机游走得到一系列路径特征，训练一个线性预测实体排序模型
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",PRA,由组成,关系r
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",关系r,实现,PRA
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",关系r,来源,PRA
"对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。",关系r,属于,PRA
在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。,PRA,被定义为,路径特征搜索过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。
在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。,PRA,由组成,路径特征搜索
在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。,PRA,实现,路径特征搜索
在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。,PRA,来源,路径特征搜索
在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。,PRA,属于,路径特征搜索
采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。,采集路径随机游走过程,包含,LVS（Low-Variance_Sampling）的方法
采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。,采集路径随机游走过程,由组成,LVS（Low-Variance_Sampling）的方法
采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。,采集路径随机游走过程,实现,LVS（Low-Variance_Sampling）
采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。,采集路径随机游走过程,属于,LVS（Low-Variance_Sampling）
结合了有效采样和随机有走的PRA能够快速有效地利用知识图谱的路径结构对知识图谱进行关系推理，是典型的基于图结构的知识图谱推理算法。,PRA,包含,快速有效地利用知识图谱的路径结构对知识图谱进行关系推理
结合了有效采样和随机有走的PRA能够快速有效地利用知识图谱的路径结构对知识图谱进行关系推理，是典型的基于图结构的知识图谱推理算法。,PRA,由组成,快速路径推理算法
（2）PRA的演化算法。,PRA,被定义为,演化算法
（2）PRA的演化算法。,PRA,由组成,演化算法
（2）PRA的演化算法。,PRA,实现,演化算法
（2）PRA的演化算法。,PRA,来源,演化算法
（2）PRA的演化算法。,PRA,属于,演化算法
所以，CoR-PRA（Constant_and_Reversed_Path_RankingAlgorithm）[43]通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。,CoR-PRA,被定义为,通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。
所以，CoR-PRA（Constant_and_Reversed_Path_RankingAlgorithm）[43]通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。,CoR-PRA,由组成,通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。
通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。,路径搜索算法,被定义为,通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。
通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。,路径搜索算法,由组成,P_
通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,路径搜索算法
通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,路径搜索算法
通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。,路径搜索算法,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
2）通过PRA计算路径特征的概率。,PRA,被定义为,路径特征的概率
2）通过PRA计算路径特征的概率。,PRA,由组成,通过PRA计算路径特征的概率。
2）通过PRA计算路径特征的概率。,PRA,由组成,通过PRA计算路径特征的概率。
3）生成候选的常量路径。,常量路径,被定义为,生成候选的常量路径
3）生成候选的常量路径。,生成候选的常量路径,由组成,3）生成候选的常量路径。
4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。,生成更长的路径特征候选集,被定义为,LongConcatenatedPathCandidates
4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。,生成更长的路径特征候选集,由组成,LongConcatenatedPathCandidates
4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。,生成更长的路径特征候选集,由组成,LongConcatenatedPathCandidates
"对每一个可，就生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。",对每一个可,由组成,"生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。"
"对每一个可，就生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。",对每一个可,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"对每一个可，就生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。",对每一个可,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"对每一个可，就生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。",对每一个可,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
反向同理。,反向同理,被定义为,反向推理
反向同理。,反向同理,由组成,由组成
反向同理。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,实现
"从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。",CoR-PRA,包含,PRA
"从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。",CoR-PRA,被定义为,PRA
"从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。",CoR-PRA,由组成,PRA
"从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。",CoR-PRA,由组成,PRA
尽管采用了随机游走策略来降低搜索空间，当PRA应用在关系丰富且连接稠密的知识图谱上时，依然会面临路径特征爆炸的问题。,PRA,被定义为,路径相关度
尽管采用了随机游走策略来降低搜索空间，当PRA应用在关系丰富且连接稠密的知识图谱上时，依然会面临路径特征爆炸的问题。,PRA,由组成,路径特征爆炸
为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。,SFE,被定义为,PRA的路径特征搜索过程
为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。,SFE,由组成,PRA
为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。,SFE,由组成,PRA
"为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。",SFE,包含,路径特征
"为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。",SFE,由组成,实体e
"为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。",SFE,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。",SFE,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
"为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。",SFE,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
为了进一步提升路径搜索效率，降低无意义的路径特征，对于图中的一个节点，如果这个节点有很多相同关系边ri连接着不同的实体节点，那么沿着这个关系继续搜索路径会急剧增加子图大小的量级。,路径搜索,被定义为,路径搜索效率
为了进一步提升路径搜索效率，降低无意义的路径特征，对于图中的一个节点，如果这个节点有很多相同关系边ri连接着不同的实体节点，那么沿着这个关系继续搜索路径会急剧增加子图大小的量级。,路径搜索,由组成,无意义的路径特征
为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。,深度优先搜索,被定义为,停止搜索
为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。,深度优先搜索,由组成,当前节点
为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。,深度优先搜索,由组成,当前节点
"为了增加子图特征的丰富性，除了PRA中用到的路径特征，SFE还增加了二元路径特征，类似自然语言处理中的bigram，即将两个具有连接的关系组成一个新的关系，例如“BIGRAM：对齐实体/妻子是”，除了二元路径特征，SFE还增加了one-sided_feature,one-sided_path指的是一个存在在给定两个节点之间的路径的，是从起始节点开始，但不一定由另一个节点结束，类似Co-PRA中的带有常量的路径特征。",SFE,被定义为,增加子图特征的丰富性
"为了增加子图特征的丰富性，除了PRA中用到的路径特征，SFE还增加了二元路径特征，类似自然语言处理中的bigram，即将两个具有连接的关系组成一个新的关系，例如“BIGRAM：对齐实体/妻子是”，除了二元路径特征，SFE还增加了one-sided_feature,one-sided_path指的是一个存在在给定两个节点之间的路径的，是从起始节点开始，但不一定由另一个节点结束，类似Co-PRA中的带有常量的路径特征。",SFE,由组成,PRA
SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。,SFE,被定义为,one-sided_feature的比较
SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。,SFE,由组成,one-sided_feature
SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。,SFE,由组成,one-sided_feature
如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。,PRA路径特征,包含,SFE
如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。,PRA路径特征,由组成,SFE
如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。,PRA路径特征,实现,SFE
如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。,PRA路径特征,来源,SFE
如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。,PRA路径特征,属于,SFE
SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。,SFE,被定义为,利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。
SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。,SFE,由组成,关系向量表示
SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。,SFE,由组成,关系向量表示
SFE还增加了一个表示任意关系的关系ANYREL来增加路径特征的丰富性。,SFE,被定义为,关系ANYREL
SFE还增加了一个表示任意关系的关系ANYREL来增加路径特征的丰富性。,SFE,由组成,ANYREL
总体来说，SFE在PRA的路径特征搜索的效率和特征的丰富性方面做了比较大的提升。,SFE,被定义为,PRA的路径特征搜索的效率和特征的丰富性
总体来说，SFE在PRA的路径特征搜索的效率和特征的丰富性方面做了比较大的提升。,SFE,由组成,PRA
从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。,路径搜索,被定义为,如何有效地搜索到路径
从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。,路径搜索,由组成,PRA系列研究
从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。,基于图结构的PRA系列研究,实现,涌现出了很多提升路径搜索效率的研究工作。
从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。,基于图结构的PRA系列研究,来源,涌现出了很多提升路径搜索效率的研究工作。
从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。,基于图结构的PRA系列研究,属于,涌现出了很多提升路径搜索效率的研究工作。
但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。,路径相关的特征,被定义为,知识图谱中包含的所有语义信息
但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。,路径相关的特征,由组成,知识图谱中包含的所有语义信息
但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。,路径相关的特征,由组成,知识图谱中包含的所有语义信息
但是，不是路径形式的图结构特征依然有待挖掘和分析。,图结构特征,被定义为,路径形式的图结构特征
但是，不是路径形式的图结构特征依然有待挖掘和分析。,图结构特征,由组成,路径形式的图结构特征
但是，不是路径形式的图结构特征依然有待挖掘和分析。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,图结构特征
2.典型工具简介或实验对比分析PRA的提出主要是针对很不完整的知识图谱，所以论文中的实验是在知识图谱NELL上进行试验的，图6-12展示了PRA中在预测某一关系时权重最高的两个路径特征，可以看出，这些高权重的路径特征可以看作是预测当前关系的一条置信度较高的规则，具有明显的语义含义。,PRA,被定义为,PRA中在预测某一关系时权重最高的两个路径特征
2.典型工具简介或实验对比分析PRA的提出主要是针对很不完整的知识图谱，所以论文中的实验是在知识图谱NELL上进行试验的，图6-12展示了PRA中在预测某一关系时权重最高的两个路径特征，可以看出，这些高权重的路径特征可以看作是预测当前关系的一条置信度较高的规则，具有明显的语义含义。,PRA,由组成,知识图谱
PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。,PRA,包含,N-FOIL
PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。,PRA,由组成,N-FOIL
PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。,PRA,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。,PRA,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。,PRA,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。,深度优先搜索策略,被定义为,用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。
从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。,深度优先搜索策略,由组成,SFE
从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。,深度优先搜索策略,由组成,SFE
图6-15SFE和PRA的性能比较典型的PRA系列工具可以参考https://github.com/noon99jaki/pra，集成了PRA以及CoR-PRA算法。,PRA,被定义为,PRA系列工具
图6-15SFE和PRA的性能比较典型的PRA系列工具可以参考https://github.com/noon99jaki/pra，集成了PRA以及CoR-PRA算法。,PRA,由组成,PRA
6.3.2基于规则学习的推理1.方法概述基于规则的推理具有精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用。,基于规则的推理,被定义为,精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用
6.3.2基于规则学习的推理1.方法概述基于规则的推理具有精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用。,基于规则的推理,由组成,基于规则的推理
规则是基于规则推理的核心，所以规则获取是一个重要的任务。,规则,被定义为,基于规则推理的核心
规则是基于规则推理的核心，所以规则获取是一个重要的任务。,规则,由组成,基于规则推理
规则是基于规则推理的核心，所以规则获取是一个重要的任务。,规则,属于,基于规则推理
在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。,规则,被定义为,领域专家提供
在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。,规则,由组成,领域专家
在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,领域知识图谱
所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。,自动化的规则学习方法,被定义为,快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务
所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。,自动化的规则学习方法,由组成,从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务
所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。,自动化的规则学习方法,由组成,从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务
规则一般包含了两个部分，分别为规则头（head）和规则主体（body），其一般形式为rule:head←body.解读为有规则主体的信息可推出规则头的信息。,规则,被定义为,规则头（head）和规则主体（body）
规则一般包含了两个部分，分别为规则头（head）和规则主体（body），其一般形式为rule:head←body.解读为有规则主体的信息可推出规则头的信息。,规则,由组成,规则头
其中，规则头由一个二元的原子（atom）构成，而规则主体由一个或多个一元原子或二元原子组成。,规则,被定义为,原子
其中，规则头由一个二元的原子（atom）构成，而规则主体由一个或多个一元原子或二元原子组成。,规则头,由组成,一个二元的原子（atom）
"原子（atom）是指包含了变量的元组，例如isLocation(X)是一个一元原子表示实体变量X是一个位置实体；hasWife(X,Y)是一个二元原子，表示实体变量X的妻子是实体变量Y。",原子,被定义为,包含变量的元组
"原子（atom）是指包含了变量的元组，例如isLocation(X)是一个一元原子表示实体变量X是一个位置实体；hasWife(X,Y)是一个二元原子，表示实体变量X的妻子是实体变量Y。",原子,由组成,一元原子
"二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。",二元原子,包含,两个或一个
"二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。",二元原子,被定义为,指含有一个实体变量X的二元原子，表示了变量X居住在杭州。
"二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。",二元原子,包含,两个或一个
"二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。",二元原子,被定义为,指含有一个实体变量X的二元原子，表示了变量X居住在杭州。
"二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。",二元原子,由组成,两个或一个
在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。,规则主体,被定义为,逻辑合取
在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。,规则主体,由组成,逻辑合取
在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。,规则主体,由组成,逻辑合取
这条规则里的规则主体就包含了以否定形式出现的原子。,规则,被定义为,以否定形式出现的原子
这条规则里的规则主体就包含了以否定形式出现的原子。,这条规则里的规则主体就包含了以否定形式出现的原子。,由组成,否定
所以，规则也可以表示为：rule:head←body+∧body_.其中，body+表示以肯定形式出现的原子的逻辑合取集合，而body_表示以否定形式出现的原子的逻辑合取集合。,规则,被定义为,：head←body+∧body_
所以，规则也可以表示为：rule:head←body+∧body_.其中，body+表示以肯定形式出现的原子的逻辑合取集合，而body_表示以否定形式出现的原子的逻辑合取集合。,规则,由组成,body+∧body_
如果规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子，称这样的规则为霍恩规则（horn规则类型，可以表示为以下形式：rules），霍恩规则是被研究得比较多的a0←a1∧a2∧�∧an.其中，每个ai都为一个原子。,霍恩规则,被定义为,规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子
如果规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子，称这样的规则为霍恩规则（horn规则类型，可以表示为以下形式：rules），霍恩规则是被研究得比较多的a0←a1∧a2∧�∧an.其中，每个ai都为一个原子。,霍恩规则,由组成,规则主体
"在知识图谱的规则学习方法中，另一种被研究得比较多的规则类型叫作路径规则（pathrules），路径规则可以表示为如下形式：r0（e1,en+1）←r1（e1,e2）∧r2（e2,e3）∧�∧rn（en,en+1）.其中，规则主体中的原子均为含有两个变量的二元原子，且规则主体的所有二元原子构成一个从规则头中的两个实体之间的路径，且整个规则在知识图谱中构成一个闭环结构。",路径规则,由组成,"r0（e1,en+1）←r1（e1,e2）∧r2（e2,e3）∧�∧rn（en,en+1）.其中，规则主体中的原子均为含有两个变量的二元原子，且规则主体的所有二元原子构成一个从规则头中的两个实体之间的路径，且整个规则在知识图谱中构成一个闭环结构。"
这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。,路径规则,包含,霍恩规则
这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。,路径规则,包含,一般规则
这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。,路径规则,由组成,霍恩规则
下面分别介绍这三种评价指标的计算方法。,评价指标,被定义为,评价指标的计算方法
对于一个规则rule，在知识图谱中，其支持度（support）指的是满足规则主体和规则头的实例个数，规则的实例化指的是将规则中的变量替换成知识图谱中真实的实体后的结果。,支持度,被定义为,满足规则主体和规则头的实例个数
对于一个规则rule，在知识图谱中，其支持度（support）指的是满足规则主体和规则头的实例个数，规则的实例化指的是将规则中的变量替换成知识图谱中真实的实体后的结果。,支持度,由组成,满足规则主体和规则头的实例个数
所以，规则的支持度通常是一个大于或等于0的整数值，用support(rule)表示。,支持度,被定义为,support(rule)表示
所以，规则的支持度通常是一个大于或等于0的整数值，用support(rule)表示。,支持度,由组成,support(rule)
一般来说，一个规则的支持度越大，说明这个规则的实例在知识图谱中存在得越多，从统计角度来看，也越可能是一个比较好的规则。,规则,包含,支持度
一般来说，一个规则的支持度越大，说明这个规则的实例在知识图谱中存在得越多，从统计角度来看，也越可能是一个比较好的规则。,支持度,由组成,规则
规则的置信度（confidence）的计算方式为：方法。,规则的置信度,方法,规则置信度
规则的置信度（confidence）的计算方式为：方法。,规则的置信度,方法,规则置信度
规则的置信度（confidence）的计算方式为：方法。,规则的置信度,方法,规则置信度
一个规则的置信度越高，一般说明规则的质量也越高。,规则的置信度,被定义为,规则的质量
一个规则的置信度越高，一般说明规则的质量也越高。,一个规则的置信度,由组成,规则的质量
一个规则的置信度越高，一般说明规则的质量也越高。,一个规则的置信度,实现,一般说明规则的质量也越高
一个规则的置信度越高，一般说明规则的质量也越高。,一个规则的置信度,属于,一个规则的置信度
"所以，基于部分完全假设（PartialCompleteness_Assumption,PCA）的置信度（PCA_Confidence）也是一个衡量规则质量的方法，且考虑了知识图谱的不完整性。",基于部分完全假设的置信度,被定义为,衡量规则质量的方法
"所以，基于部分完全假设（PartialCompleteness_Assumption,PCA）的置信度（PCA_Confidence）也是一个衡量规则质量的方法，且考虑了知识图谱的不完整性。",基于部分完全假设的置信度,由组成,PCA_Confidence
"PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。",PCA置信度,包含,规则头
"PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。",PCA置信度,被定义为,"从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。"
"PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。",PCA置信度,由组成,"r0（x,y′）"
"PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。",PCA置信度,由组成,"r0（x,y′）"
所以，在PCA置信度中排除了来自这类实例对置信度值的负向影响。,PCA置信度,被定义为,来自这类实例对置信度值的负向影响
所以，在PCA置信度中排除了来自这类实例对置信度值的负向影响。,PCA置信度,由组成,来自这类实例对置信度值的负向影响
规则的支持度、置信度以及头覆盖度从不同的角度反映了规则的质量，但三者之间没有必然的关联关系。,支持度,被定义为,规则的支持度
规则的支持度、置信度以及头覆盖度从不同的角度反映了规则的质量，但三者之间没有必然的关联关系。,支持度,由组成,支持度
例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。,规则质量评价指标,被定义为,置信度、头覆盖度、规则覆盖度
例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。,置信度高的规则,由组成,头覆盖度
例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。,置信度高的规则,属于,头覆盖度
2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。,AMIE,被定义为,AMIE算法
2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。,AMIE,由组成,AMIE
2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。,AMIE,实现,规则学习方法
2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。,AMIE,来源,规则学习方法
2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。,AMIE,属于,规则学习方法
"AMIE能挖掘的规则形如：fatherOf（f,c）←motherOf（m,c）∧marriedTo（m,f）.AMIE是一种霍恩规则，也是一种闭环规则，即整条规则可以在图中构成一个闭环结构。",AMIE,被定义为,霍恩规则
"AMIE能挖掘的规则形如：fatherOf（f,c）←motherOf（m,c）∧marriedTo（m,f）.AMIE是一种霍恩规则，也是一种闭环规则，即整条规则可以在图中构成一个闭环结构。",AMIE,由组成,霍恩规则
在规则学习的任务中，最重要的是如何有效搜索空间，因为在大型的知识图谱上简单地遍历所有可能的规则并评估规则的质量效率很低，几乎不可行。,规则学习,被定义为,搜索空间
在规则学习的任务中，最重要的是如何有效搜索空间，因为在大型的知识图谱上简单地遍历所有可能的规则并评估规则的质量效率很低，几乎不可行。,搜索空间,由组成,如何有效
AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。,AMIE,被定义为,AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。
AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。,AMIE,由组成,Mining_Operators
AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。,AMIE,由组成,Mining_Operators
3个挖掘算子如下：●增加悬挂原子（Adding_Dangling_Atom）。,增加悬挂原子,被定义为,增加悬挂原子算子
3个挖掘算子如下：●增加悬挂原子（Adding_Dangling_Atom）。,增加悬挂原子,由组成,增加悬挂原子算子
即在规则中增加一个原子，这个原子包含一个新的变量和一个已经在规则中出现的元素，可以是出现过的变量，也可以是出现过的实体。,规则,被定义为,原子
即在规则中增加一个原子，这个原子包含一个新的变量和一个已经在规则中出现的元素，可以是出现过的变量，也可以是出现过的实体。,规则,由组成,原子
●增加实例化的原子（Adding_Instantiated_Atom）。,增加实例化的原子,被定义为,增加原子实例
●增加实例化的原子（Adding_Instantiated_Atom）。,增加实例化的原子,由组成,原子
●增加实例化的原子（Adding_Instantiated_Atom）。,增加实例化的原子,由组成,原子
即在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。,SPO,被定义为,在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。
即在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。,SPO,由组成,实体
●增加闭合原子（Adding_Closing_Atom）。,增加闭合原子,被定义为,增加闭合原子
●增加闭合原子（Adding_Closing_Atom）。,增加闭合原子,由组成,闭合原子
●增加闭合原子（Adding_Closing_Atom）。,增加闭合原子,实现,实现
●增加闭合原子（Adding_Closing_Atom）。,增加闭合原子,来源,实现
●增加闭合原子（Adding_Closing_Atom）。,增加闭合原子,属于,实现
即在规则中增加一个原子，这个原子包含的两个元素都是已经出现在规则中的变量或实体。,规则,被定义为,原子
即在规则中增加一个原子，这个原子包含的两个元素都是已经出现在规则中的变量或实体。,规则,由组成,原子
增加闭合原子之后，规则就算构建完成了。,增加闭合原子,被定义为,规则
增加闭合原子之后，规则就算构建完成了。,增加闭合原子,由组成,规则
AMIE的规则学习算法如图6-16所示。,AMIE,被定义为,AMIE的规则学习算法
AMIE的规则学习算法如图6-16所示。,AMIE,由组成,规则学习算法
AMIE的规则学习算法如图6-16所示。,AMIE,由组成,规则学习算法
图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。,AMIE,被定义为,AMIE的规则学习算法
图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。,AMIE,由组成,AMIE的规则学习算法
图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。,AMIE,由组成,AMIE的规则学习算法
AMIE的剪枝策略主要包含两条：●设置最低规则头覆盖度过滤，头覆盖度很低的规则一般是一些边缘规则，可以直接过滤掉。,AMIE,包含,剪枝策略
AMIE的剪枝策略主要包含两条：●设置最低规则头覆盖度过滤，头覆盖度很低的规则一般是一些边缘规则，可以直接过滤掉。,AMIE,由组成,剪枝策略
在实践中，AMIE将头覆盖度值设为0.01。,AMIE,包含,头覆盖度值
在实践中，AMIE将头覆盖度值设为0.01。,AMIE,被定义为,头覆盖度值
在实践中，AMIE将头覆盖度值设为0.01。,AMIE,由组成,头覆盖度
在实践中，AMIE将头覆盖度值设为0.01。,AMIE,由组成,头覆盖度
●在一条规则中，每在规则主体中增加一个原子，都应该使得规则的置信度增加，即confidence（a0←a0∧a2∧�∧an∧an+1）＞confidence（a0←a0∧a2∧�∧an）。,一条规则,被定义为,confidence（a0←a0∧a2∧�∧an∧an+1）＞confidence（a0←a0∧a2∧�∧an）
●在一条规则中，每在规则主体中增加一个原子，都应该使得规则的置信度增加，即confidence（a0←a0∧a2∧�∧an∧an+1）＞confidence（a0←a0∧a2∧�∧an）。,confidence,由组成,confidence（a0←a0∧a2∧�∧an∧an+1）＞confidence（a0←a0∧a2∧�∧an）。
如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧�∧an∧an+1剪枝掉。,规则剪枝,包含,a0∧a2∧�∧an∧an+1
如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧�∧an∧an+1剪枝掉。,剪枝,由组成,拓展后的规则a0←a0∧a2∧�∧an∧an+1
如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧�∧an∧an+1剪枝掉。,剪枝,由组成,拓展后的规则a0←a0∧a2∧�∧an∧an+1
在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。,AMIE,被定义为,通过SPARQL在知识图谱上的查询对规则的质量进行评估
在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。,AMIE,由组成,规则学习
在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。,AMIE,由组成,规则学习
无论采用哪种挖掘算子来增加规则中的原子，每一个原子都伴随着需要选择一个知识图谱中的关系。,知识图谱中的关系,被定义为,原子
无论采用哪种挖掘算子来增加规则中的原子，每一个原子都伴随着需要选择一个知识图谱中的关系。,知识图谱中的关系,由组成,原子
3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。,AMIE,被定义为,AMIE是一个基于图数据库的图数据库查询语言
3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。,AMIE,由组成,AMIE
3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。,AMIE,实现,图6-17
3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。,AMIE,属于,图6-17
例如，在拥有100多万个实体以及近700万个三元组的DBpedia上，AMIE仅需不到3min就能完成规则挖掘，产生7000条规则，并帮助推理出了12万多个新的三元组。,AMIE,被定义为,DBpedia
例如，在拥有100多万个实体以及近700万个三元组的DBpedia上，AMIE仅需不到3min就能完成规则挖掘，产生7000条规则，并帮助推理出了12万多个新的三元组。,AMIE,由组成,DBpedia
图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。,AMIE,包含,AMIE+
图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。,AMIE,被定义为,AMIE+
图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。,AMIE,方法,AMIE+
图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。,AMIE,由组成,AMIE+
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,被定义为,将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,方法,将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,由组成,基于图结构的推理和基于规则学习的推理
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,实现,基于图结构的推理
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,来源,基于规则学习的推理
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,属于,基于图结构的推理
6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。,基于表示学习的推理,属于,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,实现,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,来源,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,实现,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,来源,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,实现,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,来源,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,实现,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,来源,基于规则学习的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于图结构的推理
知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。,基于表示学习的推理,属于,基于规则学习的推理
而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。,TransE,被定义为,TransE
而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。,TransE,由组成,TransE
而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。,TransE,实现,知识图谱表示学习
而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。,知识图谱表示学习,来源,TransE
而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。,TransE,属于,知识图谱表示学习
"2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。",TransE,被定义为,TransE模型
"2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。",TransE,实现,TransE
"2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。",TransE,来源,TransE
"2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。",TransE,属于,TransE
"TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。",TransE,被定义为,"TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。"
"TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。",TransE,由组成,"TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。"
在需要映射到的向量空间中，TransE将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。,TransE,被定义为,将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。
在需要映射到的向量空间中，TransE将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。,TransE,由组成,将关系看作是从头实体向量到尾实体向量的翻译
等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r_t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。,TransE,被定义为,TransE是一个基于向量空间模型的图表示学习算法，它通过向量空间模型将三元组表示为向量，然后通过向量之间的相似度计算三元组的相似度。
等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r_t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。,TransE,实现,理想情况的假设
等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r_t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。,TransE,来源,理想情况的假设
等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r_t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。,TransE,属于,理想情况的假设
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,包含,表示学习结果
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,被定义为,表示学习结果
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,包含,表示学习结果
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,被定义为,表示学习结果
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,由组成,表示学习结果
"然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。",知识图谱,由组成,表示学习结果
TransE的训练目标是最小化损失函数L，可以通过基于梯度的优化算法进行优化求解，直至训练收敛。,TransE,被定义为,最小化损失函数L
TransE的训练目标是最小化损失函数L，可以通过基于梯度的优化算法进行优化求解，直至训练收敛。,TransE,由组成,最小化损失函数L
实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。,TransE,被定义为,简单高效的知识图谱表示学习方法
实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。,TransE,被定义为,简单高效的知识图谱表示学习方法
实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。,TransE,由组成,简单高效的知识图谱表示学习方法
TransE的简单高效说明了知识图谱表示学习方法能够自动且很好地捕捉推理特征，无须人工设计，很适合在大规模复杂的知识图谱上推广，是一种有效的知识图谱推理手段。,TransE,被定义为,知识图谱表示学习方法能够自动且很好地捕捉推理特征
TransE的简单高效说明了知识图谱表示学习方法能够自动且很好地捕捉推理特征，无须人工设计，很适合在大规模复杂的知识图谱上推广，是一种有效的知识图谱推理手段。,TransE,由组成,知识图谱表示学习方法
例如，实体“中国”在关系“拥有省份”这个关系下有很多个尾实体，根据TransE的假设，任何一个省份的向量表示都满足v（省份x）:v（中国）+v（拥有省份）=v（省份x），这将会导致TransE无法很好地区分各个省份。,TransE,被定义为,无法很好地区分各个省份
图6-18TransE和TransH对比向量空间假设对比TransH为每个关系r都设计了一个投影平面，并用投影平面的法向量wr表示这个平面，h和t的投影向量的计算方法如下：然后，利用投影向量进行三元组得分的计算，即TransH通过设计关系投影平面提升了TransE表达非一对一关系的能力，TransR[8]则通过拆分实体向量表示空间和关系表示向量空间来提升TransE的表达能力。,TransE,被定义为,TransH
由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。,TransR,被定义为,实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。
由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。,TransR,由组成,实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中
由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。,TransR,由组成,实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中
为了减少TransR的参数量且同时保留其表达能力，TransD[47]提出了用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。,TransD,被定义为,用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。
为了减少TransR的参数量且同时保留其表达能力，TransD[47]提出了用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。,TransD,由组成,TransR
"图6-20TransD实体表示空间和关系表示空间其动态矩阵的计算如下：式中，m,n为关系和实体的向量表示维度；m,n可以相等也可以不相等。",TransD,被定义为,TransD是一种基于动态矩阵的图表示学习模型
"图6-20TransD实体表示空间和关系表示空间其动态矩阵的计算如下：式中，m,n为关系和实体的向量表示维度；m,n可以相等也可以不相等。",TransD,由组成,动态矩阵
TransD通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。,TransD,包含,动态计算投影矩阵
TransD通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。,TransD,由组成,通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。
之前介绍了以TransE为代表的基于翻译假设的表示学习模型，而知识图谱表示学习的推理能力和采用的向量空间假设有很大关系，除了翻译假设还有其他的空间假设，DistMult[48]采用了更灵活的线性映射假设将实体表示为向量，关系表示为矩阵，并将关系当作是一种向量空间中的线性变换。,DistMult,被定义为,基于线性映射假设的表示学习模型
"对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。",三元组,被定义为,"对于正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。"
"对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。",关系抽取,由组成,MR
"对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。",关系抽取,由组成,MR
上式表达的hMr=t.意思是头实体通过与关系矩阵相乘，经过空间中的线性变化以后，可以转变为尾实体向量。,hMr,包含,t
上式表达的hMr=t.意思是头实体通过与关系矩阵相乘，经过空间中的线性变化以后，可以转变为尾实体向量。,hMr,由组成,t
所以，训练目标是对正确的三元组让hMr与t尽可能接近，而错误的三元组尽可能远离。,hMr,被定义为,训练目标
所以，训练目标是对正确的三元组让hMr与t尽可能接近，而错误的三元组尽可能远离。,hMr,由组成,训练目标
由于向量与矩阵的运算比向量的加法运算更灵活，所以整体来说DistMult的效果比TransE效果要好。,DistMult,被定义为,向量与矩阵的运算比向量的加法运算更灵活
由于向量与矩阵的运算比向量的加法运算更灵活，所以整体来说DistMult的效果比TransE效果要好。,DistMult,由组成,TransE
当将关系的矩阵设计为对角矩阵时，参数量与TransE相同，且效果比普通矩阵更好。,TransE,包含,对角矩阵
当将关系的矩阵设计为对角矩阵时，参数量与TransE相同，且效果比普通矩阵更好。,TransE,由组成,对角矩阵
所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。,DistMult,被定义为,对角矩阵
所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。,DistMult,由组成,对角矩阵
所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。,DistMult,属于,关系表示
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于TransE,被定义为,丰富表达能力的模型
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于TransE,由组成,有很多丰富表达能力的模型
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于DistMult,由组成,有很多提升方法
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于TransE,实现,有很多丰富表达能力的模型
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于DistMult,来源,有很多提升方法
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于TransE,属于,有很多丰富表达能力的模型
基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。,基于DistMult,属于,有很多提升方法
"DistMult中一个比较明显的问题是，得分函数的设计使得当关系设计为对角矩阵时，无法隐含所有关系都是对称关系的结论，因为对于一个存在的三元组（h,r,t），经过模型训练以后，f（h,r,t）=hDrt_的值会比较大，即表示三元组（h,r,t）是正确的。",DistMult,被定义为,对称关系
"所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。",tDrh_,被定义为,hDrt_
"所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。",tDrh_,由组成,tDrh
"所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱
"所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,知识图谱
"所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,知识图谱
这说明了DistMult天然地假设了所有的关系是对称关系，这显然是不合理的。,DistMult,被定义为,假设了所有的关系是对称关系
这说明了DistMult天然地假设了所有的关系是对称关系，这显然是不合理的。,DistMult,由组成,假设
从语义的角度分析，知识图谱中的关系既包含了对称关系如“配偶是”，也包含了不对称关系如“出生地”，而且非对称关系一般还多于对称关系。,关系,由组成,对称关系
为了解决这个问题，ComplEx[49]将原来基于实数的表示学习拓展到了复数，因为基于复数的乘法计算是不满足交换律的，从而克服了DistMult不能很好地表示非对称关系的问题。,ComplEx,被定义为,将原来基于实数的表示学习拓展到了复数
为了解决这个问题，ComplEx[49]将原来基于实数的表示学习拓展到了复数，因为基于复数的乘法计算是不满足交换律的，从而克服了DistMult不能很好地表示非对称关系的问题。,ComplEx,由组成,DistMult
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",复数,包含,复数的实部和虚部
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",复数的实部和虚部,被定义为,复数的得分函数
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",得分函数,由组成,"f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。"
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",其得分函数的计算,实现,复数
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",复数,来源,复数
"其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。",复数,属于,复数
"可以看出在ComplEx中，f（h,r,t）≠f（t,r,h），所以可以更灵活地表达对称与非对称关系。",ComplEx,被定义为,对称和非对称关系
类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。,类比推理,被定义为,ANALOGY[50]
类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。,ANALOGY,实现,类比推理
类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。,ANALOGY,来源,类比推理
类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。,ANALOGY,属于,类比推理
除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。,ANALOGY,实现,类比推理
除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。,ANALOGY,来源,类比推理
除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。,ANALOGY,属于,类比推理
除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。,表示学习方法,由组成,ConvE
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识表示
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识存储
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识抽取
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识融合
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识推理
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,语义搜索
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识问答
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,包含,知识图谱项目
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,被定义为,知识表示
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,方法,知识图谱表示学习
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱,由组成,典型工具
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,来源,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
"3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。",知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现,属于,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱实现
从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。,线性变换假设模型,被定义为,线性变换假设模型系列
从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。,线性变换假设模型,由组成,翻译模型系列
从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。,线性变换假设模型,实现,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目
从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,来源,线性变换假设模型
从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。,知识图谱/知识表示/知识存储/知识抽取/知识融合/知识推理/语义搜索/知识问答/知识图谱项目,属于,线性变换假设模型
表6-6常用知识图谱表示学习方法链接预测结果比较续表常用的关于知识图谱表示学习的工具包有清华开源的OpenKE，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。,OpenKE,被定义为,OpenKE是一个开源的Python库，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。
表6-6常用知识图谱表示学习方法链接预测结果比较续表常用的关于知识图谱表示学习的工具包有清华开源的OpenKE，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。,OpenKE,由组成,OpenKE
全面的关于工具包的信息可以在网站主页获得。,全面的关于工具包的信息,被定义为,网站主页
全面的关于工具包的信息可以在网站主页获得。,全面的关于工具包的信息,由组成,可以在网站主页获得
全面的关于工具包的信息可以在网站主页获得。,全面的关于工具包的信息,由组成,可以在网站主页获得
6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。,全面的关于工具包的信息,由组成,可以在网站主页获得
6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。,全面的关于工具包的信息,由组成,可以在网站主页获得
6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。,时序预测推理,由组成,知识推理中的时序预测新应用
6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。,时序预测推理,由组成,知识推理中的时序预测新应用
传统的数据流学习主要是从连续和快速更新的数据记录中提取知识结构。,传统的数据流学习,被定义为,从连续和快速更新的数据记录中提取知识结构
传统的数据流学习主要是从连续和快速更新的数据记录中提取知识结构。,传统的数据流学习,由组成,从连续和快速更新的数据记录中提取知识结构
在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。,本体流,被定义为,本体
在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。,语义网,由组成,本体流
在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。,语义网,由组成,本体流
本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。,本体流,被定义为,通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。
本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。,本体流,由组成,重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。
本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。,本体流,由组成,重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。
数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。,数据流学习中的概念漂移问题,被定义为,数据的语义随着时间的漂移
数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。,数据流学习中的概念漂移问题,由组成,数据的语义随着时间的漂移
数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。,数据流学习中的概念漂移问题,属于,数据的语义
本体流可以看成随时间变化的本体，也就是语义增强的数据流。,本体流,被定义为,随时间变化的本体
本体流可以看成随时间变化的本体，也就是语义增强的数据流。,本体流,由组成,随时间变化的本体
本体流可以看成随时间变化的本体，也就是语义增强的数据流。,本体流,属于,随时间变化的本体
ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。,本体流,属于,随时间变化的本体
ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。,ABox_entailment,由组成,ABox中的断言
ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。,ABox_entailment,由组成,ABox中的断言
Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。,Snapshot,被定义为,快照
Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。,Snapshot,由组成,快照
Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。,Snapshot,由组成,快照
快照从一个时刻转变到下一个时刻可以看成断言公理的更新，这被称为一阶预测突变；两个快照对于某些蕴涵具有足够大的概率差异，这被称突发预测变化。,快照,包含,突变
快照从一个时刻转变到下一个时刻可以看成断言公理的更新，这被称为一阶预测突变；两个快照对于某些蕴涵具有足够大的概率差异，这被称突发预测变化。,快照,由组成,突变
这两种预测变化构成了语义概念漂移。,语义概念漂移,被定义为,语义概念漂移是语义概念的预测变化
这两种预测变化构成了语义概念漂移。,语义概念漂移,由组成,语义概念漂移
蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。,本体流,被定义为,基于规则的一致性度量和预测
蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。,蕴涵的滑动窗口之间基于规则的一致性度量和预测,由组成,可以表示和推断这些本体流中的语义概念漂移
蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。,蕴涵的滑动窗口之间基于规则的一致性度量和预测,实现,可以表示和推断这些本体流中的语义概念漂移
通过将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。,流学习,被定义为,将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。
通过将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。,语义推理,由组成,机器学习
该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。,概念漂移,包含,增强基本的流学习算法
该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。,概念漂移,包含,增强基本的流学习算法
该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。,概念漂移,由组成,增强基本的流学习算法
该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。,概念漂移,由组成,增强基本的流学习算法
实验还表明，在模型中，编码语义是一种超越目前最先进模型的方法，具有语义嵌入的模型对知识推理和预测起到重要作用。,概念漂移,由组成,增强基本的流学习算法
实验还表明，在模型中，编码语义是一种超越目前最先进模型的方法，具有语义嵌入的模型对知识推理和预测起到重要作用。,实验,由组成,编码语义
6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。,基于强化学习的知识图谱推理,被定义为,新兴的处理知识图谱推理的技术手段
6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。,基于强化学习的知识图谱推理,由组成,基于强化学习的知识图谱推理
6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。,基于强化学习的知识图谱推理,由组成,基于强化学习的知识图谱推理
比较有代表性的工作有文献[13]和[54]。,比较有代表性的工作,被定义为,文献[13]和[54]
比较有代表性的工作有文献[13]和[54]。,比较有代表性的工作,由组成,文献[13]和[54]
文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。,DeepPath,被定义为,将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。
文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。,DeepPath,由组成,文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。
文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。,DeepPath,由组成,文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。
“事实判断”即确定一个三元组是否成立。,事实判断,被定义为,确定一个三元组是否成立