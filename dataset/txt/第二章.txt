第2章 知识图谱表示与建模

漆桂林 东南大学，潘志霖 阿伯丁大学，陈华钧 浙江大学

知识图谱表示（Knowledge  Graph  Representation）指的是用什么语言对知识图谱进行
建模，从而可以方便知识计算。从图的角度来看，知识图谱是一个语义网络，即一种用互

联的节点和弧表示知识的一个结构[1]。语义网络中的节点可以代表一个概念（concept）、
一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的
关系，弧的标签指明了关系的类型。语义网络中的语义主要体现在图中边的含义。为了给

这些边赋予语义，研究人员(cid:6656)出了术语语言（Terminological  Language），并最终(cid:6656)出了
(cid:6655)述逻辑（Description  Logic），(cid:6655)述逻辑是一阶谓词逻辑的一个子集，推理复杂度是可
判定的。W3C 采用了以(cid:6655)述逻辑为逻辑基础的本体语言 OWL 作为定义 Web 术语的标准
语言。W3C  还推出了另外一种用于表示  Web  本体的语言  RDF  Schema（简称  RDFS）。
目前基于向量的知识表示开始流行，这类表示将知识图谱三元组中的主谓宾表示成数值向

量，通过向量的知识表示，可以采用统计或者神经网络的方法进行推理，对知识图谱中的

实体直接的关系进行预测。本章将对知识表示的常见方法进行介绍，并且讨论如何用这些

知识表示方法对知识进行建模。

2.1 什么是知识表示

20世纪90年代，MIT AI实验室的R.Davis定义了知识表示的五大用途或特点：
●客观事物的机器标示（A KR is a Surrogate），即知识表示首先需要定义客观实体的

机器指代或指称。

●一组本体约定和概念模型（A  KR  is  a  Set  of  Ontological  Commitments），即知识表

示还需要定义用于(cid:6655)述客观事物的概念和类别体系。

●支持推理的表示基础（A KR is a Theory of Intelligent Reasoning），即知识表示还需

要(cid:6656)供机器推理的模型与方法。

●用于高效计算的数据结构（A KR is a medium for Efficient Computation），即知识表

示也是一种用于高效计算的数据结构。

●人可理解的机器语言（A  KR  is  a  Medium  of  Human  Expression），即知识表示还必

须接近于人的认知，是人可理解的机器语言。

有关知识表示的研究可以追溯到人工智能的早期研究。例如，认知科学家  M.Ross

Quillian和Allan  M.Collins(cid:6656)出了语义网络的知识表示方法[2-3]，以网络的方式(cid:6655)述概念之
间的语义关系。典型的语义网络如WordNet属于词典类的知识库，主要定义名词、动词、
形容词和副词之间的语义关系。20世纪70年代，随着专家系统的(cid:6656)出和商业化发展，知识
库构建和知识表示更加得到重视。传统的专家系统通常包含知识库和推理引擎（Inference
Engine）两个核心模块。

无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化

的语义定义。为了解决这一问题，人们开始研究具有较好的理论模型基础和算法复杂度的

知识表示框架。比较有代表性的是(cid:6655)述逻辑语言（Description  Logic）[4]。(cid:6655)述逻辑是目
前大多数本体语言（如  OWL）的理论基础。第一个(cid:6655)述逻辑语言是1985年由  Ronald

J.Brachman等(cid:6656)出的KL-ONE[5]。(cid:6655)述逻辑主要用于刻画概念（Concepts）、属性
（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑(cid:6655)述
Logic  Statement）等知识表达要素。与传统专家系统的知识表示语言不同，(cid:6655)述逻辑家族
更关心知识表示能力和推理计算复杂性之间的关系，并深入研究了各种表达构件的组合带

来的查询、分类、一致性检测等推理计算的计算复杂度问题。

语义网的基础数据模型  RDF  受到了元数据模型、框架系统和面向对象语言等多方面
的影响，其最初是为人们在  Web  上发布结构化数据(cid:6656)供一个标准的数据(cid:6655)述框架。与此

同时，语义网进一步吸收(cid:6655)述逻辑的研究成果，发展出了用  OWL 系列标准化本体语言。
现代知识图谱如 DBpedia、Yago、Freebase、Schema.ORG、Wikidata 等大多以语义网的表
达模型为基础进行扩展或删减。

无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于

以符号逻辑为基础的知识表示方法。符号知识表示的特点是易于刻画显式、离散的知识，

因而具有内生的可解释性。但由于人类知识还包含大量不易于符号化的隐性知识，完全基

于符号逻辑的知识表示通常由于知识的不完备而失去鲁棒性，特别是推理很难达到实用。

由此催生了采用连续向量的方式来表示知识的研究。

基于向量的方式表示知识的研究由来已有。随着表示学习的发展，以及自然语言处理

领域词向量等嵌入（Embedding）技术手段的出现，启发了人们用类似于词向量的低维稠
密向量的方式表示知识。通过嵌入将知识图谱中的实体和关系投射到一个低维的连续向量

空间，可以为每一个实体和关系学习出一个低维度的向量表示。这种基于连续向量的知识

表示可以实现通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜

在假设，这些隐式知识通常是人的主观不易于观察和总结出来的。更为重要的是，知识图

谱嵌入也通常作为一种类型的先验知识辅助输入很多深度神经网络模型中，用来约束和监

督神经网络的训练过程。如图2-1所示为基于离散符号的知识表示与基于连续向量的知识
表示对比。

图2-1 基于离散符号的知识表示与基于连续向量的知识表示对比

综上所述，与传统人工智能相比，知识图谱时代的知识表示方法已经发生了很大的变

化。一方面，现代知识图谱受到规模化扩展的影响，通常采用以三元组为基础的较为简单

实用的知识表示方法，并弱化了对强逻辑表示的要求；另一方面，由于知识图谱是很多搜

索、问答和大数据分析系统的重要数据基础，基于向量的知识图谱表示使得这些数据更易

于和深度学习模型集成，使得基于向量的知识图谱表示越来越受到重视。

由于知识表示涉及大量传统人工智能的内容，并有其明确、严格的内涵及外延定义，

为避免混淆，在本书中主要侧重于知识图谱的表示方法的介绍，因此用“知识表示”和“知
识图谱的表示方法”加以了区分。

2.2 人工智能早期的知识表示方法

知识是智能的基础。人类智能往往依赖有意或无意运用已知的知识。与此类似，人工

智能系统需要获取并运用知识。这里有两个核心问题：怎么表示知识？怎样在计算机中高

效地存储与处理知识？本章主要阐述第一个核心问题。

2.2.1 一阶谓词逻辑

一阶谓词逻辑（或简称一阶逻辑）（First Order Logic）是公理系统的标准形式逻辑。
不同于命题逻辑（Propositional 
Logic），一阶逻辑支持量词（Quantifier）和谓词
（Predicate）。例如，在命题逻辑里，以下两个句子是不相关的命题：“John  MaCarthy  是
图灵奖得主”（p）、“Tim Berners-Lee是图灵奖得主”（q）。

但是，在一阶逻辑里，可以用谓词和变量表示知识，例如，图灵奖得主（x）表示  x
是图灵奖得主。这里，图灵奖得主是一元谓词（Predicate）,x  是变量（Variable），图灵
奖得主（x）是一个原子公式（Atomic  Formula）。Ø  图灵奖得主（x）是一个否定公式
（Negated  Formula）。在上面的例子中，若x为John  MaCarthy，图灵奖得主（x）为第一
个命题p。若x为Tim Berners-Lee，图灵奖得主（x）为第二个命题q。

1.一阶谓词逻辑优点
●结构性。能把事物的属性以及事物间的各种语义联想显式地表示出来。
●严密性。有形式化的语法和语义，以及相关的推理规则。
●可实现性。可以转换为计算机内部形式，以便用算法实现。
2.一阶谓词逻辑缺点
●有限的可用性。一阶逻辑的逻辑归结只是半可判定性的。
●无法表示不确定性知识。

2.2.2 霍恩子句和霍恩逻辑

霍恩子句（Horn  Clause）得名于逻辑学家  Alfred  Horn[6]。一个子句是文字的析取。

霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的
文字。例如，Øp1∨…∨Øpn∨ q 是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→

q。Alfred Horn于1951年撰文指出这种子句的重要性。

霍恩逻辑（Horn  Logic）是一阶逻辑的子集。基于霍恩逻辑的知识库是一个霍恩规则
的集合。一个霍恩规则由原子公式构成：B1∧…∧  Bn→  H，其中  H  是头原子公式，  B1,

…,Bn是体原子公式。事实是霍恩规则的特例，它们是没有体原子公式且没有变量的霍恩

Berners-Lee）是一个事实，可以简写为图灵奖得主

规则。例如，→图灵奖得主（Tim 
（Tim Berners-Lee）。
1.霍恩逻辑的优点
●结构性。能把事物的属性以及事物间的各种语义联想显式地表示出来。
●严密性。有形式化的语法和语义，以及相关的推理规则。
●易实现性。可判定，可以转换为计算机内部形式，以便用算法实现。
2.霍恩逻辑的缺点
●有限的表达能力。不能定义类表达式，不能够任意使用量化。
●无法表示不确定性知识。

2.2.3 语义网络

语义网络是由  Quillian  等人(cid:6656)出用于表达人类的语义知识并且支持推理[3]。语义网络

又称联想网络，它在形式上是一个带标识的有向图。图中“节点”用以表示各种事物、概
念、情况、状态等。每个节点可以带有若干属性。节点与节点间的“连接弧”（称为联想
弧）用以表示各种语义联系、动作。语义网络的单元是三元组：（节点1，联想弧，节点
2）。例如（Tim  Berners-Lee，类型，图灵奖得主）和（Tim  Berners-Lee，发明，互联
网）是三元组。由于所有的节点均通过联想弧彼此相连，语义网络可以通过图上的操作进

行知识推理。

1.语义网络的优点
1）联想性。它最初是作为人类联想记忆模型(cid:6656)出来的。
2）易用性。直观地把事物的属性及其语义联系表示出来，便于理解，自然语言与语
义网络的转换比较容易实现，故语义网络表示法在自然语言理解系统中的应用最为广泛。

3）结构性。语义网络是一种结构化的知识表示方法，对数据子图特别有效。它能把

事物的属性以及事物间的各种语义联想显式地表示出来。

2.语义网络的缺点
1）无形式化语法。语义网络表示知识的手段多种多样，虽然灵活性很高，但同时也
由于表示形式的不一致(cid:6656)高了对其处理的复杂性。例如，“每个学生都读过一本书”可以表
示为多种不同的语义网络，例如图2-2和图2-3中的语义网络。在图2-2中，GS表示一个概

念节点，指的是具有全称量化的一般事件，g  是一个实例节点，代表  GS  中的一个具体例
子，而  s  是一个全称变量，是学生这个概念的一个个体，r  和  b  都是存在变量，其中r  是
读这个概念的一个个体，b  是书这个概念的一个个体，F  指  g  覆盖的子空间及其具体形
式，而∀代表全称量词。而图2-3则把“每个学生都读过一本书”表示成：任何一个学生s1都

是属于读过一本书这个概念的元素。

图2-3 表示“每个学生都读过一本书”的语义网络

2）无形式化语义。与一阶谓词逻辑相比，语义网络没有公认的形式表示体系。一个
给定的语义网络表达的含义完全依赖处理程序如何对它进行解释。通过推理网络而实现的

推理不能保证其正确性。此外，目前采用量词（包括全称量词和存在量词）的语义网络表

示法在逻辑上是不充分的，不能保证不存在二义性。

2.2.4 框架

框架（Frame）最早由Marvin  Minsky在1975年(cid:6656)出[7]，目标是更好地理解视觉推理和
自然语言处理。其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类

似于框架的结构存储在记忆中。当面临一个新事物时，就从记忆中找出一个合适的框架，

并根据实际情况对其细节加以修改、补充，从而形成对当前事物的认识。

框架是一种(cid:6655)述对象（事物、事件或概念等）属性的数据结构。在框架理论中，类是

知识表示的基本单位。每个类有一些槽，每个槽又可分为若干“侧面”。一个槽用于表示(cid:6655)
述对象的一个属性，而一个侧面用语表示槽属性的一个方面，槽和侧面都可以有属性值，

分别称为槽值和侧面值。除此之外，框架还允许给属性设默认值，以及设立触发器以维护

框架。

1）下面是框架的基本组成的一个示例：

2）表2-1给出一个带变量框架实例。
如果把框架“tx  未遂杀人案”的变量赋值，可以得到下面的一个框架实例，如表2-2所

示。

表2-1 带变量框架实例

表2-2 变量赋值框架实例

1.框架的优点
1）结构性：能把事物的属性以及事物间的各种语义联想显式地表示出来。
2）框架对于知识的(cid:6655)述比较全面，支持默认值以及触发器。
2.框架的缺点
1）框架的构建成本非常高，对知识库的质量要求非常高。
2）默认值会增大推理的复杂度。
3）无法表示不确定性知识。

2.2.5 (cid:6655)述逻辑

(cid:6655)述逻辑是一阶逻辑的一个可判定子集。最初由Ronald  J.Brachman在1985年(cid:6656)出。(cid:6655)
述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。(cid:6655)述逻辑一般

支持一元谓词和二元谓词。一元谓词称为类，二元谓词称为关系。(cid:6655)述逻辑的重要特征是

同时具有很强的表达能力和可判定性。(cid:6655)述逻辑近年来受到广泛关注，被选为  W3C  互联
网本体语言（OWL）的理论基础。

1.(cid:6655)述逻辑的优点
1）结构性。能把事物的属性以及事物间的各种语义联想显式地表示出来。
2）严密性。有形式化的语法和语义，以及相关的推理规则。
3）多样性。具有大量可判定的扩展，以满足不同应用场景的需求。
4）易实现性。可判定，可以转换为计算机内部形式，以便用算法实现。
2.(cid:6655)述逻辑的缺点
1）有限的表达能力。不支持显式使用变量，不能够任意使用量化。
2）无法表示不确定性知识。

2.3 互联网时代的语义网知识表示框架

随着语义网的(cid:6656)出，知识表示迎来了新的契机和挑战，契机在于语义网为知识表示(cid:6656)

供了一个很好的应用场景，挑战在于面向语义网的知识表示需要(cid:6656)供一套标准语言可以用

来(cid:6655)述Web的各种信息。早期Web的标准语言HTML和XML无法适应语义网对知识表示的
要求，所以W3C(cid:6656)出了新的标准语言RDF、RDFS和OWL。这两种语言的语法可以跟
XML兼容。下面详细介绍这几种语言。

2.3.1 RDF和RDFS

RDF是W3C的RDF工作组制定的关于知识图谱的国际标准。RDF是W3C一系列语义

网标准的核心，如图2-4所示。

●表示组（Representation）包括URI/IRI、XML和RDF。前两者主要是为RDF(cid:6656)供语

法基础。

●推理组（Reasoning）包括RDF-S、本体OWL、规则RIF和统一逻辑。统一逻辑目前

还没有定论。

●信任组和用户互动组。
图2-4对W3C的语义网标准栈做了分组。目前，跟知识图谱最相关的有：

图2-4 W3C的语义网标准栈及其分组

2006年，人们开始用  RDF  发布和链接数据，从而生成知识图谱，比较知名的有
DBpedia、Yago和Freebase。2009年，Tim  Berners-Lee为进一步推动语义网开放数据的发
展，进一步(cid:6656)出了开放链接数据的五星级原则，如表2-3所示。

表2-3 开放链接数据的五星级原则

Tim Berners-Lee(cid:6656)出了实现五星级原则的四个步骤：
●使用URIs对事物命名；
●使用HTTP URIs，以方便搜索；
●使用RDF (cid:6655)述事物并(cid:6656)供SPARQL端点，以方便对RDF图谱查询；
●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。
2007年，不少开放图谱实现与DBpedia链接。如图2-5为开放链接数据早期的发展。

图2-5 开放链接数据早期的发展

1.RDF简介
在  RDF  中，知识总是以三元组的形式出现。每一份知识可以被分解为如下形式：
(subject,predicate,object)。例如，“IBM邀请Jeff  Pan作为讲者，演讲主题是知识图谱”可以
写成以下  RDF  三元组：（IBM-Talk,speaker,Jeff）,（IBM-Talk,theme,KG）。RDF  中的主

语是一个个体（Individual），个体是类的实例。RDF  中的谓语是一个属性。属性可以连
接两个个体，或者连接一个个体和一个数据类型的实例。换言之，RDF  中的宾语可以是
一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-
Talk,talkDate,“05-10-2012”^xsd:date）。

如果把三元组的主语和宾语看成图的节点，三元组的谓语看成边，那么一个  RDF  知

识库则可以被看成一个图或一个知识图谱，如图2-6所示。三元组则是图的单元。

在  RDF  中，三元组中的主谓宾都有一个全局标识  URI，包括以上例子中的  Jeff、

IBM_Talk 和KG，如图2-7所示。

图2-6 一个RDF知识库可以被看成一个图

图2-7 三元组的全局标识URI

全局标识 URI 可以被简化成前缀 URI，如图2-8所示。RDF 允许没有全局标识的空白
节点（Blank Node）。空白节点的前缀为“_”。例如，Jeff 是(cid:7680)一次关于 KG 讲座的讲者，
如图2-9所示。

图2-8 前缀URI

图2-9 没有全局标识的空白节点

RDF  是抽象的数据模型，支持不同的序列化格式，例如  RDF/XML、Turtle  和  N-

Triple，如图2-10所示。

图2-10 不同的序列化格式

2.开放世界假设
不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。也就是说，RDF
的开放性特点和要求。（IBM-
图谱里的知识有可能是不完备的，这符合 
Web 
讲座只有一位讲者。换一个角度，（IBM-
Talk,speaker,Jeff）并不意味着 
Talk,speaker,Jeff）意味着 IBM 讲座至少有一位讲者。采用开放世界假设意味着 RDF 图谱
可以被分布式储存，如图2-11所示。

IBM 

图2-11 RDF图谱可以被分布式储存

同时，分布式定义的知识可以自动合并，如图2-12所示。

图2-12 分布式定义的知识可以自动合并3.RDFS 简介

RDF  用到了类以及属性(cid:6655)述个体之间的关系。这些类和属性由模式（schema）定
义。RDF  Schema（RDF  模式，简称  RDFS）(cid:6656)供了对类和属性的简单(cid:6655)述，从而给  RDF
数据(cid:6656)供词汇建模的语言。更丰富的定义则需要用到OWL本体(cid:6655)述语言。

RDFS(cid:6656)供了最基本的对类和属性的(cid:6655)述元语：
●rdf:type ：用于指定个体的类；
●rdfs:subClassOf：用于指定类的父类；
●rdfs:subPropertyOf：用于指定属性的父属性；
●rdfs:domain：用于指定属性的定义域；
●rdfs:range：用于指定属性的值域。
举例来说，下面的三元组表示用户自定义的元数据  Author  是  Dublin  Core  的元数据

Creator的子类，如图2-13所示。

RDF  Schema  通过这样的方式(cid:6655)述不同词汇集的元数据之间的关系，从而为网络上统
一格式的元数据交换打下基础。下面用图2-14说明 
RDFS，为了简便，边的标签省略了
RDF  或者  RDFS。知识被分为两类，一类是数据层面的知识，例如  haofen  type  Person
（haofen  是  Person  类的一个实例），另外一类是模式层面的知识，例如  speaker  domain
Person（speaker属性的定义域是Person类）。

图2-13 Author是Creator的子类

图2-14 RDFS示例

2.3.2 OWL和OWL2 Fragments

前面介绍了RDF和RDFS，通过RDF（S）可以表示一些简单的语义，但在更复杂的场

景下，RDF（S）语义的表达能力显得太弱，还缺少常用的特征：

（1）对于局部值域的属性定义。RDF（S）中通过rdfs:range定义了属性的值域，该

值域是全局性的，无法说明该属性应用于(cid:7680)些具体的类时具有的特殊值域限制，如无法声

明父母至少有一个孩子。

（2）类、属性、个体的等价性。RDF（S）中无法声明两个类或多个类、属性和个

体是等价还是不等价，如无法声明Tim-Berns Lee和T.B.Lee是同一个人。

（3）不相交类的定义。在  RDF（S）中只能声明子类关系，如男人和女人都是人的

子类，但无法声明这两个类是不相交的。

（4）基数约束。即对(cid:7680)属性值可能或必需的取值范围进行约束，如说明一个人有双

亲（包括两个人），一门课至少有一名教师等。

（5）关于属性特性的(cid:6655)述。即声明属性的(cid:7680)些特性，如传递性、函数性、对称性，

以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。

为了得到一个表达能力更强的本体语言，W3C (cid:6656)出了 OWL 语言扩展 RDF（S），作
为在语义网上表示本体的推荐语言。W3C  于2002年7月31日发布了  OWL  Web  本体语言
（OWL Web Ontology Language）工作草案的细节，是为了更好地开发语义网。

1.OWL的语言特征
如图2-15所示，OWL1.0有 OWL Lite、OWL DL、OWL Full 三个子语言，三个子语言

的特征和使用限制举例如表2-4所示。

图2-15 OWL 1.0的主要子语言

表2-4 三个子语言的特征和使用限制举例

可以采用以下原则选择这些语言：

●选择OWL  Lite还是OWL  DL主要取决于用户需要整个语言在多大程度上给出约束的

可表达性；

●选择OWL  DL还是OWL  Full主要取决于用户在多大程度上需要RDF的元模型机制，

如定义类型的类型以及为类型赋予属性；

●当使用OWL  Full而不是OWL  DL时，推理的支持可能不能工作，因为目前还没有完

全支持OWL Full的系统实现。

OWL  的子语言与  RDF  有以下关系。首先，OWL  Full  可以看成是  RDF  的扩展；其
次，OWL Lite 和 OWL Full 可以看成是一个约束化的 RDF 的扩展；再次，所有的 OWL文
Full文档；最
档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL 
后，只有一些RDF文档是一个合法的OWL Lite和OWL DL文档。

2.OWL的重要词汇
（1）等价性声明。声明两个类、属性和实例是等价的。如：
exp：运动员 owl:equivalentClass exp：体育选手
exp：获得 owl:equivalentProperty exp：取得
exp：运动员A owl:sameIndividualAs exp：小明
以上三个三元组分别声明了两个类、两个属性以及两个个体是等价的，exp  是命名空
间  http://www.example.org  的别称，命名空间是唯一识别的一套名字，用来避免名字冲
突，在OWL中可以是一个URL。

（2）属性传递性声明。声明一个属性是传递关系。例如，exp:ancestor 

rdf:type
owl:TransitiveProperty  指的是  exp:ancestor  是一个传递关系。如果一个属性被声明为传
递，则由  a  exp:ancestor  b  和  b  exp:ancestor  c  可以推出  a  exp:ancestor  c。例如  exp：小明
exp:ancestor  exp：小林；exp：小林  exp:ancestor  exp：小志，根据上述声明，可以推出
exp：小明exp:ancestor exp：小志。

（3）属性互逆声明。声明两个属性有互逆的关系。例如，exp:ancestor  owl:inverseOf
exp:descendant  指的是  exp:ancestor  和  exp:descendant  是互逆的。如果  exp：小明

exp:ancestor exp：小林，根据上述声明，可以推出exp：小林 exp:descendant exp：小明。

（4）属性的函数性声明。声明一个属性是函数。例如，exp:hasMother 

rdf:type

owl:FunctionalProperty指的是exp:hasMother是一个函数，即一个生物只能有一个母亲。

（5）属性的对称性声明。声明一个属性是对称的。例如 

rdf:type
owl:SymmetricProperty  指的是  exp:friend  是一个具有对称性的属性；如果  exp：小明
exp:friend exp：小林，根据上述声明，有exp：小林 exp:friend exp：小明。

exp:friend 

（6）属性的全称限定声明。声明一个属性是全称限定。如：

exp:Person owl:allValuesFrom exp:Women

exp:Person owl:onProperty exp:hasMother
这个说明  exp:hasMother  在主语属于  exp:Person  类的条件下，宾语的取值只能来自

exp:Women类。

（7）属性的存在限定声明。声明一个属性是存在限定。如：

exp:SemanticWebPaper owl:someValuesFrom exp:AAAI

exp:SemanticWebPaper owl:onProperty exp:publishedIn
这个说明exp:publishedIn在主语属于exp:SemanticWebPaper类的条件下，宾语的取值
部分来自exp:AAAI类。上面的三元组相当于：关于语义网的论文部分发表在AAAI上。

（8）属性的基数限定声明。声明一个属性的基数。如：

exp:Person owl:cardinality “1”^^xsd:integer

exp:Person owl:onProperty exp:hasMother
指的是  exp:hasMother  在主语属于  exp:Person  类的条件下，宾语的取值只能有一

个，“1”的数据类型被声明为xsd:integer，这是基数约束，本质上属于属性的局部约束。

（9）相交的类声明。声明一个类是等价于两个类相交。如：

exp:Mother owl:intersectionOf _tmp

_tmp rdf:type rdfs:Collection

_tmp rdfs:member exp:Person

_tmp rdfs:member exp:HasChildren
指_tmp  是临时资源，它是 

exp:Person  和 
exp:HasChildren两个类的交集。

exp:HasChildren。上述三元组说明 

rdfs:Collection  类型，是一个容器，它的两个成员是
exp:Person  和
exp:Mother  是 

此外，OWL还有如表2-5所示词汇扩展。

表2-5 OWL词汇扩展

3.OWL版本
目前，OWL2  是OWL的最新版本，老的OWL版本也被称为OWL1。OWL2定义了一
些 OWL 的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不
同的应用。OWL2的三大子语言是OWL 2 RL、OWL 2 QL和OWL 2 EL。

OWL  2  QL是OWL2子语言中最为简单的，QL代表Query  Language，所以OWL  2  QL

是专为基于本体的查询设计的。它的查询复杂度是  AC0，非常适合大规模处理。它是基
于(cid:6655)述逻辑DL-Lite定义的。表2-6给出了OWL 2 QL词汇总结。

表2-6 OWL 2 QL词汇总结

另外一个能够(cid:6656)供多项式推理的OWL是OWL 2 EL。与OWL 2 QL不同，OWL 2 EL专
为概念术语(cid:6655)述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本

体SNOMED  CT。OWL  2  EL的分类复杂度是Ptime-Complete，它是基于(cid:6655)述逻辑语言
EL++定义的。表2-7给出了OWL 2 QL词汇总结。

表2-7 OWL 2 QL词汇总结

例如，OWL 2 EL 允许表达如下复杂的概念：
Female ⊓ ∃likes.Movie ⊓ ∃hasSon.(Student ⊓ ∃attends.CSCourse)
指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。

下面给出一个例子。假设有一个本体，包含以下公理：

公理1.Apple ⊑ ∃beInvestedBy.(Fidelity ⊓BlackStone)：苹果由富达和黑石投资。
公理2.∃beFundedBy.Fidelity ⊑ InnovativeCompanies：借助富达融资的公司都是创新企

业。

公理3.∃beFundedBy.BlackStone  ⊑  InnovativeCompanies：借助黑石融资的公司都是创

新企业。

公理4.beInvestedBy ⊑ beFundedBy：投资即是帮助融资。
由公理1可以推出公理5:Apple  ⊑  ∃beInvestedBy.Fidelity；由公理5和公理4可以推出公
⊑

⊑  ∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple 

理6:Apple 
InnovativeCompanies。

还有一个推理复杂度是多项式时间的OWL2子语言叫OWL  2  RL。OWL  2  RL扩展了
RDFS  的表达能力，在  RDFS  的基础上引入属性的特殊特性（函数性、互反性和对称
性），允许声明等价性，允许属性的局部约束。OWL 2 RL 的推理是一种前向链推理，即
将推理规则应用到OWL  2  RL本体，得到新的知识，即OWL  2  RL推理是针对实例数据的
推理。下面给出两个OWL 2 RL上的推理规则：

p rdfs:domain x,　 spo　　⇒　s rdf:type x
p rdfs:range x,　　spo　　⇒　o rdf:type x
其中，s、p、o、x 为变量。第一条规则表示如果属性 p 的定义域是类 x，而且实例 s
和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。第二条规
则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。例
如exp:hasChild rdfs:domain exp:Person, exp:Helen exp:hasChild exp:Jack，由第一条规则可以
推出 exp:Helen rdf:type exp:Person。OWL 2 RL允许的核心词汇有：

●rdfs:subClassOf；
●rdfs:subPropertyOf；
●rdfs:domain；
●rdfs:range；
●owl:TransitiveProperty；
●owl:FunctionalProperty；
●owl:sameAs；
●owl:equivalentClass；

●owl:equivalentProperty；
●owl:someValuesFrom；
●owl:allValuesFrom。
OWL  2  RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理

得到的结果。

2.3.3 知识图谱查询语言的表示

RDF 支持类似数据库的查询语言，叫作  SPARQL[1]，它(cid:6656)供了查询 RDF 数据的标准

语法、处理SPARQL查询的规则以及结果返回形式。

1.SPARQL知识图谱查询基本构成
●变量，RDF中的资源，以“?”或者“$”指示；
●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三

元组中允许存在变量；

●SELECT子句中指示要查询的目标变量。
下面是一个简单的SPARQL查询例子：

这个 SPARQL 查询指的是查询所有选修 CS328课程的学生，PREFIX 部分进行命名空

间的声明，使得下面查询的书写更为简洁。

2.常见的SPARQL查询算子
（1）OPTIONAL。可选算子，指的是在这个算子覆盖范围的查询语句是可选的。例

如：

指的是查询所有选修  CS328课程的学生姓名，以及他们的邮箱。OPTIONAL  关键字

指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。

（2）FILTER。过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结

果。例如：

指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25

岁。

（3）UNION。并算子，指的是将两个查询的结果合并起来。例如：

指的是查询选修课程CS328或CS909的学生姓名以及邮件。注意，这里的邮件是必须
返回的，如果没有邮件值，则不返回这条记录。需要注意UNION和OPTIONAL的区别。

下面给出一个SPARQL查询的例子。给定一个RDF数据集：

以及一个SPARQL查询：

这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。

表2-8 查询结果

给定论文一个SPARQL查询：

这个查询期望查询所有具备关联交易的公司。假设有下面两条规则：

hold_share（X, Y）:- control（X, Y）
conn_trans（Y,Z）:- hold_share（X, Y）, hold_share（X, Z）
第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股

Y和Z，那么Y和Z具备关联交易。通过查询重写技术，可以得到下面的SPARQL查询：

但是这个查询比较复杂，可以通过下面的SPARQL查询简化：

在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。

2.3.4 语义Markup表示语言

语义网进一步定义了在网页中嵌入语义  Markup  的方法和表示语言。被谷歌知识图谱
以及  Schema.Org  采用的语义  Markup  语言主要包括  JSON-LD、RDFa  和  HTML5
MicroData。

1.JSON-LD
JSON-LD（JavaScript Object Notation for Linked Data）是一种基于JSON表示和传输链
接数据的方法。JSON-LD  (cid:6655)述了如何通过  JSON  表示有向图，以及如何在一个文档中混
合表示链接数据及非链接数据。JSON-LD  的语法和  JSON  兼容。JSON-LD  处理算法和
API（JSON-LD Processing Algorithms and API）(cid:6655)述了处理JSON-LD数据所需的算法及编
程接口，通过这些接口可以在 JavaScript、Python 及 Ruby 等编程环境中直接对  JSON-LD
文档进行转换和处理。

下面是一个简单的JSON例子：

JSON 

文档表示一个人。人们很容易推断这里的含义：“name”是人的名
字，“homepage”是其主页，“image”是其(cid:7680)种照片。当然，机器不理解“name”和“image”这
样的术语。JSON-LD 
通过引入规范的术语表示，例如统一化表
示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。如下所
示：

可以看出，JSON-LD  呈现出语义网技术的风格，它们有着类似的目标：围绕(cid:7680)类知

识(cid:6656)供共享的术语。例如，每个数据集不应该围绕“name”重复发明概念。但是，JSON-
LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad 
单、不复杂以及面向一般开发人员的方式推进。

Stores），而是以简

2.RDFa
RDFa（Resource Description Framework in attributes）是一种早期网页语义标记语言。
RDFa  也是  W3C  推荐标准。它扩充了  XHTML  的几个属性，网页制作者可以利用这些属
性在网页中添加可供机器读取的资源。与RDF的对应关系使得RDFa可以将RDF的三元组
嵌入在 XHTML 文档中，它也使得符合标准的使用端可以从 RDFa 文件中(cid:6656)取出这些RDF
三元组。

RDFa  通过引入名字空间的方法，在已有的标签中加入  RDFa  相应的属性，以便解析

支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。

上面的代码示例中用到了RDFa 属性中的 about属性和 property属性。这段代码示例说
明了一篇文章，然后(cid:6655)述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可

以让支持  RDFa  的机器识别这些属性。RDFa  可以从机器可理解的层面优化搜索，(cid:6656)升访
问体验以及网页数据的关联。

3.HTML5 Microdata
Microdata（微数据）是在网页标记语言中嵌入机器可读的属性数据。微数据使用自

定义词汇表、带作用域的键值对给 DOM 做标记，用户可以自定义微数据词汇表，在自己
的网页中嵌入自定义的属性。微数据是给那些已经在页面上可见的数据施加额外的语义，

当HTML的词汇不够用时，使用微数据可以取得较好的效果。下面是一个HTML5
Microdata的示例。

这个例子给出了Person类下一个叫Andy的人的照片和URL地址。
通过 HTML5 Microdata，浏览器可以很方便地从网页上(cid:6656)取微数据实体、属性及属性

值。

2.4 常见开放域知识图谱的知识表示方法

不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。这些框架有不同

的(cid:6655)述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。这里以三个最典

型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱
项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。为便于比较分析，

以RDF、OWL的(cid:6655)述术语和表达能力为主要比较对象。

2.4.1 Freebase

Freebase  的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-
ID，称为  MID
Types和属性-Properties。“Object”代表实体。每一个“Object”有唯一的 
（Machine  ID）。一个“Object”可以有一个或多个“Types”。“Properties”用来(cid:6655)述“Facts”。
例如，“Barack  Obama”是一个  Object，并拥有一个唯一的  MID:“/m/02mjmr”。这个  Object
是“/government/us_president”，并有一个称
的一个 
为“/government/us_president/presidency_number”的Property，其数值是“44”。Freebase使用
复合值类型（Compound Value Types,CVT）处理多元关系。

type 

如图2-16所示，示例的 

CVT  (cid:6655)述了关于 

Obama  的任职期限的多元关

系“government_position_held”。这个多元关系包含多个子二元关
系：“office_holder”“office_position”“from”“to”等。一个CVT  就是有唯一  MID  的  Object，
也可以有多个Types。为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。

图2-16 Freebase的知识表示结构示例

2.4.2 Wikidata

Wikidata 

的知识表示框架主要包含如下要素：页面-Pages、实体-Entities、条目-
Items、属性-Properties、陈述-Statements、修饰-Qualifiers、引用-Reference  等。Wikidata
起源于Wikipedia，因此与 Wikipedia 一样，以页面“Page”为基本的组织单元。Entities 类似
于OWL:Things，代指最顶层的对象。每一个  Entity  都有一个独立的维基页面。Entities  主
要有两类：Items  和  Properties。Items  类似于  RDF  中的  Instance，代指实例对象。
Properties和Statements分别等价于RDF中的Property和Statement。通常一个Item的页面还包
含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。

每个  Entities  有多个  Statements。一个  Statement  包含一个  Property、一个或多个

Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。

修饰-Qualifiers用于处理复杂的多元表示。如一个陈述“spouse:  Jane  Belson”(cid:6655)述了一
个二元关系。可以使用  Qualifiers  给这个陈述增加多个附加信息来刻画多元关系，如“start
date: 25 November 1991” and “end date: 11 May 2011”等。

引用-References  用于标识每个陈述的来源或出处，如来源于(cid:7680)个维基百科页面等。

引用也是一种Qualifiers，通常添加到Statements的附加信息中。

Wikidata支持多种数值类型，包括其自有的Item类型、RDF  Literal、URL、媒体类型

Commons Media，以及Time、Globe coordinates和Quantity三种复杂类型。

Wikidata  允许给每个  Statement  增加三种权重：normal（缺省）、preferred  和

deprecated。

Wikidata  定义了三种  Snacks  作为  Statement  的具体(cid:6655)述结构：PropertyValueSnack、
PropertyNoValueSnack、PropertySomeValueSnack。PropertyNoValueSnack  类似于  OWL  中
的  Negation，表示类似于“Elizabeth 
spouse”的知识。
PropertySomeValueSnack  类似于  OWL  中的存在量词  someValuesFrom，表示类似于“Pope
Linus had a date of birth, but it is unknown to us”这样的知识。

of  England 

had 

no 

I 

Wikidata的URI机制遵循了Linked  Open  Data的URI原则，采用统一的URI机制：
Item，如  Q49，或者一个

http://www.wikidata.org/entity/<id>。其中，<id>可以是一个 
Property，如P234。

2.4.3 ConceptNet5

ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-
Phrases、断言-Assertions、关系-Relations、边-Edges。Concepts由Words或Phrases组成，构
成了图谱中的节点。与其他知识图谱的节点不同，这些  Concepts  通常是从自然语言文本
中(cid:6656)取出来的，更接近自然语言(cid:6655)述，而不是形式化的命名。Assertions  (cid:6655)述了Concepts
之间的关系，类似于RDF中的Statements。Edges类似于RDF中的Property。一个  Concepts
包含多条边，而一条边可能有多个产生来源。例如，一个“化妆 Cause 漂亮”的断言可能来
源于文本抽取，也可能来源于用户的手工输入。来源越多，该断言就越可靠。

ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。ConceptNet5示例如图2-
17所示。

ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如  IsA、UsedFor等，

以及从自然语言文本中抽取的更加接近自然语言(cid:6655)述的非形式化的关系，如 
of,caused by等。

on 

top

图2-17 ConceptNet5示例

ConceptNet5对  URI  进行了精心的设计。URI  同时考虑了类型（如是概念还是关

系）、语言、正则化后的概念名称、词性、歧义等因素。例如“run”是一个动词，但也可
能是一个名词（如  basement比赛中一个“run”），其  URI为：“/c/en/run/n/basement”。其
中，n代指这是一个名词，basement用于区分歧义。

在处理表示“x is the first argument of y”这类多元关系的问题上，ConceptNet5把所有关

于(cid:7680)条边的附加信息增加为边的属性，如图2-18所示。

图2-18 ConceptNet5的知识表示结构

2.5 知识图谱的向量表示方法

与前面所述的表示方法不同的是，本节要(cid:6655)述的方法是把知识图谱中的实体和关系映

射到低维连续的向量空间，而不是使用基于离散符号的表达方式。

2.5.1 知识图谱表示的挑战

在前面(cid:6656)到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行

组织。在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的

关系。虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大

规模应用上也面临着巨大的挑战。

知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层

面的信息，也不能进行语义计算，对下游的一些应用并不友好。在基于网络结构的知识图

谱上进行相关应用时，因为图结构的特殊性，应用算法的使用与图算法有关，相关算法具

有较高的复杂度，面对大规模的知识库很难扩展。

数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情

况，也就是(cid:7680)一个实体或关系具有极少的实例样本，这种现象会影响(cid:7680)些应用的准确率。

从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，

需要改进传统的表示方法。

2.5.2 词的向量表示方法

在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。在自然语言处

理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不

仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。知识图谱

中的向量表示方法也在此次有所借鉴。

1.独热编码
传统的独热编码（One-Hot  Encoding）方法是将一个词表示成一个很长的向量，该向
量的维度是整个词表的大小。对于(cid:7680)一个具体的词，在其独热表示的向量中，除了表示该

词编号的维度为1，其余都为0。如图2-19所示，假如词Rome的编号为1，则在其独热编码

中，仅有维度1是1，其余都是0。这种表示方法虽然简单，但是可以看出其并没有编码语

义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。

2.词袋模型
词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。该方法将文本想象

成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录

每个词在该文本（词袋）中出现的次数。具体的方法是先收集所有文本的可见词汇并组成

一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向

量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。如

图2-20所示，在文本doc_1中，Rome出现32次，Paris出现14次，France出现0次。

图2-19 独热编码示例1

图2-20 独热编码示例2

3.词向量
上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义

相似程度，(cid:6656)出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量

或词嵌入（Word Embedding）。产生词向量的手段主要有三种：

●Count-based。基于计数的方法，简单说就是记录文本中词的出现次数。
●Predictive。基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预

测上下文。

●Task-based。基于任务的，也就是通过任务驱动的方法。通过对词向量在具体任务

上的表现效果对词向量进行学习。

对词向量的产生方法到现在为止有较多的研究，在本章中并不展开讨论，下面简单介

绍经典的开源工具word2vec[8]中包含的CBoW和Skip-gram两个模型。

CBoW也就是连续词袋模型（Continuous  Bag-of-Words），和之前(cid:6656)到的BoW相似之
处在于该模型也不用考虑词序的信息。其主要思想是，用上下文预测中心词，从而训练出
的词向量包含了一定的上下文信息。如图2-21（a）所示，其中wn是中心词， 

wn−2,wn

−1,wn+1,wn+2为该中心词的上下文的词。将上下文词的独热表示与词向量矩阵E相乘，(cid:6656)取

相应的词向量并求和得到投影层，然后再经过一个 Softmax 层最终得到输出，输出的每一
维表达的就是词表中每个词作为该上下文的中心词的概率。整个模型在训练的过程就像是

一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。

Skip-gram  的思想与  CBoW  恰恰相反，其考虑用中心词来预测上下文词。如图2-21
（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，
然后经过一层 Softmax 得到输出，输出的每一维中代表(cid:7680)个词作为输入中心词的上下文出

现的概率。

图2-21 CBoW模型

在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所

示。

vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）

可以看出，Roma  和  Italy  之间有  is-capital-of的关系，而这种关系恰好也在Paris  和
France之间出现。通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜
想出  Roma  和  Italy  的词向量通过简单的相减运算，得到了一种类似  is-capital-of关系的连
续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。这也

说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。

图2-22 词向量在连续空间中的关系

上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系

（relation）、（Rome, is-capital-of, Italy）和（Paris, is-capital-of, France），可以看作是知
识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。

2.5.3 知识图谱嵌入的概念

为了解决前面(cid:6656)到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知

识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在

下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。对于计算机来

说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。把这种将知识图

谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入

（Knowledge 
Graph 
（Representation Learning）、知识表示学习。

Embedding）、知识图谱的向量表示、知识图谱的表示学习

类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编

码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。在训练的过

程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。类似

于词向量，经典的知识图谱嵌入模型TransE的设计思想就是，如果一个三元组（h, r, t）成

立，那么它们需要符合h+r ≈ t关系，例如：

vec（Rome）+vec（is−capital−of）≈vec（Italy）

所以，在知识图谱嵌入的学习过程中，不同的模型从不同的角度把相应的语义信息嵌

入知识图谱的向量表示中，如图2-23所示。

图2-23 语义信息嵌入知识图谱的向量表示中

2.5.4 知识图谱嵌入的优点

研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前

的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。

使用向量的表达方式可以(cid:6656)高应用时的计算效率，当把知识图谱的内容映射到向量空

间时，相应的算法可以使用数值计算，所以计算的效率也会同时(cid:6656)高。

增加了下游应用设计的多样性。用向量表示后，知识图谱将更加适用于当前流行的机

器学习算法，例如神经网络等方法。因为下游应用输入的并不再是符号，所以可以考虑的

方法也不会仅局限于图算法。

将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包

含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。

如上所述，知识图谱的嵌入方法可以(cid:6656)高计算的效率，增加下游应用的多样性，并可

以作为预训练，为下游模型(cid:6656)供语义支持，所以对其展开的研究具有很大的应用价值和前

景。

2.5.5 知识图谱嵌入的主要方法

多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，

也就是说，根据知识图谱中所有已知的三元组训练模型。对于这类方法，常常只需训练出

来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全

满足所有的下游任务。所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之

外的额外信息训练知识图谱嵌入。这些额外的信息包括实体类型（Entity  Types）、关系
路径（Relation Paths）等。

根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。

1.转移距离模型
转移距离模型（Translational Distance Model）的主要思想是将衡量向量化后的知识图
谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。这一方法的重点是如

何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函

数。

受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实

体和尾实体在向量空间的关系。也就是说，同样可以考虑把知识图谱中的头实体和尾实体

映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。TransE[12]便是受
到了词向量中平移不变性的启发，在  TransE  中，把实体和关系都表示为向量，对于(cid:7680)一
个具体的关系（head,  relation,  tail），把关系的向量表示解释成头实体的向量到尾实体的
向量的转移向量（Translation  vector）。也就是说，如果在一个知识图谱中，(cid:7680)一个三元
组成立，则它的实体和关系需要满足关系head+relation≈tail。

2.语义匹配模型
相比于转移距离模型，语义匹配模型（Semantic  Matching  Models），更注重挖掘向

量化后的实体和关系的潜在语义。该方向的模型主要是RESCAL[13]以及它的延伸模型。

RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出
一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中

每一行代表一个实体。由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，

如果概率大于(cid:7680)个阈值，则对应三元组正确；否则不正确。其得分函数可以写成

DistMul[14]通过限制Mr为对角矩阵简化 

RESCAL 

模型，也就是说其限制

Mr=diag（r）。但因为是对角矩阵，所以存在h⊺diag（r）t=t⊺diag（r）h，也就是说这种简

化的模型只天然地假设所有关系是对称的，显然这是不合理的。ComplEx[15]模型考虑到
复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在

了复数域，从而其得分函数不具有对称性。也就是说，对于非对称的关系，将三元组中的

头实体和尾实体调换位置后可以得到不同的分数。

3.考虑附加信息的模型
除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的

附加信息进行(cid:6656)升。

实体类型是一种容易考虑的额外信息。在知识库中，一般会给每个实体设定一定的类

别，例如Rome具有city的属性、Italy具有country的属性。最简单的考虑实体类型的方法是
在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如

（Rome,IsA,city）
（Italy,IsA,Country）

这样的三元组。当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考

虑到向量表示中。也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。

关系路径也可以称为实体之间的多跳关系（Multi-hop  Relationships），一般就是指可

以连接两个实体的关系链，例如

（Rome,is−capital−of,Italy）
（Italy,is−country−of,Europe）.

从  Rome  到  Europe  的关系路径就是一条is−capital−of→is−country−of关系链。当前很
多方法也尝试考虑关系路径来(cid:6656)升嵌入模型，这里的关键问题是考虑如何用相同的向量表

达方式来表达路径。在基于路径的  TransE，也就是  PTransE[17]中，考虑了相加、相乘和
RNN三种用关系表达关系路径的方法：

p=r1+r2+⋯+rl

p=r1∙r2∙⋯∙rl

ci=f（W[ci−1;ri]）.

在基于  RNN  的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。对于(cid:7680)

一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向
量表示相接近。

文本(cid:6655)述（Textual  Descriptions）指的是在一些知识图谱中，对实体有一些简要的文
本(cid:6655)述，如图2-24所示，这些(cid:6655)述本身具有一定的语义信息，对(cid:6656)高嵌入的质量有一定的
(cid:6656)升。除了(cid:7680)些知识库本身具有的文本(cid:6655)述，也可以使用外部的文本信息和语料库。

Wang[18](cid:6656)出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部
分：知识模型、文本模型和对齐模型。其中，知识模型对知识图谱中的实体和关系做嵌

入，这是一个  TransE的变种；文本模型对语料库中词语进行向量化，这是一个  Skip-gram
模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。

联合模型在训练时降低来自三个子模型的损失之和。

图2-24 文本(cid:6655)述示例

逻辑规则（Logical  Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍

恩子句，例如简单规则

∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）

说明了两个不同的关系之间的关系。Guo[19](cid:6656)出了一种以规则为指导的知识图谱嵌入
方法，其中(cid:6656)出的软规则（Soft  rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘
的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软

标签预测阶段（Soft  Label  Prediction）和嵌入修正阶段（Embedding  Rectification）。简单
来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一

定的规则信息。

2.5.6 知识图谱嵌入的应用

在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入

之间有着相辅相成的关系。本小节将简单介绍一些典型的应用。

1.链接预测
链接预测（Link  Prediction）指通过一个已知的实体和关系预测另一个实体，或者通
过两个实体预测关系。简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全
任务，被称为链接预测。

当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。例如需要链接

预测(Roma,  is-capital-of,  ?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且
放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得

分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。

链接预测也常被用于评测知识图谱嵌入。一般来说，会用链接预测的正确答案的排序

评估(cid:7680)种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean  Rank）、平
均倒数等级（Mean Reciprocal Rank）和命中前n（Hist@n）。

2.三元组分类
三元组分类（Triple  Classification）指的是给定一个完整的三元组，判断三元组的真
假。这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带

入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。

3.实体对齐
实体对齐（Entity  Resolution）也称为实体解析，任务是验证两个实体是否指代或者
引用的是同一个事物或对象。该任务可以删除同一个知识库中冗余的实体，也可以在知识

库融合的时候从异构的数据源中找到相同的实体。一种方法是，如果需要确定  x、y  两个
实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,  EqualTo,
y)打分，但这种方法的前(cid:6656)是需要在知识库中存在  EqualTo  关系。也有研究者(cid:6656)出完全根
据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程

度，再进行对齐。

4.问答系统
利用知识图谱完成问答系统是该任务的一个研究方向，该任务的重心是对(cid:7680)一个具体

的通过自然语言表达的问题，使用知识图谱中的三元组对其进行回答，如下：

A: Where is the capital of Italy？
Q: Rome（Rome, is-capital-of, Italy）
A: Who is the president of USA？

Q: Donald Trump（Donald Trump, is-president-of, USA）
文献[9]介绍了一种借助知识图谱嵌入完成该问题的方法。简单来说就是设计一种得

分函数，使问题的向量表示和其正确答案的向量表示得分较高。S（q,a）是被设计出来的
得分函数

S（q,a）=（Wφ（q））⊺（Wψ（a））.
式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向
量；ψ（a）为实体和关系出现的稀疏向量。简单来说，Wφ（q）和Wψ（a）可以分别表
示问题和答案的向量表示。当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高
的分数，反之亦然。

5.推荐系统
推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或

产品，包括电影、书籍、音乐、商品等。协同过滤算法（Collaborative  Filtering）对用户
和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。

在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息(cid:6656)高推荐系统的能

力。例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含
一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两

个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。

2.6 开源工具实践：基于Protégé的本体知识建模

2.6.1 简介

本节使用  Protégé演示如何进行知识建模。本实践相关工具、实验数据及操作说明由

OpenKG(cid:6656)供，地址为http://openkg.cn。Protégé软件是斯坦福大学医学院生物信息研究中
心基于  Java  语言开发的本体编辑和本体开发工具，也是基于知识的编辑器，属于开放源
代码软件。该软件主要用于语义网中本体的构建，是语义网中本体构建的核心开发工具，

本书采用的版本为5.2.0版本。Protégé有以下特点：

●Protégé是一组自由开源的工具软件，用于构建域模型与基于知识的本体化应用程

序。

●Protégé(cid:6656)供了大量的知识模型架构与动作，用于创建、可视化、操纵各种表现形式

的本体。

●可以通过用户定制实现域—友好（领域相关）的支持，用于创建知识模型并填充数

据。

●Protégé可以通过两种方式进行扩展：插件和基于Java的API。
●与其他的本体构建工具相比，Protégé最大的好处在于支持中文。
●在插件上，用Graphviz可实现中文关系的显示。
Protégé的常见用途包括：类建模、实例编辑、模型处理和模型交换。

2.6.2 环境准备

1.开发软件版本及其下载地址
Protege5.2.0的下载地址为https://protege.stanford.edu/。
2.环境的配置
在  Protégé的官方网站可以下载对应系统的  Protégé版本。本书以  Windows  平台下的

Protégé作为示范。

2.6.3 Protégé实践主要功能演示

1.建模类
Protégé的主页面中会出现 OWL Classes（OWL 类）、Properties（属性）、Forms（表

单）、Individuals（个体）、Metedata（元类）几个标签，如图2-25所示。选择 
OWL
Classes。在  Asserted  Hierarchy（添加阶层）中，会有所有类的超类  owl:Thing，单击
Asserted Hierarchy 旁边的【Create subclass】或者右击“OWL:Thing”选择“add subclass”。会
出现Protégé自动定义名为Class_1的类。在对话框中，【Name】一栏输入名字“Animal”。

图2-25 建模类

2.建立子类
右击“Animal”，选择“add  subclass”，将名字改为“Herbivore”（素食动物）。然后建立

OWL:Thing的另一个子类Plant（植物），最后建立Plant的子类Tree（树），如图2-26所
示。

图2-26 建立子类

3.建立属性
新建一个  Object  Property（注意不是  DataProperty），右击“Object  Properties”，选
择“add  sub-Properties”，输入  is_part_of，然后勾选“Transitive”复选框，说明这是一个传递
性属性。然后建立一个对象属性（owl:ObjectProperty）eat（吃），在  Domain（定义域）
中定义该属性的主体的类是Animal。最后建立一个属性eated（被吃），它是属性eat的逆
关系（owl:inverseOf），在Inverse Of中选择属性“eat”，如图2-27所示。

图2-27 建立属性

2.7 本章小结

本章比较全面地介绍了知识图谱的表示与建模方法。目前大部分开放知识图谱的表示

语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。除了这些标准语
言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。最后，介绍了知识图
谱的嵌入式方法。

