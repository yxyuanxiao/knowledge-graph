{"text": "第4章 知识抽取与知识挖掘王志春 北京师范大学，陈华钧 浙江大学，王昊奋 上海乐言信息科技有限公司知识抽取是构建大规模知识图谱的重要环节，而知识挖掘则是在已有知识图谱的基础上发现其隐藏的知识。"}
{"text": "知识抽取和知识挖掘对于知识图谱的构建及应用具有重要的意义。"}
{"text": "本章将首先介绍知识抽取的技术和方法，然后介绍知识内容挖掘和知识结构挖掘。"}
{"text": "4.1 知识抽取任务及相关竞赛4.1.1 知识抽取任务定义知识抽取是实现自动化构建大规模知识图谱的重要技术，其目的在于从不同来源、不同结构的数据中进行知识提取并存入知识图谱中。"}
{"text": "知识抽取的数据源可以是结构化数据（如链接数据、数据库）、半结构化数据（如网页中的表格、列表）或者非结构化数据（即纯文本数据）。"}
{"text": "面向不同类型的数据源，知识抽取涉及的关键技术和需要解决的技术难点有所不同。"}
{"text": "知识抽取的概念最早在20世纪70年代后期出现于  NLP  研究领域，是指自动化地从文本中发现和抽取相关信息，并将多个文本碎片中的信息进行合并，将非结构化数据转换为结构化数据，包括某一特定领域的模式、实体关系或 RDF 三元组。"}
{"text": "给定一段关于苹果公司的文字描述，知识抽取方法可以自动获取关于苹果公司的结构化信息，包括其总部地址、创始人以及创立时间。"}
{"text": "图4-1 知识抽取的典型例子具体地，知识抽取包括以下子任务：1.命名实体识别从文本中检测出命名实体，并将其分类到预定义的类别中，例如人物、组织、地点、时间等。"}
{"text": "2.关系抽取从文本中识别抽取实体及实体之间的关系。"}
{"text": "例如，从句子“[王思聪]是万达集团董事长[王健林]的独子”中识别出实体“[王健林]”和“[王思聪]”之间具有“父子”关系。"}
{"text": "3.事件抽取识别文本中关于事件的信息，并以结构化的形式呈现。"}
{"text": "例如，从恐怖袭击事件的新闻报道中识别袭击发生的地点、时间、袭击目标和受害人等信息。"}
{"text": "4.1.2 知识抽取相关竞赛一些重要的竞赛对知识抽取技术的发展起到了巨大的推动作用。"}
{"text": "这些竞赛一般与学术会议同时举办，在明确定义知识抽取相关任务的基础上，提供标准评测数据和评测指标，吸引了大量的参与者。"}
{"text": "本节将介绍知识抽取相关的重要竞赛。"}
{"text": "1.消息理解会议（Message Understanding Conference,MUC）MUC 由美国国防部高级研究计划局（DARPA）启动并资助，目的是鼓励和开发更好的信息抽取方法。"}
{"text": "1987—1998年，MUC  会议共举办了七届。"}
{"text": "MUC  不仅仅是学术会议，其更重要的是在于对信息抽取系统的评测。"}
{"text": "在每届 MUC  会议前，组织者向参加者提供消息文本的样例和信息抽取任务的说明；参加者开发参赛系统并提交系统的输出结果。"}
{"text": "各个系统的结果与标准结果比对后得到最终的评测结果，参与者最后在会议上交流技术和感受。"}
{"text": "在MUC的评测中，召回率（Recall）和精确率（Precision）是评价信息抽取系统性能的两个重要评价指标。"}
{"text": "召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。"}
{"text": "为了综合两个方面的因素考量系统的性能，通常基于召回率和准确率计算F1值。"}
{"text": "MUC  会议积极推动了命名实体识别和共指消解等技术的进步与发展。"}
{"text": "在  MUC  会议中，出现了一些F1值高达90%左右的系统，接近于人工标注的质量。"}
{"text": "MUC定义的一系列规范以及确立的评价体系也已经成为知识抽取领域的标准。"}
{"text": "2.自动内容抽取（Automatic Content Extraction,ACE）ACE是一项由美国国家标准技术研究所（NIST）组织的评测会议，该会议从1999年至2008年共举办了八次评测。"}
{"text": "ACE与MUC解决的问题类似，但是ACE对MUC定义的任务进行了融合、分类和细化。"}
{"text": "ACE  评测涉及英语、阿拉伯语和汉语三种语言，主要包括以下任务：（1）实体检测和跟踪。"}
{"text": "这是 ACE 最基础和核心的任务，该任务要求识别文本中的实体，实体类型包括人物（Person,PER）、组织（Organization,ORG）、设施（Facility,FAC）、地缘政治实体（Geographical Political Entity,GPE）和位置（Location,LOC）等。"}
{"text": "（2）关系检测与表征。"}
{"text": "该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。"}
{"text": "（3）事件检测与表征。"}
{"text": "该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。"}
{"text": "任务要求自动标注每个事件的文本提及或锚点，并按类型和子类型对其进行分类；最后，还需要根据类型特定的模板进一步确定事件参数和属性。"}
{"text": "3.知识库填充（Knowledge Base Population,KBP）KBP 评测由文本分析会议（Text Analysis Conference,TAC）主办，其目标是开发和评估从非结构化文本中获取知识填充知识库的技术。"}
{"text": "KBP  评测从2009年开始，每年举办一次，截至2017年，已经举办了九届。"}
{"text": "KBP  评测覆盖了知识库填充的独立子任务以及被称为“冷启动”的端到端知识库构建任务。"}
{"text": "独立子任务主要包括以下四个方面：（1）实体发现与链接（Entity  Discovery  and  Linking,EDL）。"}
{"text": "主要的EDL任务是在评估文档集合中提取特定个人（PER）、组织（ORG）、设施（FAC）、地缘政治实体（GPE）和位置（LOC）实体的名称和提及，并将每个提及链接到其对应的KB节点。"}
{"text": "（2）槽填充（Slot  Filling,SF）。"}
{"text": "插槽填充任务是搜索文档集合以填充特定实体的特定属性（“插槽”）值。"}
{"text": "（3）事件跟踪（Event  Track）。"}
{"text": "事件跟踪旨在从非结构化文本中提取关于事件的信息，使其作为结构化知识库的输入。"}
{"text": "该任务具体包括事件块（Event  Nugget）任务（检测和链接事件块）和事件参数（Event  Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。"}
{"text": "（4）信念和情感（Belief  and  Sentiment,BeSt）。"}
{"text": "信仰和情感跟踪检测实体对另一个实体、关系或事件的信念和情绪。"}
{"text": "端到端冷启动知识库构建任务基于给定的知识库模式（KB  schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。"}
{"text": "4.语义评测（Semantic Evaluation,SemEval）SemEval  是由  ACL-SIGLEX  组织的国际权威的词义消歧评测，目标是增进人们对词SenseEval，于1998年举办第一届。"}
{"text": "截至2017义与多义现象的理解。"}
{"text": "该评测前期被称为 年，已经成功举办了十一届。"}
{"text": "早期评测比较关注词义消歧问题，后来出现了更多文本语义理解的任务，包括语义角色标注、情感分析、跨语言语义分析等。"}
{"text": "4.2 面向非结构化数据的知识抽取大量的数据以非结构化数据（即自由文本）的形式存在，如新闻报道、科技文献和政府文件等，面向文本数据的知识抽取一直是广受关注的问题。"}
{"text": "在前文介绍的知识抽取领域的评测竞赛中，评测数据大多属于非结构化文本数据。"}
{"text": "本节将对这一类知识抽取技术和方法进行概要介绍，具体包括面向文本数据的实体抽取、关系抽取和事件抽取。"}
{"text": "4.2.1 实体抽取实体抽取又称命名实体识别，其目的是从文本中抽取实体信息元素，包括人名、组织机构名、地理位置、时间、日期、字符值和金额值等。"}
{"text": "实体抽取是解决很多自然语言处理问题的基础，也是知识抽取中最基本的任务。"}
{"text": "想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。"}
{"text": "例如，给定一段新闻报道中的句子“北京时间10月25日，骑士后来居上，在主场以119∶112击退公牛”。"}
{"text": "实体抽取旨在获取如图4-2所示的结果。"}
{"text": "例句中的“北京”“10月25日”分别为地点和时间类型的实体，而“骑士”和“公牛”均为组织实体。"}
{"text": "实体抽取问题的研究开展得比较早，该领域也积累了大量的方法。"}
{"text": "总体上，可以将已有的方法分为基于规则的方法、基于统计模型的方法和基于深度学习的方法。"}
{"text": "图4-2 实体抽取举例1.基于规则的方法早期的命名实体识别方法主要采用人工编写规则的方式进行实体抽取。"}
{"text": "这类方法首先构建大量的实体抽取规则，一般由具有一定领域知识的专家手工构建。"}
{"text": "然后，将规则与文本字符串进行匹配，识别命名实体。"}
{"text": "这种实体抽取方式在小数据集上可以达到很高的准确率和召回率，但随着数据集的增大，规则集的构建周期变长，并且移植性较差。"}
{"text": "2.基于统计模型的方法基于统计模型的方法利用完全标注或部分标注的语料进行模型训练，主要采用的模型包括隐马尔可夫模型（Hidden  Markov  Model）、条件马尔可夫模型（Conditional  MarkovModel）、最大熵模型（Maximum  Entropy  Model）以及条件随机场模型（ConditionalRandom  Fields）。"}
{"text": "该类方法将命名实体识别作为序列标注问题处理。"}
{"text": "与普通的分类问题相比，序列标注问题中当前标签的预测不仅与当前的输入特征相关，还与之前的预测标签相关，即预测标签序列是有强相互依赖关系的。"}
{"text": "从自然文本中识别实体是一个典型的序列标注问题。"}
{"text": "基于统计模型构建命名实体识别方法主要涉及训练语料标注、特征定义和模型训练三个方面。"}
{"text": "（1）训练语料标注。"}
{"text": "为了构建统计模型的训练语料，人们一般采用  Inside–Outside–Beginning（IOB）或  Inside–Outside（IO）标注体系对文本进行人工标注。"}
{"text": "在  IOB  标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。"}
{"text": "而在IO标注体系中，文本中的词被标记为实体名称内部词（I）或实体名称外部词（D）。"}
{"text": "表4-1以句子“苹果公司是一家美国的跨国公司”为例，给出了IOB和IO实体标注示例。"}
{"text": "表4-1 IOB和IO实体标注示例（2）特征定义。"}
{"text": "在训练模型之前，统计模型需要计算每个词的一组特征作为模型的输入。"}
{"text": "这些特征具体包括单词级别特征、词典特征和文档级特征等。"}
{"text": "单词级别特征包括是否首字母大写、是否以句点结尾、是否包含数字、词性、词的  n-gram  等。"}
{"text": "词典特征依赖外部词典定义，例如预定义的词表、地名列表等。"}
{"text": "文档级特征基于整个语料文档集计算，例如文档集中的词频、同现词等。"}
{"text": "斯坦福大学的  NER[1]是一个被广泛使用的命名实体识别工具，具有较高的准确率。"}
{"text": "Stanford NER 模型中定义的特征包括当前词、当前词的前一个词、当前词的后一个词、当前词的字符n-gram、当前词的词性、当前词上下文词性序列、当前词的词形、当前词上下文词形序列、当前词左侧窗口中的词（窗口大小为4）、当前词右侧窗口中的词（窗口大小为4）。"}
{"text": "定义何种特征对于命名实体识别结果有较大的影响，因此不同命名实体识别算法使用的特征有所不同。"}
{"text": "（3）模型训练。"}
{"text": "隐马尔可夫模型（Hidden  Markov  Model,HMM）和条件随机场（Conditional  Random  Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。"}
{"text": "HMM  是一种有向图概率模型，模型中包含了隐藏的状态序列和可观察的观测序列。"}
{"text": "每个状态代表了一个可观察的事件，观察到的事件是状态的随机函数。"}
{"text": "HMM 模型结构如图4-3所示，每个圆圈代表一个随机变量，随机变量xt是  t  时刻的隐藏状态；随机变量yt是t时刻的观测值，图中的箭头表示条件依赖关系。"}
{"text": "  HMM模型有两个基本假设：●在任意 t 时刻的状态只依赖于其前一时刻的状态，与其他观测及状态无关，即P（xt|xt−1,xt−2,...,x1,yt−1,yt−2,...,y1）=P（xt|xt−1）；●任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关，即P（yt|xt,xt−1,xt−2,...,x1,yt−1,yt−2,...,y1）=P（yt|xt）。"}
{"text": "图4-3 HMM模型结构在应用于命名实体识别问题时，HMM  模型中的状态对应词的标记，标注问题可以看作是对给定的观测序列进行序列标注。"}
{"text": "基于HMM的有代表性的命名实体识别方法可参考文献[2, 3]。"}
{"text": "CRF是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型。"}
{"text": "在序列标注问题中，线性链  CRF  是常用的模型，其结构如图4-4所示。"}
{"text": "在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。"}
{"text": "图4-4 线性链CRF模型结构给定训练数据集，模型可以通过极大似然估计得到条件概率模型；当标注新数据时，给定输入序列  y，模型输出使条件概率P（x|y）最大化的x*。"}
{"text": "美国斯坦福大学开发的命名实体识别工具Stanford NER是基于CRF的代表性系统[1]。"}
{"text": "3.基于深度学习的方法随着深度学习方法在自然语言处理领域的广泛应用，深度神经网络也被成功应用于命名实体识别问题，并取得了很好的效果。"}
{"text": "与传统统计模型相比，基于深度学习的方法直接以文本中词的向量为输入，通过神经网络实现端到端的命名实体识别，不再依赖人工定义的特征。"}
{"text": "目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional  NeuralNetwork,CNN）、循环神经网络（Recurrent  Neural  Network,RNN）以及引入注意力机制（Attention  Mechanism）的神经网络。"}
{"text": "一般地，不同的神经网络结构在命名实体识别过程中扮演编码器的角色，它们基于初始输入以及词的上下文信息，得到每个词的新向量表示；最后再通过CRF模型输出对每个词的标注结果。"}
{"text": "（1）LSTM-CRF  模型。"}
{"text": "该模型使用了长短时记忆神经网络（Long Shot-Term Memory Neural Network,LSTM）与CRF相结合进行命名实体识别。"}
{"text": "该模型自底向上分别是Embedding层、双向LSTM层和CRF层。"}
{"text": "Embedding层是句子中词的向量表示，作为双向  LSTM  的输入，通过词向量学习模型获得。"}
{"text": "双向  LSTM  层通过一个正向  LSTM  和一个反向  LSTM，分别计算每个词考虑左侧和右侧词时对应的向量，然后将每个词的两个向量进行连接，形成词的向量输出；最后，CRF层以双向LSTM输出的向量作为输入，对句子中的命名实体进行序列标注。"}
{"text": "经过实验对比发现，双向LSTM  与  CRF组合的模型在英文测试数据上取得了与传统统计方法最好结果相近的结果，而传统方法中使用了大量的人工定义的特征以及外部资源；在德语测试数据上，深度学习模型取得了比统计学习方法更优的结果。"}
{"text": "图4-5 LSTM-CRF命名实体识别模型[4]（2）LSTM-CNNs-CRF模型。"}
{"text": "MA  Xuezhe等人发表于ACL2016的论文提出了将双向LSTM、CNN  和  CRF  相结合的序列标注模型[5]，并成功地应用于命名实体识别问题中。"}
{"text": "该模型与  LSTM-CRF  模型十分相似，不同之处是在  Embedding  层中加入了每个词的字符级向量表示。"}
{"text": "模型Embedding层中每个词的向量输入由预训练获得的词向量和  CNN  获得的字符级向量连接而成，通过双向  LSTM  和  CRF  层获得词的标注结果。"}
{"text": "LSTM-CNNs-CRF序列标注模型框架如图4-7所示。"}
{"text": "在CoNLL-2003命名实体识别数据集上，该模型获得了91.2%的F1值。"}
{"text": "图4-6 获取词语字符级向量表示的CNN模型[5]图4-7 LSTM-CNNs-CRF序列标注模型框架[5]（3）基于注意力机制的神经网络模型。"}
{"text": "在自然语言处理领域，基于注意力机制的神经网络模型最早应用于解决机器翻译问题，注意力机制可以帮助扩展基本的编码器-解码器模型结构，让模型能够获取输入序列中与下一个目标词相关的信息。"}
{"text": "在命名实体识别问题方面，Marek  Rei等人在COLING2016的论文中提出了基于注意力机制的词向量和字符级向量组合方法[6]。"}
{"text": "该方法认为除了将词作为句子基本元素学习得到的特征向量，命名实体识别还需要词中的字符级信息。"}
{"text": "因此，该方法除了使用双向  LSTM  得到词的特征向量，还基于双向LSTM计算词的字符级特征向量。"}
{"text": "假设输入词为“big”，该方法将词中的字符看作一个序列，然后通过正、反向的  LSTM  计算字符序列的最终状态 和 ，两者相连得到词“big”的字符级向量h∗。"}
{"text": "h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。"}
{"text": "在得到句子中每个词的新向量 之后，模型使用  CRF  对句子中的命名实体进行序列标注。"}
{"text": "注意力机制的引入使得模型可以动态地确定每个词的词向量和字符级向量在最终特征中的重要性，有效地提升了命名识别的效果。"}
{"text": "与基于词向量和字符级向量拼接的方法相比，基于注意力机制的方法在八个数据集上都获得了最好的实验结果。"}
{"text": "图4-8 基于注意力机制的词向量和字符级向量组合方法[6]4.2.2 关系抽取关系抽取是知识抽取的重要子任务之一，面向非结构化文本数据，关系抽取是从文本中抽取出两个或者多个实体之间的语义关系。"}
{"text": "关系抽取与实体抽取密切相关，一般在识别出文本中的实体后，再抽取实体之间可能存在的关系。"}
{"text": "目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。"}
{"text": "1.基于模板的关系抽取方法早期的实体关系抽取方法大多基于模板匹配实现。"}
{"text": "该类方法基于语言学知识，结合语料的特点，由领域专家手工编写模板，从文本中匹配具有特定关系的实体。"}
{"text": "在小规模、限定领域的实体关系抽取问题上，基于模板的方法能够取得较好的效果。"}
{"text": "假设想从文本中自动抽取具有“夫妻”关系的实体，并且观察到包含“夫妻”关系的例句。"}
{"text": "板：●例句1:[姚明]与妻子[叶莉]还有女儿姚沁蕾并排坐在景区的游览车上，画面十分温馨●例句2:[徐峥]老婆[陶虹]晒新写真可以简单地将上述句子中的实体替换为变量，从而得到如下能够获取“夫妻”关系的模●模板1:[X]与妻子[Y] ……●模板2:[X]老婆[Y] ……利用上述模板在文本中进行匹配，可以获得新的具有“夫妻”关系的实体。"}
{"text": "为了进一步提高模板匹配的准确率，还可以将句法分析的结果加入模板中。"}
{"text": "基于模板的关系抽取方法的优点是模板构建简单，可以比较快地在小规模数据集上实现关系抽取系统。"}
{"text": "但是，当数据规模较大时，手工构建模板需要耗费领域专家大量的时间。"}
{"text": "此外，基于模板的关系抽取系统可移植性较差，当面临另一个领域的关系抽取问题时，需要重新构建模板。"}
{"text": "最后，由于手工构建的模板数量有限，模板覆盖的范围不够，基于模板的关系抽取系统召回率普遍不高。"}
{"text": "2.基于监督学习的关系抽取方法基于监督学习的关系抽取方法将关系抽取转化为分类问题，在大量标注数据的基础上，训练有监督学习模型进行关系抽取。"}
{"text": "利用监督学习方法进行关系抽取的一般步骤包括：预定义关系的类型；人工标注数据；设计关系识别所需的特征，一般根据实体所在句子的上下文计算获得；选择分类模型（如支持向量机、神经网络和朴素贝叶斯等），基于标注数据训练模型；对训练的模型进行评估。"}
{"text": "在上述步骤中，关系抽取特征的定义对于抽取的结果具有较大的影响，因此大量的研究工作围绕关系抽取特征的设计展开。"}
{"text": "根据计算特征的复杂性，可以将常用的特征分为轻量级、中等量级和重量级三大类。"}
{"text": "轻量级特征主要是基于实体和词的特征，例如句子中实体前后的词、实体的类型以及实体之间的距离等。"}
{"text": "中等量级特征主要是基于句子中语块序列的特征。"}
{"text": "重量级特征一般包括实体间的依存关系路径、实体间依存树结构的距离以及其他特定的结构信息。"}
{"text": "例如，对于句子“Forward [motion] of the vehicle through the air caused a [suction] on thetube”，轻量级的特征可以是实体[motion]和[suction]、实体间的词road {of,the,vehicle,through,the,air,caused,a}等；重量级的特征可以包括依存树中的路径“caused→nsubj→实体1”“caused→dobj→实体2”等。"}
{"text": "draft 传统的基于监督学习的关系抽取是一种依赖特征工程的方法，近年来有多个基于深度学习的关系抽取模型被研究者们提出。"}
{"text": "深度学习的方法不需要人工构建各种特征，其输入一般只包括句子中的词及其位置的向量表示。"}
{"text": "目前，已有的基于深度学习的关系抽取方法主要包括流水线方法和联合抽取方法两大类。"}
{"text": "流水线方法将识别实体和关系抽取作为两个分离的过程进行处理，两者不会相互影响；关系抽取在实体抽取结果的基础上进行，因此关系抽取的结果也依赖于实体抽取的结果。"}
{"text": "联合抽取方法将实体抽取和关系抽取相结合，在统一的模型中共同优化；联合抽取方法可以避免流水线方法存在的错误积累问题。"}
{"text": "（1）基于深度学习的流水线关系抽取方法●CR-CNN  模型[7]。"}
{"text": "给定输入的句子，CR-CNN模型首先将句子中的词映射到长度为dw的低维向量，每个词的向量包含了词向量和位置向量两部分。"}
{"text": "然后，模型对固定大小滑动窗口中的词的向量进行卷积操作，为每个窗口生成新的长度为  dc的特征向量；对所有的窗口特征向量求最大值，模型最终得到整个句子的向量表示dx。"}
{"text": "在进行关系分类时，CR-CNN 模型计算句子向量和每个关系类型向量的点积，得到实体具有每种预定义关系的分值。"}
{"text": "CR-CNN模型在SemEval-2010  Task  8数据集上获得了84.1%的F1值，这个结果优于当时最好的非深度学习方法。"}
{"text": "图4-9 CR-CNN模型[7]●Attention  CNNs  模型[8]。"}
{"text": "Wang  等人提出的多层注意力卷积神经网络（Multi-levelAttention  CNN），将注意力机制引入到神经网络中，对反映实体关系更重要的词语赋予更大的权重，借助改进后的目标函数提高关系提取的效果。"}
{"text": "其模型的结构如图4-10所示，在输入层，模型引入了词与实体相关的注意力，同时还在池化和混合层引入了针对目标关系类别的注意力。"}
{"text": "在 SemEval-2010 Task 8数据集上，该模型获得了88%的F1值。"}
{"text": "●Attention  BLSTM  模型[9]。"}
{"text": "Attention  BLSTM  模型如图4-11所示，它包含两个LSTM网络，从正向和反向处理输入的句子，从而得到每个词考虑左边和右边序列背景的状态向量；词的两个状态向量通过元素级求和产生词的向量表示。"}
{"text": "在双向  LSTM  产生的词向量基础上，该模型通过注意力层组合词的向量产生句子向量，进而基于句子向量将关系分类。"}
{"text": "注意力层首先计算每个状态向量的权重，然后计算所有状态向量的加权和得到句子的向量表示。"}
{"text": "实验结果表明，增加注意力层可以有效地提升关系分类的结果。"}
{"text": "图4-10 Attention CNNs模型的结构[8]图4-11 Attention BLSTM模型[9]在关系抽取问题方面，还有许多其他属于流水线方法的深度学习模型。"}
{"text": "图4-12 关系抽取模型在SemEval-2010 Task 8数据集F1值对比（%）（2）基于深度学习的联合关系抽取方法。"}
{"text": "在流水线关系抽取方法中，实体抽取和关系抽取两个过程是分离的。"}
{"text": "联合关系抽取方法则是将实体抽取和关系抽取相结合，图4-13展示的是一个实体抽取和关系抽取的联合模型[13]。"}
{"text": "该模型主要由三个表示层组成：词嵌入层（嵌入层）、基于单词序列的  LSTM-RNN  层（序列层）以及基于依赖性子树的LSTM-RNN  层（依存关系层）。"}
{"text": "在解码过程中，模型在序列层上构建从左到右的实体识别，并实现依存关系层上的关系分类，其中每个基于子树的  LSTM-RNN  对应于两个被识别实体之间的候选关系。"}
{"text": "在对整个模型结构进行解码之后，模型参数通过基于时间的反向传播进行更新。"}
{"text": "在依存关系层堆叠在序列层上，因此嵌入层和序列层被实体识别和关系分类任务共享，共享参数受实体和关系标签的共同影响。"}
{"text": "该联合模型在  SemEval-2010  Task8数据集上获得了84.4%的F1值；将WordNet作为外部知识后，该模型可以获得85.6%的F1值。"}
{"text": "图4-13 实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。"}
{"text": "当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。"}
{"text": "基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。"}
{"text": "（1）远程监督方法。"}
{"text": "远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。"}
{"text": "远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。"}
{"text": "例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和  CEO”则可被用作关系创始人的训练正例。"}
{"text": "因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。"}
{"text": "远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。"}
{"text": "但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。"}
{"text": "为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。"}
{"text": "最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。"}
{"text": "下面介绍两个具有代表性的模型。"}
{"text": "Guoliang Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型  APCNNs[14]。"}
{"text": "模型结构如图4-14所示，图4-14（a）是 PCNNs（Piecewise  Convolutional  Neural  Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。"}
{"text": "关系的分类是基于包特征上的  Softmax  分类器实现的。"}
{"text": "APCNNs  模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。"}
{"text": "实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。"}
{"text": "图4-14 APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。"}
{"text": "针对这一问题，Jun  Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。"}
{"text": "CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。"}
{"text": "样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。"}
{"text": "整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。"}
{"text": "在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。"}
{"text": "图4-15 CNN-RL模型[15]（2）Bootstrapping  方法。"}
{"text": "Bootstrapping  方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。"}
{"text": "通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。"}
{"text": "有很多实体关系抽取系统都采用了Bootstrapping方法。"}
{"text": "Brin等人[16]构建的DIPER利用少量实体对作为种子，从  Web  上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用  Bootstrapping  方法的系统。"}
{"text": "Agichtein  等人[17]设计实现了 Snowball 关系抽取系统，该系统在 DIPER 系统基础上提出了模板生成和关系抽取的新策略。"}
{"text": "在关系抽取过程中，Snowball  可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。"}
{"text": "Etzioni 等人[18]构建了 KnowItAll 抽取系统，从 Web 文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。"}
{"text": "此后，一些基于Bootstrapping 的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。"}
{"text": "例如  NELL  系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。"}
{"text": "Bootstrapping 方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。"}
{"text": "但是，Bootstrapping 方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。"}
{"text": "4.2.3 事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。"}
{"text": "事件的发生可能是因为一个动作的产生或者系统状态的改变。"}
{"text": "事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。"}
{"text": "基于一段苹果公司举办产品发布会的新闻报道，可以通过事件抽取方法自动获取报道事件的结构化信息，包括事件类型、涉及公司、发生时间及地点、所发布的产品。"}
{"text": "一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。"}
{"text": "图4-16 事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。"}
{"text": "1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。"}
{"text": "一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。"}
{"text": "判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。"}
{"text": "（2）元素分类器。"}
{"text": "判断词组是否为事件的元素。"}
{"text": "（3）元素角色分类器。"}
{"text": "判定事件元素的角色类别。"}
{"text": "（4）属性分类器。"}
{"text": "判定事件的属性。"}
{"text": "（5）可报告性分类器。"}
{"text": "判定是否存在值得报告的事件实例。"}
{"text": "表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。"}
{"text": "各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。"}
{"text": "表4-2 触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。"}
{"text": "为了解决这一问题，一些研究工作提出了事件的联合抽取方法。"}
{"text": "在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。"}
{"text": "一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。"}
{"text": "联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。"}
{"text": "联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。"}
{"text": "具有代表性的联合建模方法是Qi  Li等人在ACL2013论文中提出的联合事件抽取模型[20]。"}
{"text": "该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。"}
{"text": "在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。"}
{"text": "此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。"}
{"text": "为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。"}
{"text": "例如，在图4-18的句子中，事件死亡（Die）和事件（Attack）的提及“died”和“fired”共享了三个参数；基于这种情况，可以定义形如图4-19所示的事件抽取全局特征。"}
{"text": "这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。"}
{"text": "联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。"}
{"text": "图4-17 联合事件抽取方法图4-18 事件触发词和事件元素示例图4-19 事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。"}
{"text": "传统的事件抽取方法通常需要借助外部的自然语言处理工具和大量的人工设计的特征；与之相比，深度学习方法具有以下优势：●减少了对外部工具的依赖，甚至不依赖外部工具，可以构建端到端的系统；●使用词向量作为输入，词向量蕴涵了丰富的语义信息；●神经网络具有自动提取句子特征的能力，避免了人工设计特征的烦琐工作。"}
{"text": "图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。"}
{"text": "该模型由 YuboChen  等人于2015年发表在  ACL  会议上[21]。"}
{"text": "模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。"}
{"text": "其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。"}
{"text": "在 CNN方法的结果。"}
{"text": "ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20 基于动态多池化卷积神经网络的事件抽取模型4.3 面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。"}
{"text": "在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。"}
{"text": "W3C的RDB2RDF工作组于2012年发布了两个推荐的  RDB2RDF  映射语言：DM（Direct  Mapping，直接映射）和  R2RML。"}
{"text": "DM  和R2ML  映射语言用于定义关系数据库中的数据如何转换为  RDF  数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。"}
{"text": "4.3.1 直接映射直接映射规范定义了一个从关系数据库到  RDF  图数据的简单转换，为定义和比较更复杂的转换提供了基础。"}
{"text": "它也可用于实现  RDF图或定义虚拟图，可以通过  SPARQL查询或通过RDF图API访问。"}
{"text": "直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。"}
{"text": "直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。"}
{"text": "下面给出一个简单的例子，解释直接映射的基本思路。"}
{"text": "首先，假设通过  SQL  语句创建图4-21中的两个数据库表。"}
{"text": "创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21 数据库表在直接映射过程中，数据库表中的每一行（例如 People 表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。"}
{"text": "主语是由  IRI  前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的 IRI。"}
{"text": "每列的谓词是由 IRI 前缀和表名、列名连接形成的IRI。"}
{"text": "这些值是从列值的词汇形式形成的RDF文字。"}
{"text": "每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。"}
{"text": "这些三元组的宾语是被引用三元组的行标识符（例如<Addresses / ID = 18>）。"}
{"text": "直接映射不会为NULL值生成三元组。"}
{"text": "4.3.2 R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。"}
{"text": "这种映射提供了在  RDF  数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。"}
{"text": "在数据库的直接映射中，生成的  RDF  图的结构直接反映了数据库的结构，目标  RDF  词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。"}
{"text": "然而，通过使用  R2RML，用户可以在关系数据上灵活定制视图。"}
{"text": "每个  R2RML  映射都针对特定的数据库模式和目标词汇量身定制。"}
{"text": "R2RML  映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。"}
{"text": "R2RML 映射是通过逻辑表（Logic Tables）从数据库中检索数据的。"}
{"text": "一个逻辑表可以是数据库中的一个表、视图或有效的 SQL  语句查询。"}
{"text": "每个逻辑表通过三元组映射（Triples  Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。"}
{"text": "“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。"}
{"text": "三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。"}
{"text": "主语映射从逻辑表生成所有  RDF  三元组中的主语，通常使用基于数据库表中的主键生成的  IRI表示。"}
{"text": "谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。"}
{"text": "图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。"}
{"text": "将上述数据库映射为RDF数据，期望的输出结果如下：图4-22 示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。"}
{"text": "用于创建R2RML视图的SQL语句如下所示。"}
{"text": "用于DEPT表数据转换的R2RML映射文档如下所示。"}
{"text": "此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。"}
{"text": "4.3.3 相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL （Ontology Based Database Access,OBDA）系统。"}
{"text": "这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。"}
{"text": "表4-3 OBDA系统的主要特性对比（1）D2RQ[22]。"}
{"text": "D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。"}
{"text": "其中，D2R Server是一个HTTP Server，主要功能提供对 RDF 数据的查询访问接口，供上层的 RDF 浏览器、SPARQL 查询客户端以及HTML浏览器调用。"}
{"text": "D2R  Server  使用了一种可定制的  D2RQ  映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。"}
{"text": "基于D2RQ映射，Web  端的请求被重写为  SQL  查询，这种即时转换允许从大型实时数据库发布  RDF，而无须将数据复制到专用的RDF三元组存储中。"}
{"text": "此外，D2RQ系统还部分支持R2RML映射。"}
{"text": "（2）Mastro[23]。"}
{"text": "Mastro  是一个基于Java  语言开发的OBDA系统，系统中的本体使用属于 DL-Lite 轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。"}
{"text": "Mastro数据源管理器支持与最流行的商业和非商业 DBMS 的交互。"}
{"text": "除此之外，还为 Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。"}
{"text": "图4-23 D2RQ平台框架[22]图4-24 Mastro系统结构[23]（3）Ultrawrap[24]。"}
{"text": "Ultrawrap 是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。"}
{"text": "其中，编译器负责建立数据库到  RDF  和  OWL  的映射；服务器负责在数据库上执行SPARQL查询。"}
{"text": "Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持 R2RML 和 D2RQ 映射，并为用户提供图形界面个性化定制映射。"}
{"text": "图4-25 Ultrawrap系统结构（4）Morph-RDB[25]。"}
{"text": "Morph-RDB 是由马德里理工大学本体工程组开发的 RDB2RDF引擎，遵循  R2RML  规范。"}
{"text": "Morph-RDB  支持两种操作模式：数据升级（从关系数据库中的数据生成  RDF  实例）和查询转换（SPARQL  到  SQL）。"}
{"text": "Morph-RDB  采用各种优化技术来生成高效的  SQL  查询，例如自连接消除和子查询消除。"}
{"text": "目前，Morph-RDB  支持MySQL、PostgreSQL、H2、CSV文件和MonetDB等数据源。"}
{"text": "（5）Ontop[26]。"}
{"text": "Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。"}
{"text": "Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。"}
{"text": "通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop  系统将关系数据库转换为虚拟的RDF  图。"}
{"text": "Ontop  支持  R2RML  映射，它可以将  SPARQL  查询翻译为关系数据库中的  SQL查询，从而实现在数据库上的SPARQL查询。"}
{"text": "图4-26 Ontop的系统结构[26]4.4 面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。"}
{"text": "自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。"}
{"text": "目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。"}
{"text": "4.4.1 面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。"}
{"text": "在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。"}
{"text": "图4-27 维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。"}
{"text": "目前，基于维基百科已经构建起多个知识图谱，包括 DBpedia[27]和  Yago[28]等。"}
{"text": "随着中文百科站点的发展，如百度百科、互动百科，一些大规模的中文知识图谱也陆续基于百科数据被构建出来，包括Zhishi.me[29]、XLore[30]和  CN-DBpedia[31]等。"}
{"text": "在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。"}
{"text": "在基于百科数据构建的知识图谱中，DBpedia是较早发布、具有代表性的知识图谱，下面对它的构建方法进行介绍。"}
{"text": "DBpedia  是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。"}
{"text": "DBpedia采用固定模式对维基百科中的实体信息进行抽取，在  Linking  Open  Data  原则的指导下，将其以关联数据的形式在Web上发布与共享。"}
{"text": "得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。"}
{"text": "截至2019年2月，DBpedia  英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。"}
{"text": "此外，DBpedia  还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。"}
{"text": "完整的 3800万个来自125种不同语言的标签和摘要，2520万个图片链接和2980万个外部网页链接。"}
{"text": "DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。"}
{"text": "总体上，DBpedia包含约30亿条RDF三元组，其中5.8亿条是从维基百科的英文版中提取的，24.6亿条是从其他语言版本中提取的。"}
{"text": "根据抽样评测，DBpedia中RDF三元组的正确率达88%。"}
{"text": "图4-28所示为 DBpedia 知识抽取的总体框架。"}
{"text": "框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的  RDF  三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。"}
{"text": "图4-28 DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。"}
{"text": "●跨语言链接（Inter-language  Links）：抽取词条页面指向其他语言版本的跨语言链接；联；●图片（Images）：提取指向图片的链接；●重定向（Redirects）：抽取维基百科词条的重定向链接，建立其与同义词条的关●消歧（Disambiguation）：从维基百科消歧页面抽取有歧义的词条链接；●外部链接（External Links）：抽取词条正文指向维基百科外部的链接；●页面链接（Pagelinks）：抽取词条正文指向维基百科内部的链接；●主页（Homepages）：抽取诸如公司、机构等实体的主页链接；●分类（Categories）：抽取词条所属的分类；●地理坐标（Geo-Coordinates）：抽取词条页面中存在的地理位置的经纬度坐标。"}
{"text": "●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。"}
{"text": "在上述抽取器中，信息框抽取从维基百科中取获得大量的实体属性和实体关系，是DBpedia  中最有价值的信息之一。"}
{"text": "信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。"}
{"text": "信息框的一般抽取直接将信息框中的信息转换为  RDF  三元组。"}
{"text": "三元组的主语由DBpedia  的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的  URI  或者数据类型的值。"}
{"text": "然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。"}
{"text": "为了处理该类问题，DBpedia  使用了基于映射的信息框抽取方法；该方法首先将信息框的模板、属性映射到人工定义的本体中的类型和属性，然后采用本体中的词汇描述抽取出的结构化信息，获得的三元组数据质量更高。"}
{"text": "图4-29 信息框示例[27]4.4.2 面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。"}
{"text": "从页面的  HTML  代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。"}
{"text": "图4-30 某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。"}
{"text": "包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。"}
{"text": "包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。"}
{"text": "图4-31 基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。"}
{"text": "手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。"}
{"text": "XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。"}
{"text": "借助它可以获取网页中元素的位置，从而获取需要的信息。"}
{"text": "在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS  选择器是通过  CSS  元素实现对网页中元素的定位，并获取元素信息的。"}
{"text": "分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。"}
{"text": "典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。"}
{"text": "（1）网页清洗。"}
{"text": "纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。"}
{"text": "（2）网页标注。"}
{"text": "在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。"}
{"text": "例如，在图4-30的例子中，如果需要抽取页面上“华为  P10”产品的信息和价格，则可以在产品信息和价格所在的标签里打上一个特殊的标记作为标注。"}
{"text": "（3）包装器空间生成。"}
{"text": "基于标注的数据生成  XPath  集合空间，对生成的集合进行归纳，从而形成若干个子集。"}
{"text": "归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。"}
{"text": "（4）包装器评估。"}
{"text": "包装器可以通过准确率和召回率进行评估。"}
{"text": "使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为 N；准确率是  N  除以包装器输出标注的总数量，而召回率是  N  除以人工标注数据项的总数量。"}
{"text": "准确率和召回率越高，表示包装器的质量越好。"}
{"text": "3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。"}
{"text": "此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。"}
{"text": "自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。"}
{"text": "在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。"}
{"text": "在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。"}
{"text": "上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。"}
{"text": "表4-5 Web页面的信息抽取方法对比4.5 知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。"}
{"text": "4.5.1 知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。"}
{"text": "实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。"}
{"text": "通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。"}
{"text": "实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。"}
{"text": "图4-32 实体链接示例图4-33 实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。"}
{"text": "该步骤主要通过命名实体识别技术或者词典匹配技术实现。"}
{"text": "命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。"}
{"text": "2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。"}
{"text": "例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。"}
{"text": "生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。"}
{"text": "某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。"}
{"text": "然后，可以利用这些扩展形式形成实体提及的候选实体集合。"}
{"text": "表层名字扩展可以采用启发式的模式匹配方法实现。"}
{"text": "例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University of Illinois at Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。"}
{"text": "除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。"}
{"text": "（2）基于搜索引擎的方法。"}
{"text": "将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。"}
{"text": "例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。"}
{"text": "此外，维基百科自有的搜索功能也可以用于生成候选实体。"}
{"text": "（3）构建查询实体引用表。"}
{"text": "很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。"}
{"text": "实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。"}
{"text": "在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。"}
{"text": "为了构建查询实体引用表，常用的方法是基于维基百科中的词条页面、重定向页面、消歧页面、词条正文超链接等抽取实体提及与实体的对应关系。"}
{"text": "维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。"}
{"text": "维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。"}
{"text": "表4-5 实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。"}
{"text": "一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。"}
{"text": "总体上，候选实体消歧方法包括基于图的方法、基于概率生成模型的方法、基于主题模型的方法和基于深度学习的方法等。"}
{"text": "下面介绍每类方法中具有代表性的工作。"}
{"text": "[32]（1）基于图的方法。"}
{"text": "基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。"}
{"text": "该类方法比较具有代表性的是  Han  等人较早提出的基于参照图（Referent  Graph）协同实体链接方法[33]。"}
{"text": "Han  等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。"}
{"text": "在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han PageRank  算法中节点  rank  值的传递与更新方式类似。"}
{"text": "最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。"}
{"text": "采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。"}
{"text": "图4-34 参照图[33]（2）基于概率生成模型的方法。"}
{"text": "基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。"}
{"text": "在  Han  等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。"}
{"text": "图4-35 实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael  Jeffrey  Jordan]和[Michael  I.Jordan]；然后，模型依据给定实体  e  实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael  Jordan]；最后，模型依据给定实体  e  上下文的条件概率P（c|e）输出实体提及的上下文。"}
{"text": "根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。"}
{"text": "当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。"}
{"text": "Han  等人认为，在同一个文本中出现的实体应该与文本表述的主题相关。"}
{"text": "基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。"}
{"text": "实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。"}
{"text": "首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。"}
{"text": "通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。"}
{"text": "图4-36 实体-主题模型[37]（4）基于深度学习的方法。"}
{"text": "在候选实体消歧过程中，准确计算实体的相关度十分重要。"}
{"text": "因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。"}
{"text": "Huang 等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。"}
{"text": "在输入层，每个实体对应的输入信息包括实体  E、实体拥有的关系  R、实体类型  ET和实体描述 D。"}
{"text": "基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。"}
{"text": "图4-37 实体提及生成过程示例[38]4.5.2 知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive  Logic  Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。"}
{"text": "知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。"}
{"text": "给定背景知识和目标谓词（知识图谱中即为关系）,ILP 系统可以学习获得描述目标谓词的逻辑规则集合。"}
{"text": "FOIL[40]是早期具有代表性的  ILP  系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL  采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。"}
{"text": "下面通过一个例子介绍FOIL的规则学习过程。"}
{"text": "设有规则学习问题如表4-6所示。"}
{"text": "背景知识描述了某一家庭的成员关系，规则学习的目标谓词为  daughter，该目标谓词有若干正例和反例事实。"}
{"text": "FOIL  在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。"}
{"text": "表4-7列出了FOIL学习单个规则的过程。"}
{"text": "当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。"}
{"text": "表4-6 规则学习问题表4-7 FOIL学习单个规则的过程注： 和 分别为被规则ri覆盖正例和反例的数量。"}
{"text": "在扩展规则体的每一步，FOIL  选择使得规则  FOIL_Gain  达到最大的谓词加入规则体。"}
{"text": "FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字； 和 分别为被规则Ri覆盖正例和反例的数量； 和 分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。"}
{"text": "基于  FOIL_Gain  评价函数，FOIL  在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。"}
{"text": "在早期的  ILP  系统中，还有以  Progol[41]为代表的基于逆语义蕴涵的学习方法。"}
{"text": "文献[39,42]对大量 ILP 方法进行了综述。"}
{"text": "多数 ILP 系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。"}
{"text": "因此，近年来也有大量研究致力于提高 ILP 系统的可扩展性，这些工作包括  FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的  ILP  系统[46]等。"}
{"text": "最近，针对大规模知识图谱的特点，Galarraga 等人研究并提出了 AMIE 系统[47];AMIE 采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。"}
{"text": "在对  AMIE  多个计算过程进行优化后，Galarraga  等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。"}
{"text": "2.路径排序算法（Path Ranking Algorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA  计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。"}
{"text": "PRA  的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。"}
{"text": "如图4-38所示，若要预测球员和赛事联盟之间的  AlthletePlaysForLeague  关系，连接实体  HinesWard  和  NFL  的关系路径<AlthletePlaysForTeam, TeamPlaysInLeague>可以作为预测模型的一个重要特征。"}
{"text": "实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。"}
{"text": "在链接预测过程中，PRA  会自动发现有用的关系路径来构建预测模型；PRA  具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。"}
{"text": "图4-38 示例知识图谱子图[50]图4-39 霍恩子句（1）特征选择。"}
{"text": "因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。"}
{"text": "PRA  并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。"}
{"text": "为了保证特征选择的效率，PRA  使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA  基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。"}
{"text": "式中，P（si→Gi;π）是以实体  si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。"}
{"text": "PRA  对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。"}
{"text": "（2）特征计算。"}
{"text": "在选择了有用的关系路径作为特征之后，PRA  将为每个实体对计算其特征值。"}
{"text": "给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体  t  的概率作为该实体对在关系路径π特征的值。"}
{"text": "通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。"}
{"text": "（3）关系分类。"}
{"text": "基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA  为每个目标关系训练一个分类模型。"}
{"text": "利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。"}
{"text": "关系分类可以使用任何一种分类模型，PRA  中使用了逻辑回归分类模型，并取得了较好的效果。"}
{"text": "PRA  在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。"}
{"text": "图4-40 PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6 开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive 开源关系抽取框架实现的。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "该框架遵循Apache开源协议。"}
{"text": "4.6.1 开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive  在此基础上添加了神经网络模型和增量操作。"}
{"text": "在具体应用中，可以选择使用因子图模型或神经网络模型。"}
{"text": "图4-41 DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。"}
{"text": "执行上述流程需要注意以下几点：1.环境配置运行该框架需要配置的DeepDive、PostgreSQL和中文Standford  NLP环境。"}
{"text": "DeepDive可以从OpenKG网站下载。"}
{"text": "可选择配置deepke的扩展功能。"}
{"text": "2.数据准备数据准备阶段需要进行的处理包括导入结构化的监督数据、导入文本数据、利用NLP模块进行文本处理、实体抽取、候选实体对生成及样本打标。"}
{"text": "文本处理阶段可能会非常慢，可通过减少articles的行数来缩短时间。"}
{"text": "3.因子图模型在构建因子图模型之前，需要先进行特征抽取。"}
{"text": "4.深度学习深度学习模型需要准备训练和测试数据。"}
{"text": "模型输入的  train_data  和  test_data  需要符合神经网络的输入。"}
{"text": "5.增量操作并或清空操作。"}
{"text": "其他类似工具增量操作必须在原工作流程定下来之后进行。"}
{"text": "对于添加新数据部分  input  文件下的所有初始数据，都需要做一份增量。"}
{"text": "如果没有增量的需要，则定义空文件。"}
{"text": "如果需要使用原数据，则复制原有文件。"}
{"text": "需要先合并再进行新的测试或训练步骤，即增量只是数据准备过程中的增量。"}
{"text": "若想单独测试新的测试数据，直接在合并之前执行deepke  lstm-test  tmp_new_test_datatmp_new_new_test_data。"}
{"text": "查看结果后再执行合并或清空操作。"}
{"text": "4.6.2 其他类似工具Reverb是华盛顿大学Turing  center研发的开放三元组抽取工具，可以从英文句子中抽取形如（augument1, relation,  argument2）的三元组。"}
{"text": "它不需要提前指定关系，支持全网规模的信息抽取。"}
{"text": "目前用于华盛顿大学开发的KnowItAll知识库系统。"}
{"text": "OLLIE  和  Reverb  类似，都是华盛顿大学研发的知识库  KnowItAll  的三元组抽取组件，OLLIE 是第二代提取系统。"}
{"text": "Reverb 的抽取建立在文本序列上，而 OLLIE 则支持基于语法依赖树的关系抽取，对于长线依赖效果更好。"}
{"text": "Wandora是封装好的知识抽取桌面程序，支持主题图、RDF、OBO等多种输入输出格式。"}
{"text": "它内置了HTTP服务器，有完整的交互界面，支持输出可视化。"}
