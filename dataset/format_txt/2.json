{"text": "第2章知识图谱表示与建模漆桂林东南大学，潘志霖阿伯丁大学，陈华钧浙江大学知识图谱表示（Knowledge_Graph_Representation）指的是用什么语言对知识图谱进行建模，从而可以方便知识计算。"}
{"text": "从图的角度来看，知识图谱是一个语义网络，即一种用互联的节点和弧表示知识的一个结构[1]。"}
{"text": "语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。"}
{"text": "语义网络中的语义主要体现在图中边的含义。"}
{"text": "为了给这些边赋予语义，研究人员提出了术语语言（Terminological_Language），并最终提出了描述逻辑（Description_Logic），描述逻辑是一阶谓词逻辑的一个子集，推理复杂度是可判定的。"}
{"text": "W3C采用了以描述逻辑为逻辑基础的本体语言OWL作为定义Web术语的标准语言。"}
{"text": "W3C还推出了另外一种用于表示Web本体的语言RDF_Schema（简称RDFS）。"}
{"text": "目前基于向量的知识表示开始流行，这类表示将知识图谱三元组中的主谓宾表示成数值向量，通过向量的知识表示，可以采用统计或者神经网络的方法进行推理，对知识图谱中的实体直接的关系进行预测。"}
{"text": "本章将对知识表示的常见方法进行介绍，并且讨论如何用这些知识表示方法对知识进行建模。"}
{"text": "2.1什么是知识表示20世纪90年代，MIT_AI实验室的R.Davis定义了知识表示的五大用途或特点：●客观事物的机器标示（A_KR_is_a_Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。"
{"text": "●一组本体约定和概念模型（A_KR_is_a_Set_of_Ontological_Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。"}
{"text": "●支持推理的表示基础（A_KR_is_a_Theory_of_Intelligent_Reasoning），即知识表示还需要提供机器推理的模型与方法。"}
{"text": "●用于高效计算的数据结构（A_KR_is_a_medium_for_Efficient_Computation），即知识表示也是一种用于高效计算的数据结构。"}
{"text": "●人可理解的机器语言（A_KR_is_a_Medium_of_Human_Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。"}
{"text": "有关知识表示的研究可以追溯到人工智能的早期研究。"}
{"text": "例如，认知科学家M.RossQuillian和Allan_M.Collins提出了语义网络的知识表示方法[2-3]，以网络的方式描述概念之间的语义关系。"}
{"text": "典型的语义网络如WordNet属于词典类的知识库，主要定义名词、动词、形容词和副词之间的语义关系。"}
{"text": "20世纪70年代，随着专家系统的提出和商业化发展，知识库构建和知识表示更加得到重视。"}
{"text": "传统的专家系统通常包含知识库和推理引擎（InferenceEngine）两个核心模块。"}
{"text": "无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化的语义定义。"}
{"text": "为了解决这一问题，人们开始研究具有较好的理论模型基础和算法复杂度的知识表示框架。"}
{"text": "比较有代表性的是描述逻辑语言（Description_Logic）[4]。"}
{"text": "描述逻辑是目前大多数本体语言（如OWL）的理论基础。"}
{"text": "第一个描述逻辑语言是1985年由RonaldJ.Brachman等提出的KL-ONE[5]。"}
{"text": "描述逻辑主要用于刻画概念（Concepts）、属性（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑描述Logic_Statement）等知识表达要素。"}
{"text": "与传统专家系统的知识表示语言不同，描述逻辑家族更关心知识表示能力和推理计算复杂性之间的关系，并深入研究了各种表达构件的组合带来的查询、分类、一致性检测等推理计算的计算复杂度问题。"}
{"text": "语义网的基础数据模型RDF受到了元数据模型、框架系统和面向对象语言等多方面的影响，其最初是为人们在Web上发布结构化数据提供一个标准的数据描述框架。"}
{"text": "与此同时，语义网进一步吸收描述逻辑的研究成果，发展出了用OWL系列标准化本体语言。"}
{"text": "现代知识图谱如DBpedia、Yago、Freebase、Schema.ORG、Wikidata等大多以语义网的表达模型为基础进行扩展或删减。"}
{"text": "无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于以符号逻辑为基础的知识表示方法。"}
{"text": "符号知识表示的特点是易于刻画显式、离散的知识，因而具有内生的可解释性。"}
{"text": "但由于人类知识还包含大量不易于符号化的隐性知识，完全基于符号逻辑的知识表示通常由于知识的不完备而失去鲁棒性，特别是推理很难达到实用。"}
{"text": "由此催生了采用连续向量的方式来表示知识的研究。"}
{"text": "基于向量的方式表示知识的研究由来已有。"}
{"text": "随着表示学习的发展，以及自然语言处理领域词向量等嵌入（Embedding）技术手段的出现，启发了人们用类似于词向量的低维稠密向量的方式表示知识。"}
{"text": "通过嵌入将知识图谱中的实体和关系投射到一个低维的连续向量空间，可以为每一个实体和关系学习出一个低维度的向量表示。"}
{"text": "这种基于连续向量的知识表示可以实现通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜在假设，这些隐式知识通常是人的主观不易于观察和总结出来的。"}
{"text": "更为重要的是，知识图谱嵌入也通常作为一种类型的先验知识辅助输入很多深度神经网络模型中，用来约束和监督神经网络的训练过程。"}
{"text": "如图2-1所示为基于离散符号的知识表示与基于连续向量的知识表示对比。"}
{"text": "图2-1基于离散符号的知识表示与基于连续向量的知识表示对比综上所述，与传统人工智能相比，知识图谱时代的知识表示方法已经发生了很大的变化。"}
{"text": "一方面，现代知识图谱受到规模化扩展的影响，通常采用以三元组为基础的较为简单实用的知识表示方法，并弱化了对强逻辑表示的要求；另一方面，由于知识图谱是很多搜索、问答和大数据分析系统的重要数据基础，基于向量的知识图谱表示使得这些数据更易于和深度学习模型集成，使得基于向量的知识图谱表示越来越受到重视。"}
{"text": "由于知识表示涉及大量传统人工智能的内容，并有其明确、严格的内涵及外延定义，为避免混淆，在本书中主要侧重于知识图谱的表示方法的介绍，因此用“知识表示”和“知识图谱的表示方法”加以了区分。"}
{"text": "2.2人工智能早期的知识表示方法知识是智能的基础。"}
{"text": "人类智能往往依赖有意或无意运用已知的知识。"}
{"text": "与此类似，人工智能系统需要获取并运用知识。"}
{"text": "这里有两个核心问题：怎么表示知识？怎样在计算机中高效地存储与处理知识？本章主要阐述第一个核心问题。"}
{"text": "2.2.1一阶谓词逻辑一阶谓词逻辑（或简称一阶逻辑）（First_Order_Logic）是公理系统的标准形式逻辑。"}
{"text": "不同于命题逻辑（Propositional_Logic），一阶逻辑支持量词（Quantifier）和谓词（Predicate）。"}
{"text": "例如，在命题逻辑里，以下两个句子是不相关的命题：“John_MaCarthy是图灵奖得主”（p）、“Tim_Berners-Lee是图灵奖得主”（q）。"}
{"text": "但是，在一阶逻辑里，可以用谓词和变量表示知识，例如，图灵奖得主（x）表示x是图灵奖得主。"}
{"text": "这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。"}
{"text": "Ø图灵奖得主（x）是一个否定公式（Negated_Formula）。"}
{"text": "在上面的例子中，若x为John_MaCarthy，图灵奖得主（x）为第一个命题p。"}
{"text": "若x为Tim_Berners-Lee，图灵奖得主（x）为第二个命题q。"}
{"text": "1.一阶谓词逻辑优点●结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "●严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "●可实现性。"}
{"text": "可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.一阶谓词逻辑缺点●有限的可用性。"}
{"text": "一阶逻辑的逻辑归结只是半可判定性的。"}
{"text": "●无法表示不确定性知识。"}
{"text": "2.2.2霍恩子句和霍恩逻辑霍恩子句（Horn_Clause）得名于逻辑学家Alfred_Horn[6]。"}
{"text": "一个子句是文字的析取。"}
{"text": "霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。"}
{"text": "例如，Øp1∨…∨Øpn∨ q是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→q。"}
{"text": "Alfred_Horn于1951年撰文指出这种子句的重要性。"}
{"text": "霍恩逻辑（Horn_Logic）是一阶逻辑的子集。"}
{"text": "基于霍恩逻辑的知识库是一个霍恩规则的集合。"}
{"text": "一个霍恩规则由原子公式构成：B1∧…∧Bn→H，其中H是头原子公式，B1,…,Bn是体原子公式。"}
{"text": "事实是霍恩规则的特例，它们是没有体原子公式且没有变量的霍恩Berners-Lee）是一个事实，可以简写为图灵奖得主规则。"}
{"text": "例如，→图灵奖得主（Tim （Tim_Berners-Lee）。"}
{"text": "1.霍恩逻辑的优点●结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "●严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "●易实现性。"}
{"text": "可判定，可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.霍恩逻辑的缺点●有限的表达能力。"}
{"text": "不能定义类表达式，不能够任意使用量化。"}
{"text": "●无法表示不确定性知识。"}
{"text": "2.2.3语义网络语义网络是由Quillian等人提出用于表达人类的语义知识并且支持推理[3]。"}
{"text": "语义网络又称联想网络，它在形式上是一个带标识的有向图。"}
{"text": "图中“节点”用以表示各种事物、概念、情况、状态等。"}
{"text": "每个节点可以带有若干属性。"}
{"text": "节点与节点间的“连接弧”（称为联想弧）用以表示各种语义联系、动作。"}
{"text": "语义网络的单元是三元组：（节点1，联想弧，节点2）。"}
{"text": "例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。"}
{"text": "由于所有的节点均通过联想弧彼此相连，语义网络可以通过图上的操作进行知识推理。"}
{"text": "1.语义网络的优点1）联想性。"}
{"text": "它最初是作为人类联想记忆模型提出来的。"}
{"text": "2）易用性。"}
{"text": "直观地把事物的属性及其语义联系表示出来，便于理解，自然语言与语义网络的转换比较容易实现，故语义网络表示法在自然语言理解系统中的应用最为广泛。"}
{"text": "3）结构性。"}
{"text": "语义网络是一种结构化的知识表示方法，对数据子图特别有效。"}
{"text": "它能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2.语义网络的缺点1）无形式化语法。"}
{"text": "语义网络表示知识的手段多种多样，虽然灵活性很高，但同时也由于表示形式的不一致提高了对其处理的复杂性。"}
{"text": "例如，“每个学生都读过一本书”可以表示为多种不同的语义网络，例如图2-2和图2-3中的语义网络。"}
{"text": "在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。"}
{"text": "而图2-3则把“每个学生都读过一本书”表示成：任何一个学生s1都是属于读过一本书这个概念的元素。"}
{"text": "图2-3表示“每个学生都读过一本书”的语义网络2）无形式化语义。"}
{"text": "与一阶谓词逻辑相比，语义网络没有公认的形式表示体系。"}
{"text": "一个给定的语义网络表达的含义完全依赖处理程序如何对它进行解释。"}
{"text": "通过推理网络而实现的推理不能保证其正确性。"}
{"text": "此外，目前采用量词（包括全称量词和存在量词）的语义网络表示法在逻辑上是不充分的，不能保证不存在二义性。"}
{"text": "2.2.4框架框架（Frame）最早由Marvin_Minsky在1975年提出[7]，目标是更好地理解视觉推理和自然语言处理。"}
{"text": "其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类似于框架的结构存储在记忆中。"}
{"text": "当面临一个新事物时，就从记忆中找出一个合适的框架，并根据实际情况对其细节加以修改、补充，从而形成对当前事物的认识。"}
{"text": "框架是一种描述对象（事物、事件或概念等）属性的数据结构。"}
{"text": "在框架理论中，类是知识表示的基本单位。"}
{"text": "每个类有一些槽，每个槽又可分为若干“侧面”。"}
{"text": "一个槽用于表示描述对象的一个属性，而一个侧面用语表示槽属性的一个方面，槽和侧面都可以有属性值，分别称为槽值和侧面值。"}
{"text": "除此之外，框架还允许给属性设默认值，以及设立触发器以维护框架。"}
{"text": "1）下面是框架的基本组成的一个示例：2）表2-1给出一个带变量框架实例。"}
{"text": "如果把框架“tx未遂杀人案”的变量赋值，可以得到下面的一个框架实例，如表2-2所示。"}
{"text": "表2-1带变量框架实例表2-2变量赋值框架实例1.框架的优点1）结构性：能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2）框架对于知识的描述比较全面，支持默认值以及触发器。"}
{"text": "2.框架的缺点1）框架的构建成本非常高，对知识库的质量要求非常高。"}
{"text": "2）默认值会增大推理的复杂度。"}
{"text": "3）无法表示不确定性知识。"}
{"text": "2.2.5描述逻辑描述逻辑是一阶逻辑的一个可判定子集。"}
{"text": "最初由Ronald_J.Brachman在1985年提出。"}
{"text": "描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。"}
{"text": "描述逻辑一般支持一元谓词和二元谓词。"}
{"text": "一元谓词称为类，二元谓词称为关系。"}
{"text": "描述逻辑的重要特征是同时具有很强的表达能力和可判定性。"}
{"text": "描述逻辑近年来受到广泛关注，被选为W3C互联网本体语言（OWL）的理论基础。"}
{"text": "1.描述逻辑的优点1）结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2）严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "3）多样性。"}
{"text": "具有大量可判定的扩展，以满足不同应用场景的需求。"}
{"text": "4）易实现性。"}
{"text": "可判定，可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.描述逻辑的缺点1）有限的表达能力。"}
{"text": "不支持显式使用变量，不能够任意使用量化。"}
{"text": "2）无法表示不确定性知识。"}
{"text": "2.3互联网时代的语义网知识表示框架随着语义网的提出，知识表示迎来了新的契机和挑战，契机在于语义网为知识表示提供了一个很好的应用场景，挑战在于面向语义网的知识表示需要提供一套标准语言可以用来描述Web的各种信息。"}
{"text": "早期Web的标准语言HTML和XML无法适应语义网对知识表示的要求，所以W3C提出了新的标准语言RDF、RDFS和OWL。"}
{"text": "这两种语言的语法可以跟XML兼容。"}
{"text": "下面详细介绍这几种语言。"}
{"text": "2.3.1RDF和RDFSRDF是W3C的RDF工作组制定的关于知识图谱的国际标准。"}
{"text": "RDF是W3C一系列语义网标准的核心，如图2-4所示。"}
{"text": "●表示组（Representation）包括URI/IRI、XML和RDF。"}
{"text": "前两者主要是为RDF提供语法基础。"}
{"text": "●推理组（Reasoning）包括RDF-S、本体OWL、规则RIF和统一逻辑。"}
{"text": "统一逻辑目前还没有定论。"}
{"text": "●信任组和用户互动组。"}
{"text": "图2-4对W3C的语义网标准栈做了分组。"}
{"text": "目前，跟知识图谱最相关的有：图2-4W3C的语义网标准栈及其分组2006年，人们开始用RDF发布和链接数据，从而生成知识图谱，比较知名的有DBpedia、Yago和Freebase。"}
{"text": "2009年，Tim_Berners-Lee为进一步推动语义网开放数据的发展，进一步提出了开放链接数据的五星级原则，如表2-3所示。"}
{"text": "表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。"}
{"text": "2007年，不少开放图谱实现与DBpedia链接。"}
{"text": "如图2-5为开放链接数据早期的发展。"}
{"text": "图2-5开放链接数据早期的发展1.RDF简介在RDF中，知识总是以三元组的形式出现。"}
{"text": "每一份知识可以被分解为如下形式：(subject,predicate,object)。"}
{"text": "例如，“IBM邀请Jeff_Pan作为讲者，演讲主题是知识图谱”可以写成以下RDF三元组：（IBM-Talk,speaker,Jeff）,（IBM-Talk,theme,KG）。"}
{"text": "RDF中的主语是一个个体（Individual），个体是类的实例。"}
{"text": "RDF中的谓语是一个属性。"}
{"text": "属性可以连接两个个体，或者连接一个个体和一个数据类型的实例。"}
{"text": "换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。"}
{"text": "如果把三元组的主语和宾语看成图的节点，三元组的谓语看成边，那么一个RDF知识库则可以被看成一个图或一个知识图谱，如图2-6所示。"}
{"text": "三元组则是图的单元。"}
{"text": "在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。"}
{"text": "图2-6一个RDF知识库可以被看成一个图图2-7三元组的全局标识URI全局标识URI可以被简化成前缀URI，如图2-8所示。"}
{"text": "RDF允许没有全局标识的空白节点（Blank_Node）。"}
{"text": "空白节点的前缀为“_”。"}
{"text": "例如，Jeff是某一次关于KG讲座的讲者，如图2-9所示。"}
{"text": "图2-8前缀URI图2-9没有全局标识的空白节点RDF是抽象的数据模型，支持不同的序列化格式，例如RDF/XML、Turtle和N-Triple，如图2-10所示。"}
{"text": "图2-10不同的序列化格式2.开放世界假设不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。"}
{"text": "也就是说，RDF的开放性特点和要求。"}
{"text": "（IBM-图谱里的知识有可能是不完备的，这符合Web讲座只有一位讲者。"}
{"text": "换一个角度，（IBM-Talk,speaker,Jeff）并不意味着Talk,speaker,Jeff）意味着IBM讲座至少有一位讲者。"}
{"text": "采用开放世界假设意味着RDF图谱可以被分布式储存，如图2-11所示。"}
{"text": "IBM图2-11RDF图谱可以被分布式储存同时，分布式定义的知识可以自动合并，如图2-12所示。"}
{"text": "图2-12分布式定义的知识可以自动合并3.RDFS简介RDF用到了类以及属性描述个体之间的关系。"}
{"text": "这些类和属性由模式（schema）定义。"}
{"text": "RDF_Schema（RDF模式，简称RDFS）提供了对类和属性的简单描述，从而给RDF数据提供词汇建模的语言。"}
{"text": "更丰富的定义则需要用到OWL本体描述语言。"}
{"text": "RDFS提供了最基本的对类和属性的描述元语：●rdf:type ：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。"}
{"text": "举例来说，下面的三元组表示用户自定义的元数据Author是Dublin_Core的元数据Creator的子类，如图2-13所示。"}
{"text": "RDF_Schema通过这样的方式描述不同词汇集的元数据之间的关系，从而为网络上统一格式的元数据交换打下基础。"}
{"text": "下面用图2-14说明RDFS，为了简便，边的标签省略了RDF或者RDFS。"}
{"text": "知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。"}
{"text": "图2-13Author是Creator的子类图2-14RDFS示例2.3.2OWL和OWL2Fragments前面介绍了RDF和RDFS，通过RDF（S）可以表示一些简单的语义，但在更复杂的场景下，RDF（S）语义的表达能力显得太弱，还缺少常用的特征：（1）对于局部值域的属性定义。"}
{"text": "RDF（S）中通过rdfs:range定义了属性的值域，该值域是全局性的，无法说明该属性应用于某些具体的类时具有的特殊值域限制，如无法声明父母至少有一个孩子。"}
{"text": "（2）类、属性、个体的等价性。"}
{"text": "RDF（S）中无法声明两个类或多个类、属性和个体是等价还是不等价，如无法声明Tim-Berns_Lee和T.B.Lee是同一个人。"}
{"text": "（3）不相交类的定义。"}
{"text": "在RDF（S）中只能声明子类关系，如男人和女人都是人的子类，但无法声明这两个类是不相交的。"}
{"text": "（4）基数约束。"}
{"text": "即对某属性值可能或必需的取值范围进行约束，如说明一个人有双亲（包括两个人），一门课至少有一名教师等。"}
{"text": "（5）关于属性特性的描述。"}
{"text": "即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。"}
{"text": "为了得到一个表达能力更强的本体语言，W3C提出了OWL语言扩展RDF（S），作为在语义网上表示本体的推荐语言。"}
{"text": "W3C于2002年7月31日发布了OWL_Web_本体语言（OWL_Web_Ontology_Language）工作草案的细节，是为了更好地开发语义网。"}
{"text": "1.OWL的语言特征如图2-15所示，OWL1.0有OWL_Lite、OWL_DL、OWL_Full三个子语言，三个子语言的特征和使用限制举例如表2-4所示。"}
{"text": "图2-15OWL_1.0的主要子语言表2-4三个子语言的特征和使用限制举例可以采用以下原则选择这些语言：●选择OWL_Lite还是OWL_DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；●选择OWL_DL还是OWL_Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；●当使用OWL_Full而不是OWL_DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL_Full的系统实现。"}
{"text": "OWL的子语言与RDF有以下关系。"}
{"text": "首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。"}
{"text": "2.OWL的重要词汇（1）等价性声明。"}
{"text": "声明两个类、属性和实例是等价的。"}
{"text": "如：exp：运动员owl:equivalentClass_exp：体育选手exp：获得_owl:equivalentProperty_exp：取得exp：运动员A_owl:sameIndividualAs_exp：小明以上三个三元组分别声明了两个类、两个属性以及两个个体是等价的，exp_是命名空间_http://www.example.org_的别称，命名空间是唯一识别的一套名字，用来避免名字冲突，在OWL中可以是一个URL。"}
{"text": "（2）属性传递性声明。"}
{"text": "声明一个属性是传递关系。"}
{"text": "例如，exp:ancestor_rdf:typeowl:TransitiveProperty指的是exp:ancestor_是一个传递关系。"}
{"text": "如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。"}
{"text": "例如exp：小明exp:ancestor_exp：小林；exp：小林_exp:ancestor_exp：小志，根据上述声明，可以推出exp：小明exp:ancestor_exp：小志。"}
{"text": "（3）属性互逆声明。"}
{"text": "声明两个属性有互逆的关系。"}
{"text": "例如，exp:ancestor_owl:inverseOfexp:descendant指的是exp:ancestor和exp:descendant是互逆的。"}
{"text": "如果exp：小明exp:ancestor_exp：小林，根据上述声明，可以推出exp：小林_exp:descendant_exp：小明。"}
{"text": "（4）属性的函数性声明。"}
{"text": "声明一个属性是函数。"}
{"text": "例如，exp:hasMother_rdf:typeowl:FunctionalProperty指的是exp:hasMother是一个函数，即一个生物只能有一个母亲。"}
{"text": "（5）属性的对称性声明。"}
{"text": "声明一个属性是对称的。"}
{"text": "例如rdf:typeowl:SymmetricProperty指的是exp:friend是一个具有对称性的属性；如果exp：小明exp:friendexp：小林，根据上述声明，有exp：小林_exp:friend_exp：小明。"}
{"text": "exp:friend （6）属性的全称限定声明。"}
{"text": "声明一个属性是全称限定。"}
{"text": "如：exp:Person_owl:allValuesFrom_exp:Womenexp:Person_owl:onProperty_exp:hasMother这个说明exp:hasMother_在主语属于exp:Person类的条件下，宾语的取值只能来自exp:Women类。"}
{"text": "（7）属性的存在限定声明。"}
{"text": "声明一个属性是存在限定。"}
{"text": "如：exp:SemanticWebPaper_owl:someValuesFrom_exp:AAAIexp:SemanticWebPaper_owl:onProperty_exp:publishedIn这个说明exp:publishedIn在主语属于exp:SemanticWebPaper类的条件下，宾语的取值部分来自exp:AAAI类。"}
{"text": "上面的三元组相当于：关于语义网的论文部分发表在AAAI上。"}
{"text": "（8）属性的基数限定声明。"}
{"text": "声明一个属性的基数。"}
{"text": "如：exp:Person_owl:cardinality “1”^^xsd:integerexp:Person_owl:onProperty_exp:hasMother指的是exp:hasMother在主语属于exp:Person类的条件下，宾语的取值只能有一个，“1”的数据类型被声明为xsd:integer，这是基数约束，本质上属于属性的局部约束。"}
{"text": "（9）相交的类声明。"}
{"text": "声明一个类是等价于两个类相交。"}
{"text": "如：exp:Mother_owl:intersectionOf_tmp_tmp_rdf:type_rdfs:Collection_tmp_rdfs:member_exp:Person_tmp_rdfs:member_exp:HasChildren指tmp是临时资源，它是exp:Person和exp:HasChildren两个类的交集。"}
{"text": "exp:HasChildren。"}
{"text": "上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。"}
{"text": "表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。"}
{"text": "OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。"}
{"text": "OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。"}
{"text": "OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。"}
{"text": "它的查询复杂度是AC0，非常适合大规模处理。"}
{"text": "它是基于描述逻辑DL-Lite定义的。"}
{"text": "表2-6给出了OWL_2_QL词汇总结。"}
{"text": "表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。"}
{"text": "与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。"}
{"text": "OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。"}
{"text": "表2-7给出了OWL_2_QL词汇总结。"}
{"text": "表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female ⊓ ∃likes.Movie ⊓ ∃hasSon.(Student ⊓ ∃attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。"}
{"text": "下面给出一个例子。"}
{"text": "假设有一个本体，包含以下公理：公理1.Apple ⊑ ∃beInvestedBy.(Fidelity ⊓BlackStone)：苹果由富达和黑石投资。"}
{"text": "公理2.∃beFundedBy.Fidelity ⊑ InnovativeCompanies：借助富达融资的公司都是创新企业。"}
{"text": "公理3.∃beFundedBy.BlackStone⊑InnovativeCompanies：借助黑石融资的公司都是创新企业。"}
{"text": "公理4.beInvestedBy ⊑ beFundedBy：投资即是帮助融资。"}
{"text": "由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。"}
{"text": "还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。"}
{"text": "OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。"}
{"text": "OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。"}
{"text": "下面给出两个OWL_2_RL上的推理规则：p_rdfs:domain_x,spo⇒s_rdf:type_xp_rdfs:range_x,spo⇒o_rdf:type_x其中，s、p、o、x为变量。"}
{"text": "第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。"}
{"text": "第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。"}
{"text": "例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。"}
{"text": "OWL_2_RL允许的核心词汇有：●rdfs:subClassOf；●rdfs:subPropertyOf；●rdfs:domain；●rdfs:range；●owl:TransitiveProperty；●owl:FunctionalProperty；●owl:sameAs；●owl:equivalentClass；●owl:equivalentProperty；●owl:someValuesFrom；●owl:allValuesFrom。"}
{"text": "OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。"}
{"text": "2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。"}
{"text": "1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。"}
{"text": "下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。"}
{"text": "2.常见的SPARQL查询算子（1）OPTIONAL。"}
{"text": "可选算子，指的是在这个算子覆盖范围的查询语句是可选的。"}
{"text": "例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。"}
{"text": "OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。"}
{"text": "（2）FILTER。"}
{"text": "过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。"}
{"text": "例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。"}
{"text": "（3）UNION。"}
{"text": "并算子，指的是将两个查询的结果合并起来。"}
{"text": "例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。"}
{"text": "注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。"}
{"text": "需要注意UNION和OPTIONAL的区别。"}
{"text": "下面给出一个SPARQL查询的例子。"}
{"text": "给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。"}
{"text": "表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。"}
{"text": "假设有下面两条规则：hold_share（X, Y）:- control（X, Y）conn_trans（Y,Z）:- hold_share（X, Y）, hold_share（X, Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。"}
{"text": "通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。"}
{"text": "2.3.4语义Markup表示语言语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。"}
{"text": "被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5MicroData。"}
{"text": "1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。"}
{"text": "JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。"}
{"text": "JSON-LD的语法和JSON兼容。"}
{"text": "JSON-LD处理算法和API（JSON-LD_Processing_Algorithms_and_API）描述了处理JSON-LD数据所需的算法及编程接口，通过这些接口可以在JavaScript、Python及Ruby等编程环境中直接对JSON-LD文档进行转换和处理。"}
{"text": "下面是一个简单的JSON例子：JSON文档表示一个人。"}
{"text": "人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。"}
{"text": "当然，机器不理解“name”和“image”这样的术语。"}
{"text": "JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。"}
{"text": "如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。"}
{"text": "例如，每个数据集不应该围绕“name”重复发明概念。"}
{"text": "但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。"}
{"text": "Stores），而是以简2.RDFaRDFa（Resource_Description_Framework_in_attributes）是一种早期网页语义标记语言。"}
{"text": "RDFa也是W3C推荐标准。"}
{"text": "它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。"}
{"text": "与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。"}
{"text": "RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。"}
{"text": "上面的代码示例中用到了RDFa属性中的about属性和property属性。"}
{"text": "这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。"}
{"text": "RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。"}
{"text": "3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。"}
{"text": "微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。"}
{"text": "微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。"}
{"text": "下面是一个HTML5Microdata的示例。"}
{"text": "这个例子给出了Person类下一个叫Andy的人的照片和URL地址。"}
{"text": "通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。"}
{"text": "2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。"}
{"text": "这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。"}
{"text": "这里以三个最典型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。"}
{"text": "为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。"}
{"text": "2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。"}
{"text": "“Object”代表实体。"}
{"text": "每一个“Object”有唯一的 （Machine_ID）。"}
{"text": "一个“Object”可以有一个或多个“Types”。"}
{"text": "“Properties”用来描述“Facts”。"}
{"text": "例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。"}
{"text": "这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。"}
{"text": "Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。"}
{"text": "type如图2-16所示，示例的CVT描述了关于Obama的任职期限的多元关系“government_position_held”。"}
{"text": "这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。"}
{"text": "一个CVT就是有唯一MID的Object，也可以有多个Types。"}
{"text": "为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。"}
{"text": "图2-16Freebase的知识表示结构示例2.4.2WikidataWikidata的知识表示框架主要包含如下要素：页面-Pages、实体-Entities、条目-Items、属性-Properties、陈述-Statements、修饰-Qualifiers、引用-Reference等。"}
{"text": "Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。"}
{"text": "Entities类似于OWL:Things，代指最顶层的对象。"}
{"text": "每一个Entity都有一个独立的维基页面。"}
{"text": "Entities主要有两类：Items和Properties。"}
{"text": "Items类似于RDF中的Instance，代指实例对象。"}
{"text": "Properties和Statements分别等价于RDF中的Property和Statement。"}
{"text": "通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。"}
{"text": "每个Entities有多个Statements。"}
{"text": "一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。"}
{"text": "修饰-Qualifiers用于处理复杂的多元表示。"}
{"text": "如一个陈述“spouse:Jane_Belson”描述了一个二元关系。"}
{"text": "可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate: 25_November_1991” and “end_date: 11_May_2011”等。"}
{"text": "引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。"}
{"text": "引用也是一种Qualifiers，通常添加到Statements的附加信息中。"}
{"text": "Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。"}
{"text": "Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。"}
{"text": "Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。"}
{"text": "PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。"}
{"text": "PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth, but_it_is_unknown_to_us”这样的知识。"}
{"text": "of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。"}
{"text": "其中，<id>可以是一个Property，如P234。"}
{"text": "2.4.3ConceptNet5ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-Phrases、断言-Assertions、关系-Relations、边-Edges。"}
{"text": "Concepts由Words或Phrases组成，构成了图谱中的节点。"}
{"text": "与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。"}
{"text": "Assertions描述了Concepts之间的关系，类似于RDF中的Statements。"}
{"text": "Edges类似于RDF中的Property。"}
{"text": "一个Concepts包含多条边，而一条边可能有多个产生来源。"}
{"text": "例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。"}
{"text": "来源越多，该断言就越可靠。"}
{"text": "ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。"}
{"text": "ConceptNet5示例如图2-17所示。"}
{"text": "ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。"}
{"text": "on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。"}
{"text": "URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。"}
{"text": "例如“run”是一个动词，但也可能是一个名词（如basement比赛中一个“run”），其URI为：“/c/en/run/n/basement”。"}
{"text": "其中，n代指这是一个名词，basement用于区分歧义。"}
{"text": "在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。"}
{"text": "图2-18ConceptNet5的知识表示结构2.5知识图谱的向量表示方法与前面所述的表示方法不同的是，本节要描述的方法是把知识图谱中的实体和关系映射到低维连续的向量空间，而不是使用基于离散符号的表达方式。"}
{"text": "2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。"}
{"text": "在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。"}
{"text": "虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。"}
{"text": "知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。"}
{"text": "在基于网络结构的知识图谱上进行相关应用时，因为图结构的特殊性，应用算法的使用与图算法有关，相关算法具有较高的复杂度，面对大规模的知识库很难扩展。"}
{"text": "数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。"}
{"text": "从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。"}
{"text": "2.5.2词的向量表示方法在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。"}
{"text": "在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。"}
{"text": "知识图谱中的向量表示方法也在此次有所借鉴。"}
{"text": "1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。"}
{"text": "对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。"}
{"text": "如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。"}
{"text": "这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。"}
{"text": "2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"}
{"text": "该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。"}
{"text": "具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。"}
{"text": "如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。"}
{"text": "图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。"}
{"text": "产生词向量的手段主要有三种：●Count-based。"}
{"text": "基于计数的方法，简单说就是记录文本中词的出现次数。"}
{"text": "●Predictive。"}
{"text": "基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。"}
{"text": "●Task-based。"}
{"text": "基于任务的，也就是通过任务驱动的方法。"}
{"text": "通过对词向量在具体任务上的表现效果对词向量进行学习。"}
{"text": "对词向量的产生方法到现在为止有较多的研究，在本章中并不展开讨论，下面简单介绍经典的开源工具word2vec[8]中包含的CBoW和Skip-gram两个模型。"}
{"text": "CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。"}
{"text": "其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。"}
{"text": "如图2-21（a）所示，其中wn是中心词， wn−2,wn−1,wn+1,wn+2为该中心词的上下文的词。"}
{"text": "将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。"}
{"text": "整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。"}
{"text": "Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。"}
{"text": "如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。"}
{"text": "图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。"}
{"text": "vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。"}
{"text": "通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。"}
{"text": "这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。"}
{"text": "图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome, is-capital-of, Italy）和（Paris, is-capital-of, France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。"}
{"text": "2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。"}
{"text": "对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。"}
{"text": "把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph （Representation_Learning）、知识表示学习。"}
{"text": "Embedding）、知识图谱的向量表示、知识图谱的表示学习类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。"}
{"text": "在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。"}
{"text": "类似于词向量，经典的知识图谱嵌入模型TransE的设计思想就是，如果一个三元组（h, r, t）成立，那么它们需要符合h+r ≈ t关系，例如：vec（Rome）+vec（is−capital−of）≈vec（Italy）所以，在知识图谱嵌入的学习过程中，不同的模型从不同的角度把相应的语义信息嵌入知识图谱的向量表示中，如图2-23所示。"}
{"text": "图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。"}
{"text": "使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。"}
{"text": "增加了下游应用设计的多样性。"}
{"text": "用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。"}
{"text": "因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。"}
{"text": "将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。"}
{"text": "如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。"}
{"text": "2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。"}
{"text": "对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。"}
{"text": "所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。"}
{"text": "这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。"}
{"text": "根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。"}
{"text": "1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。"}
{"text": "这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。"}
{"text": "受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。"}
{"text": "也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。"}
{"text": "TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。"}
{"text": "也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。"}
{"text": "2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。"}
{"text": "该方向的模型主要是RESCAL[13]以及它的延伸模型。"}
{"text": "RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。"}
{"text": "由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。"}
{"text": "其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。"}
{"text": "但因为是对角矩阵，所以存在h⊺diag（r）t=t⊺diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。"}
{"text": "ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。"}
{"text": "也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。"}
{"text": "3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。"}
{"text": "实体类型是一种容易考虑的额外信息。"}
{"text": "在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。"}
{"text": "最简单的考虑实体类型的方法是在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如（Rome,IsA,city）（Italy,IsA,Country）这样的三元组。"}
{"text": "当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。"}
{"text": "也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。"}
{"text": "关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is−capital−of,Italy）（Italy,is−country−of,Europe）.从Rome到Europe的关系路径就是一条is−capital−of→is−country−of关系链。"}
{"text": "当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。"}
{"text": "在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+⋯+rlp=r1∙r2∙⋯∙rlci=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。"}
{"text": "对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。"}
{"text": "文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。"}
{"text": "除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。"}
{"text": "Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。"}
{"text": "其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。"}
{"text": "联合模型在训练时降低来自三个子模型的损失之和。"}
{"text": "图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）说明了两个不同的关系之间的关系。"}
{"text": "Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。"}
{"text": "简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。"}
{"text": "2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。"}
{"text": "本小节将简单介绍一些典型的应用。"}
{"text": "1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。"}
{"text": "简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全任务，被称为链接预测。"}
{"text": "当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。"}
{"text": "例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。"}
{"text": "链接预测也常被用于评测知识图谱嵌入。"}
{"text": "一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。"}
{"text": "2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。"}
{"text": "这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。"}
{"text": "3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。"}
{"text": "该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。"}
{"text": "一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。"}
{"text": "也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。"}
{"text": "4.问答系统利用知识图谱完成问答系统是该任务的一个研究方向，该任务的重心是对某一个具体的通过自然语言表达的问题，使用知识图谱中的三元组对其进行回答，如下：A: Where_is_the_capital_of_Italy？Q: Rome（Rome, is-capital-of, Italy）A: Who_is_the_president_of_USA？Q: Donald_Trump（Donald_Trump, is-president-of, USA）文献[9]介绍了一种借助知识图谱嵌入完成该问题的方法。"}
{"text": "简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。"}
{"text": "S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））⊺（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。"}
{"text": "简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。"}
{"text": "当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。"}
{"text": "5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。"}
{"text": "协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。"}
{"text": "在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。"}
{"text": "例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。"}
{"text": "2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。"}
{"text": "目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。"}
{"text": "除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。"}
{"text": "最后，介绍了知识图谱的嵌入式方法。"}
