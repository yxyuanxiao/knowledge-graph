{"text": "知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。"}
{"text": "本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。"}
{"text": "6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。"}
{"text": "6.4节将介绍知识图谱推理的最新进展，分别从时序预测、强化学习、元学习以及图神经网络的角度出发，并以最新发表的论文为例进行分析。"}
{"text": "希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。"}
{"text": "6.1.1什么是推理；推理在人类长期的社会发展和演变中扮演着重要的角色，包含了思考、认知和理解，是认知世界的重要途径。"}
{"text": "具体来说，推理是通过已有知识推断出未知知识的过程。"}
{"text": "推理的方法大致可以分为逻辑推理和非逻辑推理，其中逻辑推理的过程包含了严格的约束和推理过程，而非逻辑推理的过程相对模糊。"}
{"text": "逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。"}
{"text": "逻辑推理按照推理方式的不同包含两大类：演绎推理（Deductive_Reasoning）和归纳推理（Inductive_Reasoning）。"}
{"text": "其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。"}
{"text": "下面先介绍这四种基本的推理。"}
{"text": "演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。"}
{"text": "典型的演绎推理有肯定前件假言推理、否定后件假言推理（Modus_Tollens）以及三段论（Law_of_Syllogism）。"}
{"text": "在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。"}
{"text": "其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。"}
{"text": "例如，通过假言命题“如果今天是星期二（前件）。"}
{"text": "那么小明会去上班（后件）”以及性质命题“今天是星期二”，能推理出“小明会去上班”。"}
{"text": "而否定后件假言推理是指性质命题否定了假言命题的后件，从而推理出否定的假言前件。"}
{"text": "例如，通过前文的假言命题和性质命题“小明不会去上班”，能推出“今天不是星期二”。"}
{"text": "在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。"}
{"text": "例如，给定两个假言命题“如果小明生病了，那么小明会缺席”以及“如果小明缺席了，他将错过课堂讨论”，可以推理出“如果小明生病了，他将错过课堂讨论”。"}
{"text": "从以上的例子可以看出，演绎推理是一种形式化的逻辑推理。"}
{"text": "归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。"}
{"text": "例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。"}
{"text": "典型的归纳推理有归纳泛化（Inductive_Generalization）、统计推理（StatisticalSyllogism）。"}
{"text": "归纳泛化是指基于对个体的观察而得出可能适用于整体的结论，即在整体的一些样本中得到的结论可以泛化到整体上。"}
{"text": "例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。"}
{"text": "可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。"}
{"text": "而统计推理是将整体的统计结论应用于个体。"}
{"text": "例如，经统计，90%就读于某高中的同学都上了大学，如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。"}
{"text": "归纳推理是一种非形式化的推理，是由具体到一般的推理过程。"}
{"text": "它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。"}
{"text": "但在演绎推理中，如果前提均为真，那么一定可以推理得到结论也为真。"}
{"text": "溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。"}
{"text": "例如，当一个病人显示出某种病症，而造成这个病症的原因可能有很多时，寻找在这个病人例子里最可能的原因的过程就是溯因推理。"}
{"text": "在溯因推理中，要使基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。"}
{"text": "例如，我们知道下雨了马路一定会湿（T），如果观察到马路是湿的（O），可以通过溯因推理得到很大概率是因为下雨了（E）。"}
{"text": "溯因推理是归纳推理的一种，因为整个推理过程的前提和结论并没有必然的关系。"}
{"text": "类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。"}
{"text": "例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。"}
{"text": "由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。"}
{"text": "例如在上例中，如果歌手C和歌手A、歌手B完全不是一种类型或一个领域的歌手，那么小明喜欢歌手C与他喜欢歌手A和歌手B是完全无关的，所以将“喜欢歌手C”的结论应用到小红身上不合适。"}
{"text": "造成不当类比的原因有很多，包括类比事物不相干、类比理由不充分以及类比预设不当等。"}
{"text": "尽管类比推理的结论相较于前面介绍的三种推理得到的结论错误率更高，但类比推理依然是一种普遍存在的推理方式。"}
{"text": "除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。"}
{"text": "例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。"}
{"text": "又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。"}
{"text": "从推理过程精确性来看，又可分为精确推理和模糊推理。"}
{"text": "不同的研究领域也有各自的推理问题。"}
{"text": "例如，在自然语言处理领域，典型的问题是自然语言推理（Natutal_Language_Inference)，其任务判断两个给定句子的蕴涵关系，给定的两个句子一个前提（Premise），一个是假设结论（Hypothsis），目标是判断在给定前提句子的情况下是否可以推理出假设结论的句子。"}
{"text": "答案分为三种，包括：表示假设结论句子和前提句子矛盾的“冲突（Contradiction）”、表示可以由前提句子推出假设结论句子的“蕴涵（Entailment）”以及表示前提句子和假设结论既不冲突也不蕴涵的“中立（Neutral）”。"}
{"text": "例如，前提句子“正在进行一场男子足球比赛”和假设结论句子“几个男运动员们在打比赛”应判断为“蕴涵”，而前提句子“两个小女孩在笑”和结论句子“两个小女孩因为这周末要去游乐场很开心”应判断为“中立”，将“一个男子沉睡在梦乡”和“男子眨了眨眼睛”判断为“冲突”。"}
{"text": "在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。"}
{"text": "例如，给定一个包含多个不同色彩、不同形状的几何体图片，回答问题“图中最小的正方体右边的几何体是什么颜色”。"}
{"text": "在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。"}
{"text": "6.1.2面向知识图谱的推理面向知识图谱的推理主要围绕关系的推理展开，即基于图谱中已有的事实或关系推断出未知的事实或关系[5]，一般着重考察实体、关系和图谱结构三个方面的特征信息。"}
{"text": "如图6-1所示为人物关系图推理，利用推理可以得到新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。"}
{"text": "具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。"}
{"text": "图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。"}
{"text": "将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。"}
{"text": "即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。"}
{"text": "由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。"}
{"text": "知识图谱中的三元组可以通过人工定义得到，也可以通过文本抽取得到。"}
{"text": "由于人工知识的局限性以及算法的不确定性，一个知识图谱中不可避免地会存在冲突的信息，所以不一致性检测也是知识图谱中重要的推理任务，即检测知识图谱中有冲突或不正确的事实。"}
{"text": "存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。"}
{"text": "知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。"}
{"text": "以演绎推理为核心的知识图谱推理主要是基于描述逻辑、DataLog等进行的，而以归纳推理为核心的知识图谱推理主要是围绕对知识图谱图结构的分析、对知识图谱中元素的表示学习、利用图上搜索和分析进行规则学习以及应用强化学习方法等进行的。"}
{"text": "下面分别从这两类展开，介绍不同的推理实现方法。"}
{"text": "6.2基于演绎的知识图谱推理6.2.1本体推理1.本体与描述逻辑概述演绎推理的过程需要明确定义的先验信息，所以基于演绎的知识图谱推理多围绕本体展开。"}
{"text": "本体的一般定义为概念化的显示规约，它给不同的领域提供共享的词汇。"}
{"text": "因为共享的词汇需要赋予一定的语义，所以基于演绎的推理一般都在具有逻辑描述基础的知识图谱上展开。"}
{"text": "对于逻辑描述的规范，W3C提出了OWL。"}
{"text": "OWL按表达能力从低到高划分成OWL_Lite、OWL_DL和OWL_Full。"}
{"text": "OWL_Lite和OWL_DL在语义上等价于某些描述逻辑（Description_Logics,DLs）[14,15]，而OWL_Full没有对应的描述逻辑。"}
{"text": "2009年，为了适应更多应用的需求，W3C组织又提出了OWL的新版本OWL_2[15]。"}
{"text": "与OWL不同，OWL_2仅有对应的Full和DL层次。"}
{"text": "OWL_2_Full比OWL_Full的表达能力更强，同样没有对应的描述逻辑。"}
{"text": "而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。"}
{"text": "为了适应高效的应用需求，W3C组织从OWL_2中分裂出三种易处理的剖面OWL_2_EL、OWL_2_QL和OWL_2RL。"}
{"text": "这些剖面都有对应的描述逻辑。"}
{"text": "表6-1总结了OWL成员与描述逻辑之间的对应关系。"}
{"text": "目前，OWL是知识图谱语言中最规范、最严谨、表达能力最强的语言，而且OWL基于RDF语法，使表示出来的文档具有语义理解的结构基础，OWL的另外一个作用是促进了统一词汇表的使用，定义了丰富的语义词汇。"}
{"text": "表6-1OWL成员与描述逻辑之间的对应关系基于OWL的模型论语义，在丰富逻辑描述的知识图谱中，除了包含实体和二元关系，还包含了许多更抽象的信息，例如描述实体类别的概念以及关系之间的从属信息等。"}
{"text": "从而有一系列实用有趣的推理问题，包括：（1）概念包含。"}
{"text": "判定概念C是否为D的子概念，即C是否被D包含。"}
{"text": "例如，在包含公理Mother⊑Women和Women⊑Person的本体中，可以判定Mother⊑Person成立。"}
{"text": "（2）概念互斥。"}
{"text": "判定两个概念C和D是否互斥，即不相交。"}
{"text": "需要判定C⊓D⊑⊥是否为给定知识库的逻辑结论。"}
{"text": "例如，在包含Man⊓Women⊑⊥的本体中，概念Man和Women是互斥的。"}
{"text": "（3）概念可满足。"}
{"text": "判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。"}
{"text": "例如，包含公理Eternity⊑⊥的本体中，概念Eternity是不可满足概念。"}
{"text": "（4）全局一致。"}
{"text": "判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。"}
{"text": "例如，包含公理Man⊓Women⊑⊥、Man（Allen）和Women（Allen）的本体是不一致的。"}
{"text": "（5）TBox一致。"}
{"text": "判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。"}
{"text": "例如，包含公理Man⊓Women⊑⊥、Professor⊑Man和Professor⊑Women的TBox是不一致的。"}
{"text": "（6）实例测试。"}
{"text": "判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。"}
{"text": "（7）实例检索。"}
{"text": "找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。"}
{"text": "2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。"}
{"text": "基于表运算的推理方法通过一系列规则构建Abox，以检测可满足性，或者检测某一实例是否存在某概念，基本思想类似于一阶逻辑的归结反驳。"}
{"text": "以一个例子阐述该方法的基本思想。"}
{"text": "假设知识库K由以下三个声明构成：将以a作为实例的所有概念的集合记作L(a)。"}
{"text": "我们使用L←C表示通过加入C进行更新。"}
{"text": "例如，如果=｛D｝而且通过←C来对进行更新，那么将变成{C,D}。"}
{"text": "在给出的例子中，不经推导可以得到。"}
{"text": "TBox声明C⊑D与等价。"}
{"text": "因此，通过，得到，得到了矛盾，这表明K是不一致的。"}
{"text": "在上面例子中构建的东西实质上是表的一部分。"}
{"text": "表是表达知识库逻辑结论的一种结构化方法。"}
{"text": "如果在表构建过程中出现矛盾，那么知识库是不一致的。"}
{"text": "以描述逻辑为例，在初始情况下，是原始的Abox，迭代运用如下规则：其中，y是新加进来的个体。"}
{"text": "给定包含如下公理和断言的本体：Man⊓Women⊑⊥,Man(Allen)，检测实例Allen是否Woman_Woman(Allen)，根据⊓−−规则，在Man⊓Women（Allen）加入中，再通过⊑−规则得到⊥(Allen)，这样就得到了一个矛盾，中。"}
{"text": "首先，加入待反驳的结论所以拒绝现在的，即Allen不在Woman中。"}
{"text": "为了提高Tableaux算法的效率，研究者提出了不少优化技术[20-22]，使该算法对于中小型描述逻辑知识库的推理达到了实用化的程度。"}
{"text": "目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。"}
{"text": "目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。"}
{"text": "虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。"}
{"text": "例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。"}
{"text": "因此，如何为SHOIN等强表达力的描述逻辑设计最优组合复杂度的Tableaux算法仍有待研究。"}
{"text": "3.常用本体推理工具简介（1）FaCT++。"}
{"text": "FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。"}
{"text": "Java版本名为Jfact，基于OWL_API。"}
{"text": "构建推理机采用下面的代码：采用以下代码对本体进行分类：（2）Racer。"}
{"text": "Racer是美国Franz_Inc.公司开发的以描述逻辑为基础的本体推理机，也可以用作语义知识库，支持OWL_DL，支持部分OWL_2_DL并且支持单机和客户端/服务器两种模式，用Allegro_Common_Lisp实现。"}
{"text": "以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。"}
{"text": "Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。"}
{"text": "构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。"}
{"text": "HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。"}
{"text": "构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。"}
{"text": "表6-2本体推理工具总结6.2.2基于逻辑编程的推理方法1.逻辑编程与Datalog简介逻辑编程是一族基于规则的知识表示语言。"}
{"text": "与本体推理相比，规则推理有更大的灵活性。"}
{"text": "本体推理通常仅支持预定义的本体公理上的推理，而规则推理可以根据特定的场景定制规则，以实现用户自定义的推理过程。"}
{"text": "逻辑编程是一个很大的研究领域，在工业界应用广泛。"}
{"text": "逻辑编程也可以与本体推理相结合，集合两者的优点。"}
{"text": "逻辑编程的研究始于Prolog语言[24,25]，后来由ISO标准化。"}
{"text": "Prolog在多种系统中被实现，例如SWI-Prolog、Sicstus_Prolog、GNU_Prolog和XSB。"}
{"text": "Prolog在早期的人工智能研究中应用广泛，多用于实现专家系统。"}
{"text": "在通常情况下，Prolog程序是通过SLD消解和回溯来执行的[25]。"}
{"text": "运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。"}
{"text": "在程序存在递归的情况下，有可能出现运行无法终止的情况。"}
{"text": "为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。"}
{"text": "从语法上来说，Datalog程序基本上是Prolog的一个子集。"}
{"text": "它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。"}
{"text": "在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。"}
{"text": "读者可参考文献[26]获得更多关于逻辑程序的相关介绍。"}
{"text": "2.Datalog语言Datalog语言是一种面向知识库和数据库设计的逻辑语言。"}
{"text": "便于撰写规则，实现推理。"}
{"text": "Datalog与OWL的关系如图6-2所示，其中OWL_RL和RDFS处于OWL和Datalog的交集之中。"}
{"text": "OWL_RL的设计目标之一就是找出可以用规则推理来实现的一个OWL的片段。"}
{"text": "图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。"}
{"text": "常量通常用小写字母a、b、c表示一个具体的实例。"}
{"text": "变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。"}
{"text": "项（term）包括常量和变量。"}
{"text": "原子（atom）形如p(t1,…,tn），其中p是一个谓词，t1,…,tn为项，n被称为p的元数。"}
{"text": "例如，假定has_child为一个二元谓词，原子has_child(X,Y)表示变量X和Y有has_child的关系，而原子has_child(jim,bob)表示常量jim和bob有has_child的关系。"}
{"text": "Datalog规则形如H:-B1,B2,…,Bm.其中，H,B1,B2,…,Bm为原子。"}
{"text": "H称为此规则的头部原子，B1,B2,…,Bm称为体部原子。"}
{"text": "规则的直观含义为：当体部原子都成真时，头部原子也应成真。"}
{"text": "例如，规则has_child(Y,X):-has_son(X,Y)表示当X和Y有has_son的关系时，则Y与X有has_child的关系。"}
{"text": "Datalog事实（fact）是形如F(c1,c2,…,cn):-的没有体部且没有变量的规则。"}
{"text": "事实也常写成“F(c1,c2,…,cn).”的形式。"}
{"text": "例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。"}
{"text": "Datalog程序是规则的集合。"}
{"text": "例如，下面的两条规则构成了一个Datalog程序：has_child(X,Y):-has_son(X,Y).has_child(Alice,Bob).3.Datalog推理举例下面的规则集表达了给定一个图，计算所有的路径关系，即节点X、Y之间是否联通：path(X,Y):-edge(X,Y).①path(X,Y):-path(X,Z),path(Z,Y).②节点X和Y联通有两种情况：①X、Y之间通过一条边（edge）直接连接；②存在一个节点Z，使得X、Z联通并且Z、Y联通。"}
{"text": "下面的三个事实表示了一个图中的三条边。"}
{"text": "edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。"}
{"text": "例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。"}
{"text": "图6-3Datalog推理举例4.Datalog与知识图谱Datalog程序可以应用在知识图谱中进行规则推理。"}
{"text": "一个知识图谱可以自然地被看作一个事实集。"}
{"text": "只需人为引入一个特殊的谓词triple，每一个三元组(subject,property,object)便可以作为一个事实triple(subject,property,object)。"}
{"text": "另一种方法是按照描述逻辑ABox的方式来看待，即三元组(s,rdf:type,C)看作C(s)，其他的三元组(s,p,o)看作p(s,o)。"}
{"text": "这样一来，Datalog规则就可以作用于知识图谱上。"}
{"text": "下面介绍的三种语言SWRL、OWL_RL、RDFS与Datalog密切相关。"}
{"text": "（1）SWRL（Semantic_Web_Rule_Language）。"}
{"text": "SWRL是2004年提出的一个完全基于Datalog的规则语言。"}
{"text": "SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。"}
{"text": "SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。"}
{"text": "（2）OWL_RL。"}
{"text": "OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。"}
{"text": "（3）RDFS（RDF_Schema）。"}
{"text": "RDFS是W3C定义的一个基于RDF的轻量级的本体语言。"}
{"text": "RDFS的推理也可以用Datalog程序表示。"}
{"text": "RDFS的表达能力大体是OWL_RL的一个子集。"}
{"text": "5.基于Datalog的推理工具RDFox介绍目前，最主要的Datalog工具包括DLV[5]和Clingo[6]。"}
{"text": "这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。"}
{"text": "知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。"}
{"text": "Datalog相关工具总结如表6-3所示。"}
{"text": "下面简要介绍一下RDFox。"}
{"text": "表6-3Datalog相关工具总结RDFox是由牛津大学开发的可扩展、跨平台、基于内存的RDF三元组存储系统。"}
{"text": "其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。"}
{"text": "RDFox的架构如图6-4所示。"}
{"text": "RDFox的输入包括本体（TBox）、数据（ABox）和一个自定规则集。"}
{"text": "其核心为RDFox推理机，支持增量更新。"}
{"text": "图6-4RDFox的架构1.RDFox_Java_API使用方法（1）创建本体与存储（2）导入本体进行推理2.RDFox_Java_API使用举例下面用一个具体的例子介绍RDFox。"}
{"text": "假定有如图6-5所示的某金融领域相关的图。"}
{"text": "首先把它转换成一个知识图谱。"}
{"text": "对每一个实体，要创建一个IRI。"}
{"text": "为此引入命名空间finance：来表示http://www.example.org/kse/finance#。"}
{"text": "<http://www.example.org/kse/finance#孙宏斌>这个IRI就可以使用命名空间简写为“finance：孙宏斌”。"}
{"text": "图6-5某金融领域相关的图一个三元组例子为：finance：融创中国rdf:type_finance：地产事业本体（TBox）如下：●SubClassOf(PublicCompany,Company)//类PublicCompany是Company的子类●ObjectPropertyDomain(Control,Person)//属性Control的定义域是Person●ObjectPropertyRange(Control,Company)//属性Control的值域是Company此本体用RDF/XML的格式描述如下：数据（ABox）用Triple的语法，如下所示。"}
{"text": "自定义规则如下：1）执掌一家公司就一定是这家公司的股东。"}
{"text": "2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。"}
{"text": "用Datalog形式化，写成SWRL规则，具体如下：下面演示如何使用代码（Java）数据读取本体、数据，声明规则并进行推理。"}
{"text": "读取本体、数据，声明规则。"}
{"text": "推理，定义命名空间与查询操作（用于输出当前三元组）。"}
{"text": "将结果输出为结合规则推理的所有三元组实例化。"}
{"text": "6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。"}
{"text": "考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。"}
{"text": "第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。"}
{"text": "在OMQ下，查询重写的任务是将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。"}
{"text": "第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。"}
{"text": "在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。"}
{"text": "映射的标准语言为W3C的R2RML语言。"}
{"text": "OMQ可以看作OBDA的特殊情况，即每个本体中谓词的实例都存储在一个特定的对应表中，而映射只是一个简单的同构关系。"}
{"text": "以下着重介绍OBDA。"}
{"text": "1.OBDA框架OBDA框架包含外延（extensional）和内涵（intensional）两个部分。"}
{"text": "外延层为符合某个数据库架构（schema）S的一个源数据库D,S通常包括数据库表的定义和完整性约束。"}
{"text": "内涵层为一个OBDA规范P=（T,M,S），其中T是本体，S是数据源模式，M是从S到T的映射。"}
{"text": "这样OBDA的实例定义为外延层和内涵层的一个对I=(P,D)，其中P=(T,M,S)，且D符合S。"}
{"text": "用M(D)表示将映射M作用于数据库D上生成的知识图谱。"}
{"text": "给定这样一个OBDA实例I,OBDA的语义即定义为一个知识库(T,M(D))。"}
{"text": "OBDA的主要推理任务为查询。"}
{"text": "当查询时，本体T为用户提供了一个高级概念视图数据和方便的查询词汇，用户只针对T查询，而数据库存储层和映射层对用户完全透明。"}
{"text": "这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。"}
{"text": "OBDA有多种实现方式，最直接的方式是生成映射得到的知识图谱M(D)，然后保存到一个三元组存储库中，这种方式也称作ETL（Extract_Transform_Load)，优点是实现简单直接。"}
{"text": "但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。"}
{"text": "在此，我们更感兴趣的是虚拟OBDA的方式，此方式下的三元组并不需要被真正生成，而通过查询重写的方式来实现，OBDA将在本体层面的SPARQL查询重写为在原始数据库上的SQL查询。"}
{"text": "相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。"}
{"text": "为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。"}
{"text": "OBDA查询重写的流程如图6-6所示。"}
{"text": "给定一个OBDA实例I=(P,D)、P=(T,S,M)以及一个SPARQL查询q，通过重写回答查询的具体步骤为：（1）查询重写。"}
{"text": "对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。"}
{"text": "（2）查询展开。"}
{"text": "将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。"}
{"text": "（3）查询执行。"}
{"text": "将生成的SQL语句交给数据库引擎并执行。"}
{"text": "（4）结果转换。"}
{"text": "SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。"}
{"text": "为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂[29]。"}
{"text": "图6-6OBDA查询重写的流程2.查询重写举例（OMQ）假定有如下一个关于学校信息系统的本体T：查询q1=SELECT?teacherWHERE{?teacheraTeacher}试图查询所有的教师。"}
{"text": "通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。"}
{"text": "查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。"}
{"text": "可以先利用teaches的定义域和值域将q2优化为SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。"}
{"text": "可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。"}
{"text": "此数据库包含以下三个数据库表，其中下画线的列构成数据表的主键：同时，假设有如下的映射规则：利用这些映射，q1’可以被展开为：并进一步简化为：查询q2’可以展开为：并进一步简化为：查询q3’可以展开为：并进一步简化为：这些生成的SQL语句可以直接在原始的数据库上运行。"}
{"text": "4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。"}
{"text": "这些工具的功能对比如表6-4所示。"}
{"text": "表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。"}
{"text": "Ontop兼容RDFS、OWL_2_QL、R2RML、SPARQL标准，并支持主流关系数据库，如Oracle、MySQL、SQL_Server、PostgreSQL。"}
{"text": "Ontop的Protégé插件可以用于编辑映射和测试查询。"}
{"text": "RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。"}
{"text": "Ontop也提供Java_API。"}
{"text": "Mastro最初是由意大利罗马大学开发的OBDA系统，现在由OBDA_Systems商业化运行。"}
{"text": "此系统支持对OWL2_QL本体的推理。"}
{"text": "与此处提到的其他OBDA系统不同，它仅支持与合取查询相对应的SPARQL的受限片段。"}
{"text": "Ultrawrap是由Capsenta公司商业化的OBDA系统。"}
{"text": "它被扩展为支持对具有反向和传递属性的RDFS扩展的推断。"}
{"text": "Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。"}
{"text": "Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。"}
{"text": "Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。"}
{"text": "因此，它现在也可以归为OBDA系统。"}
{"text": "在v5版本中有了自己的OBDA实现。"}
{"text": "5.OBDA的应用OBDA在学术界和工业级有着广泛的应用，如石油与天然气领域，挪威国家石油公司[31]；涡轮发电机故障诊断，西门子[32]；数据集成解决方案，SIRIS_Academic_SLBarcellona[33]；日志流程挖掘，KAOS项目[34]；文化遗产，EPNet项目[35]；海事安全，EMSec项目[36]；制造业，工业4.0[37]；医疗保健，电子健康记录[38]；政务信息，意大利公共债务[39]；智慧城市，IBM爱尔兰[40]。"}
{"text": "限于篇幅，不展开讲解，有兴趣的读者可以查阅参考文献[41]。"}
{"text": "6.2.4基于产生式规则的方法1.产生式系统产生式系统是一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。"}
{"text": "产生式系统可以应用于自动规划和专家系统等领域。"}
{"text": "一个产生式系统由事实集合、产生式集合和推理引擎三部分组成。"}
{"text": "（1）事实集合。"}
{"text": "事实集合是运行内存（Working_Memory,WM）为事实（WME）的集合，用于存储当前系统中的所有事实。"}
{"text": "事实可描述对象，形如(typeattr_1:val_1attr_2:val_2…attr_n:val_n），其中type、attr_i、val_i均为原子（常量）。"}
{"text": "例如，(studentage:24)表示一个学生，姓名为Alice，年龄为24。"}
{"text": "事实也可描述关系name:\"Alice\"（Refication）。"}
{"text": "例如，(basicFactrelation:olderThanfirstArg:JohnsecondArg:Alice)表示John比Alice的年纪大，此事实也可简记为(olderThanJohnAlice)。"}
{"text": "（2）产生式集合。"}
{"text": "产生式集合（ProductionMemory,PM）由一系列的产生式组成。"}
{"text": "产生式形如：●IFconditionsTHENactions其中，conditions是由条件组成的集合，又称为LHS;actions是由动作组成的序列，又称为RHS。"}
{"text": "LHS是conditions的集合，各条件之间为且的关系。"}
{"text": "当LHS中所有条件均被满足时，触发规则。"}
{"text": "每个条件形如(typeattr_1:spec_1attr_2:spec_2…attr_n:spec_n）。"}
{"text": "其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。"}
{"text": "动作的种类有如下三种：●ADDpattern。"}
{"text": "向WM中加入形如pattern的WME。"}
{"text": "●REMOVEi。"}
{"text": "从WM中移除当前规则第i个条件匹配的WME。"}
{"text": "●MODIFYi(attrspec)。"}
{"text": "对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。"}
{"text": "例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。"}
{"text": "产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)⇒ADD(Personname:x)。"}
{"text": "（3）推理引擎。"}
{"text": "推理引擎用于控制系统的执行。"}
{"text": "产生式系统执行流程如图6-7所示。"}
{"text": "图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。"}
{"text": "用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。"}
{"text": "●选择规则。"}
{"text": "按一定的策略从被触发的多条规则中选择一条。"}
{"text": "●执行规则。"}
{"text": "执行被选择出来的规则的RHS，从而操作WM。"}
{"text": "模式匹配用每条规则的条件部分匹配当前的WM，如图6-8所示为匹配规则过程。"}
{"text": "规则为：（typexy）,(subClassOfyz)⇒ADD(typexz)。"}
{"text": "图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。"}
{"text": "目前，最流行的算法是Rete算法，在1979年由CharlesForgy提出[42]。"}
{"text": "其主要的想法为将产生式的LHS组织成判别网络形式，以实现用空间换时间的效果。"}
{"text": "下面用图6-9和图6-10解释Rete算法的形状。"}
{"text": "最主要的部分为α网络和β网络。"}
{"text": "α和β的名字来源于产生式规则常写成α⇒β的形式。"}
{"text": "α网络对应条件，检验并保存各个条件对应的WME集合。"}
{"text": "β网络对应结果，用于保存join的中间结果。"}
{"text": "图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。"}
{"text": "从被触发的规则中随机选择一条执行。"}
{"text": "注意在推理的场景下，被触发的多条规则可全被执行。"}
{"text": "●具体性（specificity）。"}
{"text": "选择最具体的规则，例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)⇒…(Studentname:age:20)⇒…●新近程度（recency）。"}
{"text": "选择最近没有被触发的规则执行动作。"}
{"text": "4.相关工具介绍表6-5为三个基于产生式规则的系统，它们都是基于Rete算法或其改进的。"}
{"text": "表6-5三个基于产生式规则的系统（1）Drools。"}
{"text": "Drools是一个商用规则管理系统，提供了一个规则推理引擎。"}
{"text": "核心算法是基于Rete算法的改进。"}
{"text": "提供规则定义语言，支持嵌入Java代码。"}
{"text": "Drools使用举例：创建容器与会话，如下：触发规则，如下：（2）Jena。"}
{"text": "Jena是一个用于构建语义网应用的Java框架。"}
{"text": "提供了处理RDF、RDFS、OWL数据的接口，还提供了一个规则引擎。"}
{"text": "提供三元组的内存存储于SPARQL、查询。"}
{"text": "Jena使用举例：创建模型，如下：创建规则推理机，如下：（3）GraphDB。"}
{"text": "GraphDB（原OWLIM）是一个可扩展的语义数据存储系统（基于RDF4J），其功能包含三元组存储、推理引擎、查询引擎，支持RDFS、OWL_DLP、OWL_Horst、OWL_2_RL等多种语言。"}
{"text": "6.3基于归纳的知识图谱推理随着技术的发展，越来越多的知识图谱自动化构建方法被提出来，例如利用算法对文本进行三元组抽取，这使得大规模知识图谱能够迅速被建立起来，例如NELL。"}
{"text": "但这类知识图谱的信息准确度稍差于利用专家知识人工构建的知识图谱，且冗余度较大。"}
{"text": "在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。"}
{"text": "基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。"}
{"text": "按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。"}
{"text": "下面分别介绍这三类推理的主要方法和现有进展。"}
{"text": "6.3.1基于图结构的推理1.方法概述对于那些自底向上构建的知识图谱，图谱中大部分信息都是表示两个实体之间拥有某种关系的事实三元组。"}
{"text": "对于这些三元组，从图的角度来看，可以看作是标签的有向图，有向图以实体为节点，以关系为有向边，并且每个关系边从头实体的节点指向尾实体的节点，如图6-11所示。"}
{"text": "图6-11知识图谱中的实体关系图有向图中丰富的图结构反映了知识图谱丰富的语义信息，在知识图谱中典型的图结构是两个实体之间的路径。"}
{"text": "例如，上面的示例中描述了不同人物之间的关系以及人物的职业信息，包含了如下的路径：这是一条从实体小明到实体小小的路径，表述的信息是小明的妻子是小红，小红的孩子有小小。"}
{"text": "从语义角度来看，这条由关系“妻子是”和“孩子有”组成的路径揭示了小明和小小之间的父子关系，这条路径蕴涵着三元组：而这个推理过程不仅仅存在于这个包含小明、小红和小小的子图中，同样也存在于建国、秀娟和小明的子图中，而路径和三元组是常常同时出现在知识图谱中的。"}
{"text": "其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。"}
{"text": "这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。"}
{"text": "除了路径，实体的邻居节点以及它们之间的关系也是刻画和描述一个实体的重要信息，例如在上例中的关于“小明”的7个三元组鲜明地描述了小明这个人物，包括（小明，父亲是，建国）、（小明，获得奖项，最佳男主角）以及（小明，妻子是，小红）等。"}
{"text": "一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。"}
{"text": "当把知识图谱看作是有向图时，往往强调的是在知识图谱中的事实三元组，即表示两个实体之间拥有某种关系的三元组，而对于知识图谱的本体和上层的schema则关注较少，因为本体中许多含有丰富逻辑描述的信息并不能简单地转化为图的结构。"}
{"text": "下面将介绍常见的基于图结构的知识图谱推理算法。"}
{"text": "2.常见算法简介典型的基于图结构的推理方法有PRA（Path_Ranking_Algorithm）[10]利用了实体节点之间的路径当作特征从而进行链接预测推理。"}
{"text": "（1）基于知识图谱路径特征的PRA算法。"}
{"text": "PRA处理的推理问题是关系推理，其中包含了两个任务，一个是给定关系r和头实体h预测可能的尾实体t是什么，即在给定h,r的情况下，预测哪个三元组（h,r,t）成立的可能性比较大，叫作尾实体链接预测；另一个是在给定r,t的情况下，预测可能的头实体h是什么，叫作头实体链接预测。"}
{"text": "PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。"}
{"text": "PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。"}
{"text": "在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。"}
{"text": "在PRA中，利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn−1的值域（domian)，即Tn=range（rn）=domain（rn−1），关系的值域和作用域通常指的是实体的类型。"}
{"text": "基于路径的随机游走定义了一个关系路径的分布，并得到每条路径的特征值sℎ,P（t）,sℎ,P（t）可以理解为沿着路径P从h开始能够到达t的概率。"}
{"text": "具体操作为，在随机游走的初始阶段，sℎ,P（e）初始化为1，如果e=s，否则初始化为0。"}
{"text": "在随机游走的过程中，sℎ,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。"}
{"text": "对于关系r，在通过随机游走得到一系列路径特征Pr={P1,⋯,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1−yi）ln（1−pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。"}
{"text": "在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。"}
{"text": "采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。"}
{"text": "结合了有效采样和随机有走的PRA能够快速有效地利用知识图谱的路径结构对知识图谱进行关系推理，是典型的基于图结构的知识图谱推理算法。"}
{"text": "（2）PRA的演化算法。"}
{"text": "在PRA中的路径是连续的且在路径中的关系是同向的，这种路径特征可以理解为一种简单的霍恩规则（Hornrule），但是在知识图谱中，有很多种路径是含有常量的：由这个路径可以推理出三元组小明，这种有明显语义的含有常量的且不是收尾闭合的路径特征是不能被PRA捕捉到的，又例如由t=NFL直接推理ex，即将NFL直接设置为关系“服役于运动队”的值域，这种很明显的推理特征也是PRA无法捕捉的。"}
{"text": "所以，CoR-PRA（Constant_and_Reversed_Path_RankingAlgorithm）[43]通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。"}
{"text": "给定关系r下的训练样本（h,t）,Co-PRA中搜索图结构特征的步骤如下：1）生成初步的路径。"}
{"text": "通过路径搜索算法生成以h为起点的小于长度l的路径集合Pℎ；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。"}
{"text": "2）通过PRA计算路径特征的概率。"}
{"text": "对于路径πℎ∈Pℎ，计算沿着路径πℎ正向地由h到达x的概率P（h→x;πℎ），以及沿着路径πℎ逆向地由h到达x的概率；同理，对路径πt∈Pt，计算沿着路径πt正向地由t到达x的概率P（t→x;πt），以及沿着路径πt逆向地由t到达x的概率；并将所有的x放入常量候选集N中。"}
{"text": "3）生成候选的常量路径。"}
{"text": "对每一个（x∈N,πϵPt）的组合，如果P（t→x|πt）＞0，那么生成路径特征，其中c=x，并且将路径特征对应的覆盖度值（coverage）加1，即；同理，对每一个（x∈N,πϵPt）的组合，如果，那么生成路径特征P（c→t;πt），其中c=x，并且将路径特征对应的覆盖度值加1，即coverage（P（c→t;πt））+=1。"}
{"text": "4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。"}
{"text": "对每一个可，就生成路能的组合（x∈N,πℎ∈Pℎ,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。"}
{"text": "反向同理。"}
{"text": "从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。"}
{"text": "尽管采用了随机游走策略来降低搜索空间，当PRA应用在关系丰富且连接稠密的知识图谱上时，依然会面临路径特征爆炸的问题。"}
{"text": "为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。"}
{"text": "为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。"}
{"text": "为了进一步提升路径搜索效率，降低无意义的路径特征，对于图中的一个节点，如果这个节点有很多相同关系边ri连接着不同的实体节点，那么沿着这个关系继续搜索路径会急剧增加子图大小的量级。"}
{"text": "为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。"}
{"text": "为了增加子图特征的丰富性，除了PRA中用到的路径特征，SFE还增加了二元路径特征，类似自然语言处理中的bigram，即将两个具有连接的关系组成一个新的关系，例如“BIGRAM：对齐实体/妻子是”，除了二元路径特征，SFE还增加了one-sided_feature,one-sided_path指的是一个存在在给定两个节点之间的路径的，是从起始节点开始，但不一定由另一个节点结束，类似Co-PRA中的带有常量的路径特征。"}
{"text": "SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。"}
{"text": "如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。"}
{"text": "SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。"}
{"text": "SFE还增加了一个表示任意关系的关系ANYREL来增加路径特征的丰富性。"}
{"text": "总体来说，SFE在PRA的路径特征搜索的效率和特征的丰富性方面做了比较大的提升。"}
{"text": "从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。"}
{"text": "但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。"}
{"text": "但是，不是路径形式的图结构特征依然有待挖掘和分析。"}
{"text": "2.典型工具简介或实验对比分析PRA的提出主要是针对很不完整的知识图谱，所以论文中的实验是在知识图谱NELL上进行试验的，图6-12展示了PRA中在预测某一关系时权重最高的两个路径特征，可以看出，这些高权重的路径特征可以看作是预测当前关系的一条置信度较高的规则，具有明显的语义含义。"}
{"text": "PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。"}
{"text": "图6-12PRA关系预测路径图6-13PRA在链接预测上与N-FOIL的对比结果图6-14展示了CoR-PRA在知识图谱推理和命名实体抽取上的实验比较，从实验结果可以看出，CoR-PRA由于提升了路径特征的丰富性，其结果明显优于PRA，但计算效率不及PRA。"}
{"text": "图6-14知识图谱推理及命名实体抽取结果对比图6-15展示了SFE和PRA的性能比较，左边是在同样的拥有10个关系的NELL数据集上PRA和SFE的MAP（Mean_Average_Precision）结果、平均抽取的特征数量以及运行时间的比较。"}
{"text": "从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。"}
{"text": "图6-15SFE和PRA的性能比较典型的PRA系列工具可以参考https://github.com/noon99jaki/pra，集成了PRA以及CoR-PRA算法。"}
{"text": "6.3.2基于规则学习的推理1.方法概述基于规则的推理具有精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用。"}
{"text": "规则是基于规则推理的核心，所以规则获取是一个重要的任务。"}
{"text": "在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。"}
{"text": "所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。"}
{"text": "规则一般包含了两个部分，分别为规则头（head）和规则主体（body），其一般形式为rule:head←body.解读为有规则主体的信息可推出规则头的信息。"}
{"text": "其中，规则头由一个二元的原子（atom）构成，而规则主体由一个或多个一元原子或二元原子组成。"}
{"text": "原子（atom）是指包含了变量的元组，例如isLocation(X)是一个一元原子表示实体变量X是一个位置实体；hasWife(X,Y)是一个二元原子，表示实体变量X的妻子是实体变量Y。"}
{"text": "二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。"}
{"text": "在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。"}
{"text": "这条规则里的规则主体就包含了以否定形式出现的原子。"}
{"text": "所以，规则也可以表示为：rule:head←body+∧body−.其中，body+表示以肯定形式出现的原子的逻辑合取集合，而body−表示以否定形式出现的原子的逻辑合取集合。"}
{"text": "如果规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子，称这样的规则为霍恩规则（horn规则类型，可以表示为以下形式：rules），霍恩规则是被研究得比较多的a0←a1∧a2∧…∧an.其中，每个ai都为一个原子。"}
{"text": "在知识图谱的规则学习方法中，另一种被研究得比较多的规则类型叫作路径规则（pathrules），路径规则可以表示为如下形式：r0（e1,en+1）←r1（e1,e2）∧r2（e2,e3）∧…∧rn（en,en+1）.其中，规则主体中的原子均为含有两个变量的二元原子，且规则主体的所有二元原子构成一个从规则头中的两个实体之间的路径，且整个规则在知识图谱中构成一个闭环结构。"}
{"text": "这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。"}
{"text": "在规则学习过程中，对于学习到的规则一般有三种评估方法，分别是支持度（support）、置信度（confidence）、规则头覆盖度（headcoverage）。"}
{"text": "下面分别介绍这三种评价指标的计算方法。"}
{"text": "对于一个规则rule，在知识图谱中，其支持度（support）指的是满足规则主体和规则头的实例个数，规则的实例化指的是将规则中的变量替换成知识图谱中真实的实体后的结果。"}
{"text": "所以，规则的支持度通常是一个大于或等于0的整数值，用support(rule)表示。"}
{"text": "一般来说，一个规则的支持度越大，说明这个规则的实例在知识图谱中存在得越多，从统计角度来看，也越可能是一个比较好的规则。"}
{"text": "规则的置信度（confidence）的计算方式为：即规则支持度和满足规则主体的实例个数的比值，即在满足规则主体的实例中，同时也能满足规则头的实例比例。"}
{"text": "一个规则的置信度越高，一般说明规则的质量也越高。"}
{"text": "由于知识图谱往往具有明显的不完整性，而前文介绍的规则置信度计算方法间接假设了不存在知识图谱中的三元组是错误的，这显然是不合理的。"}
{"text": "所以，基于部分完全假设（PartialCompleteness_Assumption,PCA）的置信度（PCA_Confidence）也是一个衡量规则质量的方法，且考虑了知识图谱的不完整性。"}
{"text": "PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。"}
{"text": "这样考虑的原因是，如果头实体x和关系r0没有在知识图谱中构成相关的三元组，而通过规则主体可以推出三元组r0（x,y），那么根据知识图谱的不完全假设，r0（x,y）只是在知识图谱中缺失而不是错误的三元组，所以，不应该将这类实例化例子计算在分母中，否则会降低规则的置信度。"}
{"text": "所以，在PCA置信度中排除了来自这类实例对置信度值的负向影响。"}
{"text": "规则头覆盖度（Head_Coverage）的计算方法为即规则支持度和满足规则头的实例个数的比值，即在满足规则头的实例中，同时也满足规则主体的实例比例。"}
{"text": "一个规则的置信度越高，一般说明规则的质量也越高。"}
{"text": "规则的支持度、置信度以及头覆盖度从不同的角度反映了规则的质量，但三者之间没有必然的关联关系。"}
{"text": "例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。"}
{"text": "2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。"}
{"text": "AMIE能挖掘的规则形如：fatherOf（f,c）←motherOf（m,c）∧marriedTo（m,f）.AMIE是一种霍恩规则，也是一种闭环规则，即整条规则可以在图中构成一个闭环结构。"}
{"text": "在规则学习的任务中，最重要的是如何有效搜索空间，因为在大型的知识图谱上简单地遍历所有可能的规则并评估规则的质量效率很低，几乎不可行。"}
{"text": "AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。"}
{"text": "3个挖掘算子如下：●增加悬挂原子（Adding_Dangling_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个新的变量和一个已经在规则中出现的元素，可以是出现过的变量，也可以是出现过的实体。"}
{"text": "●增加实例化的原子（Adding_Instantiated_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。"}
{"text": "●增加闭合原子（Adding_Closing_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含的两个元素都是已经出现在规则中的变量或实体。"}
{"text": "增加闭合原子之后，规则就算构建完成了。"}
{"text": "AMIE的规则学习算法如图6-16所示。"}
{"text": "图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。"}
{"text": "AMIE的剪枝策略主要包含两条：●设置最低规则头覆盖度过滤，头覆盖度很低的规则一般是一些边缘规则，可以直接过滤掉。"}
{"text": "在实践中，AMIE将头覆盖度值设为0.01。"}
{"text": "●在一条规则中，每在规则主体中增加一个原子，都应该使得规则的置信度增加，即confidence（a0←a0∧a2∧…∧an∧an+1）＞confidence（a0←a0∧a2∧…∧an）。"}
{"text": "如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧…∧an∧an+1剪枝掉。"}
{"text": "在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。"}
{"text": "无论采用哪种挖掘算子来增加规则中的原子，每一个原子都伴随着需要选择一个知识图谱中的关系。"}
{"text": "在选择增加实例化算子时还涉及选择一个实体方面，为了满足选出来的实体和关系组成的原子，在添加到规则中以后，能够满足事先设置的头覆盖度的要求，AMIE用对知识图谱的查询来筛选合适的选项，例如：SELECT?rWHEREa0∧a1∧…∧an∧?r（X,Y）HAVVINGCOUNT（a0）≥k这样经过查询筛选得到的关系候选项满足了一定符合头覆盖度的要求。"}
{"text": "3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。"}
{"text": "例如，在拥有100多万个实体以及近700万个三元组的DBpedia上，AMIE仅需不到3min就能完成规则挖掘，产生7000条规则，并帮助推理出了12万多个新的三元组。"}
{"text": "图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。"}
{"text": "6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。"}
{"text": "表示学习让算法在学习向量表示的过程中自动捕捉、推理所需的特征，通过训练学习，将知识图谱中离散符号表示的信息编码在不同的向量空间表示中，使得知识图谱的推理能够通过预设的向量空间表示之间的计算自动实现，不需要显式的推理步骤。"}
{"text": "知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）−vec（queen）≈vec（man）−vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。"}
{"text": "而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。"}
{"text": "2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。"}
{"text": "在TransE中，知识图谱中的每个实体和关系都被表示成了一个向量，按照词向量的启示，TransE将三元组中的关系看作是从头实体向量到尾实体向量的翻译（translation），并对知识图谱将要映射到的向量空间做了如下假设，即在理想情况下，对每一个存在知识图谱中的三元组都满足h+r=t.式中，h是头实体的向量表示；r是关系的向量表示；t是尾实体的向量表示。"}
{"text": "TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。"}
{"text": "在需要映射到的向量空间中，TransE将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。"}
{"text": "等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r≉t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。"}
{"text": "然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′ℎ,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。"}
{"text": "TransE的训练目标是最小化损失函数L，可以通过基于梯度的优化算法进行优化求解，直至训练收敛。"}
{"text": "实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。"}
{"text": "TransE的简单高效说明了知识图谱表示学习方法能够自动且很好地捕捉推理特征，无须人工设计，很适合在大规模复杂的知识图谱上推广，是一种有效的知识图谱推理手段。"}
{"text": "尽管有效，TransE依然存在着表达能力不足的问题，例如按照关系头尾实体个数比例划分，知识图谱中的关系可以分为四种类型，分别为一对一（1-1）、一对多（1-N）、多对一（N-1）以及多对多（N-N）,TransE能够较好地捕捉一对一（1-1）的关系，却无法很好地表示一对多（1-N）、多对一（N-1）以及多对多（N-N）的关系。"}
{"text": "例如，实体“中国”在关系“拥有省份”这个关系下有很多个尾实体，根据TransE的假设，任何一个省份的向量表示都满足v（省份x）:v（中国）+v（拥有省份）=v（省份x），这将会导致TransE无法很好地区分各个省份。"}
{"text": "所以，TransH[46]就提出了在通过关系将头实体向量翻译到尾实体向量之前，先将头实体和尾实体向量投影到一个和当前关系相关的平面上，由于向量空间中的不同向量在同一个平面上的投影可以是一样的，这就帮助TransE从理论上解决了难以处理一对多（1-N）、多对一（N-1）以及多对多（N-N）关系的问题，TransE和TransH的对比向量空间假设对比如图6-18所示。"}
{"text": "图6-18TransE和TransH对比向量空间假设对比TransH为每个关系r都设计了一个投影平面，并用投影平面的法向量wr表示这个平面，h和t的投影向量的计算方法如下：然后，利用投影向量进行三元组得分的计算，即TransH通过设计关系投影平面提升了TransE表达非一对一关系的能力，TransR[8]则通过拆分实体向量表示空间和关系表示向量空间来提升TransE的表达能力。"}
{"text": "由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。"}
{"text": "图6-19TransR的实体表示空间和关系表示空间TransR设定所有的计算都发生在关系表示空间中，并在计算三元组得分之前首先将实体向量通过关系矩阵投影向关系表示空间，即：hr=hMr,tr=tMr.然后，利用投影到关系表示空间的头实体向量和尾实体向量进行三元组得分的计算：TransR通过区分实体和关系表示空间增加了模型的表达能力，并提升了表示学习结果，但是在TransR中，每个关系除拥有一个表示向量以外，还对应了一个d×d的矩阵，这相比起TransE增加了很多参数。"}
{"text": "为了减少TransR的参数量且同时保留其表达能力，TransD[47]提出了用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。"}
{"text": "图6-20TransD实体表示空间和关系表示空间其动态矩阵的计算如下：式中，m,n为关系和实体的向量表示维度；m,n可以相等也可以不相等。"}
{"text": "TransD通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。"}
{"text": "之前介绍了以TransE为代表的基于翻译假设的表示学习模型，而知识图谱表示学习的推理能力和采用的向量空间假设有很大关系，除了翻译假设还有其他的空间假设，DistMult[48]采用了更灵活的线性映射假设将实体表示为向量，关系表示为矩阵，并将关系当作是一种向量空间中的线性变换。"}
{"text": "对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。"}
{"text": "上式表达的hMr=t.意思是头实体通过与关系矩阵相乘，经过空间中的线性变化以后，可以转变为尾实体向量。"}
{"text": "所以，训练目标是对正确的三元组让hMr与t尽可能接近，而错误的三元组尽可能远离。"}
{"text": "与TransE不同的是，DistMult采用向量点积衡量两个向量接近与否，故三元组的得分函数设计如下：f（h,r,t）=hMrt⊺.损失函数与TransE系列的方法相同，设计为基于最大间隔的损失函数。"}
{"text": "由于向量与矩阵的运算比向量的加法运算更灵活，所以整体来说DistMult的效果比TransE效果要好。"}
{"text": "当将关系的矩阵设计为对角矩阵时，参数量与TransE相同，且效果比普通矩阵更好。"}
{"text": "所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。"}
{"text": "基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。"}
{"text": "DistMult中一个比较明显的问题是，得分函数的设计使得当关系设计为对角矩阵时，无法隐含所有关系都是对称关系的结论，因为对于一个存在的三元组（h,r,t），经过模型训练以后，f（h,r,t）=hDrt⊺的值会比较大，即表示三元组（h,r,t）是正确的。"}
{"text": "所以，三元组（t,r,h）的得分f（t,r,h）=tDrh⊺的值也会比较大，因为tDrh⊺=hDrt⊺。"}
{"text": "这说明了DistMult天然地假设了所有的关系是对称关系，这显然是不合理的。"}
{"text": "从语义的角度分析，知识图谱中的关系既包含了对称关系如“配偶是”，也包含了不对称关系如“出生地”，而且非对称关系一般还多于对称关系。"}
{"text": "为了解决这个问题，ComplEx[49]将原来基于实数的表示学习拓展到了复数，因为基于复数的乘法计算是不满足交换律的，从而克服了DistMult不能很好地表示非对称关系的问题。"}
{"text": "其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞−＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。"}
{"text": "可以看出在ComplEx中，f（h,r,t）≠f（t,r,h），所以可以更灵活地表达对称与非对称关系。"}
{"text": "类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。"}
{"text": "除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。"}
{"text": "3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。"}
{"text": "从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。"}
{"text": "表6-6常用知识图谱表示学习方法链接预测结果比较续表常用的关于知识图谱表示学习的工具包有清华开源的OpenKE，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。"}
{"text": "全面的关于工具包的信息可以在网站主页获得。"}
{"text": "6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。"}
{"text": "传统的数据流学习主要是从连续和快速更新的数据记录中提取知识结构。"}
{"text": "在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。"}
{"text": "本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。"}
{"text": "数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。"}
{"text": "本体流可以看成随时间变化的本体，也就是语义增强的数据流。"}
{"text": "在描述逻辑中，本体流包含TBox（术语成分）和ABox（断言公理）。"}
{"text": "ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。"}
{"text": "Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。"}
{"text": "快照从一个时刻转变到下一个时刻可以看成断言公理的更新，这被称为一阶预测突变；两个快照对于某些蕴涵具有足够大的概率差异，这被称突发预测变化。"}
{"text": "这两种预测变化构成了语义概念漂移。"}
{"text": "蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。"}
{"text": "通过将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。"}
{"text": "该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。"}
{"text": "实验还表明，在模型中，编码语义是一种超越目前最先进模型的方法，具有语义嵌入的模型对知识推理和预测起到重要作用。"}
{"text": "6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。"}
{"text": "比较有代表性的工作有文献[13]和[54]。"}
{"text": "文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。"}
{"text": "“事实判断”即确定一个三元组是否成立。"}
{"text": "文献作者将“事实判断”看作是这样一个问题：寻找一条能连接已知头实体h和尾实体t的路径。"}
{"text": "文献作者将此问题建模为序列决策问题，并利用基于策略梯度的强化学习方法REINFORCE求解。"}
{"text": "具体而言，强化学习中智能体的状态被定义为当前节点实体和目标节点实体的联合表示st=（et,etarget−et）.智能体的动作则是在当前节点实体的出边（Outgoing_edge）中选择一个适当的边作为组成路径的关系。"}
{"text": "在选择动作后，智能体的状态会随即更新。"}
{"text": "在奖励函数设计方面，文献作者同时考虑了准确率、路径效率和路径多样性。"}
{"text": "实验证明，DeepPath能学习到等价的推理路径，相比基于表示学习的方法，有更好的可解释性和推理效果。"}
{"text": "文献[54]考虑更有难度的“查询问答”（Query_Answering）问题，提出了MINERVA模型。"}
{"text": "与“事实判断”相比，“查询问答”无法预知答案对应的尾实体，需要从知识图谱中寻找可作为答案的尾实体。"}
{"text": "在这类知识图谱推理问题中，需要尽可能避免遍历大规模知识图谱，影响算法的效率。"}
{"text": "文献作者将这类问题建模成部分可观察的马尔科夫决策过程（POMDP）。"}
{"text": "我们可以想象一个智能体在知识图谱上游走，寻找目标尾实体。"}
{"text": "智能体的当前状态与它所处的当前实体有关，其动作即该实体可选的出边。"}
{"text": "尽管整个知识图谱中的关系总数可能繁多，但具体到某一实体，可选的出边往往减少一个或两个数量级，可大幅降低遍历的规模。"}
{"text": "实验结果表明：在这类“查询问答”的推理任务上，MINERVA模型远远超过了未使用强化学习的基于随机游走的模型。"}
{"text": "同时，当路径较长时，仍有良好的表现，具有鲁棒性。"}
{"text": "6.4.3基于元学习的少样本知识图谱推理在以往常见的基于表示学习的推理模型中，往往都会利用大量的数据对模型进行训练，并且当前大多数的研究都会假设对于其实验使用的知识库，所有的关系都有充足的三元组用来训练。"}
{"text": "但在真实的知识图谱中，有大量的关系仅仅具有非常少的三元组实例，称这种关系为长尾关系（Long-Tail_Relation），这类关系多被以往的研究忽视。"}
{"text": "但事实上，对于某一个关系，其具有的三元组实例越少，其对知识图谱的补全越有利用的价值。"}
{"text": "元学习的目的是解决“学习如何学习”（Learning_to_Learn），旨在通过少量样本迅速完成学习，其相对主要的应用是少样本学习（Few-Shot_Learning）。"}
{"text": "当前主要的元学习方法分为三类，基于度量（Metric-Based）、基于模型（Model-Based）和基于优化（Optimization-Based）的方法。"}
{"text": "关于元学习的研究，一开始主要应用于图像分类[55-57]，研究者近来尝试使用元学习的方法解决知识图谱中有关长尾关系的推理。"}
{"text": "XIONG等人[58]提出了使用基于度量的方法对长尾关系做少样本的链接预测，也就是在某一种关系的样本实例较少的情况下，通过头实体和关系对尾实体进行预测。"}
{"text": "HAN等人[59]确切地描述了关系分类的少样本学习任务，并提出了一个用于测试少样本关系分类（Few-Shot_Relation_Classification）的数据集FewRel，在将近来效果突出的少样本学习模型应用于该数据集后，对少样本知识图谱推理的难点进行了分析。"}
{"text": "把元学习应用于少样本知识图谱推理的研究还相对较少，该领域还有很多可以挖掘和研究的地方。"}
{"text": "6.4.4图神经网络与知识图谱推理近年来提出的图神经网络（Graph_Neural_Networks,GNNs）主要用于处理图结构的数据，随着信息在节点之间的传播以捕捉图中节点间的依赖关系，其图结构的表示方式使得模型可以基于图进行推理。"}
{"text": "而知识图谱作为一种典型的图结构数据，图神经网络在知识图谱的表示学习和推理方面贡献颇多，如知识库补全（链接预测、实体分类）等任务。"}
{"text": "Takuo_Hamaguchi_[60]主要针对KG中的OOKB（out-of-knowledge-base）实体进行知识库补全等任务。"}
{"text": "OOKB实体，即在训练过程中未被训练到的实体，无法得到其Embedding表示，从而无法预测其与知识库中其他实体之间的关系。"}
{"text": "而文中将知识库补全的任务定义为：基于知识库中已存在的三元组和当前出现的包含新实体的三元组，推理当前新实体与知识库中其他实体之间的关系。"}
{"text": "基于此，可以通过知识库中现有的实体表示推理得到OOKB实体表示。"}
{"text": "因此，这篇文献利用GNN中节点表示的方式，以OOKB实体分别为头实体、尾实体的三元组集合为周围邻居，对当前OOKB实体进行表示。"}
{"text": "每个实体节点经GNN的信息传播获取新的表示。"}
{"text": "基于此，通过TransE等经典模型，进行知识库补全任务。"}
{"text": "Schlichtkrull[61]利用R-GCNs（Relational_Graph_Convolutional_Networks）进行链接预测和实体发现等任务。"}
{"text": "本文的思想同样基于已知实体或关系在图结构中周围节点的结构，推理得到未知节点的表示，从而可对知识库中缺失的实体获取它们的Embedding向量。"}
{"text": "同时，结合TransE和DisMult等表示学习模型，进行知识库中缺失元素的补全任务。"}
{"text": "文献提出的R-GCNs，基于GCN进行图中节点信息的传播，同时考虑到真实知识库场景中的多关系类型数据，本文提出了两个正则化的优化方法，以此对由不同类型的关系连接的实体进行表示。"}
{"text": "实验结果证明，本文提出的方法对比传统的表示学习模型具有很大的提升。"}
{"text": "GNN模型的引入丰富了知识库中实体和关系元素的表达，尤其是在得到未知实体或关系的表示等方面具备一定的推理能力，针对目前在知识图谱表示学习和推理等方面遇到的问题，相信GNN一定能发挥出重要的作用。"}
{"text": "6.5开源工具实践：基于Jena和Drools的知识推理实践6.5.1开源工具简介Jena是一个免费且开源的支持构建语义网络和数据连接应用的Java框架，提供了处理RDF、RDFS、OWL数据的接口，一个规则引擎，用于查询的三元组的内存存储。"}
{"text": "Drools（JBoss_Rules）具有一个易于访问企业策略、易于调整以及易于管理的开源业务规则引擎，符合业内标准，具有速度快、效率高的特点。"}
{"text": "业务分析师或审核人员可以利用它轻松查看业务规则，从而检验已编码的规则是否执行了所需的业务规则。"}
{"text": "JBoss_Rules的前身是Codehaus的一个开源项目——Drools。"}
{"text": "现在被纳入JBoss门下，更名为JBoss_Rules，成为JBoss应用服务器的规则引擎。"}
{"text": "Drools是基于Charles_Forgy的RETE算法的规则引擎为Java量身定制的实现，具有OO接口的RETE，使得商业规则有了更自然的表达。"}
{"text": "6.5.2开源工具的技术架构图3-42所示为Jena框架。"}
{"text": "如图6-21所示为Drools框架。"}
{"text": "图6-21Drools框架规则引擎实现了数据同逻辑的完全解耦。"}
{"text": "规则并不能被直接调用，因为它们不是方法或函数，规则的激发是对Working_Memory中数据变化的响应。"}
{"text": "结果（Consequence，即RHS）作为LHS_events完全匹配的Listener。"}
{"text": "数据被assert进WorkingMemory后，和RuleBase中rule的LHS进行匹配，如果匹配成功，则这条rule连同和它匹配的数据（Activation）一起被放入Agenda，等待Agenda激发Activation（即执行rule的RHS）。"}
{"text": "6.6本章小结知识图谱是一种重要的组织知识的方式，知识图谱上的推理任务在其生命周期的各个阶段都存在，基于知识图谱的推理方法可大致分为基于演绎的推理和基于归纳的推理，而这两种不同的推理策略都包含了多种推理方法。"}
{"text": "（1）基于演绎的知识图谱推理可能有以下发展趋势：●演绎推理方法的效率是阻碍它们被广泛应用的瓶颈之一，通过并行技术、模块化技术、递增式推理技术和其他优化技术，实现高效推理机是演绎推理研究的趋势。"}
{"text": "●目前的演绎推理方法在处理流数据和移动数据方面还缺少完善的理论以及实用化算法，如何处理流数据的动态性以及时序性是值得研究的方向。"}
{"text": "（2）基于归纳的知识图谱推理可能有以下发展趋势：●尽管归纳推理主要是基于对已有数据的观察总结，但在归纳推理中也将逐渐融入先验的语义信息，例如规则等，使得归纳推理不仅仅是基于大量数据的观察，同时也包含先验知识的约束，从而达到更精准的推理。"}
{"text": "●不同的归纳推理方法，例如基于图结构、基于规则学习和基于表示学习的推理应该互相融合，形成优势互补，完成更智能的推理。"}
{"text": "（3）整体来说，知识图谱推理可能有以下发展趋势：●演绎和归纳两种不同的推理方式将逐渐融合，充分发挥各自的优势并互相补充，两者同时作用能完成更复杂、多样的知识图谱推理任务。"}
{"text": "●任何知识图谱都具有不完整性，仅仅基于知识图谱本身的推理无法突破不完整性的限制，因此外部信息，例如文本、图像等信息可能是很好的补充。"}
