{"text": "这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。"}
{"text": "自然语言转化逻辑表达式需要训练一个语法分析器将过程自动化。"}
{"text": "应注意两个关键步骤：资源映射和逻辑表达式生成。"}
{"text": "资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。"}
{"text": "简单映射是指字符形式上比较相似的，一般可以通过字符串相似度匹配来找到映射关系，例如“出生”和“出生地”的映射。"}
{"text": "复杂映射是指无法通过字符串匹配找到对应关系的映射，例如“老婆”与“配偶”的映射，这类映射在实际问答中出现的概率更高，一般可以采用基于统计的方法来找到映射关系。"}
{"text": "逻辑表达式生成即自底向上自动地将自然语言查询解析为语法树，语法树的根节点即是最终对应的逻辑表达式。"}
{"text": "如图8-24所示，查询“where_was_Obamaborn”对应的逻辑表达式是Type.Location?PeopleBornHere.BarackObama，其中lexicon是指资源映射操作，PeopleBornHere和BarackObama用Join连接组合，此组合结果再与Type.Location用求交集组合成为最终的逻辑表达式。"}
{"text": "图8-24自然语言查询转换成逻辑表达式[41]训练语法分析器需要大量的标注数据，传统的方法是基于规则生成标注数据，通过手工编写规则虽然直接，但是存在较明显的局限性：一方面，规则的编写需要语言学专家完成，导致规则的建立效率低且成本高，还不具备扩展性；另一方面，这种人工规则可能仅适用于某一类语言甚至某一特定领域，泛化能力较弱。"}
{"text": "为了改进传统方法的缺陷，有大量研究工作采用弱监督或者无监督的方法来训练语法分析器，一个经典的方法是Berant[41]提出利用“问题/答案对”数据结合Freebase作为语法分析器的训练集。"}
{"text": "此方法不需要逻辑表示式的专家人工标注数据，可以低成本地获得。"}
{"text": "Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。"}
{"text": "（1）资源映射。"}
{"text": "自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。"}
{"text": "例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。"}
{"text": "如图8-25所示，左边的“grew_up_in”是三元组中的自然语言关系短语r1，右边的“DateOfBirth”是知识库中的关系r2。"}
{"text": "统计所有自然语言三元组中符合r1[t1,t2]的实体对，得到集合F(r1)，统计知识库中符合r2[t1,t2]的实体对，得到集合F(r2)。"}
{"text": "通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。"}
{"text": "图8-25关系短语映射到知识库关系的方法[41]（2）桥接操作。"}
{"text": "在完成资源映射后仍然存在一些问题，首先，例如go、have、do等轻动词（Light_Verb）由于在语法上使用相对自由，难以通过统计的方式直接映射到实体关系上；其次，部分知识库关系的出现频率较低，利用统计也较难找到准确的映射方式。"}
{"text": "这样就需要补充一个额外的二元关系将这些词两端的逻辑表达式连接起来，这就是桥接操作。"}
{"text": "如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University?Education.BarackObama的逻辑表达式。"}
{"text": "由于知识库中的关系是有定义域和值域的，所以文献基于此特点在知识库中查找所有潜在的关系，例如Education的定义域和值域分别是Person和University，则Education可以是候选的桥接操作。"}
{"text": "这里针对每一种候选的桥接操作都会生成很多特征，基于这些特征训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "图8-26桥接操作示例[41]（3）组合操作。"}
{"text": "即逻辑表达式间的连接、求交集以及聚合三种操作。"}
{"text": "至于最终应该用哪种操作，作者同样通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "（4）候选逻辑表达式评估。"}
{"text": "即训练一个分类器，计算每一种候选逻辑表达式的概率，DiscriminativeLog-Linear模型，最终实现逻辑表达式的筛选。"}
{"text": "Berant等人基于前面候选逻辑表达式生成过程中的所有特征，训练了一个8.5.4基于深度学习的传统问答模块优化基于深度学习的知识问答主要有两个方向，分别是利用深度学习对传统问答方法进行模块级的改进和基于深度学习的端到端问答模型。"}
{"text": "深度学习可以直接用于改进传统问答流程的各个模块，包括语义解析、实体识别、意图分类和实体消歧等。"}
{"text": "下面通过Yih[51]的工作，说明如何使用深度神经网络来提升知识问答的效果。"}
{"text": "传统的基于语义解析的方法需要将问题转换成逻辑表达式，如图8-27所示。"}
{"text": "这类方法最大的问题是找到问题中自然语言短语与知识库的映射关系，Yih等人提出了一种语义解析的框架，首先基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。"}
{"text": "因为查询图可以直接映射到Lambda_Calculus形式的逻辑表达式，并且在语义上与λ-DCS（Lambda_Dependency-Based_CompositionalSemantics）紧密相关，因此就可以将语义解析的过程转换成查询图生成的过程。"}
{"text": "图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。"}
{"text": "这个例子对应的问句是“Who_first_voiced_Meg_on_Family_Guy?”，在不考虑聚合操作的情况下，该查询图对应的逻辑表达式是λx.?y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)。"}
{"text": "图8-28查询图示例[51]下面介绍查询图的生成过程。"}
{"text": "第一步，选择一个主题实体（Topic_Entity）作为根节点，如图8-29（a）中可以选择s1“FamilyGuy”作为根节点。"}
{"text": "第二步，确定一条从根节点到Lambda变量（答案节点）的有向路径，路径上可以有一个或者多个中间变量，这条路径被称为核心推断链（Core_Inferential_Chain），如图8-29（b）所示从三条路径s3、s4、s5中选取s3作为核心推断链。"}
{"text": "核心推断链上除了根节点为实体，其他的都只能是变量，节点间的关系都是知识库中的关系。"}
{"text": "第三步，给查询图添加约束条件和聚合函数（AugmentingConstraints&Aggregations），形式上就是把其他的实体或者聚合函数节点通过知识库中的关系与核心推断链上的变量连接起来，如图8-29（c）所示对y增加两个限制argmin和character(y,MegGriffin)。"}
{"text": "图8-29查询图的生成过程[51]对于生成查询图的第二步，需要一种从众多候选核心推断链中选出最优核心推断链的方法，针对图8-29（b）的例子，要评估{cast-actor,writer-start,genre}三个谓语序列中哪个最接近问题中“Family_Guy”和“Who”的关系，该文献使用一个CNN网络将候选序列和问题文本中的关键词向量化，CNN结构如图8-30所示，通过语义相似度计算找到最优的核心推断链。"}
{"text": "具体做法是将自然语言问题和谓语序列分别通过图8-30所示的网络得到两个300维的分布式表达，然后利用表达向量之间的相似度距离（如cosine距离）计算自然语言问题和谓语序列的语义相似度得分。"}
{"text": "该CNN网络的输入运用了词散列技术[52]，将句子中每个单词拆分成字母三元组，每个字母三元组对应一个向量，比如单词who可以拆为#-w-h,w-h-o,h-o-#，每个单词通过前后添加符号#来区分单词界限。"}
{"text": "然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。"}
{"text": "图8-30Yih[51]中的CNN结构8.5.5基于深度学习的端到端问答模型端到端的深度学习问答模型将问题和知识库中的信息均转化为向量表示，通过向量间的相似度计算的方式完成用户问题与知识库答案的匹配。"}
{"text": "首先根据问题中的主题词在知识库中确定候选答案，然后把问题和知识库中的候选答案都通过神经网络模型映射到一个低维空间，得到它们的分布式向量（Distributed_Embedding），则可计算候选答案分布式向量与问题向量的相似度得分，找出相似度最高的候选答案作为最终答案。"}
{"text": "该神经网络模型通过标注数据对进行训练，使得问题向量与知识库中正确答案的向量在低维空间的关联得分尽量高。"}
{"text": "典型的工作有BordesA等人[53]提出的方法，为解决WebQuestions上数据量不够的问题，文献作者使用一些规则从Freebase、ClueWeb等知识库中构建了大量（问题，知识库答案）的标注数据用于训练模型。"}
{"text": "如图8-31所示，自底向上计算。"}
{"text": "第一步，利用实体链接定位问题中的核心实体，对应到Freebase的实体；第二步，找到从问题中核心实体到候选答案实体的路径；第三步，生成候选答案的子图；第四步，分别将问题和答案子图映射成Embedding向量；第五步，进行点积运算，获得候选答案和问题之间的匹配度。"}
{"text": "该方法取得了比Berant[41]更好的结果（F1=0.392,P@1=0.40）。"}
{"text": "图8-31BordesA等人提出方法的核心流程[53]另一个基于Multi-ColumnCNN[54]的工作，该工作同时训练自然语言问句词向量与知识库三元组，将问题与知识库映射到同一个语义空间。"}
{"text": "该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。"}
{"text": "这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。"}
{"text": "该方法的核心流程如图8-32所示，对于问题“when_did_Avatarrelease_in_UK”，首先通过Multi-Column卷积神经网络提取该问题的三个分布式向量。"}
{"text": "最后，通过分别点乘运算再求和的方式得到最终的答案-问题对得分。"}
{"text": "在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。"}
{"text": "两个案例的基本框架一致，而知识问答增加了将自然语言问题转化为对应逻辑表达式以及查询语句的过程。"}
{"text": "因此，本小节通过一个简单案例介绍自然语言问题到Elasticsearch查询语句的转化，而用Elasticsearch查询语句进行查询即可得到问答结果。"}
{"text": "注意，真实的知识问答系统的语义理解远比本文方案复杂。"}
{"text": "自然语言问题对应的查询类型同本书第7章中的语义检索，如表8-4所示，主要包含四种类型的查询，即实体检索、实体属性检索、实体属性的多跳检索以及多种属性条件检索实体。"}
{"text": "表8-4自然语言问题的四种类型自然语言问题转化为逻辑表达式的过程如下：（1）定义逻辑表达式模板。"}
{"text": "如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。"}
{"text": "多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。"}
{"text": "<OP>表8-5自然语言问题对应的逻辑表达式模板（2）解析自然语言问题。"}
{"text": "从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。"}
{"text": "首先，实体和属性的识别可以采用词典的方法，例如从知识库中抽取所有的实体名和属性名，构建分词器的自定义词典。"}
{"text": "然后，对自然语言问题进行分词，可直接识别其中的属性名和实体名。"}
{"text": "其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。"}
{"text": "最后，查看自然语言问题中属性值和属性名的对应关系，当某属性值没有对应的属性名时，例如“（国籍是)中国(的)运动员”，缺省了“国籍”，就用该属性值对应的最频繁的属性名作为补全的属性名。"}
{"text": "例如下面的两段代码，分别实现了属性名识别和实体名识别。"}
{"text": "（3）后生成逻辑表达式。"}
{"text": "在识别出自然语言问题中所有的实体名、属性名和属性值后，依据它们的数目及位置，确定问题对应的查询类型，以便基于逻辑表达式模板生成对应的逻辑表达式。"}
{"text": "逻辑表达式生成流程如下：查询中含有实体名。"}
{"text": "如果有多个属性名，那么是属性值的多跳检索；如果有一个属性名，则需判断实体名和属性名的位置及中间的连接词(“是”“在”“的”等)，若实体名在前，则是实体的属性查询，例如“姚明的身高”，若属性名在前，则是依据属性查询实体，例如“女儿是姚沁蕾”。"}
{"text": "查询中没有实体名，则认为是依据属性查询实体，需要根据所有属性名和属性值位置的相对关系确定它们之间的对应关系。"}
{"text": "如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。"}
{"text": "工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。"}
{"text": "在生成逻辑表达式之后，可基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询。"}
{"text": "本方法定义了一组Elasticsearch查询模板，基于该模板将逻辑表达式按照一定的层次结构自动转换成Elasticsearch查询语句。"}
{"text": "如表8-6所示，对于实体属性查询，包括多跳检索，都是先检索实体，然后获取对应的属性。"}
{"text": "如表8-7所示，对于多个属性条件检索实体，先为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询，表中part_query表示单个属性条件对应的部分查询。"}
{"text": "gAnswer系统[55]是一个基于海量知识库的自然语言问答系统，针对用户的自然语言问题，能够输出SPARQL格式的知识库查询表达式以及查询答案的结果。"}
{"text": "gAnswer同时支持中文问答和英文问答。"}
{"text": "gAnswer参加了QALD-9的评测比赛，并取得了第一名的成绩。"}
{"text": "对于中文问答，使用PKUBASE知识库；对于英文问答，使用DBpedia知识库。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "此外，我们给出了一个使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/。"}
{"text": "如图8-33所示为gAnswer系统处理流程。"}
{"text": "主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。"}
{"text": "在构建语义查询图阶段，系统借助数据集的信息以及自然语言分析工具，对问句进行实体识别和关系抽取，构建语法依存树，并用这些结果构建对应的查询图。"}
{"text": "这时，并不对其中的实体和关系做消歧处理，而是利用谓词词典，记录词或短语可能对应的谓词或实体。"}
{"text": "在生成SPARQL查询阶段，系统利用查询图生成多个SPARQL，并利用数据集中的部分信息对多个SPARQL进行过滤和优化，其中就包括歧义的消除。"}
{"text": "在查询执行阶段，借助gStore系统返回的SPARQL查询结果，返回并展示给用户。"}
{"text": "图8-33gAnswer系统处理流程1.系统配置需求读者可以使用gAnswer系统构建自己的领域知识问答。"}
{"text": "在系统配置需求方面，gAnswer系统使用RDF格式的数据集，默认的中文数据集是PKUBASE，默认的英文数据集是DBpedia2016。"}
{"text": "gAnswer系统的运行需要借助支持SPARQL查询的图数据库系统来获取最终答案。"}
{"text": "在目前的版本中，使用gStore系统（http://openkg.cn/tool/gstore）。"}
{"text": "gAnswer的部署还依赖一些外部工具包。"}
{"text": "包括Maltparser、StanfordNLP，在生成SPARQL阶段，需要借助Lucene对辅助信息进行索引。"}
{"text": "8.7本章小结本章介绍了问答系统的基本概念、主流方法以及评价体系，并详细阐述了知识图谱问答系统的主要方法与最新进展。"}
{"text": "知识问答以自然语言问答的方式简化了人们获取知识的过程，在知识检索过程中增加了泛化、联想、探索等智能化体验并拓展了知识获取的途径。"}
{"text": "KBQA作为知识问答的重要分支，一方面强化了针对结构化信息的检索能力，另一方面也可以利用知识图谱提升问题理解的准确性。"}
{"text": "深度学习技术在KBQA也起到了重要的作用，不但可以优化传统KBQA的各个模块，尤其是实体识别和语义相似度匹配，而且可以直接作为知识库表示支持端到端的知识问答。"}
{"text": "正如万维网是开放的一样，多种多样的领域知识是不可能被任何一家企业垄断的，所以知识问答应该走万维网一样的开放路线，允许不同的参与者形成生态体系。"}
{"text": "参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。"}
