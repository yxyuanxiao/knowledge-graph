{"text": "表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。"}
{"text": "OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。"}
{"text": "OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。"}
{"text": "OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。"}
{"text": "它的查询复杂度是AC0，非常适合大规模处理。"}
{"text": "它是基于描述逻辑DL-Lite定义的。"}
{"text": "表2-6给出了OWL_2_QL词汇总结。"}
{"text": "表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。"}
{"text": "与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。"}
{"text": "OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。"}
{"text": "表2-7给出了OWL_2_QL词汇总结。"}
{"text": "表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female??likes.Movie??hasSon.(Student??attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。"}
{"text": "下面给出一个例子。"}
{"text": "假设有一个本体，包含以下公理：公理1.Apple??beInvestedBy.(Fidelity?BlackStone)：苹果由富达和黑石投资。"}
{"text": "公理2.?beFundedBy.Fidelity?InnovativeCompanies：借助富达融资的公司都是创新企业。"}
{"text": "公理3.?beFundedBy.BlackStone?InnovativeCompanies：借助黑石融资的公司都是创新企业。"}
{"text": "公理4.beInvestedBy?beFundedBy：投资即是帮助融资。"}
{"text": "由公理1可以推出公理5:Apple??beInvestedBy.Fidelity；由公理5和公理4可以推出公???beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。"}
{"text": "还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。"}
{"text": "OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。"}
{"text": "OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。"}
{"text": "下面给出两个OWL_2_RL上的推理规则：p_rdfs:domain_x,spo?s_rdf:type_xp_rdfs:range_x,spo?o_rdf:type_x其中，s、p、o、x为变量。"}
{"text": "第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。"}
{"text": "第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。"}
{"text": "例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。"}
{"text": "OWL_2_RL允许的核心词汇有：●rdfs:subClassOf；●rdfs:subPropertyOf；●rdfs:domain；●rdfs:range；●owl:TransitiveProperty；●owl:FunctionalProperty；●owl:sameAs；●owl:equivalentClass；●owl:equivalentProperty；●owl:someValuesFrom；●owl:allValuesFrom。"}
{"text": "OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。"}
{"text": "2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。"}
{"text": "1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。"}
{"text": "下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。"}
{"text": "2.常见的SPARQL查询算子（1）OPTIONAL。"}
{"text": "可选算子，指的是在这个算子覆盖范围的查询语句是可选的。"}
{"text": "例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。"}
{"text": "OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。"}
{"text": "（2）FILTER。"}
{"text": "过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。"}
{"text": "例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。"}
{"text": "（3）UNION。"}
{"text": "并算子，指的是将两个查询的结果合并起来。"}
{"text": "例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。"}
{"text": "注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。"}
{"text": "需要注意UNION和OPTIONAL的区别。"}
{"text": "下面给出一个SPARQL查询的例子。"}
{"text": "给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。"}
{"text": "表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。"}
{"text": "假设有下面两条规则：hold_share（X,Y）:-control（X,Y）conn_trans（Y,Z）:-hold_share（X,Y）,hold_share（X,Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。"}
{"text": "通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。"}
{"text": "2.3.4语义Markup表示语言语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。"}
{"text": "被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5MicroData。"}
{"text": "1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。"}
{"text": "JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。"}
{"text": "JSON-LD的语法和JSON兼容。"}
{"text": "下面是一个简单的JSON例子：JSON文档表示一个人。"}
{"text": "人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。"}
{"text": "当然，机器不理解“name”和“image”这样的术语。"}
{"text": "JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。"}
{"text": "如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。"}
{"text": "例如，每个数据集不应该围绕“name”重复发明概念。"}
{"text": "但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。"}
{"text": "Stores），而是以简2.RDFaRDFa（Resource_Description_Framework_in_attributes）是一种早期网页语义标记语言。"}
{"text": "RDFa也是W3C推荐标准。"}
{"text": "它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。"}
{"text": "与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。"}
{"text": "RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。"}
{"text": "上面的代码示例中用到了RDFa属性中的about属性和property属性。"}
{"text": "这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。"}
{"text": "RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。"}
{"text": "3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。"}
{"text": "微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。"}
{"text": "微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。"}
{"text": "下面是一个HTML5Microdata的示例。"}
{"text": "这个例子给出了Person类下一个叫Andy的人的照片和URL地址。"}
{"text": "通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。"}
{"text": "2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。"}
{"text": "这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。"}
{"text": "这里以三个最典型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。"}
{"text": "为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。"}
{"text": "2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。"}
{"text": "“Object”代表实体。"}
{"text": "每一个“Object”有唯一的（Machine_ID）。"}
{"text": "一个“Object”可以有一个或多个“Types”。"}
{"text": "“Properties”用来描述“Facts”。"}
{"text": "例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。"}
{"text": "这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。"}
{"text": "Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。"}
{"text": "type如图2-16所示，示例的CVT描述了关于Obama的任职期限的多元关系“government_position_held”。"}
{"text": "这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。"}
{"text": "一个CVT就是有唯一MID的Object，也可以有多个Types。"}
{"text": "为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。"}
{"text": "Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。"}
{"text": "Entities类似于OWL:Things，代指最顶层的对象。"}
{"text": "每一个Entity都有一个独立的维基页面。"}
{"text": "Entities主要有两类：Items和Properties。"}
{"text": "Items类似于RDF中的Instance，代指实例对象。"}
{"text": "Properties和Statements分别等价于RDF中的Property和Statement。"}
{"text": "通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。"}
{"text": "一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。"}
{"text": "修饰-Qualifiers用于处理复杂的多元表示。"}
{"text": "如一个陈述“spouse:Jane_Belson”描述了一个二元关系。"}
{"text": "可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。"}
{"text": "引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。"}
{"text": "引用也是一种Qualifiers，通常添加到Statements的附加信息中。"}
{"text": "Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。"}
{"text": "Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。"}
{"text": "Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。"}
{"text": "PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。"}
{"text": "PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。"}
{"text": "of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。"}
{"text": "其中，<id>可以是一个Property，如P234。"}
{"text": "2.4.3ConceptNet5ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-Phrases、断言-Assertions、关系-Relations、边-Edges。"}
{"text": "Concepts由Words或Phrases组成，构成了图谱中的节点。"}
{"text": "与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。"}
{"text": "Assertions描述了Concepts之间的关系，类似于RDF中的Statements。"}
{"text": "Edges类似于RDF中的Property。"}
{"text": "一个Concepts包含多条边，而一条边可能有多个产生来源。"}
{"text": "例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。"}
{"text": "来源越多，该断言就越可靠。"}
{"text": "ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。"}
{"text": "ConceptNet5示例如图2-17所示。"}
{"text": "ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。"}
{"text": "on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。"}
{"text": "URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。"}
{"text": "其中，n代指这是一个名词，basement用于区分歧义。"}
{"text": "在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。"}
{"text": "图2-18ConceptNet5的知识表示结构2.5知识图谱的向量表示方法与前面所述的表示方法不同的是，本节要描述的方法是把知识图谱中的实体和关系映射到低维连续的向量空间，而不是使用基于离散符号的表达方式。"}
{"text": "2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。"}
{"text": "在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。"}
{"text": "虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。"}
{"text": "知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。"}
{"text": "数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。"}
{"text": "从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。"}
{"text": "2.5.2词的向量表示方法在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。"}
{"text": "在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。"}
{"text": "知识图谱中的向量表示方法也在此次有所借鉴。"}
{"text": "1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。"}
{"text": "对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。"}
{"text": "如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。"}
{"text": "这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。"}
{"text": "2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"}
{"text": "该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。"}
{"text": "具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。"}
{"text": "如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。"}
{"text": "图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。"}
{"text": "产生词向量的手段主要有三种：●Count-based。"}
{"text": "基于计数的方法，简单说就是记录文本中词的出现次数。"}
{"text": "●Predictive。"}
{"text": "基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。"}
{"text": "●Task-based。"}
{"text": "基于任务的，也就是通过任务驱动的方法。"}
{"text": "通过对词向量在具体任务上的表现效果对词向量进行学习。"}
{"text": "对词向量的产生方法到现在为止有较多的研究，在本章中并不展开讨论，下面简单介绍经典的开源工具word2vec[8]中包含的CBoW和Skip-gram两个模型。"}
{"text": "CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。"}
{"text": "其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。"}
{"text": "如图2-21（a）所示，其中wn是中心词，wn?2,wn?1,wn+1,wn+2为该中心词的上下文的词。"}
{"text": "将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。"}
{"text": "整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。"}
{"text": "Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。"}
{"text": "如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。"}
{"text": "图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。"}
{"text": "vec（Rome）?vec（Italy）≈vec（Paris）?vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。"}
{"text": "通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。"}
{"text": "这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。"}
{"text": "图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。"}
{"text": "2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。"}
{"text": "对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。"}
{"text": "把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph（Representation_Learning）、知识表示学习。"}
{"text": "Embedding）、知识图谱的向量表示、知识图谱的表示学习类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。"}
{"text": "在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。"}
{"text": "类似于词向量，经典的知识图谱嵌入模型TransE的设计思想就是，如果一个三元组（h,r,t）成立，那么它们需要符合h+r≈t关系，例如：vec（Rome）+vec（is?capital?of）≈vec（Italy）所以，在知识图谱嵌入的学习过程中，不同的模型从不同的角度把相应的语义信息嵌入知识图谱的向量表示中，如图2-23所示。"}
{"text": "图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。"}
{"text": "使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。"}
{"text": "用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。"}
{"text": "因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。"}
{"text": "将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。"}
{"text": "如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。"}
{"text": "2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。"}
{"text": "对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。"}
{"text": "所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。"}
{"text": "这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。"}
{"text": "根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。"}
{"text": "1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。"}
{"text": "这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。"}
{"text": "受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。"}
{"text": "也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。"}
{"text": "TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。"}
{"text": "也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。"}
{"text": "2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。"}
{"text": "该方向的模型主要是RESCAL[13]以及它的延伸模型。"}
{"text": "RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。"}
{"text": "由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。"}
{"text": "其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。"}
{"text": "但因为是对角矩阵，所以存在h?diag（r）t=t?diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。"}
{"text": "ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。"}
{"text": "也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。"}
{"text": "3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。"}
{"text": "实体类型是一种容易考虑的额外信息。"}
{"text": "在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。"}
{"text": "最简单的考虑实体类型的方法是在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如（Rome,IsA,city）（Italy,IsA,Country）这样的三元组。"}
{"text": "当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。"}
{"text": "也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。"}
{"text": "关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is?capital?of,Italy）（Italy,is?country?of,Europe）.从Rome到Europe的关系路径就是一条is?capital?of→is?country?of关系链。"}
{"text": "当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。"}
{"text": "在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+?+rlp=r1?r2???rlci=f（W[ci?1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。"}
{"text": "对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。"}
{"text": "文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。"}
{"text": "除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。"}
{"text": "Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。"}
{"text": "其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。"}
{"text": "联合模型在训练时降低来自三个子模型的损失之和。"}
{"text": "图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则?x,y:IsDirectorOf（x,y）?BeDirectedBy（y,x）说明了两个不同的关系之间的关系。"}
{"text": "Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。"}
{"text": "简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。"}
{"text": "2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。"}
{"text": "本小节将简单介绍一些典型的应用。"}
{"text": "1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。"}
{"text": "简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全任务，被称为链接预测。"}
{"text": "当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。"}
{"text": "例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。"}
{"text": "链接预测也常被用于评测知识图谱嵌入。"}
{"text": "一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。"}
{"text": "2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。"}
{"text": "这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。"}
{"text": "3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。"}
{"text": "该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。"}
{"text": "一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。"}
{"text": "也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。"}
{"text": "4.问答系统利用知识图谱完成问答系统是该任务的一个研究方向，该任务的重心是对某一个具体的通过自然语言表达的问题，使用知识图谱中的三元组对其进行回答，如下：A:Where_is_the_capital_of_Italy？Q:Rome（Rome,is-capital-of,Italy）A:Who_is_the_president_of_USA？Q:Donald_Trump（Donald_Trump,is-president-of,USA）文献[9]介绍了一种借助知识图谱嵌入完成该问题的方法。"}
{"text": "简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。"}
{"text": "S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））?（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。"}
{"text": "简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。"}
{"text": "当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。"}
{"text": "5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。"}
{"text": "协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。"}
{"text": "在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。"}
{"text": "例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。"}
{"text": "2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。"}
{"text": "目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。"}
{"text": "除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。"}
{"text": "（4）插件管理器在Engine内起到插件管理作用，既包括GraphDB内部实现的插件，也包括各种外部工具连接器。"}
{"text": "7.商业RDF三元组数据库BlazegraphBlazegraph在1.5版本之前叫作Bigdata，但众所周知的“大数据”的兴起使得这个不温不火的RDF三元组库软件被淹没其中。"}
{"text": "但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。"}
{"text": "原来仅仅是支持RDF三元组存储和SPARQL，现在已经定位为全面支持Blueprints标准的图数据库。"}
{"text": "不过，其内部实现技术仍是面向RDF三元组和SPARQL的，因而可以理解为是“基于RDF三元组库的图数据库”。"}
{"text": "从2006年发布至今，Blazegraph一直由SYSTAP公司开发，虽然它既不是最知名的RDF三元组库，也不是最流行的图数据库，但开发进展稳扎稳打，积累了相对全面的功能。"}
{"text": "Blazegraph可以通过其官方网站下载。"}
{"text": "既可以将Blazegraph作为War包部署为Web程序，也可以将其配置为单机或分布式数据库服务器。"}
{"text": "图3-27Blazegraph的Web用户界面8.商业RDF三元组数据库StardogStardog是由美国Stardog_Union公司开发的RDF三元组数据库，其首个公开发布版本是2012年2月发布的Stardog_0.9。"}
{"text": "Stardog分为企业版和社区版，社区版可以免费用于非商业用途。"}
{"text": "3.2.3原生图数据库1.最流行的图数据库Neo4jNeo4j的1.0版本发布于2010年。"}
{"text": "Neo4j基于属性图模型，其存储管理层为属性图结构中的节点、节点属性、边、边属性等设计了专门的存储方案。"}
{"text": "这使得Neo4j在存储层对于图数据的存取效率天生就优于关系数据库。"}
{"text": "同时，Neo4j还具备OLTP数据库必需的ACID事务处理功能。"}
{"text": "如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。"}
{"text": "Neo4j浏览器是功能完善的Neo4j可视化交互式客户端工具，可以用于执行Cypher语言。"}
{"text": "使用Neo4j内置的Movie图数据库执行Cypher查询，返回“TomHanks”所出演的全部电影，如图3-31所示。"}
{"text": "此外，成功启动Neo4j服务器之后，会在7474和7473端口分别开启HTTP和HTTPS服务。"}
{"text": "例如，使用浏览器访问http://localhost:7474/进入Web界面，执行Cypher查询，其功能与Neo4j浏览器是一致的。"}
{"text": "图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。"}
{"text": "JanusGraph的前身Titan是由Aurelius公司开发的，而该公司的创始人Rodriguez博士恰恰就是Blueprints标准及Gremlin语言的主要开发者，Titan对于Blueprints标准和Gremlin语言的全面支持便不难理解，JanusGraph基本上继承了Titan的这一特性。"}
{"text": "同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。"}
{"text": "另一方面，JanusGraph还具备基于Hadoop_MapReduce的图分析引擎，其可以将Gremlin导航查询自动转化为MapReduce任务。"}
{"text": "从这个角度看，JanusGraph也可作为图计算引擎使用。"}
{"text": "3.图数据库OrientDBOrientDB对于数据模式的支持也相对灵活，可以管理无模式数据（Schema-less），也可以像关系数据库那样定义完整的模式（Schema-full），还可以适应介于两者之间的混合模式（Schema-mixed）数据。"}
{"text": "在查询语言方面，OrientDB支持扩展的SQL和Gremlin用于图上的导航式查询；值得注意的是，在2.2版本引入的MATCH语句实现了声明式的模式匹配，这类似于Cypher语言查询模式。"}
{"text": "需要指出的是，Cayley虽然可以存储N-Quads格式的RDF文件，但目前尚不支持SPARQL查询。"}
{"text": "总体来讲，基于关系的存储系统继承了关系数据库的优势，成熟度较高，在硬件性能和存储容量满足的前提下，通常能够适应千万到十亿级三元组规模的管理。"}
{"text": "对于一般在百万到上亿级三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。"}
{"text": "如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。"}
{"text": "近年来，以Neo4j为代表的图数据库系统发展迅猛，使用图数据库管理RDF三元组也是一种很好的选择；但目前大部分图数据库还不能直接支持RDF三元组存储，对于这种情况，可采用数据转换方式，先将RDF预处理为图数据库支持的数据格式（如属性图模型），再进行后续管理操作。"}
{"text": "本节首先以图数据库Neo4j为例介绍其内部存储方案，然后简要描述知识图谱数据库的两类索引技术。"}
{"text": "3.3.1知识图谱数据库的存储：以Neo4j为例这一节将深入Neo4j图数据库底层，探究其原生的图存储方案。"}
{"text": "对于遵循属性图的图数据库，存储管理层的任务是将属性图编码表示为在磁盘上存储的数据格式。"}
{"text": "虽然不同图数据库的具体存储方案各有差异，但一般认为具有“无索引邻接”特性（Index-FreeAdjacency）的图数据库才称为原生图数据库[35]。"}
{"text": "在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。"}
{"text": "这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。"}
{"text": "作为对比，来看看在非原生图数据库中使用全局索引关联邻接节点的情形。"}
{"text": "如果觉得这样的查找代价还是可以接受的话，那么换一个问题，“谁认识张三”的查找代价是多少？显然，对于这个查询，需要通过全局索引检查每个节点，看其认识的人中有没有张三，总代价为O(nlogn)，这样的复杂度对于大图数据的遍历操作是不可接受的。"}
{"text": "有人说，可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。"}
{"text": "只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。"}
{"text": "图3-36邻接关系的全局索引示例图3-37将关系作为“一等公民”在Neo4j数据库中，属性图的不同部分是被分开存储在不同文件中的。"}
{"text": "正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。"}
{"text": "首先，来看在Neo4j中是如何存储图节点和边的。"}
{"text": "节点记录存储在文件neostore.nodestore.db中。"}
{"text": "节点记录的第0字节inUse是记录使用标志字节的，告诉数据库该记录是否在使用中，还是已经删除并可回收用来装载新的记录；第1～4字节nextRelId是与节点相连的第1条边的id；第5～8字节nextPropId是节点的第1个属性的id。"}
{"text": "边记录存储在文件neostore.relationshipstore.db中。"}
{"text": "边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。"}
{"text": "和第5～8字节firstNode图3-38Neo4j中节点和边记录的物理存储结构Neo4j实现节点和边快速定位的关键是“定长记录”的存储方案，将具有定长记录的图结构与具有变长记录的属性数据分开存储。"}
{"text": "例如，一个节点记录长度是9字节，如果要查找id为99的节点记录所在位置（id从0开始），则可直接到节点存储文件第891个字节处访问（存储文件从第0个字节开始）。"}
{"text": "边记录也是“定长记录”，长度为33字节。"}
{"text": "这样，数据库已知记录id可以O(1)的代价直接计算其存储地址，而避免了全局索引中O(nlogn)的查找代价。"}
{"text": "图3-39展示了Neo4j中各种存储文件之间是如何交互的。"}
{"text": "存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。"}
{"text": "需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。"}
{"text": "这些操作除了记录字段的读取，就是定长记录地址的计算，均是O(1)时间的高效率操作。"}
{"text": "可见，正是由于将边作为“一等公民”，将图结构实现为定长记录的存储方案，赋予了Neo4j作为原生图数据库的“无索引邻接”特性。"}
{"text": "3.3.2知识图谱数据库的索引图数据上的索引一种是对节点或边上属性数据的索引，一种是对图结构的索引；前者可应用关系数据库中已有的B+树索引技术直接实现，而后者仍是业界没有达成共识的、开放的研究问题。"}
{"text": "1.属性数据索引Neo4j数据库在前述存储方案的基础上还支持用户对属性数据建立索引，目的是加速针对某属性的查询处理性能。"}
{"text": "Neo4j索引的定义通过Cypher语句完成，目前支持对于同一个类型节点的某个属性构建索引。"}
{"text": "例如，对所有程序员节点的姓名属性构建索引。"}
{"text": "在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。"}
{"text": "例如，下面的查询查找姓名为张三的程序员，显然会用到刚刚建立的索引。"}
{"text": "应用该索引无疑会根据姓名属性的值快速定位到姓名是“张三”的节点，而无须扫描程序员节点的全部属性。"}
{"text": "删除索引的语句为：不难发现，为图节点或边的属性建立索引与为关系表的某一列建立索引在本质上并无不同之处，完全可以通过B+树或散列表实现。"}
{"text": "这种索引并不涉及图数据上的任何图结构信息。"}
{"text": "2.图结构索引图结构索引是为图数据中的点边结构信息建立索引的方法。"}
{"text": "利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。"}
{"text": "大体上，图结构索引分为“基于路径的”和“基于子图的”两种。"}
{"text": "（1）基于路径的图索引。"}
{"text": "一种典型的基于路径的图索引叫作GraphGrep[36]。"}
{"text": "这种索引将图中长度小于或等于一个固定长度的全部路径构建为索引结构。"}
{"text": "索引的关键字可以是组成路径的节点或边上属性值或标签的序列。"}
{"text": "图3-40是在图3-3的属性图上构建的GraphGrep索引。"}
{"text": "这里构建的是长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。"}
{"text": "例如，索引将关键字“认识.参加”映射到节点id序列(1,4,3)和(1,4,5)。"}
{"text": "利用该路径索引，类似前面出现过的“查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目”的查询处理效率会大幅提高，因为由节点1出发，根据关键字“认识.参加”，可以快速找到满足条件的节点3和节点5。"}
{"text": "（2）基于子图的索引。"}
{"text": "基于子图的索引可以看作是基于路径索引的一般化形式，是将图数据中的某些子图结构信息作为关键字，将该子图的实例数据作为值而构建的索引结构。"}
{"text": "图3-41是在图3-3的属性图上构建的一种子图索引。"}
{"text": "满足第1个关键字子图的节点序列为(1,2,4)，满足第2个关键字子图的节点序列为(1,4,3)。"}
{"text": "如果查询中包含某些作为关键字的子图结构，则可以利用该子图索引，快速找到与这些子图结构匹配的节点序列，这样可大幅度减小查询操作的搜索空间。"}
{"text": "图3-40基于路径的图索引示例图3-41基于子图的图索引示例不过，一个图数据的子图有指数个，将哪些子图作为关键字建立索引尚未得到很好的解决。"}
{"text": "一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。"}
{"text": "但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。"}
{"text": "一种更合理的方法是从用户的查询日志中挖掘频繁使用的子图模式，并以此作为关键字建立索引。"}
{"text": "3.4开源工具实践3.4.1三元组数据库Apache_Jena1.开源工具简介Apache_Jena是Apache顶级项目，其前身为惠普实验室开发的Jena工具包。"}
{"text": "Jena是语义Web领域主要的开源框架和RDF三元组库，较好地遵循W3C标准，其功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理等。"}
{"text": "Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。"}
{"text": "本实践相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "2.开源工具的技术架构ApacheJena框架如图3-42所示。"}
{"text": "推理API为上层提供本体推理服务，可以使用Jena内置基于规则的推理机进行RDFS和OWL本体上的推理任务，或者选择通过接口调用第三方外部推理机。"}
{"text": "Jena对外界应用程序的API包括实现基本三元组管理功能的RDFAPI、实现RDFS和OWL本体推理功能的本体API和实现查询处理功能的SPARQL_API。"}
{"text": "Java应用程序代码可以通过导入类库的形式直接调用这些API。"}
{"text": "Jena还提供了支持各种RDF三元组格式的解析器和编写器，支持的三元组格式包括：RDF/XML、Turtle、N-Triple和RDFa。"}
{"text": "图3-42Apache_Jena框架实质上，Jena是一个Java框架类库。"}
{"text": "在一般情况下，上述功能需要在Java程序中进行调用。"}
{"text": "Jena为了用户使用方便，提供了一个名为Fuseki的独立RDF数据库Web应用程序。"}
{"text": "本实践将使用Fuseki作为认识知识图谱数据库的入门工具。"}
{"text": "Fuseki是基于Jena的SPARQL服务器，可以作为独立的服务由命令行启动，也可以作为操作系统服务或JavaWeb应用程序。"}
{"text": "Fuseki底层存储基于TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。"}
{"text": "Fuseki支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。"}
{"text": "访问OpenKG可以获取使用实例和整体配置细节。"}
{"text": "3.其他类似工具RDF4J是Eclipse基金会旗下的开源孵化项目，其前身是荷兰软件公司Aduna开发的Sesame框架，其功能包括：RDF数据的解析、存储、推理和查询等。"}
{"text": "RDF4J提供内存和磁盘两种RDF存储机制，支持SPARQL1.1查询和更新语言。"}
{"text": "gStore是由北京大学开发的基于图的RDF三元组数据库。"}
{"text": "AllegroGraph是Franz公司开发的RDF三元组数据库。"}
{"text": "AllegroGraph对语义推理功能具有较为完善的支持。"}
{"text": "除了三元组数据库的基本功能，AllegroGraph_RDFS++推理机、OWL2RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析还支持动态物化的库、可视化RDF图浏览器等。"}
{"text": "GraphDB是由Ontotext软件公司开发的RDF三元组数据库。"}
{"text": "GraphDB实现了RDF4J框架的SAIL层，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。"}
{"text": "GraphDB的特色是对于RDF推理功能的良好支持。"}
{"text": "3.4.2面向RDF的三元组数据库gStore1.开源工具简介gStore是由北京大学计算机科学技术研究所数据管理实验室自2011年开始研发的面向RDF知识图谱的开源图数据库系统，遵循Apache开源协议。"}
{"text": "不同于传统基于关系数据库的RDF数据管理方法，gStore原生基于图数据模型，在存储RDF数据时维持并根据其图结构构建了基于二进制位图索引的新型索引结构――VS树。"}
{"text": "本实践相关工具、实验数据及操作说明由OpenKG提供，下载链接为http://openkg.cn/tool/gstore。"}
{"text": "2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。"}
{"text": "图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。"}
{"text": "同时，gStore将RDF数据上的所有点和边通过二进制编码的方式编码成若干位图索引，并将这些位图索引组织成VS树。"}
{"text": "在在线查询处理阶段，gStore也将SPARQL查询解析成查询图。"}
{"text": "然后，gStore按照对RDF数据图的编码方式，将SPARQL查询图进行编码以形成一个标签图，并在VS树和RDF数据图的邻接表上进行检索以得到每个查询变量的候选匹配。"}
{"text": "最后，gStore将所有查询变量的候选匹配连接成最终匹配。"}
{"text": "目前，gStore只能在Linux系统上通过Shell命令编译、安装与运行。"}
{"text": "同时，gStore官网还提供了gStore_Workbench，方便用户操作RDF数据库。"}
{"text": "具体包括：（1）环境配置。"}
{"text": "可以从OpenKG网站或gStore官网上下载gStore源代码，然后通过make来编译得到gStore运行程序。"}
{"text": "同时，通过OpenKG网站或gStore官网可以下载gStore_Workbench，进行编译安装后可以得到gStore_Workbench。"}
{"text": "（2）数据导入。"}
{"text": "gStore目前支持NT格式的RDF数据，利用gStore安装路径下bin目录中gbuild或者gStore_Workbench中的数据库管理页面导入数据。"}
{"text": "gStore_Workbench中的数据库管理页面还记录目前gStore包括的数据库统计信息。"}
{"text": "（3）查询处理。"}
{"text": "gStore目前完全支持SPARQL1.0查询语法，利用gStore安装路径下bin目录中gquery或者gStoreWorkbench中的图数据库查询页面，就可以输入查询然后得到结果。"}
{"text": "gStore同时还提供HTTP接口，可以利用gStore安装路径下bin目录中ghttp启动HTTP服务，进而接收其他机器远程通过HTTP发来的SPARQL查询请求。"}
{"text": "访问OpenKG网站可以获取使用实例和整体配置细节。"}
{"text": "3.其他类似工具Jena的前身是惠普实验室（HP_Labs）2000年开发的工具包。"}
{"text": "Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。"}
{"text": "针对RDF数据，Jena维护了一张大的三元组表和三种属性表，包括单值属性表、多值属性表和属性类表。"}
{"text": "Virtuoso是OpenLink公司开发的知识图谱管理系统，有免费的社区版和收费的商业版。"}
{"text": "Virtuoso是可以支持包括RDF在内的多种数据模型的混合数据库管理系统。"}
{"text": "其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。"}
{"text": "图4-13实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。"}
{"text": "当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。"}
{"text": "基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。"}
{"text": "（1）远程监督方法。"}
{"text": "远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。"}
{"text": "远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。"}
{"text": "例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。"}
{"text": "因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。"}
{"text": "远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。"}
{"text": "但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。"}
{"text": "为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。"}
{"text": "最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。"}
{"text": "下面介绍两个具有代表性的模型。"}
{"text": "Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。"}
{"text": "模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。"}
{"text": "关系的分类是基于包特征上的Softmax分类器实现的。"}
{"text": "APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。"}
{"text": "实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。"}
{"text": "图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。"}
{"text": "针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。"}
{"text": "CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。"}
{"text": "样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。"}
{"text": "整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。"}
{"text": "在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。"}
{"text": "图4-15CNN-RL模型[15]（2）Bootstrapping方法。"}
{"text": "Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。"}
{"text": "通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。"}
{"text": "有很多实体关系抽取系统都采用了Bootstrapping方法。"}
{"text": "Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。"}
{"text": "Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。"}
{"text": "在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。"}
{"text": "Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。"}
{"text": "此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。"}
{"text": "例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。"}
{"text": "Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。"}
{"text": "但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。"}
{"text": "4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。"}
{"text": "事件的发生可能是因为一个动作的产生或者系统状态的改变。"}
{"text": "事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。"}
{"text": "一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。"}
{"text": "图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。"}
{"text": "1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。"}
{"text": "一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。"}
{"text": "判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。"}
{"text": "（2）元素分类器。"}
{"text": "判断词组是否为事件的元素。"}
{"text": "（3）元素角色分类器。"}
{"text": "判定事件元素的角色类别。"}
{"text": "（4）属性分类器。"}
{"text": "判定事件的属性。"}
{"text": "（5）可报告性分类器。"}
{"text": "判定是否存在值得报告的事件实例。"}
{"text": "表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。"}
{"text": "各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。"}
{"text": "表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。"}
{"text": "为了解决这一问题，一些研究工作提出了事件的联合抽取方法。"}
{"text": "在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。"}
{"text": "一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。"}
{"text": "联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。"}
{"text": "联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。"}
{"text": "具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。"}
{"text": "该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。"}
{"text": "在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。"}
{"text": "此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。"}
{"text": "为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。"}
{"text": "这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。"}
{"text": "联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。"}
{"text": "图4-17联合事件抽取方法图4-18事件触发词和事件元素示例图4-19事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。"}
{"text": "图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。"}
{"text": "该模型由YuboChen等人于2015年发表在ACL会议上[21]。"}
{"text": "模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。"}
{"text": "其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。"}
{"text": "在CNN方法的结果。"}
{"text": "ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。"}
{"text": "在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。"}
{"text": "W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。"}
{"text": "DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。"}
{"text": "4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。"}
{"text": "它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。"}
{"text": "直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。"}
{"text": "直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。"}
{"text": "下面给出一个简单的例子，解释直接映射的基本思路。"}
{"text": "首先，假设通过SQL语句创建图4-21中的两个数据库表。"}
{"text": "创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。"}
{"text": "主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。"}
{"text": "每列的谓词是由IRI前缀和表名、列名连接形成的IRI。"}
{"text": "这些值是从列值的词汇形式形成的RDF文字。"}
{"text": "每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。"}
{"text": "这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。"}
{"text": "直接映射不会为NULL值生成三元组。"}
{"text": "4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。"}
{"text": "这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。"}
{"text": "在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。"}
{"text": "然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。"}
{"text": "每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。"}
{"text": "R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。"}
{"text": "R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。"}
{"text": "一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。"}
{"text": "每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。"}
{"text": "“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。"}
{"text": "三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。"}
{"text": "主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。"}
{"text": "谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。"}
{"text": "图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。"}
{"text": "将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。"}
{"text": "用于创建R2RML视图的SQL语句如下所示。"}
{"text": "用于DEPT表数据转换的R2RML映射文档如下所示。"}
{"text": "此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。"}
{"text": "4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。"}
{"text": "这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。"}
{"text": "表4-3OBDA系统的主要特性对比（1）D2RQ[22]。"}
{"text": "D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。"}
{"text": "其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。"}
{"text": "D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。"}
{"text": "基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。"}
{"text": "此外，D2RQ系统还部分支持R2RML映射。"}
{"text": "（2）Mastro[23]。"}
{"text": "Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。"}
{"text": "Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。"}
{"text": "除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。"}
{"text": "图4-23D2RQ平台框架[22]图4-24Mastro系统结构[23]（3）Ultrawrap[24]。"}
{"text": "Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。"}
{"text": "其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。"}
{"text": "Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。"}
{"text": "图4-25Ultrawrap系统结构（4）Morph-RDB[25]。"}
{"text": "Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。"}
{"text": "Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。"}
{"text": "Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。"}
{"text": "（5）Ontop[26]。"}
{"text": "Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。"}
{"text": "Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。"}
{"text": "通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。"}
{"text": "Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。"}
{"text": "图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。"}
{"text": "自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。"}
{"text": "目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。"}
{"text": "4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。"}
{"text": "在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。"}
{"text": "图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。"}
{"text": "目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。"}
{"text": "在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。"}
{"text": "DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。"}
{"text": "得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。"}
{"text": "截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。"}
{"text": "此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。"}
{"text": "DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。"}
{"text": "根据抽样评测，DBpedia中RDF三元组的正确率达88%。"}
{"text": "图4-28所示为DBpedia知识抽取的总体框架。"}
{"text": "框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。"}
{"text": "图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。"}
{"text": "●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。"}
{"text": "信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。"}
{"text": "信息框的一般抽取直接将信息框中的信息转换为RDF三元组。"}
{"text": "三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。"}
{"text": "然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。"}
{"text": "图4-29信息框示例[27]4.4.2面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。"}
{"text": "从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。"}
{"text": "图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。"}
{"text": "包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。"}
{"text": "包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。"}
{"text": "图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。"}
{"text": "手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。"}
{"text": "XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。"}
{"text": "借助它可以获取网页中元素的位置，从而获取需要的信息。"}
{"text": "在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。"}
{"text": "分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。"}
{"text": "典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。"}
{"text": "（1）网页清洗。"}
{"text": "纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。"}
{"text": "（2）网页标注。"}
{"text": "在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。"}
{"text": "（3）包装器空间生成。"}
{"text": "基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。"}
{"text": "归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。"}
{"text": "（4）包装器评估。"}
{"text": "包装器可以通过准确率和召回率进行评估。"}
{"text": "使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。"}
{"text": "准确率和召回率越高，表示包装器的质量越好。"}
{"text": "3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。"}
{"text": "此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。"}
{"text": "自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。"}
{"text": "在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。"}
{"text": "在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。"}
{"text": "上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。"}
{"text": "表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。"}
{"text": "4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。"}
{"text": "实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。"}
{"text": "通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。"}
{"text": "实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。"}
{"text": "图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。"}
{"text": "该步骤主要通过命名实体识别技术或者词典匹配技术实现。"}
{"text": "命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。"}
{"text": "2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。"}
{"text": "例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。"}
{"text": "生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。"}
{"text": "某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。"}
{"text": "然后，可以利用这些扩展形式形成实体提及的候选实体集合。"}
{"text": "表层名字扩展可以采用启发式的模式匹配方法实现。"}
{"text": "例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。"}
{"text": "除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。"}
{"text": "（2）基于搜索引擎的方法。"}
{"text": "将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。"}
{"text": "例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。"}
{"text": "此外，维基百科自有的搜索功能也可以用于生成候选实体。"}
{"text": "（3）构建查询实体引用表。"}
{"text": "很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。"}
{"text": "实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。"}
{"text": "在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。"}
{"text": "维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。"}
{"text": "维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。"}
{"text": "表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。"}
{"text": "一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。"}
{"text": "下面介绍每类方法中具有代表性的工作。"}
{"text": "[32]（1）基于图的方法。"}
{"text": "基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。"}
{"text": "该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。"}
{"text": "Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。"}
{"text": "在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。"}
{"text": "最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。"}
{"text": "采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。"}
{"text": "图4-34参照图[33]（2）基于概率生成模型的方法。"}
{"text": "基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。"}
{"text": "在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。"}
{"text": "图4-35实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael_Jeffrey_Jordan]和[Michael_I.Jordan]；然后，模型依据给定实体e实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael_Jordan]；最后，模型依据给定实体e上下文的条件概率P（c|e）输出实体提及的上下文。"}
{"text": "根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。"}
{"text": "当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。"}
{"text": "基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。"}
{"text": "实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。"}
{"text": "首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。"}
{"text": "通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。"}
{"text": "图4-36实体-主题模型[37]（4）基于深度学习的方法。"}
{"text": "在候选实体消歧过程中，准确计算实体的相关度十分重要。"}
{"text": "因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。"}
{"text": "Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。"}
{"text": "在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。"}
{"text": "基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。"}
{"text": "图4-37实体提及生成过程示例[38]4.5.2知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive_Logic_Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。"}
{"text": "知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。"}
{"text": "给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。"}
{"text": "FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。"}
{"text": "下面通过一个例子介绍FOIL的规则学习过程。"}
{"text": "设有规则学习问题如表4-6所示。"}
{"text": "背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。"}
{"text": "FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。"}
{"text": "表4-7列出了FOIL学习单个规则的过程。"}
{"text": "当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。"}
{"text": "表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。"}
{"text": "在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。"}
{"text": "FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。"}
{"text": "基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。"}
{"text": "在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。"}
{"text": "多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。"}
{"text": "因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。"}
{"text": "最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。"}
{"text": "在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。"}
{"text": "2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。"}
{"text": "PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。"}
{"text": "如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。"}
{"text": "实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。"}
{"text": "在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。"}
{"text": "图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。"}
{"text": "因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。"}
{"text": "PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。"}
{"text": "为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。"}
{"text": "式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。"}
{"text": "PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。"}
{"text": "（2）特征计算。"}
{"text": "在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。"}
{"text": "给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"}
{"text": "通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。"}
{"text": "（3）关系分类。"}
{"text": "基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。"}
{"text": "利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。"}
{"text": "关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。"}
{"text": "PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。"}
{"text": "图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "该框架遵循Apache开源协议。"}
{"text": "4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。"}
{"text": "在具体应用中，可以选择使用因子图模型或神经网络模型。"}
{"text": "图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。"}
{"text": "根据使用技术的不同，下面分别介绍一些典型的本体映射工作。"}
{"text": "很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。"}
{"text": "此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。"}
{"text": "1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。"}
{"text": "这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。"}
{"text": "（1）技术综述1）基于术语的本体映射技术。"}
{"text": "这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。"}
{"text": "比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。"}
{"text": "①基于字符串的方法。"}
{"text": "基于字符串的方法直接比较表示本体成分的术语的字符串结构。"}
{"text": "主要的字符串比较技术如下。"}
{"text": "（a）规范化。"}
{"text": "在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。"}
{"text": "这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。"}
{"text": "（b）相似度量方法。"}
{"text": "在规范字符串的基础上，能进一步度量不同字符串间的相似程度。"}
{"text": "常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。"}
{"text": "如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。"}
{"text": "一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。"}
{"text": "定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。"}
{"text": "定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。"}
{"text": "还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。"}
{"text": "定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。"}
{"text": "两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。"}
{"text": "这些编辑操作包括插入、删除和替代字符。"}
{"text": "显然，编辑距离越大，表示两字符串的相似程度越小。"}
{"text": "编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。"}
{"text": "除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。"}
{"text": "路径比较便是这类方法中的一种。"}
{"text": "定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"}
{"text": "②基于语言的方法。"}
{"text": "基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。"}
{"text": "这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。"}
{"text": "内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。"}
{"text": "它寻找同一字符串的不同语言形态，如Apple和Apples等。"}
{"text": "寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。"}
{"text": "外部方法利用词典等外部资源来寻找映射。"}
{"text": "基于词典的方法使用外部词典匹配语义相关的术语。"}
{"text": "例如，使用WordNet能判断两个术语是否有同义或上下义关系。"}
{"text": "尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。"}
{"text": "2）基于结构的本体映射技术。"}
{"text": "在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。"}
{"text": "基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。"}
{"text": "①内部结构。"}
{"text": "基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。"}
{"text": "通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。"}
{"text": "②外部结构。"}
{"text": "比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。"}
{"text": "从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。"}
{"text": "有一些常用来判断本体成分相似的准则，这些准则包括：(C1)直接超类或所有的超类相似；(C2)兄弟相似；(C3)直接子类或所有的子类相似；(C4)所有或大部分后继（不一定是子类，可能通过其他关系连接）相似；(C5)所有或大部分的叶子成分相似；(C6)从根节点到当前节点的路径上的实体都相似。"}
{"text": "对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。"}
{"text": "计算概念之间的相似也可以考虑它们之间的关系。"}
{"text": "如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。"}
{"text": "然而，这种方法的问题在于如何判断关系的相似性。"}
{"text": "关系的相似性计算一直是一个很困难的问题。"}
{"text": "外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。"}
{"text": "基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。"}
{"text": "（2）方法和工具1）AnchorPROMPT。"}
{"text": "除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。"}
{"text": "PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。"}
{"text": "目前，PROMPT的这些工具已集成到Protégé系统中。"}
{"text": "本体映射是解决很多多本体问题的基础。"}
{"text": "为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。"}
{"text": "AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。"}
{"text": "①AnchorPROMPT的思想。"}
{"text": "AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。"}
{"text": "AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。"}
{"text": "术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。"}
{"text": "AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。"}
{"text": "AnchorPROMPT将每个本体O视为一个带边有向图G。"}
{"text": "O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。"}
{"text": "图中通过一条边连接的两节点称为相邻节点。"}
{"text": "如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。"}
{"text": "路径的长度是边的数目。"}
{"text": "为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。"}
{"text": "AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。"}
{"text": "因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。"}
{"text": "②AnchorPROMPT算法。"}
{"text": "为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。"}
{"text": "对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。"}
{"text": "这样的术语对利用基本的术语比较技术能很容易识别出来。"}
{"text": "根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。"}
{"text": "对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。"}
{"text": "在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。"}
{"text": "图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。"}
{"text": "当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。"}
{"text": "在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。"}
{"text": "AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。"}
{"text": "结果，经常出现在相同位置的术语对间的相似度分数往往最高。"}
{"text": "（a）等价组。"}
{"text": "在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。"}
{"text": "与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。"}
{"text": "AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。"}
{"text": "等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。"}
{"text": "图5-5路径中的等价组（b）相似度分数。"}
{"text": "给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。"}
{"text": "步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。"}
{"text": "步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。"}
{"text": "如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。"}
{"text": "当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。"}
{"text": "这个问题在接下来的部分进行分析。"}
{"text": "根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。"}
{"text": "③AnchorPROMPT评估。"}
{"text": "Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。"}
{"text": "（a）等价组大小。"}
{"text": "试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。"}
{"text": "当等价组的最大尺寸为2时，只有12%的试验没有结果。"}
{"text": "因此，在随后的试验中设定等价组的最大尺寸大小为2。"}
{"text": "（b）等价组成员的相似度分数。"}
{"text": "为评价等价组成员如何打分合理而做了两类试验。"}
{"text": "第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。"}
{"text": "试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。"}
{"text": "（c）锚的数目和路径最大长度。"}
{"text": "在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。"}
{"text": "试验表明，当最大长度路径设为2时，能获得最好的正确率。"}
{"text": "当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。"}
{"text": "④AnchorPROMPT的讨论。"}
{"text": "当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。"}
{"text": "以此类推，可以得到路径上更多的关系对也是相似的。"}
{"text": "实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。"}
{"text": "在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。"}
{"text": "而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。"}
{"text": "AnchorPROMPT其他方面的讨论如下。"}
{"text": "（a）减少负面结果的影响。"}
{"text": "概念间的相似度分数是一个累加值。"}
{"text": "两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。"}
{"text": "AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。"}
{"text": "试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。"}
{"text": "试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。"}
{"text": "（b）执行本体映射。"}
{"text": "AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。"}
{"text": "（c）局限性。"}
{"text": "AnchorPROMPT的映射发现方法并非适用于所有的本体。"}
{"text": "当两个本体间的结构差别很大时，该方法处理的效果并不好。"}
{"text": "此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。"}
{"text": "⑤AnchorPROMPT的总结。"}
{"text": "AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。"}
{"text": "由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。"}
{"text": "对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。"}
{"text": "从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。"}
{"text": "2）iPROMPT。"}
{"text": "PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。"}
{"text": "iPROMPT从语言角度判断本体间概念或关系的相似。"}
{"text": "然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。"}
{"text": "在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。"}
{"text": "图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。"}
{"text": "iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。"}
{"text": "步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。"}
{"text": "当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。"}
{"text": "合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。"}
{"text": "这样的冲突可以通过重命名来解决。"}
{"text": "②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。"}
{"text": "在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。"}
{"text": "③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。"}
{"text": "对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。"}
{"text": "Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。"}
{"text": "这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。"}
{"text": "试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。"}
{"text": "总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。"}
{"text": "3）MAFRA。"}
{"text": "MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。"}
{"text": "MAFRA引入了语义桥和以服务为中心的思想。"}
{"text": "语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。"}
{"text": "MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。"}
{"text": "要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。"}
{"text": "MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。"}
{"text": "②相似度。"}
{"text": "MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。"}
{"text": "在计算概念间关系的过程中还考虑了概念的属性。"}
{"text": "③语义桥。"}
{"text": "根据本体成分间的相似度，利用语义桥来表示本体映射。"}
{"text": "这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。"}
{"text": "还能利用推理建立一些隐含的语义桥。"}
{"text": "④执行。"}
{"text": "在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。"}
{"text": "⑤后处理。"}
{"text": "映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。"}
{"text": "垂直方向四个模块具体包括：①演化。"}
{"text": "当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。"}
{"text": "②协同创建。"}
{"text": "对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。"}
{"text": "③领域限制和背景知识。"}
{"text": "给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。"}
{"text": "④用户界面交互。"}
{"text": "给出图形化的操作界面能让本体建立的过程更容易。"}
{"text": "图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。"}
{"text": "尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。"}
{"text": "因此，MAFRA更多只是一个处理异构本体映射的框架。"}
{"text": "4）ONION。"}
{"text": "ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。"}
{"text": "该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。"}
{"text": "为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。"}
{"text": "本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。"}
{"text": "本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。"}
{"text": "专家还可以添加新的映射，以补充算法无法生成的映射规则。"}
{"text": "ONION的映射生成过程同时使用了术语匹配和本体图匹配。"}
{"text": "对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。"}
{"text": "在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。"}
{"text": "为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。"}
{"text": "在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。"}
{"text": "“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。"}
{"text": "①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。"}
{"text": "在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。"}
{"text": "同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。"}
{"text": "②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。"}
{"text": "Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。"}
{"text": "因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。"}
{"text": "ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。"}
{"text": "试验还表明，在映射发现过程中采用多种策略能提高精度。"}
{"text": "ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。"}
{"text": "5）Wang_Peng和Xu_Baowen的方法。"}
{"text": "Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。"}
{"text": "该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。"}
{"text": "该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。"}
{"text": "这种方法认为不同本体间概念的相似度包括三个部分：①概念的同义词集相似度。"}
{"text": "同义词集是语义相同或相近词的分组[38]。"}
{"text": "基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。"}
{"text": "②概念特征上的相似度。"}
{"text": "概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。"}
{"text": "③概念上下文上的相似度。"}
{"text": "以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。"}
{"text": "以下定义概念的语义邻居概念集。"}
{"text": "定义5.6概念Co的语义邻居概念集N(Co,r)={Ci|_i,d(Co,Ci)≤r}。"}
{"text": "式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。"}
{"text": "这里的关系包含直接继承关系。"}
{"text": "d≤r表明与当前的概念在语义距离上小于某一定常数。"}
{"text": "在以上分析的基础上，给出了本体间概念相似度的计算公式：S(Cp,Cq)=Ww×Sw(Cp,Cq)+Wu×Su(Cp,Cq)+Wn×Sn(Cp,Cq)式中，Ww、Wu和Wn是权重；Sw、Su和Sn分别代表概念名称、特征以及上下文三方面的相似性度量。"}
{"text": "计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。"}
{"text": "该方法利用概念间的相似度辅助本体映射的生成。"}
{"text": "①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。"}
{"text": "通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。"}
{"text": "②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。"}
{"text": "根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。"}
{"text": "生成规则如下。"}
{"text": "定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。"}
{"text": "式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。"}
{"text": "式中，isa表示两概念具有上义和下义关系。"}
{"text": "从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。"}
{"text": "6）S-Match。"}
{"text": "S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。"}
{"text": "它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。"}
{"text": "S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。"}
{"text": "S-Match的核心是计算异构本体间的语义关系。"}
{"text": "输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。"}
{"text": "该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。"}
{"text": "执行结果的输出是一个被丰富的树。"}
{"text": "然后，用户协调两本体的匹配过程，这种方法使用三个外部库。"}
{"text": "第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。"}
{"text": "目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。"}
{"text": "第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。"}
{"text": "第三个库是由结构层次的强语义匹配器组成的。"}
{"text": "输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。"}
{"text": "其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。"}
{"text": "其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese__Cheese>；词形分析，即将词的形态转换为基本形式，如Images_Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。"}
{"text": "<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。"}
{"text": "扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。"}
{"text": "步骤3：对所有T1和T2中的标签对，计算标签间的关系。"}
{"text": "利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。"}
{"text": "步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。"}
{"text": "将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。"}
{"text": "与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。"}
{"text": "7）Cupid。"}
{"text": "Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。"}
{"text": "该方法输入图格式的模式，图节点表示模式中的元素。"}
{"text": "与其他的混合方法比较[42],Cupid得到更好的映射结果。"}
{"text": "发现模式匹配的算法包含三个阶段。"}
{"text": "①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。"}
{"text": "Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。"}
{"text": "8）其他方法。"}
{"text": "Chimaera是一个合并和测试大本体的环境[43]。"}
{"text": "寻找本体映射是进行合并操作的一个主要任务。"}
{"text": "Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。"}
{"text": "Chimaera能识别术语间是否包含或不相关等简单的映射关系。"}
{"text": "BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。"}
{"text": "BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。"}
{"text": "它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。"}
{"text": "因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。"}
{"text": "COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。"}
{"text": "COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。"}
{"text": "它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。"}
{"text": "面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。"}
{"text": "模式被编码为有向无环图。"}
{"text": "COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。"}
{"text": "ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。"}
{"text": "ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。"}
{"text": "该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。"}
{"text": "（3）基于术语和结构的本体映射总结。"}
{"text": "这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。"}
{"text": "2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。"}
{"text": "（1）技术综述。"}
{"text": "基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。"}
{"text": "①共享实例的方法。"}
{"text": "当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。"}
{"text": "当两概念等价时，显然有AB=A=B。"}
{"text": "然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。"}
{"text": "定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。"}
{"text": "此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。"}
{"text": "②无共享实例的方法。"}
{"text": "当两概念没有共享实例时，基于共享实例的方法无能为力。"}
{"text": "事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。"}
{"text": "在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。"}
{"text": "常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。"}
{"text": "其中，Haussdorf距离度量两个集合之间的最大距离。"}
{"text": "而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。"}
{"text": "基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。"}
{"text": "通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。"}
{"text": "训练完成后，训练结果用于发现异构本体间的映射。"}
{"text": "大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。"}
{"text": "常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。"}
{"text": "（2）方法和工具1）GLUE。"}
{"text": "GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。"}
{"text": "GLUE是对半自动模式发现系统LSD的一个改进[53]。"}
{"text": "GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。"}
{"text": "该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。"}
{"text": "①GLUE的思想。"}
{"text": "GLUE的目的是根据分类本体寻找本体间1∶1的映射。"}
{"text": "其中的主要思想包括：（a）相似度定义。"}
{"text": "GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。"}
{"text": "GLUE定义了4种概念的联合概率分布。"}
{"text": "（b）计算相似度。"}
{"text": "由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。"}
{"text": "它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。"}
{"text": "（c）多策略学习。"}
{"text": "使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。"}
{"text": "然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。"}
{"text": "为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。"}
{"text": "（d）利用领域约束。"}
{"text": "GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。"}
{"text": "一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。"}
{"text": "（e）处理复杂映射。"}
{"text": "为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。"}
{"text": "以下给出GLUE方法的详细介绍。"}
{"text": "②相似度度量。"}
{"text": "很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。"}
{"text": "GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。"}
{"text": "在此基础上，GLUE定义不同概念间的联合)和P(概率分布。"}
{"text": "概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。"}
{"text": "以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。"}
{"text": "GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。"}
{"text": "第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。"}
{"text": "另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。"}
{"text": "这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。"}
{"text": "这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。"}
{"text": "类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。"}
{"text": "③GLUE体系结构。"}
{"text": "GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。"}
{"text": "图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。"}
{"text": "然后利用机器学习技术计算每对概念的联合概率分布。"}
{"text": "由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。"}
{"text": "分布评估使用一组基本学习器和一个元学习器。"}
{"text": "相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。"}
{"text": "放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。"}
{"text": "④分布估计。"}
{"text": "考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。"}
{"text": "通常这个比值是无法计算的，因为不可能知道全体实例。"}
{"text": "因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。"}
{"text": "注意，两个本体的实例可以重叠，但没有必要必须那样。"}
{"text": "Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。"}
{"text": "N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。"}
{"text": "这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。"}
{"text": "为了达到这个目的，GLUE使用了机器学习方法。"}
{"text": "特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。"}
{"text": "然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。"}
{"text": "最后，使用该分类器预测O2中的实例s是否属于A。"}
{"text": "通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。"}
{"text": "这个值反映了分类的不确定性。"}
{"text": "这里规定置信度大于0.5就表示“是”。"}
{"text": "常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。"}
{"text": "基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。"}
{"text": "具体的过程如图5-9所示。"}
{"text": "●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。"}
{"text": "●使用和作为正例和反例分别训练学习器L，如图5-9（c）。"}
{"text": "●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。"}
{"text": "●对中的每个实例使用学习器L进行分类。"}
{"text": "将划分为两个集合和。"}
{"text": "相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。"}
{"text": "●重复（a）～（d），得到集合和。"}
{"text": "●使用公式计算P(A,B)。"}
{"text": "类似地，可以计算出其他3种联合概率分布。"}
{"text": "图5-9估计概念A和B的概率分布⑤多策略学习。"}
{"text": "训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。"}
{"text": "为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。"}
{"text": "在分布估计阶段，系统会训练多个基本学习器L1,�,Lk。"}
{"text": "每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。"}
{"text": "训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。"}
{"text": "与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。"}
{"text": "目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。"}
{"text": "此外，还有1个元学习器将基本学习器的结果进行线性合并。"}
{"text": "内容学习器和名字学习器的细节如下：（a）内容学习器。"}
{"text": "利用实例文本内容中的词频来进行分类预测。"}
{"text": "一个实例通常由名将这些信息都作为实例的文本内容。"}
{"text": "例如，实字、属性集合以及属性值组成。"}
{"text": "GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。"}
{"text": "内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。"}
{"text": "它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,�,wk}，其中的wj是标记。"}
{"text": "内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。"}
{"text": "根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。"}
{"text": "其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。"}
{"text": "特别地，P(A)被估计为属于A的实例占全部训练实例的比例。"}
{"text": "因此，只需要计算P(d|A)就可以得到P(A|d)。"}
{"text": "为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)・・・P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。"}
{"text": "注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。"}
{"text": "P(|d)可通过相似的方法来计算。"}
{"text": "（b）名字学习器。"}
{"text": "相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。"}
{"text": "这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。"}
{"text": "（c）元学习器。"}
{"text": "基本学习器的预测结果通过元学习器来合并。"}
{"text": "元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。"}
{"text": "这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。"}
{"text": "⑥利用领域约束和启发式知识。"}
{"text": "经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。"}
{"text": "放松标记是一种解决图中节点的标签分配问题的有效技术。"}
{"text": "该方法的思想是节点的标签通常受其邻居的特征影响。"}
{"text": "基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。"}
{"text": "放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。"}
{"text": "GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。"}
{"text": "考虑约束能提高映射的精度。"}
{"text": "约束又可分为领域独立约束和领域依赖约束两种。"}
{"text": "领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。"}
{"text": "邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。"}
{"text": "领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。"}
{"text": "以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。"}
{"text": "GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。"}
{"text": "⑦实验评估。"}
{"text": "GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。"}
{"text": "在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。"}
{"text": "在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。"}
{"text": "放松标记能进一步提高3%～18%的正确率，只有一个实验例外。"}
{"text": "由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。"}
{"text": "尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。"}
{"text": "首先，一些概念不能被匹配是因为缺少足够的训练数据。"}
{"text": "其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。"}
{"text": "第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。"}
{"text": "最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。"}
{"text": "⑧扩充GLUE发现复杂映射。"}
{"text": "GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。"}
{"text": "为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。"}
{"text": "目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。"}
{"text": "CGLUE中的复杂映射形式如A=X1op1X2op2�opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。"}
{"text": "这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。"}
{"text": "由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。"}
{"text": "CGLUE将形如X1op1X2op2・・・opn-1Xn的复合概念称作映射对象。"}
{"text": "CGLUE还进一步假设概念D的孩子C1,C2,�,Ck要满足条件,1≤i,j≤k,i≠j，且。"}
{"text": "CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。"}
{"text": "对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。"}
{"text": "比较的方法与GLUE中的相似。"}
{"text": "最后返回相似度最高的映射结果。"}
{"text": "由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。"}
{"text": "因此需要考虑从巨量的候选复合概念中搜索A的近似。"}
{"text": "为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。"}
{"text": "定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。"}
{"text": "设highest_sim=0。"}
{"text": "扩展这些候选创建新的候选对象。"}
{"text": "添加新候选对象到S。"}
{"text": "设置highest_sim=new_highest_sim。"}
{"text": "算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。"}
{"text": "在步骤2（c）中，ε最初设置为0。"}
{"text": "在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。"}
{"text": "因为每个候选对象只是O2概念的并，去除过程很快。"}
{"text": "CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。"}
{"text": "试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。"}
{"text": "实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。"}
{"text": "⑨GLUE的总结。"}
{"text": "GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。"}
{"text": "GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。"}
{"text": "试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。"}
{"text": "扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。"}
{"text": "尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。"}
{"text": "其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。"}
{"text": "最后，GLUE无法处理关于异构本体的关系之间的映射。"}
{"text": "2）概念近似的方法。"}
{"text": "在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。"}
{"text": "本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。"}
{"text": "①方法的思想。"}
{"text": "在本体查询系统中，信息源和查询都是针对特定本体的。"}
{"text": "不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。"}
{"text": "一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。"}
{"text": "因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。"}
{"text": "当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。"}
{"text": "令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。"}
{"text": "查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。"}
{"text": "但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。"}
{"text": "令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。"}
{"text": "R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。"}
{"text": "如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。"}
{"text": "查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。"}
{"text": "本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。"}
{"text": "这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。"}
{"text": "②Stuckenschmidt_H的概念近似。"}
{"text": "寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。"}
{"text": "Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。"}
{"text": "该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。"}
{"text": "从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。"}
{"text": "C为O1中概念，概念C的最小上界lub(C,T)包含A1,A2,�,Am，是C在O2中的直接父类；概念C的最大下界glb(C,T)包含B1,B2,�,Bn，是C在O2中的直接父类。"}
{"text": "图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。"}
{"text": "找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。"}
{"text": "定义5.11令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。"}
{"text": "找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。"}
{"text": "显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。"}
{"text": "因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。"}
{"text": "任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。"}
{"text": "这样概念数目最多翻倍，但所有非算子都被消去。"}
{"text": "Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。"}
{"text": "上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。"}
{"text": "但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。"}
{"text": "在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。"}
{"text": "但这种方法无法得到概念的最佳近似，近似的质量有时是不可接受的。"}
{"text": "如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。"}
{"text": "同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。"}
{"text": "异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。"}
{"text": "这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。"}
{"text": "实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。"}
{"text": "如果考虑这些蕴涵关系，也许可以提高近似查询的质量。"}
{"text": "图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。"}
{"text": "为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。"}
{"text": "它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。"}
{"text": "该方法需要一个训练实例集合。"}
{"text": "令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。"}
{"text": "在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K_QI(S)};K-={Q|QI(S)_K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。"}
{"text": "这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。"}
{"text": "为此，引入一个将对象映射到概念合取的函数：。"}
{"text": "可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。"}
{"text": "对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。"}
{"text": "遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。"}
{"text": "与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。"}
{"text": "第一是查询效率问题。"}
{"text": "该方法需要遍历所有实例计算概念近似。"}
{"text": "得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。"}
{"text": "第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。"}
{"text": "最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。"}
{"text": "④基于多元界的概念近似。"}
{"text": "Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。"}
{"text": "这种方法能进一步推广到关系映射的发现。"}
{"text": "由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。"}
{"text": "基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。"}
{"text": "将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。"}
{"text": "证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。"}
{"text": "通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。"}
{"text": "该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。"}
{"text": "该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。"}
{"text": "引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。"}
{"text": "由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。"}
{"text": "证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。"}
{"text": "这是该方法的理论基础。"}
{"text": "3）FCA。"}
{"text": "Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。"}
{"text": "该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。"}
{"text": "当然，这些概念分别来自两个不同的初始本体。"}
{"text": "①形式化概念分析基础。"}
{"text": "首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。"}
{"text": "形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。"}
{"text": "概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。"}
{"text": "另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。"}
{"text": "因此，概念格被认为是进行数据分析的有力工具。"}
{"text": "从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。"}
{"text": "形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。"}
{"text": "(s,d)∈R表示实例s有属性d。"}
{"text": "一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。"}
{"text": "这种由背景(S,D,R)导出的格L就称为一个概念格。"}
{"text": "格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。"}
{"text": "每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|_y∈Y,xRy}2）Y={y∈D|_x∈X,xRy}在概念格节点间能够建立起一种偏序关系。"}
{"text": "给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1_Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。"}
{"text": "根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。"}
{"text": "②自底向上的FCA-Merge本体合并。"}
{"text": "该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。"}
{"text": "整个本体合并的过程分三步。"}
{"text": "（a）实例提取。"}
{"text": "由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。"}
{"text": "从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。"}
{"text": "而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。"}
{"text": "这一步采用自然语言处理技术，得到两本体的形式背景。"}
{"text": "每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。"}
{"text": "显然，一个文档可能是多个概念的实例。"}
{"text": "（b）概念格计算。"}
{"text": "输入第一步中得到的两张布尔表来计算概念格。"}
{"text": "FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。"}
{"text": "（c）交互生成合并的本体。"}
{"text": "生成的概念格已经将独立的两个本体合并在一起。"}
{"text": "本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。"}
{"text": "显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。"}
{"text": "②FCA总结。"}
{"text": "形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。"}
{"text": "这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。"}
{"text": "FCA具有一些不足。"}
{"text": "首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。"}
{"text": "其次，映射结果质量受提取共享实例过程的影响。"}
{"text": "最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。"}
{"text": "4）IF-Map。"}
{"text": "该方法是一种自动的本体映射发现技术，基于信息流理论[71]。"}
{"text": "IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。"}
{"text": "那样的参考本体没有实例，而实例只在局部本体中才考虑。"}
{"text": "因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。"}
{"text": "映射生成的过程包括4个阶段：①采集，即收集不同的本体；②转换，即将待映射本体转换为特定格式；③信息映射生成，即利用信息流理论生成本体间的映射；④映射投影，将生成的概念间等价映射用本体语言表示出来，如owl:sameAs等。"}
{"text": "IF-Map也只能生成异构本体概念间的简单等价映射。"}
{"text": "（3）基于实例的本体映射总结。"}
{"text": "与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。"}
{"text": "一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。"}
{"text": "此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。"}
{"text": "3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。"}
{"text": "因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。"}
{"text": "（1）方法和工具1）QOM。"}
{"text": "QOM是采用综合方法发现本体映射的典型工作[72-75]。"}
{"text": "该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。"}
{"text": "QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。"}
{"text": "①QOM的思路。"}
{"text": "大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。"}
{"text": "目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。"}
{"text": "对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。"}
{"text": "与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。"}
{"text": "QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。"}
{"text": "②QOM方法的过程。"}
{"text": "QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。"}
{"text": "特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。"}
{"text": "QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。"}
{"text": "搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。"}
{"text": "相似度计算：对每一对候选映射对象，判断它们之间的相似度值。"}
{"text": "一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。"}
{"text": "QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。"}
{"text": "为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。"}
{"text": "相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。"}
{"text": "这些不同的相似度值需要累加，成为单个的相似度值。"}
{"text": "QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。"}
{"text": "解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。"}
{"text": "根据处理后的最终相似度值判断本体之间的映射。"}
{"text": "迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。"}
{"text": "每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。"}
{"text": "③实验评估和结果。"}
{"text": "QOM分析了几种典型的本体映射方法的时间复杂度。"}
{"text": "iPROMPT的复杂度为O(n・log(n)),AnchorPROMPT的复杂度为O(n2・log2(n)),GLUE的复杂度为O(2n)。"}
{"text": "与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n・og(n))。"}
{"text": "注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。"}
{"text": "试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。"}
{"text": "2）OLA。"}
{"text": "OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。"}
{"text": "目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。"}
{"text": "OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。"}
{"text": "图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。"}
{"text": "实体之间的相似度被赋予权重并线性累加。"}
{"text": "OLA能发现本体概念间的等价映射。"}
{"text": "3）KRAFT。"}
{"text": "KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。"}
{"text": "这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。"}
{"text": "KRAFT并没有给出映射发现的方法。"}
{"text": "4）OntoMap。"}
{"text": "OntoMap是一个知识表示的形式化、推理和Web接口。"}
{"text": "它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。"}
{"text": "为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。"}
{"text": "这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。"}
{"text": "OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。"}
{"text": "映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。"}
{"text": "这些原语表明了OntoMapO支持的映射类型。"}
{"text": "但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。"}
{"text": "因此，OntoMap更多只是提供了一个映射的表示框架。"}
{"text": "和5）OBSERVER。"}
{"text": "OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。"}
{"text": "OBSERVER使用基于组件的方法发现本体映射。"}
{"text": "它使用多个预先定义的本体来表示异构数据库的模式。"}
{"text": "映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。"}
{"text": "OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。"}
{"text": "但是，该方法的本体映射依靠手工建立。"}
{"text": "6）InfoSleuth。"}
{"text": "InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。"}
{"text": "本体间的映射是概念间的关系。"}
{"text": "本体的映射由一个特殊的被称为“资源主体”的类完成。"}
{"text": "一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。"}
{"text": "7）基于虚拟文档的本体匹配。"}
{"text": "本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。"}
{"text": "元素还可以通过自身注释中的简单语句，对其含义进行补充说明。"}
{"text": "此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。"}
{"text": "因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。"}
{"text": "一个元素的虚拟文档包含3种。"}
{"text": "①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。"}
{"text": "②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。"}
{"text": "在此过程中，越远的元素会被赋予越小的描述权重。"}
{"text": "③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。"}
{"text": "注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。"}
{"text": "在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。"}
{"text": "两元素的语义描述文档相似度越高，它们相匹配的可能性越大。"}
{"text": "描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。"}
{"text": "虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,�,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。"}
{"text": "基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。"}
{"text": "（2）本体映射的综合方法总结。"}
{"text": "考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。"}
{"text": "但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。"}
{"text": "此外，将各种映射方法的结果进行综合也很重要。"}
{"text": "5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。"}
{"text": "要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。"}
{"text": "管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。"}
{"text": "这里讨论如何通过组织映射来达到管理异构的多本体的目的。"}
{"text": "实际上，在数据库等领域中就有针对模式或模型管理的研究。"}
{"text": "他们指出，模型间的映射和操作是模型管理的核心问题。"}
{"text": "在本体研究领域，一些工作分析了本体管理的挑战[87,88]。"}
{"text": "这些研究将本体管理的任务分为两方面。"}
{"text": "一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。"}
{"text": "另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。"}
{"text": "Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。"}
{"text": "Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。"}
{"text": "Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。"}
{"text": "显然，这些工作都关注本体的表示、存储和维护。"}
{"text": "而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。"}
{"text": "但这些工作为管理多个本体打下了基础。"}
{"text": "Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。"}
{"text": "PROMPTDiff只使用结构不同检测两个版本的不同。"}
{"text": "而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。"}
{"text": "Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。"}
{"text": "Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。"}
{"text": "从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。"}
{"text": "这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。"}
{"text": "与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。"}
{"text": "传统的本体管理通常是二层结构：本体存储层和应用层。"}
{"text": "二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。"}
{"text": "Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。"}
{"text": "这样的管理方式具有灵活的特点，适应动态Web环境。"}
{"text": "然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。"}
{"text": "Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。"}
{"text": "框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。"}
{"text": "五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。"}
{"text": "各层的具体功能如下：①本体库层。"}
{"text": "本体库层存放不同渠道获得的本体。"}
{"text": "本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。"}
{"text": "②本体表示层。"}
{"text": "不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。"}
{"text": "这种转换会造成一些信息的损失。"}
{"text": "通常少许的非关键本体信息在转换中丢失是可容忍的。"}
{"text": "③桥本体层。"}
{"text": "多本体间常常重叠，其间往往有关联。"}
{"text": "为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。"}
{"text": "桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。"}
{"text": "在这层中，利用文献[62,36]的方法生成本体间的映射。"}
{"text": "桥的生成是半自动化的，并在桥本体中组织管理。"}
{"text": "本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。"}
{"text": "Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。"}
{"text": "对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。"}
{"text": "前者是由于引入等价桥后造成的，通过算法可消除。"}
{"text": "后者是由于原始本体中的错误或引入不当的桥造成的。"}
{"text": "算法能够找到环路，但区分恶性和良性环路需要人工参与。"}
{"text": "经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。"}
{"text": "本体间映射抽取出来，可通过桥本体进行管理。"}
{"text": "当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。"}
{"text": "④多本体功能层。"}
{"text": "多本体的管理能提供满足应用需求的一些主要功能。"}
{"text": "第一，桥本体中的桥提供了大量的简单和复杂的本体映射。"}
{"text": "通过这些映射，很容易实现异构本体间的互操作问题。"}
{"text": "第二，利用多本体间的桥，能实现跨不同本体的推理。"}
{"text": "第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。"}
{"text": "第四，还可以从多本体中抽取满足需求的子本体。"}
{"text": "第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。"}
{"text": "⑤多本体应用层。"}
{"text": "在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。"}
{"text": "5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。"}
{"text": "大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。"}
{"text": "使用整个本体会大大增加系统的复杂性和降低效率。"}
{"text": "因此，从源本体中抽取一个小的子本体能让系统更有效。"}
{"text": "子本体抽取是一个新的研究领域。"}
{"text": "Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。"}
{"text": "随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。"}
{"text": "Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。"}
{"text": "Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。"}
{"text": "当前的方法都是从单个本体中抽取子本体。"}
{"text": "但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。"}
{"text": "从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。"}
{"text": "Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。"}
{"text": "抽取子本体是一种重要的知识重用手段。"}
{"text": "本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。"}
{"text": "在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。"}
{"text": "5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。"}
{"text": "实例匹配的过程虽然与本体匹配有相似之处，但实例匹配通常是一个大规模数据处理问题，需要在匹配过程中解决其中的时间复杂度和空间复杂度问题，其难度和挑战更大。"}
{"text": "5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。"}
{"text": "人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。"}
{"text": "与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。"}
{"text": "这些本体的规模正随着人类知识的增长而变得越来越大。"}
{"text": "近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。"}
{"text": "然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。"}
{"text": "因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。"}
{"text": "本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。"}
{"text": "从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。"}
{"text": "这些大本体总体上可划分为三类：通用本体，即用于描述人类通用知识、语言知识和常识知识的本体，如Cyc、WordNet和SUMO等；领域本体，各个领域中的研究人员也建立了很多专业领域中的本体，如生物医学领域中的基因本体和统一医学语言系统本体UMLS；企业应用本体，为了有效管理、维护和利用拥有的大量数据，很多企业都利用本体对自身的海量数据进行重组，以便为用户提供更高效和智能的服务。"}
{"text": "出于商业保密的目的，这些企业本体通常并不公开。"}
{"text": "大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。"}
{"text": "表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。"}
{"text": "从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。"}
{"text": "基于不同大规模知识图谱的系统间可能需要进行交互。"}
{"text": "一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。"}
{"text": "随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。"}
{"text": "总之，大规模知识图谱间的异构现象依然普遍存在。"}
{"text": "在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。"}
{"text": "大规模知识图谱匹配是极具挑战性的任务。"}
{"text": "Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。"}
{"text": "显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。"}
{"text": "传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。"}
{"text": "然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。"}
{"text": "在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。"}
{"text": "2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。"}
{"text": "由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。"}
{"text": "大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。"}
{"text": "1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。"}
{"text": "通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。"}
{"text": "当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。"}
{"text": "很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。"}
{"text": "因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。"}
{"text": "目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。"}
{"text": "因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。"}
{"text": "2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。"}
{"text": "为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。"}
{"text": "虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。"}
{"text": "此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。"}
{"text": "令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。"}
{"text": "因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。"}
{"text": "3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。"}
{"text": "此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。"}
{"text": "然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。"}
{"text": "最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。"}
{"text": "尽管目前能处理该问题的映射系统还较少，但一些研究者已进行了积极尝试，其中包括集成通用本体用于机器翻译[104]，建立Web_Directory之间的映射用于信息检索[105]，以及匹配生物医学领域的本体用于不同医学系统间信息交互[106-108]等。"}
{"text": "最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。"}
{"text": "本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。"}
{"text": "就目前来看，现有的大规模知识图谱匹配系统都能克服空间复杂度问题，因为匹配过程中需要的大量空间可以借助数据压缩技术（如将稀疏矩阵压缩存储）、外部数据库或临时文件等方式解决。"}
{"text": "因此，下面着重分析三类方法的时间复杂度。"}
{"text": "5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。"}
{"text": "基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。"}
{"text": "很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。"}
{"text": "大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。"}
{"text": "采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。"}
{"text": "首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。"}
{"text": "其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。"}
{"text": "Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。"}
{"text": "Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。"}
{"text": "此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。"}
{"text": "5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。"}
{"text": "但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。"}
{"text": "基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。"}
{"text": "上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。"}
{"text": "该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。"}
{"text": "具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。"}
{"text": "该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。"}
{"text": "在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。"}
{"text": "该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。"}
{"text": "图5-12基于规则挖掘的实例匹配过程[112]在进一步介绍该方法之前，需要定义一些基础概念。"}
{"text": "定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。"}
{"text": "URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。"}
{"text": "定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。"}
{"text": "如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。"}
{"text": "然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。"}
{"text": "重复迭代步骤直至满足终止条件。"}
{"text": "前面提到，该框架通过学习规则来推导实例之间的等价关系。"}
{"text": "首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。"}
{"text": "实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。"}
{"text": "（p（e,o）是三元组＜e,p,o＞的函数式表示，o1_o2表示o1和o2指向同一实例或者字面值相等）。"}
{"text": "这样的规则可以推导出大量的等价实例，从而完成实例匹配。"}
{"text": "定义5.14（属性-值对等价）给定两个隐含等价属性（p1,p2）和两个值（o1,o2），属性-值对＜p1,o1＞和＜p2,o2＞等价当且仅当＜o1,o2＞∈～I（o1,o2为实例），或者o1=o2（o1,o2为字面值），记作～P。"}
{"text": "将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。"}
{"text": "定义5.15（等价属性-值对集）给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞），两个键值对集等价当且仅当存在一个从到的双射f∈～P，记作～S。"}
{"text": "定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。"}
{"text": "定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞,EIFPS规则有如下形式：根据以上定义，该方法实现了一个基于EM算法的实例匹配框架，输入为待匹配三元组、初始匹配对阈值，输出为匹配结果集与IFPS规则集。"}
{"text": "该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。"}
{"text": "这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。"}
{"text": "根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。"}
{"text": "EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。"}
{"text": "采用准确度优先策略，可以得到以下的近似公式，用精确度来代表在一个EIPFS规则集合下，提取出来的对应图和真正的对应图之间的关系：最后，求出的匹配图M的精确度等于M中被连接的成分除以M中边的数量：L（θ;M）≈Precision（M|θ）同一个匹配对可能会由不同的EIFPS规则导出，该匹配对有多个匹配置信度，因此集成两个置信度是一个很有必要的工作。"}
{"text": "传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。"}
{"text": "这里给出了另外的两种集成方式，具体如下：第1种是基于概率理论：conf1_conf2=1_（1_conf1）（1_conf2）第2种利用了一种特殊性形式下的贝叶斯理论的泛化理论（Dempster-Shafertheory）：该方法先后用在DBpedia、GeoNames、LinkedMDB、GeoSpecies等知识图谱间进行实例匹配。"}
{"text": "该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。"}
{"text": "5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。"}
{"text": "采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。"}
{"text": "由此可见，系统效率取决于能将原有问题划分为多少个小规模。"}
{"text": "最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。"}
{"text": "分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。"}
{"text": "Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。"}
{"text": "这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。"}
{"text": "本体模块化方法是对大规模本体进行划分的一种直观手段。"}
{"text": "已有多种本体模块化方法被提出。"}
{"text": "Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。"}
{"text": "然而，这种方法在实际应用中效果并不好。"}
{"text": "例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。"}
{"text": "Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。"}
{"text": "此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。"}
{"text": "Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。"}
{"text": "总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。"}
{"text": "特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。"}
{"text": "目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。"}
{"text": "Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。"}
{"text": "Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。"}
{"text": "Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。"}
{"text": "Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。"}
{"text": "Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。"}
{"text": "该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。"}
{"text": "接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。"}
{"text": "该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。"}
{"text": "Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。"}
{"text": "基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。"}
{"text": "一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。"}
{"text": "Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。"}
{"text": "Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。"}
{"text": "该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。"}
{"text": "1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。"}
{"text": "类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。"}
{"text": "第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。"}
{"text": "本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。"}
{"text": "6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。"}
{"text": "6.5节将介绍知识图谱开源工具并提供实践建议。"}
{"text": "6.6节将对本章进行总结。"}
{"text": "希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。"}
{"text": "推理的方法大致可以分为逻辑推理和非逻辑推理，其中逻辑推理的过程包含了严格的约束和推理过程，而非逻辑推理的过程相对模糊。"}
{"text": "逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。"}
{"text": "其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。"}
{"text": "下面先介绍这四种基本的推理。"}
{"text": "演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。"}
{"text": "典型的演绎推理有肯定前件假言推理、否定后件假言推理（Modus_Tollens）以及三段论（Law_of_Syllogism）。"}
{"text": "在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。"}
{"text": "其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。"}
{"text": "例如，通过假言命题“如果今天是星期二（前件）。"}
{"text": "那么小明会去上班（后件）”以及性质命题“今天是星期二”，能推理出“小明会去上班”。"}
{"text": "而否定后件假言推理是指性质命题否定了假言命题的后件，从而推理出否定的假言前件。"}
{"text": "例如，通过前文的假言命题和性质命题“小明不会去上班”，能推出“今天不是星期二”。"}
{"text": "在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。"}
{"text": "从以上的例子可以看出，演绎推理是一种形式化的逻辑推理。"}
{"text": "归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。"}
{"text": "例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。"}
{"text": "例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。"}
{"text": "可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。"}
{"text": "例如，经统计，90%就读于某高中的同学都上了大学，如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。"}
{"text": "它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。"}
{"text": "溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。"}
{"text": "例如，当一个病人显示出某种病症，而造成这个病症的原因可能有很多时，寻找在这个病人例子里最可能的原因的过程就是溯因推理。"}
{"text": "在溯因推理中，要使基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。"}
{"text": "例如，我们知道下雨了马路一定会湿（T），如果观察到马路是湿的（O），可以通过溯因推理得到很大概率是因为下雨了（E）。"}
{"text": "类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。"}
{"text": "例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。"}
{"text": "由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。"}
{"text": "例如在上例中，如果歌手C和歌手A、歌手B完全不是一种类型或一个领域的歌手，那么小明喜欢歌手C与他喜欢歌手A和歌手B是完全无关的，所以将“喜欢歌手C”的结论应用到小红身上不合适。"}
{"text": "造成不当类比的原因有很多，包括类比事物不相干、类比理由不充分以及类比预设不当等。"}
{"text": "尽管类比推理的结论相较于前面介绍的三种推理得到的结论错误率更高，但类比推理依然是一种普遍存在的推理方式。"}
{"text": "除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。"}
{"text": "例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。"}
{"text": "又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。"}
{"text": "从推理过程精确性来看，又可分为精确推理和模糊推理。"}
{"text": "不同的研究领域也有各自的推理问题。"}
{"text": "例如，在自然语言处理领域，典型的问题是自然语言推理（Natutal_Language_Inference)，其任务判断两个给定句子的蕴涵关系，给定的两个句子一个前提（Premise），一个是假设结论（Hypothsis），目标是判断在给定前提句子的情况下是否可以推理出假设结论的句子。"}
{"text": "答案分为三种，包括：表示假设结论句子和前提句子矛盾的“冲突（Contradiction）”、表示可以由前提句子推出假设结论句子的“蕴涵（Entailment）”以及表示前提句子和假设结论既不冲突也不蕴涵的“中立（Neutral）”。"}
{"text": "在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。"}
{"text": "例如，给定一个包含多个不同色彩、不同形状的几何体图片，回答问题“图中最小的正方体右边的几何体是什么颜色”。"}
{"text": "在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。"}
{"text": "6.1.2面向知识图谱的推理面向知识图谱的推理主要围绕关系的推理展开，即基于图谱中已有的事实或关系推断出未知的事实或关系[5]，一般着重考察实体、关系和图谱结构三个方面的特征信息。"}
{"text": "如图6-1所示为人物关系图推理，利用推理可以得到新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。"}
{"text": "具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。"}
{"text": "图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。"}
{"text": "将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。"}
{"text": "即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。"}
{"text": "由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。"}
{"text": "存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。"}
{"text": "知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。"}
{"text": "以演绎推理为核心的知识图谱推理主要是基于描述逻辑、DataLog等进行的，而以归纳推理为核心的知识图谱推理主要是围绕对知识图谱图结构的分析、对知识图谱中元素的表示学习、利用图上搜索和分析进行规则学习以及应用强化学习方法等进行的。"}
{"text": "下面分别从这两类展开，介绍不同的推理实现方法。"}
{"text": "6.2基于演绎的知识图谱推理6.2.1本体推理1.本体与描述逻辑概述演绎推理的过程需要明确定义的先验信息，所以基于演绎的知识图谱推理多围绕本体展开。"}
{"text": "本体的一般定义为概念化的显示规约，它给不同的领域提供共享的词汇。"}
{"text": "对于逻辑描述的规范，W3C提出了OWL。"}
{"text": "OWL_Lite和OWL_DL在语义上等价于某些描述逻辑（Description_Logics,DLs）[14,15]，而OWL_Full没有对应的描述逻辑。"}
{"text": "2009年，为了适应更多应用的需求，W3C组织又提出了OWL的新版本OWL_2[15]。"}
{"text": "OWL_2_Full比OWL_Full的表达能力更强，同样没有对应的描述逻辑。"}
{"text": "而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。"}
{"text": "为了适应高效的应用需求，W3C组织从OWL_2中分裂出三种易处理的剖面OWL_2_EL、OWL_2_QL和OWL_2RL。"}
{"text": "这些剖面都有对应的描述逻辑。"}
{"text": "表6-1总结了OWL成员与描述逻辑之间的对应关系。"}
{"text": "目前，OWL是知识图谱语言中最规范、最严谨、表达能力最强的语言，而且OWL基于RDF语法，使表示出来的文档具有语义理解的结构基础，OWL的另外一个作用是促进了统一词汇表的使用，定义了丰富的语义词汇。"}
{"text": "表6-1OWL成员与描述逻辑之间的对应关系基于OWL的模型论语义，在丰富逻辑描述的知识图谱中，除了包含实体和二元关系，还包含了许多更抽象的信息，例如描述实体类别的概念以及关系之间的从属信息等。"}
{"text": "从而有一系列实用有趣的推理问题，包括：（1）概念包含。"}
{"text": "判定概念C是否为D的子概念，即C是否被D包含。"}
{"text": "例如，在包含公理Mother_Women和Women_Person的本体中，可以判定Mother_Person成立。"}
{"text": "（2）概念互斥。"}
{"text": "判定两个概念C和D是否互斥，即不相交。"}
{"text": "需要判定C_D_⊥是否为给定知识库的逻辑结论。"}
{"text": "例如，在包含Man_Women_⊥的本体中，概念Man和Women是互斥的。"}
{"text": "（3）概念可满足。"}
{"text": "判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。"}
{"text": "例如，包含公理Eternity_⊥的本体中，概念Eternity是不可满足概念。"}
{"text": "（4）全局一致。"}
{"text": "判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。"}
{"text": "例如，包含公理Man_Women_⊥、Man（Allen）和Women（Allen）的本体是不一致的。"}
{"text": "（5）TBox一致。"}
{"text": "判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。"}
{"text": "例如，包含公理Man_Women_⊥、Professor_Man和Professor_Women的TBox是不一致的。"}
{"text": "（6）实例测试。"}
{"text": "判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。"}
{"text": "（7）实例检索。"}
{"text": "找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。"}
{"text": "2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。"}
{"text": "基于表运算的推理方法通过一系列规则构建Abox，以检测可满足性，或者检测某一实例是否存在某概念，基本思想类似于一阶逻辑的归结反驳。"}
{"text": "以一个例子阐述该方法的基本思想。"}
{"text": "假设知识库K由以下三个声明构成：将以a作为实例的所有概念的集合记作L(a)。"}
{"text": "我们使用L←C表示通过加入C进行更新。"}
{"text": "例如，如果=｛D｝而且通过←C来对进行更新，那么将变成{C,D}。"}
{"text": "在给出的例子中，不经推导可以得到。"}
{"text": "TBox声明C_D与等价。"}
{"text": "因此，通过，得到，得到了矛盾，这表明K是不一致的。"}
{"text": "在上面例子中构建的东西实质上是表的一部分。"}
{"text": "如果在表构建过程中出现矛盾，那么知识库是不一致的。"}
{"text": "以描述逻辑为例，在初始情况下，是原始的Abox，迭代运用如下规则：其中，y是新加进来的个体。"}
{"text": "给定包含如下公理和断言的本体：Man_Women_⊥,Man(Allen)，检测实例Allen是否Woman_Woman(Allen)，根据___规则，在Man_Women（Allen）加入中，再通过__规则得到⊥(Allen)，这样就得到了一个矛盾，中。"}
{"text": "首先，加入待反驳的结论所以拒绝现在的，即Allen不在Woman中。"}
{"text": "目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。"}
{"text": "目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。"}
{"text": "虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。"}
{"text": "例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。"}
{"text": "因此，如何为SHOIN等强表达力的描述逻辑设计最优组合复杂度的Tableaux算法仍有待研究。"}
{"text": "3.常用本体推理工具简介（1）FaCT++。"}
{"text": "FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。"}
{"text": "Java版本名为Jfact，基于OWL_API。"}
{"text": "构建推理机采用下面的代码：采用以下代码对本体进行分类：（2）Racer。"}
{"text": "Racer是美国Franz_Inc.公司开发的以描述逻辑为基础的本体推理机，也可以用作语义知识库，支持OWL_DL，支持部分OWL_2_DL并且支持单机和客户端/服务器两种模式，用Allegro_Common_Lisp实现。"}
{"text": "以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。"}
{"text": "Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。"}
{"text": "构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。"}
{"text": "HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。"}
{"text": "构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。"}
{"text": "与本体推理相比，规则推理有更大的灵活性。"}
{"text": "本体推理通常仅支持预定义的本体公理上的推理，而规则推理可以根据特定的场景定制规则，以实现用户自定义的推理过程。"}
{"text": "逻辑编程是一个很大的研究领域，在工业界应用广泛。"}
{"text": "逻辑编程也可以与本体推理相结合，集合两者的优点。"}
{"text": "逻辑编程的研究始于Prolog语言[24,25]，后来由ISO标准化。"}
{"text": "Prolog在多种系统中被实现，例如SWI-Prolog、Sicstus_Prolog、GNU_Prolog和XSB。"}
{"text": "Prolog在早期的人工智能研究中应用广泛，多用于实现专家系统。"}
{"text": "在通常情况下，Prolog程序是通过SLD消解和回溯来执行的[25]。"}
{"text": "运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。"}
{"text": "在程序存在递归的情况下，有可能出现运行无法终止的情况。"}
{"text": "为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。"}
{"text": "从语法上来说，Datalog程序基本上是Prolog的一个子集。"}
{"text": "它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。"}
{"text": "在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。"}
{"text": "读者可参考文献[26]获得更多关于逻辑程序的相关介绍。"}
{"text": "便于撰写规则，实现推理。"}
{"text": "Datalog与OWL的关系如图6-2所示，其中OWL_RL和RDFS处于OWL和Datalog的交集之中。"}
{"text": "OWL_RL的设计目标之一就是找出可以用规则推理来实现的一个OWL的片段。"}
{"text": "图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。"}
{"text": "常量通常用小写字母a、b、c表示一个具体的实例。"}
{"text": "变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。"}
{"text": "项（term）包括常量和变量。"}
{"text": "原子（atom）形如p(t1,�,tn），其中p是一个谓词，t1,�,tn为项，n被称为p的元数。"}
{"text": "例如，假定has_child为一个二元谓词，原子has_child(X,Y)表示变量X和Y有has_child的关系，而原子has_child(jim,bob)表示常量jim和bob有has_child的关系。"}
{"text": "Datalog规则形如H:-B1,B2,�,Bm.其中，H,B1,B2,�,Bm为原子。"}
{"text": "H称为此规则的头部原子，B1,B2,�,Bm称为体部原子。"}
{"text": "例如，规则has_child(Y,X):-has_son(X,Y)表示当X和Y有has_son的关系时，则Y与X有has_child的关系。"}
{"text": "Datalog事实（fact）是形如F(c1,c2,�,cn):-的没有体部且没有变量的规则。"}
{"text": "事实也常写成“F(c1,c2,�,cn).”的形式。"}
{"text": "例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。"}
{"text": "例如，下面的两条规则构成了一个Datalog程序：has_child(X,Y):-has_son(X,Y).has_child(Alice,Bob).3.Datalog推理举例下面的规则集表达了给定一个图，计算所有的路径关系，即节点X、Y之间是否联通：path(X,Y):-edge(X,Y).①path(X,Y):-path(X,Z),path(Z,Y).②节点X和Y联通有两种情况：①X、Y之间通过一条边（edge）直接连接；②存在一个节点Z，使得X、Z联通并且Z、Y联通。"}
{"text": "下面的三个事实表示了一个图中的三条边。"}
{"text": "edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。"}
{"text": "例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。"}
{"text": "图6-3Datalog推理举例4.Datalog与知识图谱Datalog程序可以应用在知识图谱中进行规则推理。"}
{"text": "一个知识图谱可以自然地被看作一个事实集。"}
{"text": "只需人为引入一个特殊的谓词triple，每一个三元组(subject,property,object)便可以作为一个事实triple(subject,property,object)。"}
{"text": "另一种方法是按照描述逻辑ABox的方式来看待，即三元组(s,rdf:type,C)看作C(s)，其他的三元组(s,p,o)看作p(s,o)。"}
{"text": "这样一来，Datalog规则就可以作用于知识图谱上。"}
{"text": "下面介绍的三种语言SWRL、OWL_RL、RDFS与Datalog密切相关。"}
{"text": "（1）SWRL（Semantic_Web_Rule_Language）。"}
{"text": "SWRL是2004年提出的一个完全基于Datalog的规则语言。"}
{"text": "SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。"}
{"text": "SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。"}
{"text": "（2）OWL_RL。"}
{"text": "OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。"}
{"text": "（3）RDFS（RDF_Schema）。"}
{"text": "RDFS的推理也可以用Datalog程序表示。"}
{"text": "5.基于Datalog的推理工具RDFox介绍目前，最主要的Datalog工具包括DLV[5]和Clingo[6]。"}
{"text": "这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。"}
{"text": "知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。"}
{"text": "Datalog相关工具总结如表6-3所示。"}
{"text": "下面简要介绍一下RDFox。"}
{"text": "表6-3Datalog相关工具总结RDFox是由牛津大学开发的可扩展、跨平台、基于内存的RDF三元组存储系统。"}
{"text": "其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。"}
{"text": "RDFox的架构如图6-4所示。"}
{"text": "其核心为RDFox推理机，支持增量更新。"}
{"text": "图6-4RDFox的架构1.RDFox_Java_API使用方法（1）创建本体与存储（2）导入本体进行推理2.RDFox_Java_API使用举例下面用一个具体的例子介绍RDFox。"}
{"text": "假定有如图6-5所示的某金融领域相关的图。"}
{"text": "首先把它转换成一个知识图谱。"}
{"text": "对每一个实体，要创建一个IRI。"}
{"text": "为此引入命名空间finance：来表示http://www.example.org/kse/finance#。"}
{"text": "<http://www.example.org/kse/finance#孙宏斌>这个IRI就可以使用命名空间简写为“finance：孙宏斌”。"}
{"text": "图6-5某金融领域相关的图一个三元组例子为：finance：融创中国rdf:type_finance：地产事业本体（TBox）如下：●SubClassOf(PublicCompany,Company)//类PublicCompany是Company的子类●ObjectPropertyDomain(Control,Person)//属性Control的定义域是Person●ObjectPropertyRange(Control,Company)//属性Control的值域是Company此本体用RDF/XML的格式描述如下：数据（ABox）用Triple的语法，如下所示。"}
{"text": "自定义规则如下：1）执掌一家公司就一定是这家公司的股东。"}
{"text": "2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。"}
{"text": "用Datalog形式化，写成SWRL规则，具体如下：下面演示如何使用代码（Java）数据读取本体、数据，声明规则并进行推理。"}
{"text": "读取本体、数据，声明规则。"}
{"text": "推理，定义命名空间与查询操作（用于输出当前三元组）。"}
{"text": "将结果输出为结合规则推理的所有三元组实例化。"}
{"text": "6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。"}
{"text": "考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。"}
{"text": "第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。"}
{"text": "在OMQ下，查询重写的任务是将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。"}
{"text": "第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。"}
{"text": "在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。"}
{"text": "映射的标准语言为W3C的R2RML语言。"}
{"text": "OMQ可以看作OBDA的特殊情况，即每个本体中谓词的实例都存储在一个特定的对应表中，而映射只是一个简单的同构关系。"}
{"text": "以下着重介绍OBDA。"}
{"text": "这样OBDA的实例定义为外延层和内涵层的一个对I=(P,D)，其中P=(T,M,S)，且D符合S。"}
{"text": "用M(D)表示将映射M作用于数据库D上生成的知识图谱。"}
{"text": "给定这样一个OBDA实例I,OBDA的语义即定义为一个知识库(T,M(D))。"}
{"text": "当查询时，本体T为用户提供了一个高级概念视图数据和方便的查询词汇，用户只针对T查询，而数据库存储层和映射层对用户完全透明。"}
{"text": "这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。"}
{"text": "OBDA有多种实现方式，最直接的方式是生成映射得到的知识图谱M(D)，然后保存到一个三元组存储库中，这种方式也称作ETL（Extract_Transform_Load)，优点是实现简单直接。"}
{"text": "但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。"}
{"text": "在此，我们更感兴趣的是虚拟OBDA的方式，此方式下的三元组并不需要被真正生成，而通过查询重写的方式来实现，OBDA将在本体层面的SPARQL查询重写为在原始数据库上的SQL查询。"}
{"text": "相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。"}
{"text": "为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。"}
{"text": "OBDA查询重写的流程如图6-6所示。"}
{"text": "给定一个OBDA实例I=(P,D)、P=(T,S,M)以及一个SPARQL查询q，通过重写回答查询的具体步骤为：（1）查询重写。"}
{"text": "对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。"}
{"text": "（2）查询展开。"}
{"text": "将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。"}
{"text": "（3）查询执行。"}
{"text": "将生成的SQL语句交给数据库引擎并执行。"}
{"text": "（4）结果转换。"}
{"text": "SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。"}
{"text": "为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂[29]。"}
{"text": "图6-6OBDA查询重写的流程2.查询重写举例（OMQ）假定有如下一个关于学校信息系统的本体T：查询q1=SELECT?teacherWHERE{?teacheraTeacher}试图查询所有的教师。"}
{"text": "通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。"}
{"text": "查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。"}
{"text": "可以先利用teaches的定义域和值域将q2优化为SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。"}
{"text": "可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。"}
{"text": "此数据库包含以下三个数据库表，其中下画线的列构成数据表的主键：同时，假设有如下的映射规则：利用这些映射，q1’可以被展开为：并进一步简化为：查询q2’可以展开为：并进一步简化为：查询q3’可以展开为：并进一步简化为：这些生成的SQL语句可以直接在原始的数据库上运行。"}
{"text": "4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。"}
{"text": "这些工具的功能对比如表6-4所示。"}
{"text": "表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。"}
{"text": "Ontop的Protégé插件可以用于编辑映射和测试查询。"}
{"text": "RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。"}
{"text": "Ontop也提供Java_API。"}
{"text": "此系统支持对OWL2_QL本体的推理。"}
{"text": "与此处提到的其他OBDA系统不同，它仅支持与合取查询相对应的SPARQL的受限片段。"}
{"text": "Ultrawrap是由Capsenta公司商业化的OBDA系统。"}
{"text": "它被扩展为支持对具有反向和传递属性的RDFS扩展的推断。"}
{"text": "Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。"}
{"text": "Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。"}
{"text": "Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。"}
{"text": "因此，它现在也可以归为OBDA系统。"}
{"text": "在v5版本中有了自己的OBDA实现。"}
{"text": "限于篇幅，不展开讲解，有兴趣的读者可以查阅参考文献[41]。"}
{"text": "6.2.4基于产生式规则的方法1.产生式系统产生式系统是一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。"}
{"text": "产生式系统可以应用于自动规划和专家系统等领域。"}
{"text": "（1）事实集合。"}
{"text": "事实集合是运行内存（Working_Memory,WM）为事实（WME）的集合，用于存储当前系统中的所有事实。"}
{"text": "事实可描述对象，形如(typeattr_1:val_1attr_2:val_2�attr_n:val_n），其中type、attr_i、val_i均为原子（常量）。"}
{"text": "例如，(studentage:24)表示一个学生，姓名为Alice，年龄为24。"}
{"text": "事实也可描述关系name:\"Alice\"（Refication）。"}
{"text": "例如，(basicFactrelation:olderThanfirstArg:JohnsecondArg:Alice)表示John比Alice的年纪大，此事实也可简记为(olderThanJohnAlice)。"}
{"text": "（2）产生式集合。"}
{"text": "LHS是conditions的集合，各条件之间为且的关系。"}
{"text": "当LHS中所有条件均被满足时，触发规则。"}
{"text": "每个条件形如(typeattr_1:spec_1attr_2:spec_2�attr_n:spec_n）。"}
{"text": "其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。"}
{"text": "动作的种类有如下三种：●ADDpattern。"}
{"text": "向WM中加入形如pattern的WME。"}
{"text": "●REMOVEi。"}
{"text": "从WM中移除当前规则第i个条件匹配的WME。"}
{"text": "●MODIFYi(attrspec)。"}
{"text": "对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。"}
{"text": "例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。"}
{"text": "产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)_ADD(Personname:x)。"}
{"text": "（3）推理引擎。"}
{"text": "产生式系统执行流程如图6-7所示。"}
{"text": "图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。"}
{"text": "用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。"}
{"text": "●选择规则。"}
{"text": "按一定的策略从被触发的多条规则中选择一条。"}
{"text": "●执行规则。"}
{"text": "执行被选择出来的规则的RHS，从而操作WM。"}
{"text": "模式匹配用每条规则的条件部分匹配当前的WM，如图6-8所示为匹配规则过程。"}
{"text": "规则为：（typexy）,(subClassOfyz)_ADD(typexz)。"}
{"text": "图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。"}
{"text": "目前，最流行的算法是Rete算法，在1979年由CharlesForgy提出[42]。"}
{"text": "其主要的想法为将产生式的LHS组织成判别网络形式，以实现用空间换时间的效果。"}
{"text": "下面用图6-9和图6-10解释Rete算法的形状。"}
{"text": "最主要的部分为α网络和β网络。"}
{"text": "α和β的名字来源于产生式规则常写成α_β的形式。"}
{"text": "α网络对应条件，检验并保存各个条件对应的WME集合。"}
{"text": "β网络对应结果，用于保存join的中间结果。"}
{"text": "图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。"}
{"text": "从被触发的规则中随机选择一条执行。"}
{"text": "注意在推理的场景下，被触发的多条规则可全被执行。"}
{"text": "●具体性（specificity）。"}
{"text": "选择最具体的规则，例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)_�(Studentname:age:20)_�●新近程度（recency）。"}
{"text": "选择最近没有被触发的规则执行动作。"}
{"text": "4.相关工具介绍表6-5为三个基于产生式规则的系统，它们都是基于Rete算法或其改进的。"}
{"text": "表6-5三个基于产生式规则的系统（1）Drools。"}
{"text": "Drools是一个商用规则管理系统，提供了一个规则推理引擎。"}
{"text": "核心算法是基于Rete算法的改进。"}
{"text": "提供规则定义语言，支持嵌入Java代码。"}
{"text": "Drools使用举例：创建容器与会话，如下：触发规则，如下：（2）Jena。"}
{"text": "Jena是一个用于构建语义网应用的Java框架。"}
{"text": "提供了处理RDF、RDFS、OWL数据的接口，还提供了一个规则引擎。"}
{"text": "提供三元组的内存存储于SPARQL、查询。"}
{"text": "Jena使用举例：创建模型，如下：创建规则推理机，如下：（3）GraphDB。"}
{"text": "GraphDB（原OWLIM）是一个可扩展的语义数据存储系统（基于RDF4J），其功能包含三元组存储、推理引擎、查询引擎，支持RDFS、OWL_DLP、OWL_Horst、OWL_2_RL等多种语言。"}
{"text": "6.3基于归纳的知识图谱推理随着技术的发展，越来越多的知识图谱自动化构建方法被提出来，例如利用算法对文本进行三元组抽取，这使得大规模知识图谱能够迅速被建立起来，例如NELL。"}
{"text": "但这类知识图谱的信息准确度稍差于利用专家知识人工构建的知识图谱，且冗余度较大。"}
{"text": "在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。"}
{"text": "基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。"}
{"text": "按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。"}
{"text": "下面分别介绍这三类推理的主要方法和现有进展。"}
{"text": "6.3.1基于图结构的推理1.方法概述对于那些自底向上构建的知识图谱，图谱中大部分信息都是表示两个实体之间拥有某种关系的事实三元组。"}
{"text": "对于这些三元组，从图的角度来看，可以看作是标签的有向图，有向图以实体为节点，以关系为有向边，并且每个关系边从头实体的节点指向尾实体的节点，如图6-11所示。"}
{"text": "例如，上面的示例中描述了不同人物之间的关系以及人物的职业信息，包含了如下的路径：这是一条从实体小明到实体小小的路径，表述的信息是小明的妻子是小红，小红的孩子有小小。"}
{"text": "从语义角度来看，这条由关系“妻子是”和“孩子有”组成的路径揭示了小明和小小之间的父子关系，这条路径蕴涵着三元组：而这个推理过程不仅仅存在于这个包含小明、小红和小小的子图中，同样也存在于建国、秀娟和小明的子图中，而路径和三元组是常常同时出现在知识图谱中的。"}
{"text": "其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。"}
{"text": "这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。"}
{"text": "除了路径，实体的邻居节点以及它们之间的关系也是刻画和描述一个实体的重要信息，例如在上例中的关于“小明”的7个三元组鲜明地描述了小明这个人物，包括（小明，父亲是，建国）、（小明，获得奖项，最佳男主角）以及（小明，妻子是，小红）等。"}
{"text": "一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。"}
{"text": "当把知识图谱看作是有向图时，往往强调的是在知识图谱中的事实三元组，即表示两个实体之间拥有某种关系的三元组，而对于知识图谱的本体和上层的schema则关注较少，因为本体中许多含有丰富逻辑描述的信息并不能简单地转化为图的结构。"}
{"text": "下面将介绍常见的基于图结构的知识图谱推理算法。"}
{"text": "2.常见算法简介典型的基于图结构的推理方法有PRA（Path_Ranking_Algorithm）[10]利用了实体节点之间的路径当作特征从而进行链接预测推理。"}
{"text": "（1）基于知识图谱路径特征的PRA算法。"}
{"text": "PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。"}
{"text": "PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。"}
{"text": "在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。"}
{"text": "在PRA中，利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn_1的值域（domian)，即Tn=range（rn）=domain（rn_1），关系的值域和作用域通常指的是实体的类型。"}
{"text": "基于路径的随机游走定义了一个关系路径的分布，并得到每条路径的特征值s_,P（t）,s_,P（t）可以理解为沿着路径P从h开始能够到达t的概率。"}
{"text": "具体操作为，在随机游走的初始阶段，s_,P（e）初始化为1，如果e=s，否则初始化为0。"}
{"text": "在随机游走的过程中，s_,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。"}
{"text": "对于关系r，在通过随机游走得到一系列路径特征Pr={P1,…,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1_yi）ln（1_pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。"}
{"text": "在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。"}
{"text": "采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。"}
{"text": "结合了有效采样和随机有走的PRA能够快速有效地利用知识图谱的路径结构对知识图谱进行关系推理，是典型的基于图结构的知识图谱推理算法。"}
{"text": "（2）PRA的演化算法。"}
{"text": "所以，CoR-PRA（Constant_and_Reversed_Path_RankingAlgorithm）[43]通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。"}
{"text": "给定关系r下的训练样本（h,t）,Co-PRA中搜索图结构特征的步骤如下：1）生成初步的路径。"}
{"text": "通过路径搜索算法生成以h为起点的小于长度l的路径集合P_；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。"}
{"text": "2）通过PRA计算路径特征的概率。"}
{"text": "对于路径π_∈P_，计算沿着路径π_正向地由h到达x的概率P（h→x;π_），以及沿着路径π_逆向地由h到达x的概率；同理，对路径πt∈Pt，计算沿着路径πt正向地由t到达x的概率P（t→x;πt），以及沿着路径πt逆向地由t到达x的概率；并将所有的x放入常量候选集N中。"}
{"text": "3）生成候选的常量路径。"}
{"text": "对每一个（x∈N,π_Pt）的组合，如果P（t→x|πt）＞0，那么生成路径特征，其中c=x，并且将路径特征对应的覆盖度值（coverage）加1，即；同理，对每一个（x∈N,π_Pt）的组合，如果，那么生成路径特征P（c→t;πt），其中c=x，并且将路径特征对应的覆盖度值加1，即coverage（P（c→t;πt））+=1。"}
{"text": "4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。"}
{"text": "对每一个可，就生成路能的组合（x∈N,π_∈P_,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。"}
{"text": "反向同理。"}
{"text": "从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。"}
{"text": "尽管采用了随机游走策略来降低搜索空间，当PRA应用在关系丰富且连接稠密的知识图谱上时，依然会面临路径特征爆炸的问题。"}
{"text": "为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。"}
{"text": "为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。"}
{"text": "为了进一步提升路径搜索效率，降低无意义的路径特征，对于图中的一个节点，如果这个节点有很多相同关系边ri连接着不同的实体节点，那么沿着这个关系继续搜索路径会急剧增加子图大小的量级。"}
{"text": "为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。"}
{"text": "为了增加子图特征的丰富性，除了PRA中用到的路径特征，SFE还增加了二元路径特征，类似自然语言处理中的bigram，即将两个具有连接的关系组成一个新的关系，例如“BIGRAM：对齐实体/妻子是”，除了二元路径特征，SFE还增加了one-sided_feature,one-sided_path指的是一个存在在给定两个节点之间的路径的，是从起始节点开始，但不一定由另一个节点结束，类似Co-PRA中的带有常量的路径特征。"}
{"text": "SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。"}
{"text": "如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。"}
{"text": "SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。"}
{"text": "SFE还增加了一个表示任意关系的关系ANYREL来增加路径特征的丰富性。"}
{"text": "总体来说，SFE在PRA的路径特征搜索的效率和特征的丰富性方面做了比较大的提升。"}
{"text": "从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。"}
{"text": "但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。"}
{"text": "但是，不是路径形式的图结构特征依然有待挖掘和分析。"}
{"text": "2.典型工具简介或实验对比分析PRA的提出主要是针对很不完整的知识图谱，所以论文中的实验是在知识图谱NELL上进行试验的，图6-12展示了PRA中在预测某一关系时权重最高的两个路径特征，可以看出，这些高权重的路径特征可以看作是预测当前关系的一条置信度较高的规则，具有明显的语义含义。"}
{"text": "PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。"}
{"text": "图6-12PRA关系预测路径图6-13PRA在链接预测上与N-FOIL的对比结果图6-14展示了CoR-PRA在知识图谱推理和命名实体抽取上的实验比较，从实验结果可以看出，CoR-PRA由于提升了路径特征的丰富性，其结果明显优于PRA，但计算效率不及PRA。"}
{"text": "图6-14知识图谱推理及命名实体抽取结果对比图6-15展示了SFE和PRA的性能比较，左边是在同样的拥有10个关系的NELL数据集上PRA和SFE的MAP（Mean_Average_Precision）结果、平均抽取的特征数量以及运行时间的比较。"}
{"text": "从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。"}
{"text": "图6-15SFE和PRA的性能比较典型的PRA系列工具可以参考https://github.com/noon99jaki/pra，集成了PRA以及CoR-PRA算法。"}
{"text": "6.3.2基于规则学习的推理1.方法概述基于规则的推理具有精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用。"}
{"text": "规则是基于规则推理的核心，所以规则获取是一个重要的任务。"}
{"text": "在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。"}
{"text": "所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。"}
{"text": "规则一般包含了两个部分，分别为规则头（head）和规则主体（body），其一般形式为rule:head←body.解读为有规则主体的信息可推出规则头的信息。"}
{"text": "其中，规则头由一个二元的原子（atom）构成，而规则主体由一个或多个一元原子或二元原子组成。"}
{"text": "原子（atom）是指包含了变量的元组，例如isLocation(X)是一个一元原子表示实体变量X是一个位置实体；hasWife(X,Y)是一个二元原子，表示实体变量X的妻子是实体变量Y。"}
{"text": "二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。"}
{"text": "在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。"}
{"text": "这条规则里的规则主体就包含了以否定形式出现的原子。"}
{"text": "所以，规则也可以表示为：rule:head←body+∧body_.其中，body+表示以肯定形式出现的原子的逻辑合取集合，而body_表示以否定形式出现的原子的逻辑合取集合。"}
{"text": "如果规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子，称这样的规则为霍恩规则（horn规则类型，可以表示为以下形式：rules），霍恩规则是被研究得比较多的a0←a1∧a2∧�∧an.其中，每个ai都为一个原子。"}
{"text": "在知识图谱的规则学习方法中，另一种被研究得比较多的规则类型叫作路径规则（pathrules），路径规则可以表示为如下形式：r0（e1,en+1）←r1（e1,e2）∧r2（e2,e3）∧�∧rn（en,en+1）.其中，规则主体中的原子均为含有两个变量的二元原子，且规则主体的所有二元原子构成一个从规则头中的两个实体之间的路径，且整个规则在知识图谱中构成一个闭环结构。"}
{"text": "这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。"}
{"text": "下面分别介绍这三种评价指标的计算方法。"}
{"text": "对于一个规则rule，在知识图谱中，其支持度（support）指的是满足规则主体和规则头的实例个数，规则的实例化指的是将规则中的变量替换成知识图谱中真实的实体后的结果。"}
{"text": "所以，规则的支持度通常是一个大于或等于0的整数值，用support(rule)表示。"}
{"text": "一般来说，一个规则的支持度越大，说明这个规则的实例在知识图谱中存在得越多，从统计角度来看，也越可能是一个比较好的规则。"}
{"text": "规则的置信度（confidence）的计算方式为：方法。"}
{"text": "一个规则的置信度越高，一般说明规则的质量也越高。"}
{"text": "所以，基于部分完全假设（PartialCompleteness_Assumption,PCA）的置信度（PCA_Confidence）也是一个衡量规则质量的方法，且考虑了知识图谱的不完整性。"}
{"text": "PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。"}
{"text": "这样考虑的原因是，如果头实体x和关系r0没有在知识图谱中构成相关的三元组，而通过规则主体可以推出三元组r0（x,y），那么根据知识图谱的不完全假设，r0（x,y）只是在知识图谱中缺失而不是错误的三元组，所以，不应该将这类实例化例子计算在分母中，否则会降低规则的置信度。"}
{"text": "所以，在PCA置信度中排除了来自这类实例对置信度值的负向影响。"}
{"text": "规则的支持度、置信度以及头覆盖度从不同的角度反映了规则的质量，但三者之间没有必然的关联关系。"}
{"text": "例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。"}
{"text": "2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。"}
{"text": "AMIE能挖掘的规则形如：fatherOf（f,c）←motherOf（m,c）∧marriedTo（m,f）.AMIE是一种霍恩规则，也是一种闭环规则，即整条规则可以在图中构成一个闭环结构。"}
{"text": "在规则学习的任务中，最重要的是如何有效搜索空间，因为在大型的知识图谱上简单地遍历所有可能的规则并评估规则的质量效率很低，几乎不可行。"}
{"text": "AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。"}
{"text": "3个挖掘算子如下：●增加悬挂原子（Adding_Dangling_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个新的变量和一个已经在规则中出现的元素，可以是出现过的变量，也可以是出现过的实体。"}
{"text": "●增加实例化的原子（Adding_Instantiated_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。"}
{"text": "●增加闭合原子（Adding_Closing_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含的两个元素都是已经出现在规则中的变量或实体。"}
{"text": "增加闭合原子之后，规则就算构建完成了。"}
{"text": "AMIE的规则学习算法如图6-16所示。"}
{"text": "图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。"}
{"text": "AMIE的剪枝策略主要包含两条：●设置最低规则头覆盖度过滤，头覆盖度很低的规则一般是一些边缘规则，可以直接过滤掉。"}
{"text": "在实践中，AMIE将头覆盖度值设为0.01。"}
{"text": "●在一条规则中，每在规则主体中增加一个原子，都应该使得规则的置信度增加，即confidence（a0←a0∧a2∧�∧an∧an+1）＞confidence（a0←a0∧a2∧�∧an）。"}
{"text": "如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧�∧an∧an+1剪枝掉。"}
{"text": "在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。"}
{"text": "无论采用哪种挖掘算子来增加规则中的原子，每一个原子都伴随着需要选择一个知识图谱中的关系。"}
{"text": "在选择增加实例化算子时还涉及选择一个实体方面，为了满足选出来的实体和关系组成的原子，在添加到规则中以后，能够满足事先设置的头覆盖度的要求，AMIE用对知识图谱的查询来筛选合适的选项，例如：SELECT?rWHEREa0∧a1∧�∧an∧?r（X,Y）HAVVINGCOUNT（a0）≥k这样经过查询筛选得到的关系候选项满足了一定符合头覆盖度的要求。"}
{"text": "3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。"}
{"text": "例如，在拥有100多万个实体以及近700万个三元组的DBpedia上，AMIE仅需不到3min就能完成规则挖掘，产生7000条规则，并帮助推理出了12万多个新的三元组。"}
{"text": "图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。"}
{"text": "6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。"}
{"text": "知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）_vec（queen）≈vec（man）_vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。"}
{"text": "而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。"}
{"text": "2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。"}
{"text": "在TransE中，知识图谱中的每个实体和关系都被表示成了一个向量，按照词向量的启示，TransE将三元组中的关系看作是从头实体向量到尾实体向量的翻译（translation），并对知识图谱将要映射到的向量空间做了如下假设，即在理想情况下，对每一个存在知识图谱中的三元组都满足h+r=t.式中，h是头实体的向量表示；r是关系的向量表示；t是尾实体的向量表示。"}
{"text": "TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。"}
{"text": "在需要映射到的向量空间中，TransE将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。"}
{"text": "等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r_t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。"}
{"text": "然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′_,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。"}
{"text": "TransE的训练目标是最小化损失函数L，可以通过基于梯度的优化算法进行优化求解，直至训练收敛。"}
{"text": "实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。"}
{"text": "TransE的简单高效说明了知识图谱表示学习方法能够自动且很好地捕捉推理特征，无须人工设计，很适合在大规模复杂的知识图谱上推广，是一种有效的知识图谱推理手段。"}
{"text": "尽管有效，TransE依然存在着表达能力不足的问题，例如按照关系头尾实体个数比例划分，知识图谱中的关系可以分为四种类型，分别为一对一（1-1）、一对多（1-N）、多对一（N-1）以及多对多（N-N）,TransE能够较好地捕捉一对一（1-1）的关系，却无法很好地表示一对多（1-N）、多对一（N-1）以及多对多（N-N）的关系。"}
{"text": "例如，实体“中国”在关系“拥有省份”这个关系下有很多个尾实体，根据TransE的假设，任何一个省份的向量表示都满足v（省份x）:v（中国）+v（拥有省份）=v（省份x），这将会导致TransE无法很好地区分各个省份。"}
{"text": "所以，TransH[46]就提出了在通过关系将头实体向量翻译到尾实体向量之前，先将头实体和尾实体向量投影到一个和当前关系相关的平面上，由于向量空间中的不同向量在同一个平面上的投影可以是一样的，这就帮助TransE从理论上解决了难以处理一对多（1-N）、多对一（N-1）以及多对多（N-N）关系的问题，TransE和TransH的对比向量空间假设对比如图6-18所示。"}
{"text": "图6-18TransE和TransH对比向量空间假设对比TransH为每个关系r都设计了一个投影平面，并用投影平面的法向量wr表示这个平面，h和t的投影向量的计算方法如下：然后，利用投影向量进行三元组得分的计算，即TransH通过设计关系投影平面提升了TransE表达非一对一关系的能力，TransR[8]则通过拆分实体向量表示空间和关系表示向量空间来提升TransE的表达能力。"}
{"text": "由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。"}
{"text": "图6-19TransR的实体表示空间和关系表示空间TransR设定所有的计算都发生在关系表示空间中，并在计算三元组得分之前首先将实体向量通过关系矩阵投影向关系表示空间，即：hr=hMr,tr=tMr.然后，利用投影到关系表示空间的头实体向量和尾实体向量进行三元组得分的计算：TransR通过区分实体和关系表示空间增加了模型的表达能力，并提升了表示学习结果，但是在TransR中，每个关系除拥有一个表示向量以外，还对应了一个d×d的矩阵，这相比起TransE增加了很多参数。"}
{"text": "为了减少TransR的参数量且同时保留其表达能力，TransD[47]提出了用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。"}
{"text": "图6-20TransD实体表示空间和关系表示空间其动态矩阵的计算如下：式中，m,n为关系和实体的向量表示维度；m,n可以相等也可以不相等。"}
{"text": "TransD通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。"}
{"text": "之前介绍了以TransE为代表的基于翻译假设的表示学习模型，而知识图谱表示学习的推理能力和采用的向量空间假设有很大关系，除了翻译假设还有其他的空间假设，DistMult[48]采用了更灵活的线性映射假设将实体表示为向量，关系表示为矩阵，并将关系当作是一种向量空间中的线性变换。"}
{"text": "对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。"}
{"text": "上式表达的hMr=t.意思是头实体通过与关系矩阵相乘，经过空间中的线性变化以后，可以转变为尾实体向量。"}
{"text": "所以，训练目标是对正确的三元组让hMr与t尽可能接近，而错误的三元组尽可能远离。"}
{"text": "由于向量与矩阵的运算比向量的加法运算更灵活，所以整体来说DistMult的效果比TransE效果要好。"}
{"text": "当将关系的矩阵设计为对角矩阵时，参数量与TransE相同，且效果比普通矩阵更好。"}
{"text": "所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。"}
{"text": "基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。"}
{"text": "DistMult中一个比较明显的问题是，得分函数的设计使得当关系设计为对角矩阵时，无法隐含所有关系都是对称关系的结论，因为对于一个存在的三元组（h,r,t），经过模型训练以后，f（h,r,t）=hDrt_的值会比较大，即表示三元组（h,r,t）是正确的。"}
{"text": "所以，三元组（t,r,h）的得分f（t,r,h）=tDrh_的值也会比较大，因为tDrh_=hDrt_。"}
{"text": "这说明了DistMult天然地假设了所有的关系是对称关系，这显然是不合理的。"}
{"text": "从语义的角度分析，知识图谱中的关系既包含了对称关系如“配偶是”，也包含了不对称关系如“出生地”，而且非对称关系一般还多于对称关系。"}
{"text": "为了解决这个问题，ComplEx[49]将原来基于实数的表示学习拓展到了复数，因为基于复数的乘法计算是不满足交换律的，从而克服了DistMult不能很好地表示非对称关系的问题。"}
{"text": "其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞_＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。"}
{"text": "可以看出在ComplEx中，f（h,r,t）≠f（t,r,h），所以可以更灵活地表达对称与非对称关系。"}
{"text": "类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。"}
{"text": "除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。"}
{"text": "3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。"}
{"text": "从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。"}
{"text": "表6-6常用知识图谱表示学习方法链接预测结果比较续表常用的关于知识图谱表示学习的工具包有清华开源的OpenKE，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。"}
{"text": "全面的关于工具包的信息可以在网站主页获得。"}
{"text": "6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。"}
{"text": "传统的数据流学习主要是从连续和快速更新的数据记录中提取知识结构。"}
{"text": "在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。"}
{"text": "本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。"}
{"text": "数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。"}
{"text": "本体流可以看成随时间变化的本体，也就是语义增强的数据流。"}
{"text": "ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。"}
{"text": "Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。"}
{"text": "快照从一个时刻转变到下一个时刻可以看成断言公理的更新，这被称为一阶预测突变；两个快照对于某些蕴涵具有足够大的概率差异，这被称突发预测变化。"}
{"text": "这两种预测变化构成了语义概念漂移。"}
{"text": "蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。"}
{"text": "通过将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。"}
{"text": "该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。"}
{"text": "实验还表明，在模型中，编码语义是一种超越目前最先进模型的方法，具有语义嵌入的模型对知识推理和预测起到重要作用。"}
{"text": "6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。"}
{"text": "比较有代表性的工作有文献[13]和[54]。"}
{"text": "文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。"}
{"text": "“事实判断”即确定一个三元组是否成立。"}
{"text": "文献作者将“事实判断”看作是这样一个问题：寻找一条能连接已知头实体h和尾实体t的路径。"}
{"text": "文献作者将此问题建模为序列决策问题，并利用基于策略梯度的强化学习方法REINFORCE求解。"}
{"text": "具体而言，强化学习中智能体的状态被定义为当前节点实体和目标节点实体的联合表示st=（et,etarget_et）.智能体的动作则是在当前节点实体的出边（Outgoing_edge）中选择一个适当的边作为组成路径的关系。"}
{"text": "在选择动作后，智能体的状态会随即更新。"}
{"text": "在奖励函数设计方面，文献作者同时考虑了准确率、路径效率和路径多样性。"}
{"text": "实验证明，DeepPath能学习到等价的推理路径，相比基于表示学习的方法，有更好的可解释性和推理效果。"}
{"text": "文献[54]考虑更有难度的“查询问答”（Query_Answering）问题，提出了MINERVA模型。"}
{"text": "与“事实判断”相比，“查询问答”无法预知答案对应的尾实体，需要从知识图谱中寻找可作为答案的尾实体。"}
{"text": "在这类知识图谱推理问题中，需要尽可能避免遍历大规模知识图谱，影响算法的效率。"}
{"text": "文献作者将这类问题建模成部分可观察的马尔科夫决策过程（POMDP）。"}
{"text": "我们可以想象一个智能体在知识图谱上游走，寻找目标尾实体。"}
{"text": "智能体的当前状态与它所处的当前实体有关，其动作即该实体可选的出边。"}
{"text": "尽管整个知识图谱中的关系总数可能繁多，但具体到某一实体，可选的出边往往减少一个或两个数量级，可大幅降低遍历的规模。"}
{"text": "实验结果表明：在这类“查询问答”的推理任务上，MINERVA模型远远超过了未使用强化学习的基于随机游走的模型。"}
{"text": "同时，当路径较长时，仍有良好的表现，具有鲁棒性。"}
{"text": "6.4.3基于元学习的少样本知识图谱推理在以往常见的基于表示学习的推理模型中，往往都会利用大量的数据对模型进行训练，并且当前大多数的研究都会假设对于其实验使用的知识库，所有的关系都有充足的三元组用来训练。"}
{"text": "但在真实的知识图谱中，有大量的关系仅仅具有非常少的三元组实例，称这种关系为长尾关系（Long-Tail_Relation），这类关系多被以往的研究忽视。"}
{"text": "但事实上，对于某一个关系，其具有的三元组实例越少，其对知识图谱的补全越有利用的价值。"}
{"text": "元学习的目的是解决“学习如何学习”（Learning_to_Learn），旨在通过少量样本迅速完成学习，其相对主要的应用是少样本学习（Few-Shot_Learning）。"}
{"text": "当前主要的元学习方法分为三类，基于度量（Metric-Based）、基于模型（Model-Based）和基于优化（Optimization-Based）的方法。"}
{"text": "关于元学习的研究，一开始主要应用于图像分类[55-57]，研究者近来尝试使用元学习的方法解决知识图谱中有关长尾关系的推理。"}
{"text": "XIONG等人[58]提出了使用基于度量的方法对长尾关系做少样本的链接预测，也就是在某一种关系的样本实例较少的情况下，通过头实体和关系对尾实体进行预测。"}
{"text": "HAN等人[59]确切地描述了关系分类的少样本学习任务，并提出了一个用于测试少样本关系分类（Few-Shot_Relation_Classification）的数据集FewRel，在将近来效果突出的少样本学习模型应用于该数据集后，对少样本知识图谱推理的难点进行了分析。"}
{"text": "把元学习应用于少样本知识图谱推理的研究还相对较少，该领域还有很多可以挖掘和研究的地方。"}
{"text": "Takuo_Hamaguchi_[60]主要针对KG中的OOKB（out-of-knowledge-base）实体进行知识库补全等任务。"}
{"text": "OOKB实体，即在训练过程中未被训练到的实体，无法得到其Embedding表示，从而无法预测其与知识库中其他实体之间的关系。"}
{"text": "而文中将知识库补全的任务定义为：基于知识库中已存在的三元组和当前出现的包含新实体的三元组，推理当前新实体与知识库中其他实体之间的关系。"}
{"text": "基于此，可以通过知识库中现有的实体表示推理得到OOKB实体表示。"}
{"text": "因此，这篇文献利用GNN中节点表示的方式，以OOKB实体分别为头实体、尾实体的三元组集合为周围邻居，对当前OOKB实体进行表示。"}
{"text": "每个实体节点经GNN的信息传播获取新的表示。"}
{"text": "基于此，通过TransE等经典模型，进行知识库补全任务。"}
{"text": "Schlichtkrull[61]利用R-GCNs（Relational_Graph_Convolutional_Networks）进行链接预测和实体发现等任务。"}
{"text": "本文的思想同样基于已知实体或关系在图结构中周围节点的结构，推理得到未知节点的表示，从而可对知识库中缺失的实体获取它们的Embedding向量。"}
{"text": "同时，结合TransE和DisMult等表示学习模型，进行知识库中缺失元素的补全任务。"}
{"text": "文献提出的R-GCNs，基于GCN进行图中节点信息的传播，同时考虑到真实知识库场景中的多关系类型数据，本文提出了两个正则化的优化方法，以此对由不同类型的关系连接的实体进行表示。"}
{"text": "实验结果证明，本文提出的方法对比传统的表示学习模型具有很大的提升。"}
{"text": "GNN模型的引入丰富了知识库中实体和关系元素的表达，尤其是在得到未知实体或关系的表示等方面具备一定的推理能力，针对目前在知识图谱表示学习和推理等方面遇到的问题，相信GNN一定能发挥出重要的作用。"}
{"text": "6.5开源工具实践：基于Jena和Drools的知识推理实践6.5.1开源工具简介Jena是一个免费且开源的支持构建语义网络和数据连接应用的Java框架，提供了处理RDF、RDFS、OWL数据的接口，一个规则引擎，用于查询的三元组的内存存储。"}
{"text": "Drools（JBoss_Rules）具有一个易于访问企业策略、易于调整以及易于管理的开源业务规则引擎，符合业内标准，具有速度快、效率高的特点。"}
{"text": "业务分析师或审核人员可以利用它轻松查看业务规则，从而检验已编码的规则是否执行了所需的业务规则。"}
{"text": "JBoss_Rules的前身是Codehaus的一个开源项目――Drools。"}
{"text": "现在被纳入JBoss门下，更名为JBoss_Rules，成为JBoss应用服务器的规则引擎。"}
{"text": "Drools是基于Charles_Forgy的RETE算法的规则引擎为Java量身定制的实现，具有OO接口的RETE，使得商业规则有了更自然的表达。"}
{"text": "6.5.2开源工具的技术架构图3-42所示为Jena框架。"}
{"text": "如图6-21所示为Drools框架。"}
{"text": "图6-21Drools框架规则引擎实现了数据同逻辑的完全解耦。"}
{"text": "规则并不能被直接调用，因为它们不是方法或函数，规则的激发是对Working_Memory中数据变化的响应。"}
{"text": "结果（Consequence，即RHS）作为LHS_events完全匹配的Listener。"}
{"text": "数据被assert进WorkingMemory后，和RuleBase中rule的LHS进行匹配，如果匹配成功，则这条rule连同和它匹配的数据（Activation）一起被放入Agenda，等待Agenda激发Activation（即执行rule的RHS）。"}
{"text": "6.6本章小结知识图谱是一种重要的组织知识的方式，知识图谱上的推理任务在其生命周期的各个阶段都存在，基于知识图谱的推理方法可大致分为基于演绎的推理和基于归纳的推理，而这两种不同的推理策略都包含了多种推理方法。"}
{"text": "（1）基于演绎的知识图谱推理可能有以下发展趋势：●演绎推理方法的效率是阻碍它们被广泛应用的瓶颈之一，通过并行技术、模块化技术、递增式推理技术和其他优化技术，实现高效推理机是演绎推理研究的趋势。"}
{"text": "●目前的演绎推理方法在处理流数据和移动数据方面还缺少完善的理论以及实用化算法，如何处理流数据的动态性以及时序性是值得研究的方向。"}
{"text": "（2）基于归纳的知识图谱推理可能有以下发展趋势：●尽管归纳推理主要是基于对已有数据的观察总结，但在归纳推理中也将逐渐融入先验的语义信息，例如规则等，使得归纳推理不仅仅是基于大量数据的观察，同时也包含先验知识的约束，从而达到更精准的推理。"}
{"text": "●不同的归纳推理方法，例如基于图结构、基于规则学习和基于表示学习的推理应该互相融合，形成优势互补，完成更智能的推理。"}
{"text": "（3）整体来说，知识图谱推理可能有以下发展趋势：●演绎和归纳两种不同的推理方式将逐渐融合，充分发挥各自的优势并互相补充，两者同时作用能完成更复杂、多样的知识图谱推理任务。"}
{"text": "●任何知识图谱都具有不完整性，仅仅基于知识图谱本身的推理无法突破不完整性的限制，因此外部信息，例如文本、图像等信息可能是很好的补充。"}
{"text": "第7章语义搜索王昊奋上海乐言信息科技有限公司，王萌东南大学知识图谱能够赋予信息明确的结构和语义，使机器不仅可以直观地显示这些信息，更能够理解、处理和整合它们。"}
{"text": "近年来，随着链接开放数据LOD（Linked_Open_Data）、OpenKG等项目的全面展开，知识图谱数据源的数量激增，大量以RDF为数据模型的图结构语义数据被发布，如DBpedia[1]、Wikidata[2]、zhishi.me[3]等。"}
{"text": "互联网从仅包含网页和网页之间超链接的文档万维网逐渐转变成包含大量描述各种实体和实体之间丰富关系的语义万维网。"}
{"text": "在这种背景下，以谷歌为代表的各大搜索引擎公司纷纷构建知识图谱来改善搜索质量，从而拉开了语义搜索的序幕。"}
{"text": "与传统互联网中的文档检索不同，语义搜索需要处理粒度更细的结构化语义数据，因此也面临着前所未有的挑战[4]。"}
{"text": "原有成熟的针对非结构化的、Web文档的存储与索引技术对知识图谱不再适用。"}
{"text": "现有的排序算法也不能直接应用到面向实体和关系的知识图谱语义搜索中。"}
{"text": "以SPARQL查询为代表的结构化查询语言的出现，为支持知识图谱的语义搜索提供了基础。"}
{"text": "此外，支持用户熟悉的关键词、自然语言查询对于知识图谱的语义搜索也至关重要。"}
{"text": "这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。"}
{"text": "自然语言转化逻辑表达式需要训练一个语法分析器将过程自动化。"}
{"text": "应注意两个关键步骤：资源映射和逻辑表达式生成。"}
{"text": "资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。"}
{"text": "简单映射是指字符形式上比较相似的，一般可以通过字符串相似度匹配来找到映射关系，例如“出生”和“出生地”的映射。"}
{"text": "复杂映射是指无法通过字符串匹配找到对应关系的映射，例如“老婆”与“配偶”的映射，这类映射在实际问答中出现的概率更高，一般可以采用基于统计的方法来找到映射关系。"}
{"text": "逻辑表达式生成即自底向上自动地将自然语言查询解析为语法树，语法树的根节点即是最终对应的逻辑表达式。"}
{"text": "如图8-24所示，查询“where_was_Obamaborn”对应的逻辑表达式是Type.Location?PeopleBornHere.BarackObama，其中lexicon是指资源映射操作，PeopleBornHere和BarackObama用Join连接组合，此组合结果再与Type.Location用求交集组合成为最终的逻辑表达式。"}
{"text": "图8-24自然语言查询转换成逻辑表达式[41]训练语法分析器需要大量的标注数据，传统的方法是基于规则生成标注数据，通过手工编写规则虽然直接，但是存在较明显的局限性：一方面，规则的编写需要语言学专家完成，导致规则的建立效率低且成本高，还不具备扩展性；另一方面，这种人工规则可能仅适用于某一类语言甚至某一特定领域，泛化能力较弱。"}
{"text": "为了改进传统方法的缺陷，有大量研究工作采用弱监督或者无监督的方法来训练语法分析器，一个经典的方法是Berant[41]提出利用“问题/答案对”数据结合Freebase作为语法分析器的训练集。"}
{"text": "此方法不需要逻辑表示式的专家人工标注数据，可以低成本地获得。"}
{"text": "Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。"}
{"text": "（1）资源映射。"}
{"text": "自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。"}
{"text": "例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。"}
{"text": "如图8-25所示，左边的“grew_up_in”是三元组中的自然语言关系短语r1，右边的“DateOfBirth”是知识库中的关系r2。"}
{"text": "统计所有自然语言三元组中符合r1[t1,t2]的实体对，得到集合F(r1)，统计知识库中符合r2[t1,t2]的实体对，得到集合F(r2)。"}
{"text": "通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。"}
{"text": "图8-25关系短语映射到知识库关系的方法[41]（2）桥接操作。"}
{"text": "在完成资源映射后仍然存在一些问题，首先，例如go、have、do等轻动词（Light_Verb）由于在语法上使用相对自由，难以通过统计的方式直接映射到实体关系上；其次，部分知识库关系的出现频率较低，利用统计也较难找到准确的映射方式。"}
{"text": "这样就需要补充一个额外的二元关系将这些词两端的逻辑表达式连接起来，这就是桥接操作。"}
{"text": "如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University?Education.BarackObama的逻辑表达式。"}
{"text": "由于知识库中的关系是有定义域和值域的，所以文献基于此特点在知识库中查找所有潜在的关系，例如Education的定义域和值域分别是Person和University，则Education可以是候选的桥接操作。"}
{"text": "这里针对每一种候选的桥接操作都会生成很多特征，基于这些特征训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "图8-26桥接操作示例[41]（3）组合操作。"}
{"text": "即逻辑表达式间的连接、求交集以及聚合三种操作。"}
{"text": "至于最终应该用哪种操作，作者同样通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "（4）候选逻辑表达式评估。"}
{"text": "即训练一个分类器，计算每一种候选逻辑表达式的概率，DiscriminativeLog-Linear模型，最终实现逻辑表达式的筛选。"}
{"text": "Berant等人基于前面候选逻辑表达式生成过程中的所有特征，训练了一个8.5.4基于深度学习的传统问答模块优化基于深度学习的知识问答主要有两个方向，分别是利用深度学习对传统问答方法进行模块级的改进和基于深度学习的端到端问答模型。"}
{"text": "深度学习可以直接用于改进传统问答流程的各个模块，包括语义解析、实体识别、意图分类和实体消歧等。"}
{"text": "下面通过Yih[51]的工作，说明如何使用深度神经网络来提升知识问答的效果。"}
{"text": "传统的基于语义解析的方法需要将问题转换成逻辑表达式，如图8-27所示。"}
{"text": "这类方法最大的问题是找到问题中自然语言短语与知识库的映射关系，Yih等人提出了一种语义解析的框架，首先基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。"}
{"text": "因为查询图可以直接映射到Lambda_Calculus形式的逻辑表达式，并且在语义上与λ-DCS（Lambda_Dependency-Based_CompositionalSemantics）紧密相关，因此就可以将语义解析的过程转换成查询图生成的过程。"}
{"text": "图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。"}
{"text": "这个例子对应的问句是“Who_first_voiced_Meg_on_Family_Guy?”，在不考虑聚合操作的情况下，该查询图对应的逻辑表达式是λx.?y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)。"}
{"text": "图8-28查询图示例[51]下面介绍查询图的生成过程。"}
{"text": "第一步，选择一个主题实体（Topic_Entity）作为根节点，如图8-29（a）中可以选择s1“FamilyGuy”作为根节点。"}
{"text": "第二步，确定一条从根节点到Lambda变量（答案节点）的有向路径，路径上可以有一个或者多个中间变量，这条路径被称为核心推断链（Core_Inferential_Chain），如图8-29（b）所示从三条路径s3、s4、s5中选取s3作为核心推断链。"}
{"text": "核心推断链上除了根节点为实体，其他的都只能是变量，节点间的关系都是知识库中的关系。"}
{"text": "第三步，给查询图添加约束条件和聚合函数（AugmentingConstraints&Aggregations），形式上就是把其他的实体或者聚合函数节点通过知识库中的关系与核心推断链上的变量连接起来，如图8-29（c）所示对y增加两个限制argmin和character(y,MegGriffin)。"}
{"text": "图8-29查询图的生成过程[51]对于生成查询图的第二步，需要一种从众多候选核心推断链中选出最优核心推断链的方法，针对图8-29（b）的例子，要评估{cast-actor,writer-start,genre}三个谓语序列中哪个最接近问题中“Family_Guy”和“Who”的关系，该文献使用一个CNN网络将候选序列和问题文本中的关键词向量化，CNN结构如图8-30所示，通过语义相似度计算找到最优的核心推断链。"}
{"text": "具体做法是将自然语言问题和谓语序列分别通过图8-30所示的网络得到两个300维的分布式表达，然后利用表达向量之间的相似度距离（如cosine距离）计算自然语言问题和谓语序列的语义相似度得分。"}
{"text": "该CNN网络的输入运用了词散列技术[52]，将句子中每个单词拆分成字母三元组，每个字母三元组对应一个向量，比如单词who可以拆为#-w-h,w-h-o,h-o-#，每个单词通过前后添加符号#来区分单词界限。"}
{"text": "然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。"}
{"text": "图8-30Yih[51]中的CNN结构8.5.5基于深度学习的端到端问答模型端到端的深度学习问答模型将问题和知识库中的信息均转化为向量表示，通过向量间的相似度计算的方式完成用户问题与知识库答案的匹配。"}
{"text": "首先根据问题中的主题词在知识库中确定候选答案，然后把问题和知识库中的候选答案都通过神经网络模型映射到一个低维空间，得到它们的分布式向量（Distributed_Embedding），则可计算候选答案分布式向量与问题向量的相似度得分，找出相似度最高的候选答案作为最终答案。"}
{"text": "该神经网络模型通过标注数据对进行训练，使得问题向量与知识库中正确答案的向量在低维空间的关联得分尽量高。"}
{"text": "典型的工作有BordesA等人[53]提出的方法，为解决WebQuestions上数据量不够的问题，文献作者使用一些规则从Freebase、ClueWeb等知识库中构建了大量（问题，知识库答案）的标注数据用于训练模型。"}
{"text": "如图8-31所示，自底向上计算。"}
{"text": "第一步，利用实体链接定位问题中的核心实体，对应到Freebase的实体；第二步，找到从问题中核心实体到候选答案实体的路径；第三步，生成候选答案的子图；第四步，分别将问题和答案子图映射成Embedding向量；第五步，进行点积运算，获得候选答案和问题之间的匹配度。"}
{"text": "该方法取得了比Berant[41]更好的结果（F1=0.392,P@1=0.40）。"}
{"text": "图8-31BordesA等人提出方法的核心流程[53]另一个基于Multi-ColumnCNN[54]的工作，该工作同时训练自然语言问句词向量与知识库三元组，将问题与知识库映射到同一个语义空间。"}
{"text": "该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。"}
{"text": "这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。"}
{"text": "该方法的核心流程如图8-32所示，对于问题“when_did_Avatarrelease_in_UK”，首先通过Multi-Column卷积神经网络提取该问题的三个分布式向量。"}
{"text": "最后，通过分别点乘运算再求和的方式得到最终的答案-问题对得分。"}
{"text": "在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。"}
{"text": "两个案例的基本框架一致，而知识问答增加了将自然语言问题转化为对应逻辑表达式以及查询语句的过程。"}
{"text": "因此，本小节通过一个简单案例介绍自然语言问题到Elasticsearch查询语句的转化，而用Elasticsearch查询语句进行查询即可得到问答结果。"}
{"text": "注意，真实的知识问答系统的语义理解远比本文方案复杂。"}
{"text": "自然语言问题对应的查询类型同本书第7章中的语义检索，如表8-4所示，主要包含四种类型的查询，即实体检索、实体属性检索、实体属性的多跳检索以及多种属性条件检索实体。"}
{"text": "表8-4自然语言问题的四种类型自然语言问题转化为逻辑表达式的过程如下：（1）定义逻辑表达式模板。"}
{"text": "如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。"}
{"text": "多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。"}
{"text": "<OP>表8-5自然语言问题对应的逻辑表达式模板（2）解析自然语言问题。"}
{"text": "从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。"}
{"text": "首先，实体和属性的识别可以采用词典的方法，例如从知识库中抽取所有的实体名和属性名，构建分词器的自定义词典。"}
{"text": "然后，对自然语言问题进行分词，可直接识别其中的属性名和实体名。"}
{"text": "其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。"}
{"text": "最后，查看自然语言问题中属性值和属性名的对应关系，当某属性值没有对应的属性名时，例如“（国籍是)中国(的)运动员”，缺省了“国籍”，就用该属性值对应的最频繁的属性名作为补全的属性名。"}
{"text": "例如下面的两段代码，分别实现了属性名识别和实体名识别。"}
{"text": "（3）后生成逻辑表达式。"}
{"text": "在识别出自然语言问题中所有的实体名、属性名和属性值后，依据它们的数目及位置，确定问题对应的查询类型，以便基于逻辑表达式模板生成对应的逻辑表达式。"}
{"text": "逻辑表达式生成流程如下：查询中含有实体名。"}
{"text": "如果有多个属性名，那么是属性值的多跳检索；如果有一个属性名，则需判断实体名和属性名的位置及中间的连接词(“是”“在”“的”等)，若实体名在前，则是实体的属性查询，例如“姚明的身高”，若属性名在前，则是依据属性查询实体，例如“女儿是姚沁蕾”。"}
{"text": "查询中没有实体名，则认为是依据属性查询实体，需要根据所有属性名和属性值位置的相对关系确定它们之间的对应关系。"}
{"text": "如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。"}
{"text": "工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。"}
{"text": "在生成逻辑表达式之后，可基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询。"}
{"text": "本方法定义了一组Elasticsearch查询模板，基于该模板将逻辑表达式按照一定的层次结构自动转换成Elasticsearch查询语句。"}
{"text": "如表8-6所示，对于实体属性查询，包括多跳检索，都是先检索实体，然后获取对应的属性。"}
{"text": "如表8-7所示，对于多个属性条件检索实体，先为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询，表中part_query表示单个属性条件对应的部分查询。"}
{"text": "gAnswer系统[55]是一个基于海量知识库的自然语言问答系统，针对用户的自然语言问题，能够输出SPARQL格式的知识库查询表达式以及查询答案的结果。"}
{"text": "gAnswer同时支持中文问答和英文问答。"}
{"text": "gAnswer参加了QALD-9的评测比赛，并取得了第一名的成绩。"}
{"text": "对于中文问答，使用PKUBASE知识库；对于英文问答，使用DBpedia知识库。"}
{"text": "此外，我们给出了一个使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/。"}
{"text": "如图8-33所示为gAnswer系统处理流程。"}
{"text": "主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。"}
{"text": "在构建语义查询图阶段，系统借助数据集的信息以及自然语言分析工具，对问句进行实体识别和关系抽取，构建语法依存树，并用这些结果构建对应的查询图。"}
{"text": "这时，并不对其中的实体和关系做消歧处理，而是利用谓词词典，记录词或短语可能对应的谓词或实体。"}
{"text": "在生成SPARQL查询阶段，系统利用查询图生成多个SPARQL，并利用数据集中的部分信息对多个SPARQL进行过滤和优化，其中就包括歧义的消除。"}
{"text": "在查询执行阶段，借助gStore系统返回的SPARQL查询结果，返回并展示给用户。"}
{"text": "图8-33gAnswer系统处理流程1.系统配置需求读者可以使用gAnswer系统构建自己的领域知识问答。"}
{"text": "在系统配置需求方面，gAnswer系统使用RDF格式的数据集，默认的中文数据集是PKUBASE，默认的英文数据集是DBpedia2016。"}
{"text": "gAnswer系统的运行需要借助支持SPARQL查询的图数据库系统来获取最终答案。"}
{"text": "在目前的版本中，使用gStore系统（http://openkg.cn/tool/gstore）。"}
{"text": "gAnswer的部署还依赖一些外部工具包。"}
{"text": "包括Maltparser、StanfordNLP，在生成SPARQL阶段，需要借助Lucene对辅助信息进行索引。"}
{"text": "8.7本章小结本章介绍了问答系统的基本概念、主流方法以及评价体系，并详细阐述了知识图谱问答系统的主要方法与最新进展。"}
{"text": "知识问答以自然语言问答的方式简化了人们获取知识的过程，在知识检索过程中增加了泛化、联想、探索等智能化体验并拓展了知识获取的途径。"}
{"text": "KBQA作为知识问答的重要分支，一方面强化了针对结构化信息的检索能力，另一方面也可以利用知识图谱提升问题理解的准确性。"}
{"text": "深度学习技术在KBQA也起到了重要的作用，不但可以优化传统KBQA的各个模块，尤其是实体识别和语义相似度匹配，而且可以直接作为知识库表示支持端到端的知识问答。"}
{"text": "正如万维网是开放的一样，多种多样的领域知识是不可能被任何一家企业垄断的，所以知识问答应该走万维网一样的开放路线，允许不同的参与者形成生态体系。"}
{"text": "参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。"}
