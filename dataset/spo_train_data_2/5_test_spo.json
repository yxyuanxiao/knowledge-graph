{"text": "根据使用技术的不同，下面分别介绍一些典型的本体映射工作。"}
{"text": "很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。"}
{"text": "此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。"}
{"text": "1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。"}
{"text": "这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。"}
{"text": "（1）技术综述1）基于术语的本体映射技术。"}
{"text": "这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。"}
{"text": "比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。"}
{"text": "①基于字符串的方法。"}
{"text": "基于字符串的方法直接比较表示本体成分的术语的字符串结构。"}
{"text": "主要的字符串比较技术如下。"}
{"text": "（a）规范化。"}
{"text": "在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。"}
{"text": "这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。"}
{"text": "（b）相似度量方法。"}
{"text": "在规范字符串的基础上，能进一步度量不同字符串间的相似程度。"}
{"text": "常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。"}
{"text": "如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。"}
{"text": "一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。"}
{"text": "定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。"}
{"text": "定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。"}
{"text": "还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。"}
{"text": "定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。"}
{"text": "两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。"}
{"text": "这些编辑操作包括插入、删除和替代字符。"}
{"text": "显然，编辑距离越大，表示两字符串的相似程度越小。"}
{"text": "编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。"}
{"text": "除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。"}
{"text": "路径比较便是这类方法中的一种。"}
{"text": "定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"}
{"text": "②基于语言的方法。"}
{"text": "基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。"}
{"text": "这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。"}
{"text": "内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。"}
{"text": "它寻找同一字符串的不同语言形态，如Apple和Apples等。"}
{"text": "寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。"}
{"text": "外部方法利用词典等外部资源来寻找映射。"}
{"text": "基于词典的方法使用外部词典匹配语义相关的术语。"}
{"text": "例如，使用WordNet能判断两个术语是否有同义或上下义关系。"}
{"text": "尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。"}
{"text": "2）基于结构的本体映射技术。"}
{"text": "在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。"}
{"text": "基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。"}
{"text": "①内部结构。"}
{"text": "基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。"}
{"text": "通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。"}
{"text": "②外部结构。"}
{"text": "比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。"}
{"text": "从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。"}
{"text": "有一些常用来判断本体成分相似的准则，这些准则包括：(C1)直接超类或所有的超类相似；(C2)兄弟相似；(C3)直接子类或所有的子类相似；(C4)所有或大部分后继（不一定是子类，可能通过其他关系连接）相似；(C5)所有或大部分的叶子成分相似；(C6)从根节点到当前节点的路径上的实体都相似。"}
{"text": "对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。"}
{"text": "计算概念之间的相似也可以考虑它们之间的关系。"}
{"text": "如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。"}
{"text": "然而，这种方法的问题在于如何判断关系的相似性。"}
{"text": "关系的相似性计算一直是一个很困难的问题。"}
{"text": "外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。"}
{"text": "基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。"}
{"text": "（2）方法和工具1）AnchorPROMPT。"}
{"text": "除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。"}
{"text": "PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。"}
{"text": "目前，PROMPT的这些工具已集成到Protégé系统中。"}
{"text": "本体映射是解决很多多本体问题的基础。"}
{"text": "为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。"}
{"text": "AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。"}
{"text": "①AnchorPROMPT的思想。"}
{"text": "AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。"}
{"text": "AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。"}
{"text": "术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。"}
{"text": "AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。"}
{"text": "AnchorPROMPT将每个本体O视为一个带边有向图G。"}
{"text": "O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。"}
{"text": "图中通过一条边连接的两节点称为相邻节点。"}
{"text": "如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。"}
{"text": "路径的长度是边的数目。"}
{"text": "为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。"}
{"text": "AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。"}
{"text": "因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。"}
{"text": "②AnchorPROMPT算法。"}
{"text": "为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。"}
{"text": "对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。"}
{"text": "这样的术语对利用基本的术语比较技术能很容易识别出来。"}
{"text": "根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。"}
{"text": "对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。"}
{"text": "在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。"}
{"text": "图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。"}
{"text": "当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。"}
{"text": "在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。"}
{"text": "AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。"}
{"text": "结果，经常出现在相同位置的术语对间的相似度分数往往最高。"}
{"text": "（a）等价组。"}
{"text": "在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。"}
{"text": "与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。"}
{"text": "AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。"}
{"text": "等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。"}
{"text": "图5-5路径中的等价组（b）相似度分数。"}
{"text": "给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。"}
{"text": "步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。"}
{"text": "步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。"}
{"text": "如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。"}
{"text": "当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。"}
{"text": "这个问题在接下来的部分进行分析。"}
{"text": "根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。"}
{"text": "③AnchorPROMPT评估。"}
{"text": "Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。"}
{"text": "（a）等价组大小。"}
{"text": "试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。"}
{"text": "当等价组的最大尺寸为2时，只有12%的试验没有结果。"}
{"text": "因此，在随后的试验中设定等价组的最大尺寸大小为2。"}
{"text": "（b）等价组成员的相似度分数。"}
{"text": "为评价等价组成员如何打分合理而做了两类试验。"}
{"text": "第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。"}
{"text": "试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。"}
{"text": "（c）锚的数目和路径最大长度。"}
{"text": "在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。"}
{"text": "试验表明，当最大长度路径设为2时，能获得最好的正确率。"}
{"text": "当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。"}
{"text": "④AnchorPROMPT的讨论。"}
{"text": "当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。"}
{"text": "以此类推，可以得到路径上更多的关系对也是相似的。"}
{"text": "实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。"}
{"text": "在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。"}
{"text": "而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。"}
{"text": "AnchorPROMPT其他方面的讨论如下。"}
{"text": "（a）减少负面结果的影响。"}
{"text": "概念间的相似度分数是一个累加值。"}
{"text": "两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。"}
{"text": "AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。"}
{"text": "试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。"}
{"text": "试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。"}
{"text": "（b）执行本体映射。"}
{"text": "AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。"}
{"text": "（c）局限性。"}
{"text": "AnchorPROMPT的映射发现方法并非适用于所有的本体。"}
{"text": "当两个本体间的结构差别很大时，该方法处理的效果并不好。"}
{"text": "此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。"}
{"text": "⑤AnchorPROMPT的总结。"}
{"text": "AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。"}
{"text": "由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。"}
{"text": "对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。"}
{"text": "从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。"}
{"text": "2）iPROMPT。"}
{"text": "PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。"}
{"text": "iPROMPT从语言角度判断本体间概念或关系的相似。"}
{"text": "然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。"}
{"text": "在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。"}
{"text": "图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。"}
{"text": "iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。"}
{"text": "步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。"}
{"text": "当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。"}
{"text": "合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。"}
{"text": "这样的冲突可以通过重命名来解决。"}
{"text": "②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。"}
{"text": "在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。"}
{"text": "③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。"}
{"text": "对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。"}
{"text": "Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。"}
{"text": "这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。"}
{"text": "试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。"}
{"text": "总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。"}
{"text": "3）MAFRA。"}
{"text": "MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。"}
{"text": "MAFRA引入了语义桥和以服务为中心的思想。"}
{"text": "语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。"}
{"text": "MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。"}
{"text": "要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。"}
{"text": "MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。"}
{"text": "②相似度。"}
{"text": "MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。"}
{"text": "在计算概念间关系的过程中还考虑了概念的属性。"}
{"text": "③语义桥。"}
{"text": "根据本体成分间的相似度，利用语义桥来表示本体映射。"}
{"text": "这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。"}
{"text": "还能利用推理建立一些隐含的语义桥。"}
{"text": "④执行。"}
{"text": "在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。"}
{"text": "⑤后处理。"}
{"text": "映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。"}
{"text": "垂直方向四个模块具体包括：①演化。"}
{"text": "当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。"}
{"text": "②协同创建。"}
{"text": "对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。"}
{"text": "③领域限制和背景知识。"}
{"text": "给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。"}
{"text": "④用户界面交互。"}
{"text": "给出图形化的操作界面能让本体建立的过程更容易。"}
{"text": "图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。"}
{"text": "尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。"}
{"text": "因此，MAFRA更多只是一个处理异构本体映射的框架。"}
{"text": "4）ONION。"}
{"text": "ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。"}
{"text": "该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。"}
{"text": "为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。"}
{"text": "本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。"}
{"text": "本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。"}
{"text": "专家还可以添加新的映射，以补充算法无法生成的映射规则。"}
{"text": "ONION的映射生成过程同时使用了术语匹配和本体图匹配。"}
{"text": "对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。"}
{"text": "在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。"}
{"text": "为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。"}
{"text": "在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。"}
{"text": "“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。"}
{"text": "①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。"}
{"text": "在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。"}
{"text": "同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。"}
{"text": "②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。"}
{"text": "Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。"}
{"text": "因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。"}
{"text": "ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。"}
{"text": "试验还表明，在映射发现过程中采用多种策略能提高精度。"}
{"text": "ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。"}
{"text": "5）Wang_Peng和Xu_Baowen的方法。"}
{"text": "Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。"}
{"text": "该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。"}
{"text": "该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。"}
{"text": "这种方法认为不同本体间概念的相似度包括三个部分：①概念的同义词集相似度。"}
{"text": "同义词集是语义相同或相近词的分组[38]。"}
{"text": "基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。"}
{"text": "②概念特征上的相似度。"}
{"text": "概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。"}
{"text": "③概念上下文上的相似度。"}
{"text": "以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。"}
{"text": "以下定义概念的语义邻居概念集。"}
{"text": "定义5.6概念Co的语义邻居概念集N(Co,r)={Ci|∀i,d(Co,Ci)≤r}。"}
{"text": "式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。"}
{"text": "这里的关系包含直接继承关系。"}
{"text": "d≤r表明与当前的概念在语义距离上小于某一定常数。"}
{"text": "在以上分析的基础上，给出了本体间概念相似度的计算公式：S(Cp,Cq)=Ww×Sw(Cp,Cq)+Wu×Su(Cp,Cq)+Wn×Sn(Cp,Cq)式中，Ww、Wu和Wn是权重；Sw、Su和Sn分别代表概念名称、特征以及上下文三方面的相似性度量。"}
{"text": "计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。"}
{"text": "该方法利用概念间的相似度辅助本体映射的生成。"}
{"text": "①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。"}
{"text": "通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。"}
{"text": "②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。"}
{"text": "根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。"}
{"text": "生成规则如下。"}
{"text": "定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。"}
{"text": "式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。"}
{"text": "式中，isa表示两概念具有上义和下义关系。"}
{"text": "从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。"}
{"text": "6）S-Match。"}
{"text": "S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。"}
{"text": "它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。"}
{"text": "S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。"}
{"text": "S-Match的核心是计算异构本体间的语义关系。"}
{"text": "输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。"}
{"text": "该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。"}
{"text": "执行结果的输出是一个被丰富的树。"}
{"text": "然后，用户协调两本体的匹配过程，这种方法使用三个外部库。"}
{"text": "第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。"}
{"text": "目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。"}
{"text": "第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。"}
{"text": "第三个库是由结构层次的强语义匹配器组成的。"}
{"text": "输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。"}
{"text": "其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。"}
{"text": "其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。"}
{"text": "<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。"}
{"text": "扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。"}
{"text": "步骤3：对所有T1和T2中的标签对，计算标签间的关系。"}
{"text": "利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。"}
{"text": "步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。"}
{"text": "将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。"}
{"text": "与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。"}
{"text": "7）Cupid。"}
{"text": "Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。"}
{"text": "该方法输入图格式的模式，图节点表示模式中的元素。"}
{"text": "与其他的混合方法比较[42],Cupid得到更好的映射结果。"}
{"text": "发现模式匹配的算法包含三个阶段。"}
{"text": "①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。"}
{"text": "Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。"}
{"text": "8）其他方法。"}
{"text": "Chimaera是一个合并和测试大本体的环境[43]。"}
{"text": "寻找本体映射是进行合并操作的一个主要任务。"}
{"text": "Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。"}
{"text": "Chimaera能识别术语间是否包含或不相关等简单的映射关系。"}
{"text": "BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。"}
{"text": "BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。"}
{"text": "它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。"}
{"text": "因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。"}
{"text": "COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。"}
{"text": "COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。"}
{"text": "它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。"}
{"text": "面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。"}
{"text": "模式被编码为有向无环图。"}
{"text": "COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。"}
{"text": "ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。"}
{"text": "ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。"}
{"text": "该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。"}
{"text": "（3）基于术语和结构的本体映射总结。"}
{"text": "这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。"}
{"text": "2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。"}
{"text": "（1）技术综述。"}
{"text": "基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。"}
{"text": "①共享实例的方法。"}
{"text": "当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。"}
{"text": "当两概念等价时，显然有AB=A=B。"}
{"text": "然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。"}
{"text": "定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。"}
{"text": "此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。"}
{"text": "②无共享实例的方法。"}
{"text": "当两概念没有共享实例时，基于共享实例的方法无能为力。"}
{"text": "事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。"}
{"text": "在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。"}
{"text": "常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。"}
{"text": "其中，Haussdorf距离度量两个集合之间的最大距离。"}
{"text": "而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。"}
{"text": "基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。"}
{"text": "通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。"}
{"text": "训练完成后，训练结果用于发现异构本体间的映射。"}
{"text": "大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。"}
{"text": "常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。"}
{"text": "（2）方法和工具1）GLUE。"}
{"text": "GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。"}
{"text": "GLUE是对半自动模式发现系统LSD的一个改进[53]。"}
{"text": "GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。"}
{"text": "该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。"}
{"text": "①GLUE的思想。"}
{"text": "GLUE的目的是根据分类本体寻找本体间1∶1的映射。"}
{"text": "其中的主要思想包括：（a）相似度定义。"}
{"text": "GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。"}
{"text": "GLUE定义了4种概念的联合概率分布。"}
{"text": "（b）计算相似度。"}
{"text": "由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。"}
{"text": "它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。"}
{"text": "（c）多策略学习。"}
{"text": "使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。"}
{"text": "然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。"}
{"text": "为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。"}
{"text": "（d）利用领域约束。"}
{"text": "GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。"}
{"text": "一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。"}
{"text": "（e）处理复杂映射。"}
{"text": "为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。"}
{"text": "以下给出GLUE方法的详细介绍。"}
{"text": "②相似度度量。"}
{"text": "很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。"}
{"text": "GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。"}
{"text": "在此基础上，GLUE定义不同概念间的联合)和P(概率分布。"}
{"text": "概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。"}
{"text": "以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。"}
{"text": "GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。"}
{"text": "第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。"}
{"text": "另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。"}
{"text": "这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。"}
{"text": "这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。"}
{"text": "类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。"}
{"text": "③GLUE体系结构。"}
{"text": "GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。"}
{"text": "图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。"}
{"text": "然后利用机器学习技术计算每对概念的联合概率分布。"}
{"text": "由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。"}
{"text": "分布评估使用一组基本学习器和一个元学习器。"}
{"text": "相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。"}
{"text": "放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。"}
{"text": "④分布估计。"}
{"text": "考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。"}
{"text": "通常这个比值是无法计算的，因为不可能知道全体实例。"}
{"text": "因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。"}
{"text": "注意，两个本体的实例可以重叠，但没有必要必须那样。"}
{"text": "Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。"}
{"text": "N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。"}
{"text": "这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。"}
{"text": "为了达到这个目的，GLUE使用了机器学习方法。"}
{"text": "特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。"}
{"text": "然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。"}
{"text": "最后，使用该分类器预测O2中的实例s是否属于A。"}
{"text": "通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。"}
{"text": "这个值反映了分类的不确定性。"}
{"text": "这里规定置信度大于0.5就表示“是”。"}
{"text": "常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。"}
{"text": "基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。"}
{"text": "具体的过程如图5-9所示。"}
{"text": "●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。"}
{"text": "●使用和作为正例和反例分别训练学习器L，如图5-9（c）。"}
{"text": "●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。"}
{"text": "●对中的每个实例使用学习器L进行分类。"}
{"text": "将划分为两个集合和。"}
{"text": "相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。"}
{"text": "●重复（a）～（d），得到集合和。"}
{"text": "●使用公式计算P(A,B)。"}
{"text": "类似地，可以计算出其他3种联合概率分布。"}
{"text": "图5-9估计概念A和B的概率分布⑤多策略学习。"}
{"text": "训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。"}
{"text": "为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。"}
{"text": "在分布估计阶段，系统会训练多个基本学习器L1,…,Lk。"}
{"text": "每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。"}
{"text": "训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。"}
{"text": "与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。"}
{"text": "目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。"}
{"text": "此外，还有1个元学习器将基本学习器的结果进行线性合并。"}
{"text": "内容学习器和名字学习器的细节如下：（a）内容学习器。"}
{"text": "利用实例文本内容中的词频来进行分类预测。"}
{"text": "一个实例通常由名将这些信息都作为实例的文本内容。"}
{"text": "例如，实字、属性集合以及属性值组成。"}
{"text": "GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。"}
{"text": "内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。"}
{"text": "它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,…,wk}，其中的wj是标记。"}
{"text": "内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。"}
{"text": "根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。"}
{"text": "其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。"}
{"text": "特别地，P(A)被估计为属于A的实例占全部训练实例的比例。"}
{"text": "因此，只需要计算P(d|A)就可以得到P(A|d)。"}
{"text": "为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)···P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。"}
{"text": "注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。"}
{"text": "P(|d)可通过相似的方法来计算。"}
{"text": "（b）名字学习器。"}
{"text": "相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。"}
{"text": "这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。"}
{"text": "（c）元学习器。"}
{"text": "基本学习器的预测结果通过元学习器来合并。"}
{"text": "元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。"}
{"text": "这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。"}
{"text": "⑥利用领域约束和启发式知识。"}
{"text": "经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。"}
{"text": "放松标记是一种解决图中节点的标签分配问题的有效技术。"}
{"text": "该方法的思想是节点的标签通常受其邻居的特征影响。"}
{"text": "基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。"}
{"text": "放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。"}
{"text": "GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。"}
{"text": "考虑约束能提高映射的精度。"}
{"text": "约束又可分为领域独立约束和领域依赖约束两种。"}
{"text": "领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。"}
{"text": "邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。"}
{"text": "领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。"}
{"text": "以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。"}
{"text": "GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。"}
{"text": "⑦实验评估。"}
{"text": "GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。"}
{"text": "在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。"}
{"text": "在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。"}
{"text": "放松标记能进一步提高3%～18%的正确率，只有一个实验例外。"}
{"text": "由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。"}
{"text": "尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。"}
{"text": "首先，一些概念不能被匹配是因为缺少足够的训练数据。"}
{"text": "其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。"}
{"text": "第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。"}
{"text": "最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。"}
{"text": "⑧扩充GLUE发现复杂映射。"}
{"text": "GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。"}
{"text": "为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。"}
{"text": "目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。"}
{"text": "CGLUE中的复杂映射形式如A=X1op1X2op2…opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。"}
{"text": "这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。"}
{"text": "由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。"}
{"text": "CGLUE将形如X1op1X2op2···opn-1Xn的复合概念称作映射对象。"}
{"text": "CGLUE还进一步假设概念D的孩子C1,C2,…,Ck要满足条件,1≤i,j≤k,i≠j，且。"}
{"text": "CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。"}
{"text": "对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。"}
{"text": "比较的方法与GLUE中的相似。"}
{"text": "最后返回相似度最高的映射结果。"}
{"text": "由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。"}
{"text": "因此需要考虑从巨量的候选复合概念中搜索A的近似。"}
{"text": "为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。"}
{"text": "定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。"}
{"text": "设highest_sim=0。"}
{"text": "扩展这些候选创建新的候选对象。"}
{"text": "添加新候选对象到S。"}
{"text": "设置highest_sim=new_highest_sim。"}
{"text": "算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。"}
{"text": "在步骤2（c）中，ε最初设置为0。"}
{"text": "在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。"}
{"text": "因为每个候选对象只是O2概念的并，去除过程很快。"}
{"text": "CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。"}
{"text": "试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。"}
{"text": "实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。"}
{"text": "⑨GLUE的总结。"}
{"text": "GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。"}
{"text": "GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。"}
{"text": "试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。"}
{"text": "扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。"}
{"text": "尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。"}
{"text": "其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。"}
{"text": "最后，GLUE无法处理关于异构本体的关系之间的映射。"}
{"text": "2）概念近似的方法。"}
{"text": "在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。"}
{"text": "本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。"}
{"text": "①方法的思想。"}
{"text": "在本体查询系统中，信息源和查询都是针对特定本体的。"}
{"text": "不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。"}
{"text": "一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。"}
{"text": "因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。"}
{"text": "当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。"}
{"text": "令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。"}
{"text": "查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。"}
{"text": "但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。"}
{"text": "令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。"}
{"text": "R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。"}
{"text": "如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。"}
{"text": "查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。"}
{"text": "本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。"}
{"text": "这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。"}
{"text": "②Stuckenschmidt_H的概念近似。"}
{"text": "寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。"}
{"text": "Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。"}
{"text": "该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。"}
{"text": "从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。"}
{"text": "C为O1中概念，概念C的最小上界lub(C,T)包含A1,A2,…,Am，是C在O2中的直接父类；概念C的最大下界glb(C,T)包含B1,B2,…,Bn，是C在O2中的直接父类。"}
{"text": "图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。"}
{"text": "找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。"}
{"text": "定义5.11令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。"}
{"text": "找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。"}
{"text": "显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。"}
{"text": "因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。"}
{"text": "任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。"}
{"text": "这样概念数目最多翻倍，但所有非算子都被消去。"}
{"text": "Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。"}
{"text": "上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。"}
{"text": "但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。"}
{"text": "在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。"}
{"text": "但这种方法无法得到概念的最佳近似，近似的质量有时是不可接受的。"}
{"text": "如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。"}
{"text": "同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。"}
{"text": "异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。"}
{"text": "这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。"}
{"text": "实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。"}
{"text": "如果考虑这些蕴涵关系，也许可以提高近似查询的质量。"}
{"text": "图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。"}
{"text": "为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。"}
{"text": "它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。"}
{"text": "该方法需要一个训练实例集合。"}
{"text": "令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。"}
{"text": "在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K⊆QI(S)};K-={Q|QI(S)⊆K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。"}
{"text": "这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。"}
{"text": "为此，引入一个将对象映射到概念合取的函数：。"}
{"text": "可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。"}
{"text": "对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。"}
{"text": "遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。"}
{"text": "与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。"}
{"text": "第一是查询效率问题。"}
{"text": "该方法需要遍历所有实例计算概念近似。"}
{"text": "得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。"}
{"text": "第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。"}
{"text": "最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。"}
{"text": "④基于多元界的概念近似。"}
{"text": "Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。"}
{"text": "这种方法能进一步推广到关系映射的发现。"}
{"text": "由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。"}
{"text": "基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。"}
{"text": "将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。"}
{"text": "证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。"}
{"text": "通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。"}
{"text": "该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。"}
{"text": "该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。"}
{"text": "引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。"}
{"text": "由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。"}
{"text": "证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。"}
{"text": "这是该方法的理论基础。"}
{"text": "3）FCA。"}
{"text": "Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。"}
{"text": "该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。"}
{"text": "当然，这些概念分别来自两个不同的初始本体。"}
{"text": "①形式化概念分析基础。"}
{"text": "首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。"}
{"text": "形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。"}
{"text": "概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。"}
{"text": "另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。"}
{"text": "因此，概念格被认为是进行数据分析的有力工具。"}
{"text": "从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。"}
{"text": "形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。"}
{"text": "(s,d)∈R表示实例s有属性d。"}
{"text": "一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。"}
{"text": "这种由背景(S,D,R)导出的格L就称为一个概念格。"}
{"text": "格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。"}
{"text": "每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|∀y∈Y,xRy}2）Y={y∈D|∀x∈X,xRy}在概念格节点间能够建立起一种偏序关系。"}
{"text": "给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1⇔Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。"}
{"text": "根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。"}
{"text": "②自底向上的FCA-Merge本体合并。"}
{"text": "该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。"}
{"text": "整个本体合并的过程分三步。"}
{"text": "（a）实例提取。"}
{"text": "由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。"}
{"text": "从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。"}
{"text": "而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。"}
{"text": "这一步采用自然语言处理技术，得到两本体的形式背景。"}
{"text": "每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。"}
{"text": "显然，一个文档可能是多个概念的实例。"}
{"text": "（b）概念格计算。"}
{"text": "输入第一步中得到的两张布尔表来计算概念格。"}
{"text": "FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。"}
{"text": "（c）交互生成合并的本体。"}
{"text": "生成的概念格已经将独立的两个本体合并在一起。"}
{"text": "本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。"}
{"text": "显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。"}
{"text": "②FCA总结。"}
{"text": "形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。"}
{"text": "这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。"}
{"text": "FCA具有一些不足。"}
{"text": "首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。"}
{"text": "其次，映射结果质量受提取共享实例过程的影响。"}
{"text": "最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。"}
{"text": "4）IF-Map。"}
{"text": "该方法是一种自动的本体映射发现技术，基于信息流理论[71]。"}
{"text": "IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。"}
{"text": "那样的参考本体没有实例，而实例只在局部本体中才考虑。"}
{"text": "因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。"}
{"text": "映射生成的过程包括4个阶段：①采集，即收集不同的本体；②转换，即将待映射本体转换为特定格式；③信息映射生成，即利用信息流理论生成本体间的映射；④映射投影，将生成的概念间等价映射用本体语言表示出来，如owl:sameAs等。"}
{"text": "IF-Map也只能生成异构本体概念间的简单等价映射。"}
{"text": "（3）基于实例的本体映射总结。"}
{"text": "与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。"}
{"text": "一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。"}
{"text": "此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。"}
{"text": "3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。"}
{"text": "因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。"}
{"text": "（1）方法和工具1）QOM。"}
{"text": "QOM是采用综合方法发现本体映射的典型工作[72-75]。"}
{"text": "该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。"}
{"text": "QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。"}
{"text": "①QOM的思路。"}
{"text": "大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。"}
{"text": "目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。"}
{"text": "对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。"}
{"text": "与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。"}
{"text": "QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。"}
{"text": "②QOM方法的过程。"}
{"text": "QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。"}
{"text": "特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。"}
{"text": "QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。"}
{"text": "搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。"}
{"text": "相似度计算：对每一对候选映射对象，判断它们之间的相似度值。"}
{"text": "一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。"}
{"text": "QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。"}
{"text": "为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。"}
{"text": "相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。"}
{"text": "这些不同的相似度值需要累加，成为单个的相似度值。"}
{"text": "QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。"}
{"text": "解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。"}
{"text": "根据处理后的最终相似度值判断本体之间的映射。"}
{"text": "迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。"}
{"text": "每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。"}
{"text": "③实验评估和结果。"}
{"text": "QOM分析了几种典型的本体映射方法的时间复杂度。"}
{"text": "iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。"}
{"text": "与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n·og(n))。"}
{"text": "注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。"}
{"text": "试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。"}
{"text": "2）OLA。"}
{"text": "OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。"}
{"text": "目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。"}
{"text": "OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。"}
{"text": "图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。"}
{"text": "实体之间的相似度被赋予权重并线性累加。"}
{"text": "OLA能发现本体概念间的等价映射。"}
{"text": "3）KRAFT。"}
{"text": "KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。"}
{"text": "这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。"}
{"text": "KRAFT并没有给出映射发现的方法。"}
{"text": "4）OntoMap。"}
{"text": "OntoMap是一个知识表示的形式化、推理和Web接口。"}
{"text": "它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。"}
{"text": "为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。"}
{"text": "这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。"}
{"text": "OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。"}
{"text": "映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。"}
{"text": "这些原语表明了OntoMapO支持的映射类型。"}
{"text": "但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。"}
{"text": "因此，OntoMap更多只是提供了一个映射的表示框架。"}
{"text": "和5）OBSERVER。"}
{"text": "OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。"}
{"text": "OBSERVER使用基于组件的方法发现本体映射。"}
{"text": "它使用多个预先定义的本体来表示异构数据库的模式。"}
{"text": "映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。"}
{"text": "OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。"}
{"text": "但是，该方法的本体映射依靠手工建立。"}
{"text": "6）InfoSleuth。"}
{"text": "InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。"}
{"text": "本体间的映射是概念间的关系。"}
{"text": "本体的映射由一个特殊的被称为“资源主体”的类完成。"}
{"text": "一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。"}
{"text": "7）基于虚拟文档的本体匹配。"}
{"text": "本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。"}
{"text": "元素还可以通过自身注释中的简单语句，对其含义进行补充说明。"}
{"text": "此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。"}
{"text": "因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。"}
{"text": "一个元素的虚拟文档包含3种。"}
{"text": "①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。"}
{"text": "②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。"}
{"text": "在此过程中，越远的元素会被赋予越小的描述权重。"}
{"text": "③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。"}
{"text": "注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。"}
{"text": "在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。"}
{"text": "两元素的语义描述文档相似度越高，它们相匹配的可能性越大。"}
{"text": "描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。"}
{"text": "虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,…,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。"}
{"text": "基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。"}
{"text": "（2）本体映射的综合方法总结。"}
{"text": "考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。"}
{"text": "但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。"}
{"text": "此外，将各种映射方法的结果进行综合也很重要。"}
{"text": "5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。"}
{"text": "要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。"}
{"text": "管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。"}
{"text": "这里讨论如何通过组织映射来达到管理异构的多本体的目的。"}
{"text": "实际上，在数据库等领域中就有针对模式或模型管理的研究。"}
{"text": "他们指出，模型间的映射和操作是模型管理的核心问题。"}
{"text": "在本体研究领域，一些工作分析了本体管理的挑战[87,88]。"}
{"text": "这些研究将本体管理的任务分为两方面。"}
{"text": "一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。"}
{"text": "另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。"}
{"text": "Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。"}
{"text": "Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。"}
{"text": "Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。"}
{"text": "显然，这些工作都关注本体的表示、存储和维护。"}
{"text": "而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。"}
{"text": "但这些工作为管理多个本体打下了基础。"}
{"text": "Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。"}
{"text": "PROMPTDiff只使用结构不同检测两个版本的不同。"}
{"text": "而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。"}
{"text": "Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。"}
{"text": "Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。"}
{"text": "从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。"}
{"text": "这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。"}
{"text": "与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。"}
{"text": "传统的本体管理通常是二层结构：本体存储层和应用层。"}
{"text": "二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。"}
{"text": "Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。"}
{"text": "这样的管理方式具有灵活的特点，适应动态Web环境。"}
{"text": "然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。"}
{"text": "Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。"}
{"text": "框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。"}
{"text": "五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。"}
{"text": "各层的具体功能如下：①本体库层。"}
{"text": "本体库层存放不同渠道获得的本体。"}
{"text": "本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。"}
{"text": "②本体表示层。"}
{"text": "不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。"}
{"text": "这种转换会造成一些信息的损失。"}
{"text": "通常少许的非关键本体信息在转换中丢失是可容忍的。"}
{"text": "③桥本体层。"}
{"text": "多本体间常常重叠，其间往往有关联。"}
{"text": "为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。"}
{"text": "桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。"}
{"text": "在这层中，利用文献[62,36]的方法生成本体间的映射。"}
{"text": "桥的生成是半自动化的，并在桥本体中组织管理。"}
{"text": "本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。"}
{"text": "Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。"}
{"text": "对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。"}
{"text": "前者是由于引入等价桥后造成的，通过算法可消除。"}
{"text": "后者是由于原始本体中的错误或引入不当的桥造成的。"}
{"text": "算法能够找到环路，但区分恶性和良性环路需要人工参与。"}
{"text": "经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。"}
{"text": "本体间映射抽取出来，可通过桥本体进行管理。"}
{"text": "当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。"}
{"text": "④多本体功能层。"}
{"text": "多本体的管理能提供满足应用需求的一些主要功能。"}
{"text": "第一，桥本体中的桥提供了大量的简单和复杂的本体映射。"}
{"text": "通过这些映射，很容易实现异构本体间的互操作问题。"}
{"text": "第二，利用多本体间的桥，能实现跨不同本体的推理。"}
{"text": "第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。"}
{"text": "第四，还可以从多本体中抽取满足需求的子本体。"}
{"text": "第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。"}
{"text": "⑤多本体应用层。"}
{"text": "在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。"}
{"text": "5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。"}
{"text": "大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。"}
{"text": "使用整个本体会大大增加系统的复杂性和降低效率。"}
{"text": "因此，从源本体中抽取一个小的子本体能让系统更有效。"}
{"text": "子本体抽取是一个新的研究领域。"}
{"text": "Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。"}
{"text": "随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。"}
{"text": "Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。"}
{"text": "Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。"}
{"text": "当前的方法都是从单个本体中抽取子本体。"}
{"text": "但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。"}
{"text": "从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。"}
{"text": "Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。"}
{"text": "抽取子本体是一种重要的知识重用手段。"}
{"text": "本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。"}
{"text": "在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。"}
{"text": "5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。"}
{"text": "实例匹配的过程虽然与本体匹配有相似之处，但实例匹配通常是一个大规模数据处理问题，需要在匹配过程中解决其中的时间复杂度和空间复杂度问题，其难度和挑战更大。"}
{"text": "5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。"}
{"text": "人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。"}
{"text": "与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。"}
{"text": "这些本体的规模正随着人类知识的增长而变得越来越大。"}
{"text": "近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。"}
{"text": "然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。"}
{"text": "因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。"}
{"text": "本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。"}
{"text": "从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。"}
{"text": "这些大本体总体上可划分为三类：通用本体，即用于描述人类通用知识、语言知识和常识知识的本体，如Cyc、WordNet和SUMO等；领域本体，各个领域中的研究人员也建立了很多专业领域中的本体，如生物医学领域中的基因本体和统一医学语言系统本体UMLS；企业应用本体，为了有效管理、维护和利用拥有的大量数据，很多企业都利用本体对自身的海量数据进行重组，以便为用户提供更高效和智能的服务。"}
{"text": "出于商业保密的目的，这些企业本体通常并不公开。"}
{"text": "大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。"}
{"text": "表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。"}
{"text": "从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。"}
{"text": "基于不同大规模知识图谱的系统间可能需要进行交互。"}
{"text": "一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。"}
{"text": "随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。"}
{"text": "总之，大规模知识图谱间的异构现象依然普遍存在。"}
{"text": "在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。"}
{"text": "大规模知识图谱匹配是极具挑战性的任务。"}
{"text": "Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。"}
{"text": "显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。"}
{"text": "传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。"}
{"text": "然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。"}
{"text": "在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。"}
{"text": "2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。"}
{"text": "由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。"}
{"text": "大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。"}
{"text": "1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。"}
{"text": "通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。"}
{"text": "当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。"}
{"text": "很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。"}
{"text": "因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。"}
{"text": "目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。"}
{"text": "因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。"}
{"text": "2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。"}
{"text": "为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。"}
{"text": "虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。"}
{"text": "此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。"}
{"text": "令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。"}
{"text": "因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。"}
{"text": "3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。"}
{"text": "此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。"}
{"text": "然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。"}
{"text": "最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。"}
{"text": "尽管目前能处理该问题的映射系统还较少，但一些研究者已进行了积极尝试，其中包括集成通用本体用于机器翻译[104]，建立Web_Directory之间的映射用于信息检索[105]，以及匹配生物医学领域的本体用于不同医学系统间信息交互[106-108]等。"}
{"text": "最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。"}
{"text": "本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。"}
{"text": "就目前来看，现有的大规模知识图谱匹配系统都能克服空间复杂度问题，因为匹配过程中需要的大量空间可以借助数据压缩技术（如将稀疏矩阵压缩存储）、外部数据库或临时文件等方式解决。"}
{"text": "因此，下面着重分析三类方法的时间复杂度。"}
{"text": "5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。"}
{"text": "基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。"}
{"text": "很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。"}
{"text": "大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。"}
{"text": "采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。"}
{"text": "首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。"}
{"text": "其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。"}
{"text": "Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。"}
{"text": "Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。"}
{"text": "此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。"}
{"text": "5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。"}
{"text": "但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。"}
{"text": "基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。"}
{"text": "上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。"}
{"text": "该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。"}
{"text": "具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。"}
{"text": "该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。"}
{"text": "在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。"}
{"text": "该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。"}
{"text": "图5-12基于规则挖掘的实例匹配过程[112]在进一步介绍该方法之前，需要定义一些基础概念。"}
{"text": "定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。"}
{"text": "URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。"}
{"text": "定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。"}
{"text": "如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。"}
{"text": "然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。"}
{"text": "重复迭代步骤直至满足终止条件。"}
{"text": "前面提到，该框架通过学习规则来推导实例之间的等价关系。"}
{"text": "首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。"}
{"text": "实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。"}
{"text": "（p（e,o）是三元组＜e,p,o＞的函数式表示，o1≃o2表示o1和o2指向同一实例或者字面值相等）。"}
{"text": "这样的规则可以推导出大量的等价实例，从而完成实例匹配。"}
{"text": "定义5.14（属性-值对等价）给定两个隐含等价属性（p1,p2）和两个值（o1,o2），属性-值对＜p1,o1＞和＜p2,o2＞等价当且仅当＜o1,o2＞∈～I（o1,o2为实例），或者o1=o2（o1,o2为字面值），记作～P。"}
{"text": "将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。"}
{"text": "定义5.15（等价属性-值对集）给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞），两个键值对集等价当且仅当存在一个从到的双射f∈～P，记作～S。"}
{"text": "定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。"}
{"text": "定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞,EIFPS规则有如下形式：根据以上定义，该方法实现了一个基于EM算法的实例匹配框架，输入为待匹配三元组、初始匹配对阈值，输出为匹配结果集与IFPS规则集。"}
{"text": "该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。"}
{"text": "这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。"}
{"text": "根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。"}
{"text": "EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。"}
{"text": "采用准确度优先策略，可以得到以下的近似公式，用精确度来代表在一个EIPFS规则集合下，提取出来的对应图和真正的对应图之间的关系：最后，求出的匹配图M的精确度等于M中被连接的成分除以M中边的数量：L（θ;M）≈Precision（M|θ）同一个匹配对可能会由不同的EIFPS规则导出，该匹配对有多个匹配置信度，因此集成两个置信度是一个很有必要的工作。"}
{"text": "传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。"}
{"text": "这里给出了另外的两种集成方式，具体如下：第1种是基于概率理论：conf1⊕conf2=1−（1−conf1）（1−conf2）第2种利用了一种特殊性形式下的贝叶斯理论的泛化理论（Dempster-Shafertheory）：该方法先后用在DBpedia、GeoNames、LinkedMDB、GeoSpecies等知识图谱间进行实例匹配。"}
{"text": "该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。"}
{"text": "5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。"}
{"text": "采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。"}
{"text": "由此可见，系统效率取决于能将原有问题划分为多少个小规模。"}
{"text": "最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。"}
{"text": "分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。"}
{"text": "Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。"}
{"text": "这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。"}
{"text": "本体模块化方法是对大规模本体进行划分的一种直观手段。"}
{"text": "已有多种本体模块化方法被提出。"}
{"text": "Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。"}
{"text": "然而，这种方法在实际应用中效果并不好。"}
{"text": "例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。"}
{"text": "Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。"}
{"text": "此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。"}
{"text": "Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。"}
{"text": "总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。"}
{"text": "特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。"}
{"text": "目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。"}
{"text": "Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。"}
{"text": "Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。"}
{"text": "Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。"}
{"text": "Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。"}
{"text": "Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。"}
{"text": "该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。"}
{"text": "接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。"}
{"text": "该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。"}
{"text": "Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。"}
{"text": "基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。"}
{"text": "一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。"}
{"text": "Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。"}
{"text": "Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。"}
{"text": "该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。"}
{"text": "1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。"}
{"text": "类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。"}
{"text": "图4-13实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。"}
{"text": "当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。"}
{"text": "基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。"}
{"text": "（1）远程监督方法。"}
{"text": "远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。"}
{"text": "远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。"}
{"text": "例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。"}
{"text": "因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。"}
{"text": "远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。"}
{"text": "但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。"}
{"text": "为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。"}
{"text": "最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。"}
{"text": "下面介绍两个具有代表性的模型。"}
{"text": "Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。"}
{"text": "模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。"}
{"text": "关系的分类是基于包特征上的Softmax分类器实现的。"}
{"text": "APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。"}
{"text": "实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。"}
{"text": "图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。"}
{"text": "针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。"}
{"text": "CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。"}
{"text": "样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。"}
{"text": "整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。"}
{"text": "在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。"}
{"text": "图4-15CNN-RL模型[15]（2）Bootstrapping方法。"}
{"text": "Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。"}
{"text": "通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。"}
{"text": "有很多实体关系抽取系统都采用了Bootstrapping方法。"}
{"text": "Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。"}
{"text": "Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。"}
{"text": "在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。"}
{"text": "Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。"}
{"text": "此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。"}
{"text": "例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。"}
{"text": "Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。"}
{"text": "但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。"}
{"text": "4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。"}
{"text": "事件的发生可能是因为一个动作的产生或者系统状态的改变。"}
{"text": "事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。"}
{"text": "一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。"}
{"text": "图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。"}
{"text": "1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。"}
{"text": "一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。"}
{"text": "判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。"}
{"text": "（2）元素分类器。"}
{"text": "判断词组是否为事件的元素。"}
{"text": "（3）元素角色分类器。"}
{"text": "判定事件元素的角色类别。"}
{"text": "（4）属性分类器。"}
{"text": "判定事件的属性。"}
{"text": "（5）可报告性分类器。"}
{"text": "判定是否存在值得报告的事件实例。"}
{"text": "表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。"}
{"text": "各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。"}
{"text": "表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。"}
{"text": "为了解决这一问题，一些研究工作提出了事件的联合抽取方法。"}
{"text": "在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。"}
{"text": "一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。"}
{"text": "联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。"}
{"text": "联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。"}
{"text": "具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。"}
{"text": "该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。"}
{"text": "在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。"}
{"text": "此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。"}
{"text": "为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。"}
{"text": "这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。"}
{"text": "联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。"}
{"text": "图4-17联合事件抽取方法图4-18事件触发词和事件元素示例图4-19事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。"}
{"text": "图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。"}
{"text": "该模型由YuboChen等人于2015年发表在ACL会议上[21]。"}
{"text": "模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。"}
{"text": "其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。"}
{"text": "在CNN方法的结果。"}
{"text": "ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。"}
{"text": "在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。"}
{"text": "W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。"}
{"text": "DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。"}
{"text": "4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。"}
{"text": "它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。"}
{"text": "直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。"}
{"text": "直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。"}
{"text": "下面给出一个简单的例子，解释直接映射的基本思路。"}
{"text": "首先，假设通过SQL语句创建图4-21中的两个数据库表。"}
{"text": "创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。"}
{"text": "主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。"}
{"text": "每列的谓词是由IRI前缀和表名、列名连接形成的IRI。"}
{"text": "这些值是从列值的词汇形式形成的RDF文字。"}
{"text": "每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。"}
{"text": "这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。"}
{"text": "直接映射不会为NULL值生成三元组。"}
{"text": "4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。"}
{"text": "这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。"}
{"text": "在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。"}
{"text": "然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。"}
{"text": "每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。"}
{"text": "R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。"}
{"text": "R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。"}
{"text": "一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。"}
{"text": "每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。"}
{"text": "“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。"}
{"text": "三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。"}
{"text": "主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。"}
{"text": "谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。"}
{"text": "图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。"}
{"text": "将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。"}
{"text": "用于创建R2RML视图的SQL语句如下所示。"}
{"text": "用于DEPT表数据转换的R2RML映射文档如下所示。"}
{"text": "此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。"}
{"text": "4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。"}
{"text": "这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。"}
{"text": "表4-3OBDA系统的主要特性对比（1）D2RQ[22]。"}
{"text": "D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。"}
{"text": "其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。"}
{"text": "D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。"}
{"text": "基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。"}
{"text": "此外，D2RQ系统还部分支持R2RML映射。"}
{"text": "（2）Mastro[23]。"}
{"text": "Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。"}
{"text": "Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。"}
{"text": "除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。"}
{"text": "图4-23D2RQ平台框架[22]图4-24Mastro系统结构[23]（3）Ultrawrap[24]。"}
{"text": "Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。"}
{"text": "其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。"}
{"text": "Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。"}
{"text": "图4-25Ultrawrap系统结构（4）Morph-RDB[25]。"}
{"text": "Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。"}
{"text": "Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。"}
{"text": "Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。"}
{"text": "（5）Ontop[26]。"}
{"text": "Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。"}
{"text": "Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。"}
{"text": "通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。"}
{"text": "Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。"}
{"text": "图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。"}
{"text": "自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。"}
{"text": "目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。"}
{"text": "4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。"}
{"text": "在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。"}
{"text": "图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。"}
{"text": "目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。"}
{"text": "在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。"}
{"text": "DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。"}
{"text": "得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。"}
{"text": "截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。"}
{"text": "此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。"}
{"text": "DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。"}
{"text": "根据抽样评测，DBpedia中RDF三元组的正确率达88%。"}
{"text": "图4-28所示为DBpedia知识抽取的总体框架。"}
{"text": "框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。"}
{"text": "图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。"}
{"text": "●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。"}
{"text": "信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。"}
{"text": "信息框的一般抽取直接将信息框中的信息转换为RDF三元组。"}
{"text": "三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。"}
{"text": "然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。"}
{"text": "图4-29信息框示例[27]4.4.2面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。"}
{"text": "从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。"}
{"text": "图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。"}
{"text": "包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。"}
{"text": "包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。"}
{"text": "图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。"}
{"text": "手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。"}
{"text": "XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。"}
{"text": "借助它可以获取网页中元素的位置，从而获取需要的信息。"}
{"text": "在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。"}
{"text": "分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。"}
{"text": "典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。"}
{"text": "（1）网页清洗。"}
{"text": "纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。"}
{"text": "（2）网页标注。"}
{"text": "在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。"}
{"text": "（3）包装器空间生成。"}
{"text": "基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。"}
{"text": "归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。"}
{"text": "（4）包装器评估。"}
{"text": "包装器可以通过准确率和召回率进行评估。"}
{"text": "使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。"}
{"text": "准确率和召回率越高，表示包装器的质量越好。"}
{"text": "3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。"}
{"text": "此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。"}
{"text": "自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。"}
{"text": "在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。"}
{"text": "在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。"}
{"text": "上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。"}
{"text": "表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。"}
{"text": "4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。"}
{"text": "实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。"}
{"text": "通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。"}
{"text": "实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。"}
{"text": "图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。"}
{"text": "该步骤主要通过命名实体识别技术或者词典匹配技术实现。"}
{"text": "命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。"}
{"text": "2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。"}
{"text": "例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。"}
{"text": "生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。"}
{"text": "某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。"}
{"text": "然后，可以利用这些扩展形式形成实体提及的候选实体集合。"}
{"text": "表层名字扩展可以采用启发式的模式匹配方法实现。"}
{"text": "例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。"}
{"text": "除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。"}
{"text": "（2）基于搜索引擎的方法。"}
{"text": "将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。"}
{"text": "例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。"}
{"text": "此外，维基百科自有的搜索功能也可以用于生成候选实体。"}
{"text": "（3）构建查询实体引用表。"}
{"text": "很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。"}
{"text": "实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。"}
{"text": "在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。"}
{"text": "维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。"}
{"text": "维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。"}
{"text": "表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。"}
{"text": "一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。"}
{"text": "下面介绍每类方法中具有代表性的工作。"}
{"text": "[32]（1）基于图的方法。"}
{"text": "基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。"}
{"text": "该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。"}
{"text": "Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。"}
{"text": "在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。"}
{"text": "最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。"}
{"text": "采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。"}
{"text": "图4-34参照图[33]（2）基于概率生成模型的方法。"}
{"text": "基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。"}
{"text": "在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。"}
{"text": "图4-35实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael_Jeffrey_Jordan]和[Michael_I.Jordan]；然后，模型依据给定实体e实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael_Jordan]；最后，模型依据给定实体e上下文的条件概率P（c|e）输出实体提及的上下文。"}
{"text": "根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。"}
{"text": "当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。"}
{"text": "基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。"}
{"text": "实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。"}
{"text": "首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。"}
{"text": "通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。"}
{"text": "图4-36实体-主题模型[37]（4）基于深度学习的方法。"}
{"text": "在候选实体消歧过程中，准确计算实体的相关度十分重要。"}
{"text": "因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。"}
{"text": "Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。"}
{"text": "在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。"}
{"text": "基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。"}
{"text": "图4-37实体提及生成过程示例[38]4.5.2知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive_Logic_Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。"}
{"text": "知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。"}
{"text": "给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。"}
{"text": "FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。"}
{"text": "下面通过一个例子介绍FOIL的规则学习过程。"}
{"text": "设有规则学习问题如表4-6所示。"}
{"text": "背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。"}
{"text": "FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。"}
{"text": "表4-7列出了FOIL学习单个规则的过程。"}
{"text": "当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。"}
{"text": "表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。"}
{"text": "在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。"}
{"text": "FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。"}
{"text": "基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。"}
{"text": "在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。"}
{"text": "多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。"}
{"text": "因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。"}
{"text": "最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。"}
{"text": "在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。"}
{"text": "2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。"}
{"text": "PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。"}
{"text": "如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。"}
{"text": "实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。"}
{"text": "在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。"}
{"text": "图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。"}
{"text": "因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。"}
{"text": "PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。"}
{"text": "为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。"}
{"text": "式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。"}
{"text": "PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。"}
{"text": "（2）特征计算。"}
{"text": "在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。"}
{"text": "给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"}
{"text": "通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。"}
{"text": "（3）关系分类。"}
{"text": "基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。"}
{"text": "利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。"}
{"text": "关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。"}
{"text": "PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。"}
{"text": "图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "该框架遵循Apache开源协议。"}
{"text": "4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。"}
{"text": "在具体应用中，可以选择使用因子图模型或神经网络模型。"}
{"text": "图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。"}
