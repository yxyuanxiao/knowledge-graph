input,subject,subject_type,relation,object,object_type
图4-13实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。,基于弱监督学习的关系抽取方法,,,基于监督学习的关系抽取方法,
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,,,只利用少量的标注数据进行模型学习,
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,,,weak supervision learning,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,远程监督方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,Bootstrapping方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,远程监督方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,Bootstrapping方法,
（1）远程监督方法。,远程监督方法,,,SPO三元组,
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督,,,非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力,
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督方法,,,remote supervision method,
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,,,基本假设,
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,,,remote supervision,
例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。,实体关系创始人,,,乔布斯，苹果公司,
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,,,一般步骤,
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,,,remote supervision relation extraction method,
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,,,利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量,
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,,,remote supervision relation extraction method,
但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。,语义漂移,,,基于远程监督的假设,
为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。,远程监督实体关系抽取方法,,,围绕如何克服训练数据中的噪声问题展开,
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,,,解决样例错误标注的问题,
下面介绍两个具有代表性的模型。,OWL_2_CR,,,OWL_2,
Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。,APCNNs,,,基于句子级注意力和实体描述的神经网络关系抽取模型,
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,,,模型,
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,,,Piecewise_Convolutional_Neural_Networks,
关系的分类是基于包特征上的Softmax分类器实现的。,基于包特征上的Softmax分类器,,,关系的分类,
关系的分类是基于包特征上的Softmax分类器实现的。,基于包特征上的Softmax分类器,,,based on the features of the package,
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,APCNNs模型,,,多示例学习,
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,多示例学习的策略,,,多示例学习的策略,
实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。,远程监督关系抽取,,,实验结果,
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,,,多示例学习策略,
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,,,多示例学习策略,
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,,,基于强化学习的关系分类模型,
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,,,基于强化学习的关系分类模型,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型,,,样例选择器,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型,,,关系分类器,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,样例选择器,,,example selector,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,关系分类器,,,relation classifier,
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,,,关系分类器从句子级特征对关系进行分类,
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,,,from sample to classify the relationship,
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,,,强化学习的方式,
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,,,基于一个随机策略,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,语义角色分类模型,,,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,句子级卷积神经网络,,,sentence-level convolution neural network,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,样例包级关系分类模型,,,example-level relation classification model,
图4-15CNN-RL模型[15]（2）Bootstrapping方法。,CNN-RL模型,,,Bootstrapping方法,
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping方法,,,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping,,,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中,
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping,,,从文本中抽取关系的大量实例,
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping,,,自底向上,
有很多实体关系抽取系统都采用了Bootstrapping方法。,实体关系抽取系统,,,Bootstrapping方法,
Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。,DIPER,,,Bootstrapping方法的系统,
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,,,Snowball关系抽取系统,
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,,,设计实现了Snowball关系抽取系统,
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,,,关系抽取,
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,,,自动评价新实例的可信度，并保留最可靠的实例加入种子集合,
Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。,KnowItAll,,,关系抽取,
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,基于Bootstrapping的系统,,,关系抽取,
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,基于Bootstrapping的系统,,,加入更合理的模板描述、限制条件和评分策略,
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,,,从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能,
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,,,NELL,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,关系抽取系统构建成本低,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,适合大规模的关系抽取任务,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,发现新关系的能力,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,对初始种子较为敏感,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,存在语义漂移问题,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,结果准确率较低,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping,,,自举,
4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。,事件,,,事件是指发生的事情,
事件的发生可能是因为一个动作的产生或者系统状态的改变。,事件的发生,,,一个动作的产生或者系统状态的改变,
事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。,事件抽取,,,从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,识别事件触发词及事件类型,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,抽取事件元素的同时判断其角色,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,抽出描述事件的词组或句子,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,事件属性标注,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,事件共指消解,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,event extraction,
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取方法,,,流水线方法,
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取方法,,,联合抽取方法,
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,,,基于分类的子任务,
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,,,pipeline method of event extraction,
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,分类器,,,事件触发词分类器,
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,事件触发词分类器,,,event trigger word classifier,
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,,,基于触发词信息对事件类别进行分类。,
（2）元素分类器。,元素分类器,,,概念/产品,
判断词组是否为事件的元素。,判断词组是否为事件的元素。,,,SPO三元组,
（3）元素角色分类器。,元素角色分类器,,,SPO三元组抽取,
判定事件元素的角色类别。,判定事件元素的角色类别。,,,概念/产品,
（4）属性分类器。,属性分类器,,,概念/产品,
判定事件的属性。,spo,,,判定事件的属性,
（5）可报告性分类器。,可报告性分类器,,,SPO三元组,
判定是否存在值得报告的事件实例。,报告事件实例的判定,,,存在值得报告的事件实例,
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类常用的分类特征,,,在事件抽取过程中,
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类常用的分类特征,,,分类特征,
各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。,各个阶段的分类器,,,机器学习算法中的不同分类器,
表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。,事件的联合抽取方法,,,事件抽取的流水线方法,
为了解决这一问题，一些研究工作提出了事件的联合抽取方法。,事件的联合抽取方法,,,研究工作提出,
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,,,事件的所有相关信息同时抽取出来,
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取方法,,,联合推断或联合建模的方法,
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取,,,联合推断或联合建模,
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,,,建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,,,联合推断,
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模,,,基于概率图模型进行联合建模获得事件抽取的总体结果,
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模,,,基于概率图模型进行联合建模,
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合建模方法,,,联合事件抽取模型,
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合建模方法,,,Qi_Li等人提出的联合事件抽取模型,
该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。,事件抽取,,,将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取,
在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。,袭击,,,Attack,
此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。,流水线方法,,,局部的分类器,
为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。,联合抽取模型,,,克服局部分类器的不足,
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,,,整体的结构中学习得到，从而使用全局的信息来提升局部的预测,
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,,,global feature,
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,联合抽取模型,,,结构预测问题,
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,集束搜索,,,bundle search,
图4-17联合事件抽取方法图4-18事件触发词和事件元素示例图4-19事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。,联合事件抽取方法,,,基于深度学习的方法被提出,
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,基于动态多池化卷积神经网络的事件抽取模型,,,基于动态多池化卷积神经网络的事件抽取模型,
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,YuboChen,,,EMNLP-2015,
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,YuboChen,,,YuboChen等人,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,词向量学习,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,词汇级特征抽取,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,句子级特征抽取,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,分类器输出,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词向量学习,,,无监督方式学习词的向量表示,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词汇级特征抽取,,,基于词的向量表示获取事件抽取相关的词汇线索,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,句子级特征抽取,,,动态多池化卷积神经网络获取句子的语义组合特征,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,分类器输出,,,产生事件元素的角色类别,
在CNN方法的结果。,CNN方法,,,抽取概念,
ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。,面向结构化数据的知识抽取,,,从数据库这种结构化数据中抽取知识,
在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。,标准,,,将数据库数据转化为RDF数据、OWL本体,
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,R2RML,,,W3C的RDB2RDF工作组于2012年发布的两个推荐的RDB2RDF映射语言,
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,R2RML,,,直接映射,
DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。,DM和R2ML映射语言,,,定义关系数据库中的数据如何转换为RDF数据的各种规则,
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,,,规范,
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,,,direct mapping,
它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。,SPARQL查询,,,实现RDF图或定义虚拟图,
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,,,关系数据库表结构和数据直接转换为RDF图,
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,,,direct mapping,
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射的基本规则,,,直接映射的五大基本规则,
下面给出一个简单的例子，解释直接映射的基本思路。,直接映射,,,概念/产品,
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL创建表,,,通过SQL语句创建图4-21中的两个数据库表,
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL语句,,,创建图4-21中的两个数据库表,
"创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。",基于直接映射标准,,,based on direct mapping standard,
"创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。",People表,,,数据库表,
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,,,IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,,,subject,
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,谓词,,,IRI前缀和表名、列名连接形成,
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,谓词,,,IRI前缀和表名、列名连接形成的IRI,
这些值是从列值的词汇形式形成的RDF文字。,列值的词汇形式形成的RDF文字,,,属于RDF文字,
这些值是从列值的词汇形式形成的RDF文字。,列值的词汇形式形成的RDF文字,,,RDF文字,
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,三元组,,,会生成一个三元组,
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,三元组,,,一个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,被引用三元组的行标识符,,,宾语,
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,宾语,,,被引用三元组的行标识符（例如<Addresses/ID=18>）。,
直接映射不会为NULL值生成三元组。,直接映射,,,为NULL值生成三元组,
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML映射语言,,,用于表示从关系数据库到RDF数据集的自定义映射的语言,
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML,,,R2RML映射语言,
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,OWL_ONR,,,在RDF数据模型下查看现有关系型数据的能力,
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,映射,,,map,
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,RDF图,,,数据库的直接映射,
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,数据库的直接映射,,,direct mapping of database,
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,,,关系数据定制视图,
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,,,在关系数据上灵活定制视图,
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,R2RML映射,,,针对特定的数据库模式和目标词汇量身定制,
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,,,关系数据库,
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,,,R2RML mapping,
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,R2RML映射,,,逻辑表（Logic_Tables）从数据库中检索数据,
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,逻辑表,,,Logic_Tables,
一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。,一个逻辑表,,,数据库中的一个表、视图或有效的SQL语句查询,
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,三元组映射,,,将逻辑表中每一行映射为若干RDF三元组的规则,
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,三元组映射,,,Triples_Map,
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,“逻辑表”,,,为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础,
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,“逻辑表”,,,logical table,
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射的规则,,,主语映射和多个谓词-宾语映射,
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射的规则,,,一个主语映射和多个谓词-宾语映射,
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,,,基于数据库表中的主键生成RDF三元组中的主语,
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,,,from logical table generate all RDF triples of subject,
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,,,谓词映射和宾语映射,
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,,,predicate-object mapping,
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,图4-22中给出的一个示例数据库,,,两个表,
将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。,R2RML视图,,,将上述数据库映射为RDF数据,
将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。,R2RML,,,将上述数据库映射为RDF数据,
用于创建R2RML视图的SQL语句如下所示。,创建R2RML视图的SQL语句,,,用于创建R2RML视图的SQL语句,
用于DEPT表数据转换的R2RML映射文档如下所示。,R2RML映射文档,,,用于DEPT表数据转换,
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,EMP,,,将EMP和DEPT表进行连接,
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,等价,,,等价,
"4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。",SPARQL,,,基于本体的数据库访问,
"4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。",SPARQL,,,"Ontology_Based_Database_Access,OBDA",
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA系统,,,表4-3列出了这些系统的主要特性,
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,,,Ontology-based Data Access,
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,,,OBDA系统的主要特性对比,
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,,,数据到资源的查询,
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,,,较早开发和发布的OBDA系统,
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,,,较早开发和发布的OBDA系统,
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,,,HTTP_Server,
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,,,等价,
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,,,可定制的D2RQ映射文件,
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,,,D2R Server,
基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。,基于D2RQ映射,,,Web端的请求重写为SQL查询,
此外，D2RQ系统还部分支持R2RML映射。,D2RQ系统,,,支持R2RML映射,
（2）Mastro[23]。,Mastro,,,SPO三元组,
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,,,基于Java语言开发的OBDA系统,
Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。,Mastro数据源管理器,,,支持与最流行的商业和非商业DBMS的交互。,
除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。,Elasticsearch,,,为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持,
图4-23D2RQ平台框架[22]图4-24Mastro系统结构[23]（3）Ultrawrap[24]。,D2RQ平台,,,图4-23D2RQ平台框架,
Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。,Ultrawrap,,,商业化系统,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,,,建立数据库到RDF和OWL的映射,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,,,建立数据库到RDF和OWL的映射,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,服务器,,,在数据库上执行SPARQL查询,
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,,,执行SPARQL查询,
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,,,执行SPARQL查询,
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,,,Ultrawrap系统结构（4）,
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,,,Ultrawrap,
Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。,Morph-RDB,,,R2RML规范,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,,,数据升级,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,,,查询转换,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,数据升级,,,data upgrade,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,查询转换,,,SPARQL to SQL,
Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。,Morph-RDB,,,各种优化技术来生成高效的SQL查询,
（5）Ontop[26]。,Ontop,,,SPO三元组抽取,
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,,,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具,
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,,,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具,
Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。,Ontop,,,基于Apache许可证的开源工具,
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,,,将本体中的词汇（类和属性）通过映射链接到数据源,
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,,,将本体中的词汇通过映射链接到数据源,
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,,,R2RML映射,
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,,,支持R2RML映射,
图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。,Ontop,,,系统结构,
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,半结构化数据,,,知识获取的来源,
目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。,面向此类数据的知识抽取方法,,,知识获取,
4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。,面向百科类数据的知识抽取,,,维基百科为代表的百科类数据,
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,词条页面,,,半结构化数据,
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,维基百科词条页面结构,,,构建大规模知识图谱的重要数据来源,
目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。,知识图谱,,,基于维基百科,
在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。,基于百科数据构建知识图谱,,,从百科数据中抽取结构化语义信息,
DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。,DBpedia,,,维基百科的机构化版本,
得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。,DBpedia,,,知识图谱,
截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。,DBpedia英文版,,,一个本体中进行分类,
截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。,DBpedia英文版,,,DBpedia English,
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,,,DBpedia数据集,
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,,,DBpedia,
DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。,DBpedia,,,DBpedia,
根据抽样评测，DBpedia中RDF三元组的正确率达88%。,DBpedia中RDF三元组的正确率,,,抽样评测,
图4-28所示为DBpedia知识抽取的总体框架。,DBpedia知识抽取,,,知识抽取的总体框架,
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架的主要组成部分,,,页面集合、目标数据、提取器、解析器、提取作业、知识提取管理器,
图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。,标签,,,Labels,
图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。,摘要,,,Abstracts,
●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。,信息框,,,从词条页面的信息框中抽取实体的结构化信息,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,一般抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,基于映射的抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,一般抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,基于映射的抽取,
信息框的一般抽取直接将信息框中的信息转换为RDF三元组。,信息框的一般抽取,,,将信息框中的信息转换为RDF三元组,
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,三元组,,,subject,
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,主语,,,主语,
然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。,抽取方式,,,等价处理属性名和信息框模板同义异名问题,
图4-29信息框示例[27]4.4.2面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。,信息框,,,面向Web网页的知识抽取,
从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。,信息的获取,,,HTML中的标记区分,
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,,,从网页中获取结构化信息,
包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。,包装器,,,能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,手工方法,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,包装器归纳方法,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,自动抽取方法,
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,基于包装器抽取网页信息的框架,,,手工方法,
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,基于包装器抽取网页信息的框架,,,基于包装器抽取网页信息的框架,
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法的抽取,,,查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式,
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法,,,manual method,
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,,,XML路径语言,
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,,,XML路径语言,
借助它可以获取网页中元素的位置，从而获取需要的信息。,spo,,,概念/产品,
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,CSS选择器,,,通过CSS元素实现对网页中元素的定位，并获取元素信息,
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,CSS选择器,,,CSS元素,
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,包装器归纳方法,,,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法,
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,包装器归纳方法,,,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取,
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,典型的包装器归纳流程,,,网页清洗、网页标注、包装器空间生成、包装器评估,
（1）网页清洗。,网页清洗,,,信息检索中概念的五大用途,
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,TIDY,,,纠正和清理网页不规范的HTML、XML标记,
（2）网页标注。,网页标注,,,SPO三元组,
在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。,标注,,,给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据,
（3）包装器空间生成。,包装器空间生成,,,SPO三元组,
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,,,归纳形成若干个子集,
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,,,基于标注的数据生成XPath集合空间,
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,,,使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,,,induction,
（4）包装器评估。,包装器评估,,,SPO三元组,
包装器可以通过准确率和召回率进行评估。,包装器,,,评估,
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,,,评估包装器性能,
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,,,计算包装器输出标注的相同项的数量除以包装器输出标注的总数量,
准确率和召回率越高，表示包装器的质量越好。,准确率,,,包装器的质量,
准确率和召回率越高，表示包装器的质量越好。,准确率,,,precision,
准确率和召回率越高，表示包装器的质量越好。,召回率,,,recall,
3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。,自动抽取方法包装器,,,归纳方法,
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,包装器,,,维护工作量,
自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。,自动抽取方法,,,不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题,
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,相似的网页,,,相似的网页首先通过聚类被分成若干组,
在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。,应用包装器,,,数据抽取,
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,表4-5,,,信息抽取方法的对比,
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,信息抽取,,,information extraction,
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识内容挖掘,,,知识内容挖掘,
4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。,实体链接,,,知识内容挖掘,
4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。,实体链接,,,entity linking,
实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。,实体链接,,,将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础,
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,实体链接,,,通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接,
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,实体链接,,,entity link,
实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。,实体链接,,,entity linking,
图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。,实体链接,,,实体指称识别,
图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。,实体链接,,,entity linking,
该步骤主要通过命名实体识别技术或者词典匹配技术实现。,命名实体识别技术,,,属于中文信息处理,
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,,,本章前面已经介绍过,
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,,,命名实体识别技术,
2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。,候选实体生成,,,确定文本中的实体指称可能指向的实体集合,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,知识库中的多个实体,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,entity designation,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,entities,
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,生成实体指称的候选实体,,,表层名字扩展,
某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,表层名字扩展技术,,,从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,
某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,表层名字扩展技术,,,从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）,
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,扩展形式,,,实体提及的候选实体集合,
表层名字扩展可以采用启发式的模式匹配方法实现。,表层名字扩展,,,启发式的模式匹配方法实现,
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,,,提取实体提及邻近括号中的缩写作为扩展结果,
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,,,提取实体提及邻近括号中的缩写作为扩展结果,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,从文本中抽取复杂的实体名称缩写,,,有监督学习的技术,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,模式匹配,,,模式匹配,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,有监督学习的技术,,,从文本中抽取复杂的实体名称缩写,
（2）基于搜索引擎的方法。,基于搜索引擎的方法,,,基于搜索引擎的SPO三元组抽取方法,
将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。,搜索引擎,,,将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体,
例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。,实体指称,,,搜索关键词提交至谷歌搜索引擎并将其返回结果中的维基百科页面作为候选实体,
此外，维基百科自有的搜索功能也可以用于生成候选实体。,维基百科自有的搜索功能,,,生成候选实体,
（3）构建查询实体引用表。,查询实体引用表,,,构建,
很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。,实体链接系统,,,基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系,
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用,,,键-值,
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用,,,entity reference,
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,引用表,,,从表中获得其候选实体,
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,实体提及,,,title of a wiki article page,
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,,,提取实体和实体提及的对应关系,
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,候选实体消歧,,,为每一个实体指称确定其指向的实体,
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,候选实体消歧,,,candidate entity disambiguation,
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,,,排序问题,
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,,,排序问题进行求解,
下面介绍每类方法中具有代表性的工作。,每类方法中具有代表性的工作,,,介绍每类方法中具有代表性的工作,
[32]（1）基于图的方法。,基于图的方法,,,基于图的数据挖掘方法,
基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。,基于图的方法,,,将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理,
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图（Referent_Graph）协同实体链接方法,,,Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法,
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图（Referent_Graph）协同实体链接方法,,,基于参照图协同实体链接方法,
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,实体提及,,,entity mention,
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,实体,,,entity,
在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。,Han_PageRank算法,,,实体消歧的初始依据并在参照图上进行传递,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧目标函数,,,基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧目标函数,,,entity disambiguation target function,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,目标实体,,,entity disambiguation result,
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,实体链接系统,,,基于图的方法进行候选实体消歧的实体链接系统,
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,实体链接系统,,,基于图的方法进行候选实体消歧的实体链接系统,
图4-34参照图[33]（2）基于概率生成模型的方法。,基于概率生成模型的方法,,,基于概率生成模型的问答系统,
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型,,,实体提及和实体的联合概率进行建模,
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型,,,based on probability generation model,
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,,,entity-mention probability generation model,
图4-35实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael_Jeffrey_Jordan]和[Michael_I.Jordan]；然后，模型依据给定实体e实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael_Jordan]；最后，模型依据给定实体e上下文的条件概率P（c|e）输出实体提及的上下文。,实体提及的名称,,,实体提及,
"根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。",实体联合概率,,,"P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）",
当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。,候选实体消歧,,,基于主题模型的方法,
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,,,对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果,
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,,,entity-topic model,
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,,,生成关于主题、实体名称和实体上下文的全局知识,
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,,,entity-topic model,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,E维狄利克雷分布抽样,,,基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,K维狄利克雷分布抽样,,,基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,V维狄利克雷分布抽样,,,基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,E维狄利克雷分布抽样,,,得到每个主题z中实体的分布φz,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,K维狄利克雷分布抽样,,,每个实体e名称的分布ψe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,V维狄利克雷分布抽样,,,实体e上下文词的分布ξe,
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,实体-主题模型,,,推断获得实体消歧所需的决策信息,
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,吉布斯抽样算法,,,吉布斯抽样,
图4-36实体-主题模型[37]（4）基于深度学习的方法。,实体-主题模型,,,基于深度学习的方法,
在候选实体消歧过程中，准确计算实体的相关度十分重要。,准确计算实体的相关度,,,候选实体消歧过程,
因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,评价实体与实体的相关度,,,在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,
Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。,实体语义相关度计算模型,,,基于深度神经网络的实体语义相关度计算模型,
在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。,实体E,,,输入层,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,语义层上实体的表示,,,经过词散列层进行降维，然后经过多层神经网络的非线性变换,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,两个实体的相关度,,,它们语义层表示向量的余弦相似度,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入,,,词散列层进行降维,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入,,,多层神经网络的非线性变换,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,语义层上实体的表示,,,语义层上实体的表示,
"图4-37实体提及生成过程示例[38]4.5.2知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive_Logic_Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。",归纳逻辑程序设计,,,"Inductive_Logic_Programming,ILP",
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,实体关系,,,二元谓词描述的事实,
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,实体关系,,,二元谓词描述的事实,
"给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。",ILP系统,,,学习获得描述目标谓词的逻辑规则集合,
FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。,FOIL,,,早期具有代表性的ILP系统,
下面通过一个例子介绍FOIL的规则学习过程。,FOIL的规则学习过程,,,例子介绍FOIL的规则学习过程,
设有规则学习问题如表4-6所示。,规则学习,,,设有规则学习问题,
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,背景知识,,,描述某一家庭的成员关系,
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,等价,,,等价,
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,,,规则学习,
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,,,FOIL,
表4-7列出了FOIL学习单个规则的过程。,FOIL学习单个规则的过程,,,表4-7,
表4-7列出了FOIL学习单个规则的过程。,FOIL,,,Fact-Only-If-Else-Last,
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,,,概念/规则覆盖正例,
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,,,"Factoid, Opinion, Instance, and Label",
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,FOIL,,,规则学习问题,
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,等价,,,等价,
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,,,扩展规则体的每一步,
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,,,FOIL_Gain,
FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。,FOIL_Gain,,,形式等同的增益,
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL_Gain评价函数,,,基于FOIL_Gain评价函数,
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL,,,基于FOIL_Gain评价函数,
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,Progol,,,早期的ILP系统,
多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。,ILP系统,,,小规模的数据集,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,FOIL-D,,,FOIL-D,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,PILP,,,PILP,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,QuickFOIL,,,QuickFOIL,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,分布式并行的ILP系统,,,分布式并行的ILP系统,
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,,,关联规则挖掘的方法,
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,,,关联规则挖掘的方法,
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE+,,,发布者发布的升级系统,
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE+,,,AMIE的升级系统,
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",PRA,,,将关系路径作为特征的知识图谱链接预测算法,
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",路径排序算法,,,PRA,
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,,,通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系,
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,,,概念/产品,
"如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。",HinesWard,,,NFL,
"如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。",等价,,,等价,
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,关系路径,,,常识知识,
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,等价,,,equivalence,
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,,,自动发现有用的关系路径来构建预测模型,
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,图4-38示例知识图谱子图,,,图4-38,
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,图4-38示例知识图谱子图,,,图4-38示例知识图谱子图,
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径,,,连接特定实体对,
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径,,,connection specific entity pairs,
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,,,连接实体对的特征选择,
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,,,概念/产品,
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,,,基于随机游走计算路径准确度和覆盖度,
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,,,基于随机游走特征选择方法,
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,P（si→Gi;π）,,,随机游走能够抵达目标实体的概率,
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,P（si→Gi;π）,,,以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,PRA,,,准确度和覆盖度,
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,等价,,,equal,
（2）特征计算。,特征计算,,,SPO三元组,
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,PRA,,,为每个实体对计算其特征值,
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,等价,,,equivalence,
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,,,从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值,
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,,,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,实体对,,,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值,
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,实体对在每个特征关系路径上的可达概率,,,entities'probability on each feature relation path,
（3）关系分类。,SPO三元组,,,关系分类,
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,,,为每个目标关系训练一个分类模型,
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,,,基于训练样例和它们的特征为每个目标关系训练一个分类模型,
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,利用训练完的模型,,,预测知识图谱中任意两个实体间是否存在某特定关系,
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,预测知识图谱中任意两个实体间是否存在某特定关系,,,利用训练完的模型,
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,PRA,,,逻辑回归分类模型,
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,关系分类,,,任何一种分类模型,
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,,,训练逻辑回归模型的过程,
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,,,概率回归分析,
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,PRA,,,在NELL数据集上进行链接预测时获得的重要关系路径和相应解释,
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,本实践,,,OpenKG,
该框架遵循Apache开源协议。,OWL_2_QRL,,,Apache开源协议,
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,,,DeepDive,
在具体应用中，可以选择使用因子图模型或神经网络模型。,因子图模型,,,具体应用,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,文件名,,,file_name,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,命令,,,command,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,脚本文件,,,script_file,