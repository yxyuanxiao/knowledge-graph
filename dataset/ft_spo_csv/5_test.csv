input,subject,subject_type,relation,object,object_type
根据使用技术的不同，下面分别介绍一些典型的本体映射工作。,本体映射工作,,,使用技术的不同,
很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。,映射发现技术,,,map discovery technique,
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语的映射发现方法,,,基于结构的映射发现方法,
此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。,基于术语的映射发现方法,,,based on term,
1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。,基于术语和结构的本体映射,,,寻找本体映射是比较直观和基础的方法。,
1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。,本体中术语和结构的相似性,,,基于术语和结构的本体映射,
这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。,本论文所介绍的方法,,,介绍这种方法的思想，然后探讨一些典型和相关的工作。,
（1）技术综述1）基于术语的本体映射技术。,基于术语的本体映射技术,,,技术综述,
这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。,本体映射方法,,,比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。,
这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。,本体映射方法,,,比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性,
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,,,基于字符串的方法,
比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。,比较本体间的术语的方法,,,基于语言的方法,
①基于字符串的方法。,基于字符串的方法,,,基于概念/产品,
基于字符串的方法直接比较表示本体成分的术语的字符串结构。,基于字符串的方法,,,直接比较表示本体成分的术语的字符串结构,
主要的字符串比较技术如下。,主要的字符串比较技术,,,字符串比较技术,
（a）规范化。,规范化,,,概念/产品,
在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。,字符串比较,,,严格字符串比较之前对字符串进行规范化,
这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。,规范化操作,,,拉丁语系,
（b）相似度量方法。,相似度量方法,,,概念/产品,
在规范字符串的基础上，能进一步度量不同字符串间的相似程度。,相似度量,,,规范字符串,
常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。,编辑距离,,,常用的字符串度量方法,
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",相似度,,,如果两个字符串完全相同,
"如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。",相似度,,,similarity,
一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。,汉明距离,,,比较两个字符串的直接方法,
定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。,汉明距离相似度,,,对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为,
定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。,汉明距离相似度,,,hamming distance similarity,
定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。,任意两字符串s和t,,,称t是s的子串或s是t的子串,
定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。,子串,,,sub-string,
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,子串相似度,,,精确度量两字符串包含共同部分的比例,
还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。,子串相似度,,,substring similarity,
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,子串相似度度量,,,任意两个字符串s和t间的相似度δ,
定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。,子串相似度,,,子串相似度的度量,
两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。,编辑距离,,,修改其中一个使之与另一个相同所需要的最小操作代价,
这些编辑操作包括插入、删除和替代字符。,编辑操作,,,插入、删除和替代字符,
显然，编辑距离越大，表示两字符串的相似程度越小。,编辑距离,,,相似程度,
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,,,判断字符串间相似度的指标,
编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。,编辑距离,,,edit distance,
除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。,比较单个术语的字符串相似,,,考虑与之相关的一系列的字符串,
路径比较便是这类方法中的一种。,路径比较,,,方法,
"定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。",路径距离,,,给定两个字符串序列和，它们之间的路径距离计算,
"定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。",路径距离,,,path distance,
②基于语言的方法。,基于语言的方法,,,概念/产品,
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,,,寻找概念或关系之间的联系,
基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。,基于语言的方法,,,自然语言处理技术,
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,内部方法,,,方法,
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,内部方法,,,内部属性,
这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。,外部方法,,,外部的资源,
内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。,内部方法,,,寻找术语间的映射,
它寻找同一字符串的不同语言形态，如Apple和Apples等。,概念/中文分词,,,属于,
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,Porter_M_F,,,寻找词形变化的算法,
寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。,Porter_M_F,,,Stemming算法,
外部方法利用词典等外部资源来寻找映射。,外部概念,,,利用词典等外部资源来寻找映射,
基于词典的方法使用外部词典匹配语义相关的术语。,基于词典的方法,,,使用外部词典匹配语义相关的术语,
例如，使用WordNet能判断两个术语是否有同义或上下义关系。,WordNet,,,判断两个术语是否有同义或上下义关系,
尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。,基于术语的相似度度量方法,,,很难得到比较好的映射结果,
尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。,基于术语的相似度度量方法,,,基于术语的相似度度量方法,
2）基于结构的本体映射技术。,基于结构的本体映射技术,,,基于结构的本体映射技术,
在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。,本体对比,,,寻找映射的过程,
基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。,基于结构的方法,,,内部结构,
基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。,基于结构的方法,,,外部结构,
基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。,内部结构,,,内部结构的等价,
①内部结构。,内部结构,,,SPO三元组,
基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。,基于内部结构的方法,,,计算本体成分之间的相似度,
基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。,基于内部结构的方法,,,基于内部结构的方法,
通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。,相似度,,,具有相同属性或者属性的数据类型相同的概念,
通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。,相似度,,,similarity,
②外部结构。,外部结构,,,SPO三元组,
比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。,比较两本体的成分之间的相似,,,考虑与它们相关的外部结构,
比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。,比较两本体的成分之间的相似,,,compare the similarity between the components of two ontologies,
比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。,考虑与它们相关的外部结构,,,consider the external structure related to them,
从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。,本体外部结构上判断本体成分的相似,,,人们在本体使用过程中所获得的一些经验,
有一些常用来判断本体成分相似的准则，这些准则包括：(C1)直接超类或所有的超类相似；(C2)兄弟相似；(C3)直接子类或所有的子类相似；(C4)所有或大部分后继（不一定是子类，可能通过其他关系连接）相似；(C5)所有或大部分的叶子成分相似；(C6)从根节点到当前节点的路径上的实体都相似。,等价,,,equivalence,
有一些常用来判断本体成分相似的准则，这些准则包括：(C1)直接超类或所有的超类相似；(C2)兄弟相似；(C3)直接子类或所有的子类相似；(C4)所有或大部分后继（不一定是子类，可能通过其他关系连接）相似；(C5)所有或大部分的叶子成分相似；(C6)从根节点到当前节点的路径上的实体都相似。,英文名,,,equivalence,
对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。,本体成分之间的关系,,,特定的方法来判断结构上的相似,
对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。,本体成分之间的关系,,,特定的方法来判断结构上的相似,
计算概念之间的相似也可以考虑它们之间的关系。,计算概念之间的相似,,,考虑它们之间的关系,
如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。,概念A和B通过关系R建立联系,,,推出概念A和A’也相似,
如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。,概念A,,,相似,
如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。,概念B,,,B和B’以及R和R’分别相似,
然而，这种方法的问题在于如何判断关系的相似性。,SPO,,,判断关系的相似性,
关系的相似性计算一直是一个很困难的问题。,关系的相似性计算,,,一个很困难的问题,
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,外部结构的方法,,,无法解决由于本体建模的观点不同而造成的异构,
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,本体O1,,,特化两个子类Man和Woman,
外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。,本体O2,,,划分为Adult和Young_Person,
基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。,基于结构的方法,,,难以解决这种不同划分下的子类之间的相似度问题,
（2）方法和工具1）AnchorPROMPT。,AnchorPROMPT,,,方法和工具,
除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。,本体映射,,,其他工具,
除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。,本体映射,,,ontology mapping,
PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。,PROMPT,,,工具,
PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。,PROMPT,,,等价,
目前，PROMPT的这些工具已集成到Protégé系统中。,PROMPT,,,Protégé系统,
本体映射是解决很多多本体问题的基础。,本体映射,,,解决很多多本体问题的基础,
"为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。",SMART,,,相似性比较,
AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。,AnchorPROMPT算法,,,扩展SMART而得到的,
AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。,AnchorPROMPT,,,SAMRT,
①AnchorPROMPT的思想。,AnchorPROMPT,,,概念/产品,
AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。,AnchorPROMPT,,,在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分,
AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。,AnchorPROMPT,,,相关术语对的集合,
术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。,术语对,,,iPROMPT工具,
AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。,AnchorPROMPT算法,,,根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对,
AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。,AnchorPROMPT,,,根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对,
AnchorPROMPT将每个本体O视为一个带边有向图G。,AnchorPROMPT,,,将每个本体O视为一个带边有向图G,
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,O,,,三元组抽取,
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,等价,,,equivalence,
O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。,英文名,,,equivalence,
图中通过一条边连接的两节点称为相邻节点。,相邻节点,,,一条边连接的两节点,
如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。,路径,,,从节点A出发，经过一系列边能到达节点B,
路径的长度是边的数目。,路径的长度,,,边的数目,
为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。,AnchorPROMPT,,,遍历异构本体中由“锚”限定的对应路径,
为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。,AnchorPROMPT,,,为发现新的语义相关术语对,
AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。,AnchorPROMPT,,,沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。,
因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。,AnchorPROMPT算法,,,产生本体间大量可能的语义相似术语对,
因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。,AnchorPROMPT算法,,,产生本体间大量可能的语义相似术语对,
②AnchorPROMPT算法。,AnchorPROMPT算法,,,属于概念/产品,
为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。,AnchorPROMPT,,,说明AnchorPROMPT的工作原理,
"对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。",本体,,,输入的初始相关术语对,
"对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。",等价,,,等价,
这样的术语对利用基本的术语比较技术能很容易识别出来。,基本的术语比较技术,,,利用这样的术语对,
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,算法,,,寻找到相关术语对之间的路径集合,
根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。,算法,,,algorithm,
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,,,本体O1,
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,,,本体O2,
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,,,本体O2,
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,TRIAL,,,试验,
对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。,PERSON,,,个人,
在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。,路径长度限制,,,预先定义路径长度,
在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。,路径长度,,,limit the total number of paths,
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path1,,,O1,
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path1,,,TRIAL→PROTOCOL→STUDY-SITE→PERSON,
图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。,Path2,,,Trial→Design→Blinding→Person,
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,,,增加路径中同一位置的一对术语的相似度分数,
当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。,AnchorPROMPT,,,增加路径中同一位置的一对术语的相似度分数,
"在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。",PROTOCOL,,,概念对,
"在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。",概念对,,,"(PROTOCOL,Design)",
"在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。",概念对,,,"(STUDY-SITE,Blinding)",
AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。,AnchorPROMPT算法,,,并行遍历相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数,
AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。,AnchorPROMPT算法,,,并行遍历相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数,
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,相似度分数,,,经常出现在相同位置的术语对,
结果，经常出现在相同位置的术语对间的相似度分数往往最高。,相似度分数,,,similarity score,
（a）等价组。,等价组,,,概念/产品,
在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。,AnchorPROMPT,,,区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系,
在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。,AnchorPROMPT,,,区别对待连接概念间的继关系和普通关系同样看待,
与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。,Is-a,,,已经相似的概念,
与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。,等价,,,Is-a,
AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。,AnchorPROMPT算法,,,将这种通过Is-a关系连接的概念作为一个等价组看待,
等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。,等价组,,,equivalence group,
图5-5路径中的等价组（b）相似度分数。,等价组（b）相似度分数,,,路径中的等价组,
"给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。","S(C1,C2)",,,"计算它们之间相似度分数S(C1,C2)的过程如下",
"给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。",等价,,,"相似度分数S(C1,C2)",
步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。,等长路径对的集合,,,从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2,
步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。,等价,,,equivalence,
步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。,相似度分,,,为节点中的所有概念对之间的相似度分加上一个常数X,
步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。,相似度分,,,similarity score,
"如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。",相似度分数,,,反映C1和C2出现在路径中的相同位置的频繁程度,
"如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。",相似度分数,,,"S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度",
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,增加相似度分数,,,进行比较的节点包含等价组时增加相似度分数的情况有所不同,
当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。,增加相似度分数,,,等价组,
这个问题在接下来的部分进行分析。,这个问题,,,分析,
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,AnchorPROMPT,,,生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,
根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。,相似分数较低的术语对,,,去除一些相似分数较低的术语对,
③AnchorPROMPT评估。,AnchorPROMPT,,,评估,
Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。,AnchorPROMPT,,,Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验,
（a）等价组大小。,等价组大小,,,概念/产品,
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,等价组大小最大值,,,0,
试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。,等价组大小最大值,,,1,
当等价组的最大尺寸为2时，只有12%的试验没有结果。,等价组,,,只有12%的试验没有结果,
当等价组的最大尺寸为2时，只有12%的试验没有结果。,等价组的最大尺寸,,,2,
因此，在随后的试验中设定等价组的最大尺寸大小为2。,等价组,,,设定等价组的最大尺寸大小为2,
因此，在随后的试验中设定等价组的最大尺寸大小为2。,等价组,,,equivalence group,
（b）等价组成员的相似度分数。,等价组成员的相似度分数,,,属于等价组成员的相似度分数,
（b）等价组成员的相似度分数。,等价组成员的相似度分数,,,equivalence group members similarity score,
为评价等价组成员如何打分合理而做了两类试验。,为评价等价组成员如何打分合理而做的两类试验。,,,为评价等价组成员如何打分合理而做的两类试验的用途,
第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。,等价组中的成员,,,第二类试验中为等价组中的成员只加X/3或X/2的分数不等,
第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。,等价组,,,equivalence group,
试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。,对等价组成员打分不同,,,结果的准确率提高14%,
（c）锚的数目和路径最大长度。,锚,,,属于锚的数目和路径最大长度,
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,输入的锚数量越多和规定的最大路径长度越大,,,得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长,
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,输入的锚数量,,,锚数量越多,
在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。,规定的最大路径长度,,,规定的最大路径长度越大,
试验表明，当最大长度路径设为2时，能获得最好的正确率。,最大长度路径,,,获得最好的正确率,
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,限制路径最大长度,,,平均正确率,
当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。,限制路径最大长度,,,max length,
④AnchorPROMPT的讨论。,AnchorPROMPT的讨论。,,,SPO三元组,
当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。,S,,,AnchorPROMPT算法考虑路径长度为1时连接A和B的关系,
当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。,AnchorPROMPT,,,考虑路径长度为1时，如果概念A和A’相似以及B和B’相似,
以此类推，可以得到路径上更多的关系对也是相似的。,关系对,,,可以得到路径上更多的关系对也是相似的。,
以此类推，可以得到路径上更多的关系对也是相似的。,关系对,,,等价,
实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。,AnchorPROMPT,,,基于这样的假设：本体中相似的术语通常也通过相似的关系连接,
在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。,生成结果的精度,,,假设的缺陷,
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径长度,,,只使用术语比较技术的iPROMPT,
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径长度,,,path length,
而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。,路径上不包含任何的术语对,,,路径上不包含任何的术语对,
AnchorPROMPT其他方面的讨论如下。,AnchorPROMPT,,,其他方面的讨论如下。,
（a）减少负面结果的影响。,SPO,,,减少负面结果的影响。,
概念间的相似度分数是一个累加值。,概念间的相似度分数,,,累加值,
概念间的相似度分数是一个累加值。,概念间的相似度分数,,,equivalent value,
两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。,两个不相关的术语,,,出现在某一对路径的相同位置,
两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。,两个不相关的术语,,,appear in the same position of different paths,
AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。,AnchorPROMPT,,,消除负面结果的影响,
AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。,AnchorPROMPT,,,累加遍历所有路径过程中对应概念对的相似度分数,
试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。,相似度分数的阈值,,,去掉相似度分数小于阈值的术语对,
试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。,AnchorPROMPT,,,去除大多数的这类术语对,
（b）执行本体映射。,本体映射,,,概念/产品,
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,AnchorPROMPT,,,建立术语之间的映射,
AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。,AnchorPROMPT,,,本体合并工具（如iPROMPT）或其他的本体应用直接使用,
（c）局限性。,局限性,,,SPO三元组,
AnchorPROMPT的映射发现方法并非适用于所有的本体。,AnchorPROMPT的映射发现方法,,,不适用于所有的本体,
当两个本体间的结构差别很大时，该方法处理的效果并不好。,本体间结构差别很大的本体,,,当两个本体间的结构差别很大时，该方法处理的效果并不好。,
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,,,比较肤浅时获得的结果也不令人满意,
此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。,AnchorPROMPT算法,,,等价,
⑤AnchorPROMPT的总结。,AnchorPROMPT的总结,,,属于概念/产品,
AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。,AnchorPROMPT,,,基于结构的本体映射发现技术,
AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。,AnchorPROMPT,,,基于结构的本体映射发现技术,
由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。,AnchorPROMPT,,,发现异构本体原子概念间的等价映射以及少量原子关系间的等价映射,
由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。,AnchorPROMPT,,,Anchor提示,
对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。,AnchorPROMPT,,,无法处理复杂概念或复杂关系间的本体映射,
对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。,AnchorPROMPT,,,对于复杂概念或复杂关系间的本体映射是无法处理的,
从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。,AnchorPROMPT算法,,,缺乏严格的理论依据,
2）iPROMPT。,iPROMPT。,,,知识问答系统,
PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。,iPROMPT,,,PROMPT工具中的概念,
PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。,PROMPT工具,,,iPROMPT,
iPROMPT从语言角度判断本体间概念或关系的相似。,iPROMPT,,,从语言角度判断本体间概念或关系的相似,
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,合并算法,,,本体合并的任务,
然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。,合并算法,,,merge algorithm,
在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。,iPROMPT的本体合并,,,与本体合并交互,
在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。,本体合并,,,iPROMPT,
图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,iPROMPT,,,基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,
图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。,合并操作建议列表,,,基于概念名或关系名相似，识别出潜在的合并候选术语,
iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。,iPROMPT,,,操作,
步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。,合并建议列表,,,choose a suggestion (also can be defined by the user directly a merge operation)，system execution suggestion of the merge operation，and automatically discover such an operation on the whole merge suggestion list generated changes，that is to realize the suggestion list update，then automatically the system judges new ontology merge suggestion list of conflicts and potential other problems，and look for possible solutions，after these processing，system generated new but no conflict suggestion list,
当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。,iPROMPT,,,检查合并后本体中的不一致性和潜在问题,
合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。,合并后的本体,,,每个术语名字必须是唯一的,
合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。,等价,,,等价,
这样的冲突可以通过重命名来解决。,重命名,,,解决冲突,
②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。,不一致问题,,,当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时,
②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。,不一致问题,,,inconsistency problem,
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,本体,,,删除概念或为本体增加概念,
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,删除概念,,,remove the concept,
在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。,为本体增加概念,,,add the concept,
③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。,概念继承冗余,,,本体合并可能造成一些概念继承连接出现冗余,
对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。,iPROMPT,,,建议避免冗余,
Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。,Noy_N_F,,,评估iPROMPT算法的效果,
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,准确率,,,用户遵循iPROMPT给出的建议占所有建议的比例,
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,召回率,,,用户实际执行的合并操作占工具给出的建议的比例,
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,准确率,,,user follows the suggestion of iPROMPT,
这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。,召回率,,,user actually executes the merge operation,
试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。,iPROMPT,,,算法,
试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。,iPROMPT,,,信息推荐与提示,
总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。,iPROMPT,,,寻找本体间概念或概念的相关属性的映射,
总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。,iPROMPT,,,概念或概念的相关属性的映射,
3）MAFRA。,MAFRA,,,SPO三元组,
MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。,MAFRA,,,处理语义Web上分布式本体间映射的一个框架,
MAFRA引入了语义桥和以服务为中心的思想。,MAFRA,,,语义桥和以服务为中心的思想,
语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。,语义桥,,,异构本体间数据（主要是实例和属性值）转换的机制并利用映射提供基于分布式本体的服务,
语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。,语义桥,,,semantic bridge,
MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。,MAFRA,,,水平方向的两个模块组成,
MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。,MAFRA,,,模块组成,
要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。,本体,,,统一形式,
MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。,MAFRA的正规化过程,,,词语方面的处理,
②相似度。,相似度,,,SPO三元组,
MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。,MAFRA,,,基本的术语或结构相似度方法来获取本体成分之间的关系,
在计算概念间关系的过程中还考虑了概念的属性。,计算概念间关系,,,计算概念间关系的过程,
在计算概念间关系的过程中还考虑了概念的属性。,计算概念间关系,,,计算概念间等价,
③语义桥。,语义桥,,,概念/产品,
根据本体成分间的相似度，利用语义桥来表示本体映射。,本体映射,,,利用语义桥来表示本体映射,
这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。,语义桥,,,表示概念桥和属性桥,
这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。,语义桥,,,semantic bridge,
还能利用推理建立一些隐含的语义桥。,推理,,,建立一些隐含的语义桥,
④执行。,SPO,,,概念/产品,
在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。,语义桥,,,本体间交互的请求,
⑤后处理。,后处理,,,SPO三元组,
映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。,映射执行产生的转换结果,,,进一步处理,
映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。,转换结果,,,转换结果,
垂直方向四个模块具体包括：①演化。,垂直方向四个模块,,,演化,
当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。,语义桥,,,semantic bridge,
②协同创建。,协同创建,,,SPO三元组,
对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。,本体成分,,,多个不同的映射建议,
对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。,映射建议,,,map suggestion,
③领域限制和背景知识。,领域限制,,,SPO,
给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。,给出一些领域限制,,,避免生成不必要的映射,
给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。,提供一些特定领域的背景知识,,,提高映射结果的质量,
④用户界面交互。,用户界面交互,,,SPO三元组,
给出图形化的操作界面能让本体建立的过程更容易。,本体建立,,,给出图形化的操作界面,
图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。,MAFRA,,,本体映射方法学,
尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。,MAFRA,,,缺乏自己特有的映射发现技术,
因此，MAFRA更多只是一个处理异构本体映射的框架。,MAFRA,,,处理异构本体映射的框架,
因此，MAFRA更多只是一个处理异构本体映射的框架。,MAFRA,,,处理异构本体映射的框架,
4）ONION。,ONION,,,概念/产品,
ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。,ONION,,,解决本体互操作的系统,
ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。,ONION,,,本体互操作的系统,
该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。,本体互操作的映射规则,,,半自动算法生成本体互操作的映射规则，解决本体之间的异构,
该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。,本体互操作的映射规则,,,semi-automatic algorithm,
为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。,ONION,,,图的形式表示本体,
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,本体图,,,五种明确定义的语义关系,
本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。,语义关系,,,五种明确定义的语义关系,
本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。,本体映射的生成,,,半自动,
本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。,本体映射的生成,,,semi-automatic,
专家还可以添加新的映射，以补充算法无法生成的映射规则。,专家,,,添加新的映射,
专家还可以添加新的映射，以补充算法无法生成的映射规则。,添加新的映射,,,add new mapping,
ONION的映射生成过程同时使用了术语匹配和本体图匹配。,ONION,,,映射生成过程,
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,,,为概念匹配算法分配置信度,
对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。,术语匹配算法,,,等价,
在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,比较两个本体之间所有可能的术语对,,,计算过慢,
在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。,比较两个本体之间所有可能的术语对,,,compare all possible term pairs between two ontologies,
为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。,窗口算法,,,window algorithm,
在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。,发现映射,,,比较只在那些可能会有映射的窗口对之间进行,
在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。,窗口对,,,compare,
“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。,窗口算法,,,比较过程的时间复杂度,
①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。,非迭代算法,,,利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。,
在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。,相似度算法,,,事先设定一些阈值，使算法自动去除一些不可能的相似度结果,
在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。,相似度算法,,,automatic remove some impossible similarity results,
同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。,非迭代算法,,,词典中同义词集提高映射发现的映射质量,
同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。,非迭代算法,,,non-iterative algorithm,
②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。,迭代算法,,,本体子图间结构上的同态,
②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。,迭代算法,,,iteration algorithm,
Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。,Nexus,,,映射发现过程,
因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。,迭代算法,,,基本匹配器生成的结果再进行子图匹配,
因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。,迭代算法,,,iterative algorithm,
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,ONION算法,,,映射精度,
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,映射结果的召回率,,,recall_rate,
ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。,映射精度,,,map_accuracy,
试验还表明，在映射发现过程中采用多种策略能提高精度。,映射发现,,,多种策略能提高精度,
ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。,原子概念之间的等价关系,,,atomic concept,
5）Wang_Peng和Xu_Baowen的方法。,Wang_Peng和Xu_Baowen的方法。,,,SPO三元组抽取,
Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。,Wang_Peng,,,建立本体映射规则的方法,
该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。,概念相似度的度量,,,寻找异构本体概念间的关系,
该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。,本体概念相似度的度量,,,concept similarity measurement,
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,概念间语义关系,,,概念名、概念属性和概念在本体中的上下文得到,
该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。,概念间的语义关系,,,概念名,
这种方法认为不同本体间概念的相似度包括三个部分：①概念的同义词集相似度。,概念的相似度,,,不同本体间概念的相似度,
同义词集是语义相同或相近词的分组[38]。,同义词集,,,语义相同或相近词的分组,
同义词集是语义相同或相近词的分组[38]。,同义词集,,,语义相同或相近词的分组,
基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。,基于同名或同义词集的概念,,,概念的名称作为相似度首要考虑的要素,
基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。,相似度,,,similarity,
②概念特征上的相似度。,概念特征上的相似度。,,,SPO三元组,
概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。,概念的特征,,,概念的属性、概念附带的关系以及属性和关系取值的限制,
概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。,概念的特征,,,概念的属性、概念附带的关系以及属性和关系取值的限制,
③概念上下文上的相似度。,概念上下文上的相似度,,,概念的相似度,
以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。,相似度的相似度,,,基于概念自身的,
以下定义概念的语义邻居概念集。,概念的语义邻居概念集,,,属于概念的语义邻居概念集,
"定义5.6概念Co的语义邻居概念集N(Co,r)={Ci|∀i,d(Co,Ci)≤r}。",概念Co,,,"概念语义邻居概念集N(Co,r)={Ci|∀i,d(Co,Ci)≤r}。",
"定义5.6概念Co的语义邻居概念集N(Co,r)={Ci|∀i,d(Co,Ci)≤r}。",等价,,,概念语义邻居概念集,
式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。,d,,,概念间的距离,
式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。,d,,,距离,
这里的关系包含直接继承关系。,直接继承关系,,,schema,
d≤r表明与当前的概念在语义距离上小于某一定常数。,d≤r,,,与当前的概念在语义距离上小于某一定常数,
"在以上分析的基础上，给出了本体间概念相似度的计算公式：S(Cp,Cq)=Ww×Sw(Cp,Cq)+Wu×Su(Cp,Cq)+Wn×Sn(Cp,Cq)式中，Ww、Wu和Wn是权重；Sw、Su和Sn分别代表概念名称、特征以及上下文三方面的相似性度量。",相似性度量,,,similarity measurement,
"计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。",相似度的度量,,,非对称的相似度度量,
该方法利用概念间的相似度辅助本体映射的生成。,本体映射生成,,,概念间的相似度辅助,
"①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。",相似度,,,三种相似度的合,
"①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。",相似度,,,similarity,
通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。,相似度,,,判断概念是否相同,
通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。,相似度,,,similarity,
②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。,同一本体中父概念与子概念的相似度,,,同一本体中子概念与父概念的相似度,
②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。,概念间存在父子关联的判别,,,同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度,
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,等价关系,,,生成概念上的等价关系,
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,上/下义关系,,,生成概念上的等价关系,
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,等价,,,equivalence,
根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。,上/下义关系,,,on/off-sense relationship,
生成规则如下。,SPO,,,生成规则,
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",Oa,,,Ci,
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",Ob,,,Cj,
"定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。",等价,,,equivalence,
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,AddBridge,,,添加一个映射的操作,
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,AddBridge,,,添加一个映射的操作,
式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。,BCequal,,,两个概念等价,
式中，isa表示两概念具有上义和下义关系。,isa,,,两概念具有上义和下义关系,
式中，isa表示两概念具有上义和下义关系。,等价,,,上义和下义关系,
从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。,概念的映射,,,多个角度综合考虑概念的映射,
从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。,等价,,,等价,
6）S-Match。,S-Match,,,SPO三元组抽取,
S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。,S-Match,,,本体匹配系统,
S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。,S-Match,,,本体匹配系统，能发现异构本体间的映射,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,语义关系,,,等价（=）,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,语义关系,,,泛化（）,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,语义关系,,,特化（）,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,语义关系,,,不相匹配（⊥）,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,语义关系,,,相交（）,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,等价,,,=,
它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。,泛化,,,,
S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。,S-Match,,,基于本体抽象层的概念继承结构树，不考虑本体中的实例。,
S-Match的核心是计算异构本体间的语义关系。,S-Match,,,计算异构本体间的语义关系,
输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。,本体树结构,,,标准的XML格式编码,
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,,,WordNet,
该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。,S-Match,,,自顶向下的方式计算树中的每个标签的含义,
执行结果的输出是一个被丰富的树。,执行结果的输出,,,丰富的树,
然后，用户协调两本体的匹配过程，这种方法使用三个外部库。,本体匹配过程,,,用户协调两本体的匹配过程,
然后，用户协调两本体的匹配过程，这种方法使用三个外部库。,两本体的匹配过程,,,user coordination two external libraries,
第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。,元素匹配器,,,包含弱语义的元素匹配器,
目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。,元素层次匹配器,,,_S-Match,
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,,,强语义的元素层次匹配器,
第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。,第二个库,,,强语义的元素层次匹配器,
第三个库是由结构层次的强语义匹配器组成的。,第三个库,,,结构层次的强语义匹配器组成的,
"输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。",S-Match,,,计算标签的含义,
"输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。",S-Match,,,四步,
其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。,概念/概念表示的节点标签转换,,,将自然语言表示的节点标签转换为一种内部的形式化形式,
其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。,概念/节点标签,,,将自然语言表示的节点标签转换为一种内部的形式化形式,
其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。,预处理,,,分词,
其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。,预处理,,,词形分析,
其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。,预处理,,,建立原子概念,
其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。,预处理,,,建立复杂概念,
"<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。",Wine,,,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。,
扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。,扩展节点标签的含义,,,捕获树结构中的知识，定义节点中概念的上下文,
扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。,扩展节点标签的含义,,,extend node label,
步骤3：对所有T1和T2中的标签对，计算标签间的关系。,T1,,,步骤3,
步骤3：对所有T1和T2中的标签对，计算标签间的关系。,等价,,,equivalence,
利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。,元素层次语义匹配器,,,建立概念间的关系,
步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,T1,,,步骤4,
步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。,等价,,,equivalence,
将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。,将概念间的匹配问题转换为验证问题,,,推理获得概念间的关系,
将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。,将概念间的匹配问题转换为验证问题,,,equivalence,
与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。,S-Match,,,本体映射系统比较,
7）Cupid。,Cupid,,,SPO三元组,
Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。,Cupid系统,,,通用的模式匹配算法,
该方法输入图格式的模式，图节点表示模式中的元素。,图节点,,,输入图模式的元素,
该方法输入图格式的模式，图节点表示模式中的元素。,图节点,,,图节点,
"与其他的混合方法比较[42],Cupid得到更好的映射结果。",Cupid,,,混合方法的比较,
发现模式匹配的算法包含三个阶段。,发现模式匹配的算法,,,三个阶段,
①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。,结构匹配,,,结构匹配算法,
Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。,Cupid,,,针对数据库模式,
Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。,Cupid,,,数据库模式,
8）其他方法。,SPO,,,其他方法,
Chimaera是一个合并和测试大本体的环境[43]。,Chimaera,,,合并和测试大本体的环境,
寻找本体映射是进行合并操作的一个主要任务。,寻找本体映射,,,进行合并操作的一个主要任务,
Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。,Chimaera,,,匹配的术语对作为候选的合并对象,
Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。,Chimaera,,,合并对象,
Chimaera能识别术语间是否包含或不相关等简单的映射关系。,Chimaera,,,识别术语间是否包含或不相关等简单的映射关系,
BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。,BUSTER,,,改善信息检索的语义转换中间件,
BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。,BUSTER,,,解决异构信息源的集成,
它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。,OWL_2_QL,,,不同系统的用户如果在一些基本词汇上达成一致,
因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。,BUSTER,,,建立局部本体和基本词汇集之间的映射,
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,,,模式匹配系统,
COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。,COMA,,,一个模式匹配系统,
COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。,COMA,,,一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。,
它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。,AlchemyQA的匹配器,,,6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器,
它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。,匹配器,,,match-engine,
面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。,面向重用的匹配器,,,其他匹配器得到的结果来得到更好的映射,
面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。,面向重用的匹配器,,,ORM,
模式被编码为有向无环图。,模式,,,有向无环图,
COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。,COMA,,,在匹配过程中与用户进行交互，提高匹配结果的准确率,
ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。,ASCO原型,,,识别不同本体间相关元素对的算法,
ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。,ASCO原型,,,发现映射,
ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。,ASCO原型,,,识别不同本体间相关元素对的算法,
ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。,ASCO,,,本体中包含的可用信息处理映射,
ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。,ASCO,,,本体中包含的可用信息来处理映射,
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,匹配过程,,,语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度,
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,匹配过程,,,结构阶段利用概念和关系的结构计算概念或关系间的相似度,
该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。,等价,,,equivalence,
（3）基于术语和结构的本体映射总结。,本体映射,,,基于术语和结构的本体映射,
这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。,概念/方法,,,缺乏理论的依据和支持,
这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。,这一类方法,,,基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低,
2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。,基于实例的本体映射,,,发现方法,
2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。,基于实例的本体映射,,,based on instance ontology mapping,
（1）技术综述。,技术综述,,,SPO三元组,
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,,,本体概念间存在共享实例,
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,,,概念之间没有共享实例,
基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。,基于实例的本体映射技术,,,based on instance ontology mapping technique,
①共享实例的方法。,SPO,,,共享实例的方法,
当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。,A,,,寻找概念A和B之间最简单的方法,
当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。,A,,,等价,
当两概念等价时，显然有AB=A=B。,AB,,,等价,
当两概念等价时，显然有AB=A=B。,等价,,,AB=A=B,
然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。,对称差分,,,symmetric difference,
定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。,对称差分相似度,,,两集合的相似度,
定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。,对称差分相似度,,,symmetric difference similarity,
此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。,实例集合的概率解释,,,计算相似度,
此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。,相似度,,,similarity,
②无共享实例的方法。,无共享实例的方法,,,无共享实例的SPO三元组,
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,,,两概念没有共享实例,
当两概念没有共享实例时，基于共享实例的方法无能为力。,基于共享实例的方法,,,based on sharing instances,
事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。,本体间,,,不存在共享实例,
事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。,本体间,,,share instance,
在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。,连接聚合,,,数据分析方法获得实例集之间的关系,
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,,,常用的连接聚合度量,
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,,,单连接,
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,,,全连接,
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,,,平均连接,
常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。,连接聚合度量,,,Haussdorf距离,
其中，Haussdorf距离度量两个集合之间的最大距离。,Haussdorf距离度量,,,两个集合之间的最大距离,
其中，Haussdorf距离度量两个集合之间的最大距离。,Haussdorf距离度量,,,两个集合之间的最大距离,
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,ValtchevP提出的匹配相似度,,,建立实体间的对应关系来进一步计算集合之间的相似度,
而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。,相似度,,,match similarity,
基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。,基于实例的映射发现方法,,,采用机器学习技术来发现异构本体间映射,
通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,有监督的学习方法,,,让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,
通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。,有监督的学习方法,,,有监督的学习,
训练完成后，训练结果用于发现异构本体间的映射。,训练结果,,,发现异构本体间的映射,
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,本体实例,,,学习算法利用这些信息能学习概念之间或关系之间的语义关系,
大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。,学习算法,,,learn algorithm,
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,形式化概念分析,,,formal concept analysis,
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,贝叶斯学习,,,bayes learning,
常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。,神经网络,,,neural network,
（2）方法和工具1）GLUE。,GLUE,,,方法和工具,
"GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。",GLUE,,,本体映射生成系统,
"GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。",GLUE,,,本体映射生成系统,
GLUE是对半自动模式发现系统LSD的一个改进[53]。,GLUE,,,对半自动模式发现系统LSD的一个改进,
GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。,概念分类,,,本体中最重要的部分,
GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。,概念分类,,,概念本体概念之间的1∶1映射,
该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。,发现关系之间的映射,,,扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）,
该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。,等价,,,equivalence,
①GLUE的思想。,GLUE,,,思想,
GLUE的目的是根据分类本体寻找本体间1∶1的映射。,GLUE,,,根据分类本体寻找本体间1∶1的映射,
其中的主要思想包括：（a）相似度定义。,相似度的定义,,,属于相似度,
GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。,GLUE,,,概念的联合概率分布,
GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。,GLUE,,,概念的联合概率分布,
GLUE定义了4种概念的联合概率分布。,GLUE,,,概念的联合概率分布,
（b）计算相似度。,计算相似度。,,,SPO三元组,
由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。,GLUE,,,机器学习技术,
由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。,相似度,,,similarity,
它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。,A,,,利用A的实例训练一个匹配器,
它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。,A,,,实例训练一个匹配器,
（c）多策略学习。,多策略学习,,,概念/产品,
使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。,机器学习技术,,,存在的一个问题,
然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。,本体中的信息类型,,,单个学习器无法有效利用各种类型的信息,
为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。,GLUE,,,多策略学习技术,
为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。,多策略学习技术,,,"multi-strategy learning,一个元学习器综合各学习器的结果",
（d）利用领域约束。,SPO,,,领域约束,
GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。,GLUE,,,领域约束条件和通用启发式规则来提高映射结果的精度,
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,领域约束,,,“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”,
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,启发式规则,,,“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”,
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,领域约束,,,“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”,
一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。,启发式规则,,,“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”,
（e）处理复杂映射。,e,,,处理复杂映射,
为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。,GLUE,,,CGLUE系统,
为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。,CGLUE,,,概念映射,
以下给出GLUE方法的详细介绍。,GLUE,,,介绍,
②相似度度量。,相似度度量,,,SPO三元组,
很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。,本体相似度,,,定义过于依赖概念本身和它的语法表示,
很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。,本体相似度,,,ontology similarity,
GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。,概念,,,实例的集合,
GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。,概念,,,concept,
在此基础上，GLUE定义不同概念间的联合)和P(概率分布。,GLUE,,,不同概念间的联合和P概率分布,
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念A和B之间的联合概率分布,,,概念/联合概率分布,
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念A之间的联合概率分布,,,"P(A,B)",
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念B之间的联合概率分布,,,"P(,B)",
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念A之间的联合概率分布,,,"P(A,)",
"概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。",概念B之间的联合概率分布,,,"P(B,)",
"以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。","P(A,)",,,属于A但不属于B的概率,
GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。,GLUE的相似度度量,,,基于这4种概念的联合分布,
GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。,相似度度量,,,基于这4种概念的联合分布,
第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。,相似度度量函数,,,基于Jaccard系数,
第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。,相似度度量函数,,,基于Jaccard系数,
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,相似度度量函数,,,“最特化双亲”,
另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。,相似度度量函数,,,“最特化双亲”,
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。",P(A|B),,,"MSP(A,B)",
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。","MSP(A,B)",,,如果B包含A,
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。",等价,,,"if B包含A,则B越特化,P(A|B)越大",
"这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。",等价,,,"那样MSP(A,B)的值越大",
这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。,A,,,最特化的双亲,
这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。,A,,,特化的双亲,
这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。,A,,,最小集,
类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。,最特化双亲,,,相似度度量,
③GLUE体系结构。,GLUE,,,体系结构,
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,,,分布估计,
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,,,相似度估计,
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,,,放松标记,
GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。,GLUE,,,分布估计,
图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。,GLUE体系结构分布估计,,,输入两个分类本体O1和O2以及它们的实例,
然后利用机器学习技术计算每对概念的联合概率分布。,语义嵌入,,,机器学习技术计算每对概念的联合概率分布,
然后利用机器学习技术计算每对概念的联合概率分布。,等价,,,等价,
由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。,联合概率分布,,,联合概率分布,
分布评估使用一组基本学习器和一个元学习器。,分布评估,,,基本学习器和一个元学习器,
分布评估使用一组基本学习器和一个元学习器。,分布评估,,,一组基本学习器和一个元学习器,
相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。,相似度估计,,,计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵,
相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。,相似度估计,,,similarity estimation,
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,,,寻找满足领域约束和常识知识的映射，输出最终的映射结果。,
放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。,放松标记模块,,,relax marking module,
④分布估计。,分布估计,,,SPO三元组,
"考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。",联合概率分布,,,属于A和B的实例数与全体实例总数的比值,
通常这个比值是无法计算的，因为不可能知道全体实例。,概念/SPO,,,属于,
"因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。",本体的输入实例,,,"基于现有的数据来估计P(A,B)",
"因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。",本体,,,ontology,
注意，两个本体的实例可以重叠，但没有必要必须那样。,本体的实例,,,重叠，但没有必要必须那样,
注意，两个本体的实例可以重叠，但没有必要必须那样。,本体的实例,,,overlap,
注意，两个本体的实例可以重叠，但没有必要必须那样。,本体的实例,,,没有必要,
Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。,Ui,,,本体Oi的实例集合,
N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。,N(Ui),,,来估计：,
"这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。","P(A,B)",,,"将P(A,B)的计算转化为计算和。",
为了达到这个目的，GLUE使用了机器学习方法。,GLUE,,,机器学习方法,
特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。,O1,,,将O1的实例集合U1划分为属于A的实例集和不属于A的实例集,
然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。,A,,,实例分类器,
然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。,实例分类器,,,关于A,
最后，使用该分类器预测O2中的实例s是否属于A。,分类器,,,预测O2中的实例s是否属于A,
最后，使用该分类器预测O2中的实例s是否属于A。,等价,,,等价,
"通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。",分类器,,,"非明确的“是”或“否”，是一个[0,1]之间的置信度值",
"通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。",分类器返回的结果,,,"[0,1]之间的置信度值",
这个值反映了分类的不确定性。,分类的不确定性,,,概念/产品,
这里规定置信度大于0.5就表示“是”。,置信度,,,“是”,
常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。,GLUE,,,分类学习器,
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,A,,,通过学习的方法得到和等参数,
基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。,等参数,,,等价,
具体的过程如图5-9所示。,SPO,,,具体的过程,
●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。,O1,,,U1,
●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。,划分本体O1的实例集合U1,,,划分本体O1的实例集合U1为和,
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,正例,,,使用和作为正例和反例分别训练学习器L,
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,正例,,,使用,
●使用和作为正例和反例分别训练学习器L，如图5-9（c）。,反例,,,作为,
●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。,O2的实例集合,,,U2,
●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。,划分本体O2的实例集合U2,,,划分属于B和不属于B的实例集合,
●对中的每个实例使用学习器L进行分类。,对中的每个实例,,,使用学习器L进行分类,
将划分为两个集合和。,,,,集合,
相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,L,,,应用学习器L,
相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。,应用学习器L,,,Learning to apply,
●重复（a）～（d），得到集合和。,集合和,,,属于三元组抽取,
"●使用公式计算P(A,B)。",SPO,,,"公式计算P(A,B)",
类似地，可以计算出其他3种联合概率分布。,联合概率分布,,,计算其他3种联合概率分布,
类似地，可以计算出其他3种联合概率分布。,联合概率分布,,,joint probability distribution,
图5-9估计概念A和B的概率分布⑤多策略学习。,概念A,,,估计概念A和B的概率分布,
训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。,训练实例分类器,,,根据不同类型的信息,
为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。,GLUE,,,多策略的学习方法,
"在分布估计阶段，系统会训练多个基本学习器L1,…,Lk。",基本学习器L1,,,分布估计阶段,
"在分布估计阶段，系统会训练多个基本学习器L1,…,Lk。",基本学习器L1,,,朴素贝叶斯,
每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。,学习器,,,来自实例数据中某种类型的信息进行分类学习训练,
训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。,基本学习器,,,合并各个学习器的预测结果,
训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。,元学习器,,,meta-learner,
与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。,多策略的学习方法,,,得到较高的分类准确率，并可以得到较好的联合分布近似值,
与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。,多策略的学习方法,,,multi-strategy learning method,
目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。,内容学习器,,,GLUE系统,
目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。,内容学习器,,,content learner,
目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。,名字学习器,,,name learner,
此外，还有1个元学习器将基本学习器的结果进行线性合并。,元学习器,,,基本学习器的结果进行线性合并,
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,,,SPO三元组抽取,
内容学习器和名字学习器的细节如下：（a）内容学习器。,内容学习器,,,content learner,
利用实例文本内容中的词频来进行分类预测。,分类预测,,,利用实例文本内容中的词频来进行分类预测。,
一个实例通常由名将这些信息都作为实例的文本内容。,实例,,,名将这些信息都作为实例的文本内容。,
例如，实字、属性集合以及属性值组成。,SPO,,,概念/产品,
例如，实字、属性集合以及属性值组成。,SPO,,,实字,
例如，实字、属性集合以及属性值组成。,SPO,,,属性集合,
例如，实字、属性集合以及属性值组成。,SPO,,,属性值组成,
"GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。",SPO,,,实字,
"GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。",SPO,,,属性集合,
"GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。",SPO,,,属性值组成,
内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。,内容学习器,,,贝叶斯学习技术,
内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。,内容学习器,,,贝叶斯学习技术,
"它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,…,wk}，其中的wj是标记。",输入实例的内容表示,,,分词和抽取词干技术将每个输入实例的文本内容表示为一组标记,
"它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,…,wk}，其中的wj是标记。","内容表示为d={w1,…,wk}",,,将每个输入实例的文本内容表示为一组标记,
内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。,内容学习器,,,计算输入的一个实例属于概念A的概率,
内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。,内容学习器,,,content learner,
根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。,P(A|d),,,贝叶斯原理,
根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。,P(d|A)P(A)/P(d),,,贝叶斯原理,
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(d|A),,,P(d)属于估计,
其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。,P(d),,,概率密度,
特别地，P(A)被估计为属于A的实例占全部训练实例的比例。,P(A),,,属于A的实例占全部训练实例的比例,
因此，只需要计算P(d|A)就可以得到P(A|d)。,P(d|A),,,计算P(d|A),
因此，只需要计算P(d|A)就可以得到P(A|d)。,P(d|A),,,计算A的依赖d,
"为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)···P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。",P(d|A),,,概率模型,
注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。,贝叶斯学习技术,,,Bayesian learning technique,
P(|d)可通过相似的方法来计算。,P,,,可通过相似的方法来计算,
（b）名字学习器。,名字学习器,,,SPO三元组抽取,
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,名字学习器,,,内容学习器,
相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。,名字学习器,,,content learner,
这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。,实例全名,,,从根节点直到实例所在位置的路径上所有概念名的连接,
这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。,实例全名,,,from root node to instance location path all concept name connect,
（c）元学习器。,元学习器,,,概念/产品,
基本学习器的预测结果通过元学习器来合并。,基本学习器,,,元学习器来合并,
元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。,元学习器,,,分配给每个基本学习器一个权重,
元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。,元学习器,,,meta-learner,
这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。,基本学习器,,,人工给定或机器学习自动设置,
这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。,基本学习器,,,basic learner,
⑥利用领域约束和启发式知识。,领域本体,,,领域约束和启发式知识,
经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。,相似估计,,,获得最佳的正确映射,
经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。,相似估计,,,similarity estimation,
经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。,最佳的正确映射,,,best correct mapping,
放松标记是一种解决图中节点的标签分配问题的有效技术。,放松标记,,,解决图中节点的标签分配问题的有效技术,
该方法的思想是节点的标签通常受其邻居的特征影响。,OWL_on_RDF_S_Schema,,,属于OWL_2_数据模型,
基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。,放松标记技术,,,将节点邻居对其标签的影响用公式量化,
放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。,放松标记技术,,,相似匹配,
GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。,GLUE,,,放松标记技术用于解决本体映射问题,
考虑约束能提高映射的精度。,约束,,,提高映射精度,
约束又可分为领域独立约束和领域依赖约束两种。,约束,,,领域独立约束,
约束又可分为领域独立约束和领域依赖约束两种。,约束,,,领域依赖约束,
约束又可分为领域独立约束和领域依赖约束两种。,约束,,,constraint,
领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。,领域独立约束,,,相关节点间交互的通用知识,
领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。,领域独立约束,,,related nodes inter-action common knowledge,
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,邻居约束,,,“两节点的邻居匹配，则两节点也匹配”,
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,并集约束,,,“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”,
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,分类本体,,,基于这样的事实，即X是它的所有孩子的并集,
邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。,并集约束,,,并集约束,
领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。,领域依赖约束,,,特定节点间交互的用户知识,
领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。,领域依赖约束,,,domain dependency constraint,
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,本体,,,约束,
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,本体,,,频率约束,
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,本体,,,邻近约束,
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,节点X,,,节点X的后继,
以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。,节点Y,,,节点X,
GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。,GLUE,,,寻找正确的映射或去除不太可能的映射,
⑦实验评估。,实验评估,,,SPO三元组,
GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。,GLUE系统的实验结果,,,正确率,
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,内容学习器,,,content learner,
在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。,名字学习器,,,name learner,
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,,,只少量提高正确率,
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,,,在另一半的实验中，正确率提高了6%～15%,
在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。,元学习器,,,meta-learner,
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,,,提高正确率,
放松标记能进一步提高3%～18%的正确率，只有一个实验例外。,放松标记,,,relaxation marker,
由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。,GLUE,,,概念间1∶1形式的映射结果,
由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。,GLUE,,,概念间1∶1形式的映射结果,
尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。,GLUE,,,映射正确率,
首先，一些概念不能被匹配是因为缺少足够的训练数据。,概念/匹配,,,缺少足够的训练数据,
其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。,利用放松标签进行优化,,,考虑全局的知识,
其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。,利用放松标签进行优化的时候可能没有考虑全局的知识,,,不考虑全局的知识,
第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。,文本分类器,,,通用文本分类器,
第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。,文本分类器,,,通用文本分类器,
最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。,节点的描述,,,难以判断与之相关的映射,
⑧扩充GLUE发现复杂映射。,扩充GLUE,,,发现复杂映射,
GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。,GLUE,,,寻找给定分类本体概念之间1∶1的简单映射,
为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。,GLUE,,,CGLUE,
目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。,CGLUE,,,概念间的复杂映射,
目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。,等价,,,equivalence,
目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。,英文名,,,equivalence,
CGLUE中的复杂映射形式如A=X1op1X2op2…opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。,CGLUE,,,复杂映射形式,
CGLUE中的复杂映射形式如A=X1op1X2op2…opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。,CGLUE中的复杂映射形式,,,A=X1op1X2op2…opn-1Xn,
这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。,m∶n的形式,,,1∶n的映射,
这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。,A1op1A2,,,m∶n的形式,
由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。,opi,,,将概念看作实例的集合,
由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。,opi,,,并、差和补,
CGLUE将形如X1op1X2op2···opn-1Xn的复合概念称作映射对象。,CGLUE,,,映射对象,
CGLUE将形如X1op1X2op2···opn-1Xn的复合概念称作映射对象。,映射对象,,,CGLUE,
"CGLUE还进一步假设概念D的孩子C1,C2,…,Ck要满足条件,1≤i,j≤k,i≠j，且。",CGLUE,,,概念/产品,
"CGLUE还进一步假设概念D的孩子C1,C2,…,Ck要满足条件,1≤i,j≤k,i≠j，且。",CGLUE,,,概念等价,
CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。,CGLUE,,,复合概念,
"对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。",O1中的概念A,,,CGLUE枚举O2中的所有概念并的组合,
"对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。",CGLUE,,,概念枚举并的组合并比较相似度,
比较的方法与GLUE中的相似。,比较的方法,,,GLUE,
最后返回相似度最高的映射结果。,相似度最高的映射结果,,,输入,
由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。,概念并组合的数目,,,指数级的,
因此需要考虑从巨量的候选复合概念中搜索A的近似。,A的近似,,,从巨量的候选复合概念中搜索A的近似,
为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。,CGLUE,,,定向搜索技术,
为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。,定向搜索技术,,,定向搜索,
定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。,定向搜索算法,,,寻找概念A的最佳映射,
设highest_sim=0。,highest_sim,,,设,
扩展这些候选创建新的候选对象。,扩展的候选,,,创建新的候选对象,
添加新候选对象到S。,S,,,添加新候选对象到S。,
设置highest_sim=new_highest_sim。,highest_sim,,,new_highest_sim,
算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,算法的步骤2（a）,,,采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,
算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。,算法的步骤2（a）,,,采用GLUE中的学习方法计算概念A和候选概念间的相似度分数,
在步骤2（c）中，ε最初设置为0。,ε,,,步骤2（c）,
在步骤2（c）中，ε最初设置为0。,ε,,,等价,
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,并操作,,,and operation,
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,产生的k个新候选对象,,,new candidate objects,
在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。,去除前面使用的候选对象,,,remove the candidate objects used before,
因为每个候选对象只是O2概念的并，去除过程很快。,候选对象,,,O2概念的并,
CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。,CGLUE的实验结果,,,发现不能发现的1∶n类型的概念映射,
试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。,CGLUE,,,对一部分实验的正确率,
试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。,CGLUE,,,中文语义分析评测,
实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。,CGLUE,,,帮助用户确定52%～84%的正确1∶1映射,
实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。,CGLUE,,,1∶1映射,
⑨GLUE的总结。,GLUE,,,概念/评价指标,
GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。,GLUE,,,早期经典的本体映射工作之一,
GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。,GLUE,,,概念的联合概率分布,
GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。,GLUE,,,语义相似基础,
试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。,GLUE,,,概念之间1∶1的简单映射,
扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。,CGLUE系统,,,发现概念间1∶n类型的映射,
尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。,GLUE,,,映射结果,
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE提出的算法,,,不能让人满意,
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,CGLUE提出的算法,,,not satisfy,
其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。,很多正确的映射,,,be missed,
最后，GLUE无法处理关于异构本体的关系之间的映射。,GLUE,,,关于异构本体的关系之间的映射,
2）概念近似的方法。,概念近似,,,概念/产品,
在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。,基于异构本体的信息检索,,,将原查询重写为近似的查询,
在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。,等价,,,equivalent,
本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。,本体间概念的近似技术,,,近似查询研究的重点,
本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。,本体间概念的近似技术,,,近似查询,
①方法的思想。,方法,,,方法的思想,
在本体查询系统中，信息源和查询都是针对特定本体的。,本体查询系统,,,信息源,
在本体查询系统中，信息源和查询都是针对特定本体的。,本体查询系统,,,查询,
不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。,查询,,,某个本体中的词汇表达,
不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。,本体,,,ontology,
一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。,S,,,基于本体O的信息源,
因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。,查询异构问题,,,本体,
因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。,查询异构问题,,,查询提出者和系统使用不同的本体,
当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。,异构查询问题,,,不存在一个全局本体时解决异构查询问题两个本体之间,
当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。,异构查询问题,,,heterogeneous query problem,
令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。,用户本体,,,O1,
令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。,系统本体,,,O2,
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,查询重写,,,把关于O1的查询重写为关于O2的解释相同的查询,
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,查询重写,,,query rewriting,
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,关于O1的查询重写,,,about O1's query rewriting,
查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。,关于O2的解释相同的查询,,,about O2's explanation same query,
但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。,O1,,,重写为解释近似于原查询的查询,
但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。,重写为解释近似于原查询的查询,,,rewrite queries approximating the original query,
令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。,R,,,Q在O2中的近似,
令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。,R,,,Q在T中的近似,
令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。,等价,,,approximate query in O2,
令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。,等价,,,近似,
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R,,,在信息源S中的查全率和查准率,
R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。,R,,,在信息源S中的查全率和查准率,
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",完备的,,,近似查询结果包括了所有原查询的结果,
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",正确的,,,所有近似查询结果都是原查询的结果,
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",完备,,,"recall(Q,R)=1",
"如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。",正确,,,"precision(Q,R)=1",
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,查询间的蕴涵关系,,,寻找完备或正确的近似,
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,上近似,,,寻找完备或正确的近似,
查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。,下近似,,,寻找完备或正确的近似,
本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。,本体间的概念近似技术,,,基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。,
本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。,本体间的概念近似技术,,,基于上述思想,
这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。,本体映射发现方法,,,寻找概念近似的过程是基于实例进行的,
②Stuckenschmidt_H的概念近似。,Stuckenschmidt_H的概念近似,,,属于概念近似,
寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。,寻找O1中概念C在O2中的近似,,,近似查询中的关键问题,
寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。,寻找O1中概念C在O2中的近似,,,近似查询中的关键问题,
Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。,Stuckenschmidt_H,,,利用概念的最小上界和最大下界计算概念近似的方法,
Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。,概念的最小上界,,,等价,
Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。,概念的最大下界,,,等价,
该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。,概念的上近似,,,定义概念的最小上界,
该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。,概念的下近似,,,定义概念的最大下界,
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念的最小上界,,,概念在另一本体中所有的直接父类,
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,概念的最大下界,,,概念在另一本体中所有的直接子类,
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,最小上界,,,概念在另一本体中所有的直接父类,
从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。,最大下界,,,概念在另一本体中所有的直接子类,
"C为O1中概念，概念C的最小上界lub(C,T)包含A1,A2,…,Am，是C在O2中的直接父类；概念C的最大下界glb(C,T)包含B1,B2,…,Bn，是C在O2中的直接父类。",C,,,O1中概念,
图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。,O1,,,C,
图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。,等价,,,equivalence,
图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。,英文名,,,equivalence,
"定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。","lub(C,T)",,,T中概念的集合,
"定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。","lub(C,T)",,,在T中的最小上界,
"找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。",C,,,找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似,
"找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。",等价,,,equivalence,
定义5.11令C为O1中概念，T为O2中全部概念的集合。,O1,,,C,
定义5.11令C为O1中概念，T为O2中全部概念的集合。,等价,,,equivalence,
"定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。","glb(C,T)",,,T的一个子集,
"定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。",等价,,,equivalence,
"找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。",下近似,,,找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似,
"找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。",下近似,,,lower approximation,
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,上近似,,,不包含非算子（）的近似,
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,上近似,,,包含非算子的近似,
显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。,下近似,,,不包含非算子的近似,
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",非算子,,,"将查询化为否定正规形式（NegationNormal_Form,NNF）消去",
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",非算子,,,non-operator,
"因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。",查询,,,query,
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,查询,,,在线性时间内通过反复应用以下公式改写为等价的NNF,
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,非算子,,,non-operator,
任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。,NNF,,,非谓词逻辑的规范形式,
这样概念数目最多翻倍，但所有非算子都被消去。,SPO,,,概念数目最多翻倍,
这样概念数目最多翻倍，但所有非算子都被消去。,SPO,,,等价,
"Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。",等价,,,"lub(C,T)",
"Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。",等价,,,"glb(C,T)",
上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。,扩展定义,,,去除了最小上界和最大下界,
但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。,最小上界,,,T的子集,
但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。,最小上界,,,upper bound of minimum,
但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。,最大下界,,,lower bound of maximum,
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,概念的近似,,,找到概念在系统本体中的超类和子类然后生成概念的最小上界和最大下界,
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,等价,,,find concept's super class and sub class,
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,等价,,,generate concept's minimal upper bound and maximal lower bound,
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,等价,,,then generate concept's minimal upper bound as concept's approximation,
在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。,等价,,,and generate concept's maximal lower bound as concept's approximation,
但这种方法无法得到概念的最佳近似，近似的质量有时是不可接受的。,概念的近似,,,得到概念的最佳近似,
如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。,上近似,,,找不到概念的超类,
如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。,上近似,,,over-approximation,
同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。,下近似,,,概念的子类,
同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。,下近似,,,subset,
异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。,异构本体,,,全异的概念集合和概念层次,
异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。,全异的概念集合,,,heterogeneous ontology,
异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。,最坏的情况,,,worst case,
这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。,概念的近似,,,现有方法的缺点,
这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。,概念的最佳近似,,,get the best approximation of concept,
实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。,蕴涵关系,,,复杂概念,
如果考虑这些蕴涵关系，也许可以提高近似查询的质量。,近似查询,,,考虑这些蕴涵关系,
图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。,TzitzikasY,,,概念近似,
为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。,近似查询,,,通过实例学习来进行近似查询的方法,
为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。,近似查询,,,instance learning,
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,,,找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似,
它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。,查询重写,,,query rewriting,
该方法需要一个训练实例集合。,OIA,,,方法,
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,T,,,概念集合T相关的信息源S为训练集,
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,K,,,非空对象集合,
令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。,K,,,概念集合T相关的信息源S为训练集,
在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K⊆QI(S)};K-={Q|QI(S)⊆K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。,K+,,,{Q|K⊆QI(S)},
在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K⊆QI(S)};K-={Q|QI(S)⊆K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。,K-,,,{Q|QI(S)⊆K},
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,非空对象集合K,,,上界和下界,
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,上界,,,计算等价的且长度有限的查询,
这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。,下界,,,计算等价的且长度有限的查询,
为此，引入一个将对象映射到概念合取的函数：。,概念合取的函数：,,,将对象映射到概念合取,
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,DI(o),,,得到与上界和下界等价的近似表示形式,
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,上界,,,name+(K),
可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。,下界,,,name-(K),
对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。,概念近似查询,,,给定的查询,
遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。,Tzitzikas_Y,,,没有提出有效发现这种概念近似的方法,
与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。,表示概念间近似,,,Stuckenschmidt_H的方法,
与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。,表示,,,not cause mapping result loss,
与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。,缺点,,,obvious disadvantage,
第一是查询效率问题。,SPO,,,查询效率问题,
该方法需要遍历所有实例计算概念近似。,概念近似,,,该方法,
得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。,得到的近似查询,,,很多小查询构成的,
第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。,OWL_2_SROIQ,,,基于概念间的包含关系,
最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。,近似,,,不能传递,
最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。,近似,,,approximate,
④基于多元界的概念近似。,基于多元界的概念近似,,,基于多元界的概念近似。,
Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。,概念近似查询,,,approximate query,
这种方法能进一步推广到关系映射的发现。,SPO,,,关系映射的发现,
由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。,等价,,,equivalence,
基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。,基于多元界的概念近似方法,,,考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似,
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的析取定义概念的多元最小上界,,,将概念的最小上界,
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的析取定义概念的多元最小上界,,,min_upper_bound,
将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。,概念的合取定义概念的多元最大下界,,,max_lower_bound,
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,概念的多元最小上界,,,得到概念的最小上近似,
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,概念的多元最大下界,,,得到概念的最大下近似,
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,最小上界,,,minimum upper bound,
证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。,最大下界,,,maximum lower bound,
通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。,多元界,,,概念近似表达的复杂度，降低查询效率,
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的多元界,,,去除冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元最小上界,,,minimal_multiple_upper_bound,
该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。,概念的最简多元最大下界,,,maximal_multiple_lower_bound,
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似的定义,,,给出概念最佳近似的定义,
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似的定义,,,概念的最小上近似,
该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。,概念最佳近似的定义,,,概念的最大下近似,
引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。,概念析取,,,概念间蕴涵关系,
引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。,概念析取,,,include the concept analysis,
由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。,新的上下界,,,概念的多元界,
由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。,上下界,,,多元界,
证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。,多元界,,,概念的最佳近似,
这是该方法的理论基础。,SPO,,,概念/方法,
3）FCA。,FCA,,,概念/产品,
"Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。",FCA-Merge,,,自底向上的本体合并方法,
该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。,本体合并,,,概念映射,
该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。,合并后的本体,,,overlap ontology,
当然，这些概念分别来自两个不同的初始本体。,概念/SPO,,,初始本体,
①形式化概念分析基础。,OWL_2_QL,,,形式化概念分析基础,
首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。,形式概念分析,,,概念格,
首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。,形式概念分析,,,"formal concept analysis, also called concept lattice",
形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。,形式概念分析,,,Wille_R,
形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。,形式概念分析,,,formal concept analysis,
概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。,概念格,,,形式概念,
概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。,概念格中的节点,,,形式概念,
另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。,概念格,,,Hasse图,
另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。,概念格,,,Hasse图,
因此，概念格被认为是进行数据分析的有力工具。,概念格,,,进行数据分析的有力工具,
从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。,概念格,,,生成概念格的过程,
从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。,概念格,,,concept lattice,
"形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。",形式背景,,,"三元组形式T=(S,D,R)",
"(s,d)∈R表示实例s有属性d。",SPO,,,三元组,
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,形式背景,,,偏序集合,
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,形式背景,,,formal background,
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,偏序集合,,,preorder set,
一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。,格结构,,,lattice structure,
"这种由背景(S,D,R)导出的格L就称为一个概念格。",概念格,,,"背景(S,D,R)导出",
"格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。",格L,,,序偶,
"每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|∀y∈Y,xRy}2）Y={y∈D|∀x∈X,xRy}在概念格节点间能够建立起一种偏序关系。",每一个序偶,,,关系R,
"给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1⇔Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。",H2,,,H1的父节点或称直接泛化,
"给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1⇔Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。",H2,,,H1,
"给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1⇔Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。",H1,,,H2,
根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。,Hasse图,,,偏序关系生成的图,
根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。,偏序关系,,,Hasse图,
②自底向上的FCA-Merge本体合并。,FCA-Merge本体合并,,,自底向上的FCA-Merge本体合并。,
该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。,本体映射,,,自底向上的方式来合并两个共享相同实例集的本体,
该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。,自底向上的方式合并两个共享相同实例集的本体,,,bottom-up approach to merge two ontologies sharing the same instance set,
整个本体合并的过程分三步。,本体合并,,,整个本体合并的过程分三步,
（a）实例提取。,实例提取,,,概念/产品,
由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。,FCA-Merge,,,FCA合并,
从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。,从相同的文本集合为两个本体提取实例,,,保证两本体相关的概念具有相近的共享实例集合,
从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。,从相同的文本集合为两个本体提取实例,,,extract instances,
而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。,提取共享实例,,,提取相似概念的基础,
而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。,提取共享实例,,,识别相似概念的基础,
这一步采用自然语言处理技术，得到两本体的形式背景。,本体的形式背景,,,采用自然语言处理技术,
每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。,FCA-Merge,,,FCA合并,
显然，一个文档可能是多个概念的实例。,文档,,,多个概念的实例,
（b）概念格计算。,概念格计算,,,概念/产品,
输入第一步中得到的两张布尔表来计算概念格。,输入第一步中得到的两张布尔表,,,概念格,
输入第一步中得到的两张布尔表来计算概念格。,概念格,,,concept lattice,
"FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。",FCA-Merge,,,经典的形式化概念分析理论,
（c）交互生成合并的本体。,c,,,交互生成合并的本体,
生成的概念格已经将独立的两个本体合并在一起。,生成的概念格,,,独立的两个本体合并在一起,
本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。,本体工程师,,,生成概念格,
显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。,合并的本体,,,初始本体概念间的映射关系,
显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。,合并的本体,,,equivalent,
②FCA总结。,FCA,,,总结,
形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。,形式化概念分析技术,,,本体间共享实例解决本体映射的发现问题,
形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。,形式化概念分析技术,,,formal concept analysis technique,
这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。,本体概念间的等价和包含映射,,,发现异构本体概念间的等价和包含映射,
FCA具有一些不足。,FCA,,,不足,
首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。,OWL_2_生成方法,,,不考虑复杂概念间的映射,
首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。,SPO,,,等价,
其次，映射结果质量受提取共享实例过程的影响。,映射结果质量,,,提取共享实例过程,
最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。,概念格生成合并本体的工作,,,错误映射结果,
4）IF-Map。,IF-Map,,,概念/产品,
该方法是一种自动的本体映射发现技术，基于信息流理论[71]。,本体映射发现技术,,,自动的本体映射发现技术，基于信息流理论,
该方法是一种自动的本体映射发现技术，基于信息流理论[71]。,本体映射发现技术,,,基于信息流理论,
IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。,IF-Map,,,寻找两个局部本体间的等价,
IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。,IF-Map,,,寻找两个局部本体间的等价,
那样的参考本体没有实例，而实例只在局部本体中才考虑。,参考本体,,,没有实例,
因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。,IF-Map,,,生成参考本体和局部本体之间的可能映射,
因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。,IF-Map,,,生成参考本体和局部本体之间的可能映射,
映射生成的过程包括4个阶段：①采集，即收集不同的本体；②转换，即将待映射本体转换为特定格式；③信息映射生成，即利用信息流理论生成本体间的映射；④映射投影，将生成的概念间等价映射用本体语言表示出来，如owl:sameAs等。,映射生成的过程,,,map generation,
IF-Map也只能生成异构本体概念间的简单等价映射。,IF-Map,,,异构本体概念间的简单等价映射,
（3）基于实例的本体映射总结。,基于实例的本体映射,,,基于实例的本体映射总结,
与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。,基于实例的本体映射发现方法,,,基于术语和结构的映射发现方法,
与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。,基于实例的本体映射发现方法,,,based on instance ontology mapping discovery method,
一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。,基于实例的方法,,,解决异构本体概念间的映射问题,
一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。,基于实例的方法,,,based on instance method,
此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。,基于实例的映射方法,,,based on instance method,
3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。,综合方法,,,映射方法,
因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。,本体映射,,,多种映射方法综合使用,
因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。,本体映射,,,combine multiple mapping methods,
（1）方法和工具1）QOM。,方法和工具,,,QOM,
QOM是采用综合方法发现本体映射的典型工作[72-75]。,QOM,,,采用综合方法发现本体映射的典型工作,
QOM是采用综合方法发现本体映射的典型工作[72-75]。,QOM,,,采用综合方法发现本体映射的典型工作,
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,A_2,,,寻找映射过程中同时考虑了映射结果的质量与发现映射的时间复杂度,
该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。,等价,,,equivalence,
QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。,QOM,,,映射发现算法,
QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。,QOM,,,合理组织各种映射发现算法,
①QOM的思路。,QOM,,,思路,
大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。,本体映射发现算法,,,强调映射结果的质量，而往往忽略发现映射的效率,
"目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。",时间复杂度,,,O(n2),
对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。,大本体间的映射需求,,,无法实用,
对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。,大本体间的映射需求,,,对于UMLS（107个概念）与WordNet（106个概念）之间的映射而言,
对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。,很多方法,,,由于效率太低而无法实用,
与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。,QOM给出的映射发现方法,,,考虑映射质量和运行时间复杂度,
与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。,QOM给出的映射发现方法,,,quality-of-mapping-discovery-by-QOM,
QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。,QOM,,,考虑异构本体间1∶1等价映射,
②QOM方法的过程。,QOM方法,,,属于QOM方法的过程,
QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。,本体映射,,,QOM处理本体映射的过程,
QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。,QOM处理本体映射的过程,,,六步,
特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。,特征工程,,,将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征,
特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。,特征工程,,,transform initial input ontology into a unified format for similarity calculation and analyze the mapping objects,
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,标识,,,URIs或RDF标签,
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,RDF(S)原语,,,属性或子类关系,
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,推导出的特征,,,由RDF(S)原语推导出的特征,
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,OWLsameAs等表示等价的原语,,,,
QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。,领域中特定的特征,,,例如某领域中概念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理,
搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。,QOM,,,启发式方法降低候选映射对象的数目,
搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。,搜索步骤,,,search steps,
相似度计算：对每一对候选映射对象，判断它们之间的相似度值。,相似度计算,,,对每一对候选映射对象，判断它们之间的相似度值。,
相似度计算：对每一对候选映射对象，判断它们之间的相似度值。,相似度计算,,,calculate the similarity value,
一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。,对象,,,不同类型的信息描述,
一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。,一个对象,,,信息描述,
QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。,QOM,,,多种关于对象特征的相似度量公式,
为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。,选择度量公式,,,提高发现映射的效率,
为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。,选择度量公式,,,ignore those complex over high measuring formula,
相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。,相似度累加,,,多种度量方法,
相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。,相似度累加,,,similarity addition,
这些不同的相似度值需要累加，成为单个的相似度值。,相似度值,,,需要累加,
这些不同的相似度值需要累加，成为单个的相似度值。,相似度值,,,sum,
QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。,QOM,,,直接累加方式,
解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。,去除不正确的映射结果,,,利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则,
解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。,去除不正确的映射结果,,,remove incorrect mapping results,
根据处理后的最终相似度值判断本体之间的映射。,本体之间的映射,,,根据处理后的最终相似度值判断,
迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。,迭代,,,算法过程可迭代执行，每次迭代都能提高映射结果的质量,
每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。,相似度计算,,,贪婪策略,
③实验评估和结果。,实验评估和结果,,,SPO三元组,
QOM分析了几种典型的本体映射方法的时间复杂度。,本体映射方法的时间复杂度,,,QOM分析,
"iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。",iPROMPT的复杂度,,,O(n·log(n)),
"iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。",AnchorPROMPT的复杂度,,,O(n2·log2(n)),
"iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。",GLUE的复杂度,,,O(2n),
"iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。",iPROMPT,,,等价O(n·log(n)),
"iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。",AnchorPROMPT,,,等价O(n2·log2(n)),
与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n·og(n))。,QOM,,,忽略一些造成较高复杂度的方法,
与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n·og(n))。,QOM,,,Query On Mapping,
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,,,时间复杂度虽然低，但映射结果的质量不尽如人意,
注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。,iPROMPT,,,输入提示,
试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。,QOM,,,保证一定映射结果质量的前提下，尽量提高发现映射的效率,
2）OLA。,OLA,,,SPO三元组,
"OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。",OLA,,,本体映射发现综合方法,
"OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。",OLA,,,本体映射发现综合方法,
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,,,本体间的映射,
目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。,OLA,,,本体间的映射,
OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。,OLA算法,,,将OWL本体编码为图，图中的边为概念之间的关系,
OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。,OLA算法,,,将OWL本体编码为图，图中的边为概念之间的关系,
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,,,根据类和它的属性将节点进行分类,
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,,,考虑分类后节点中的所有特征，如父类和属性等,
图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。,图节点之间的相似度,,,"根据类和它的属性将节点进行分类;考虑分类后节点中的所有特征,如父类和属性等",
实体之间的相似度被赋予权重并线性累加。,实体相似度的相似度,,,赋予权重并线性累加,
实体之间的相似度被赋予权重并线性累加。,相似度,,,similarity,
OLA能发现本体概念间的等价映射。,OLA,,,发现本体概念间的等价映射,
3）KRAFT。,KRAFT,,,SPO三元组,
"KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。",本体映射的体系结构,,,发现1∶1的本体映射,
"KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。",本体映射的体系结构,,,one-one mapping,
这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。,概念映射,,,concept mapping,
这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。,属性映射,,,attribute mapping,
这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。,关系映射,,,relation mapping,
这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。,复合映射,,,composite mapping,
KRAFT并没有给出映射发现的方法。,KRAFT,,,映射发现的方法,
4）OntoMap。,OntoMap,,,概念/产品,
OntoMap是一个知识表示的形式化、推理和Web接口。,OntoMap,,,知识表示的形式化、推理和Web接口,
它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。,OWL_S,,,访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射,
它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。,SPO,,,表示它们之间的映射,
为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。,OntoMap,,,OntoMapO,
为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。,OntoMap,,,OntoMapO,
这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。,OWL_2_EL,,,描述本体映射的特定原语,
这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。,OWL_2_EL,,,描述本体映射的特定原语,
OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。,OntoMapO,,,上层本体,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言中映射原语,,,MuchMoreSpecific,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言中映射原语,,,MuchMoreGeneral,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言中映射原语,,,TopInstance,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,映射语言中映射原语,,,ParentAsInstance_MuchMoreSpecific_ChildAsClass,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,MuchMoreSpecific,,,两个概念的特化程度,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,MuchMoreGeneral,,,与相反,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,TopInstance,,,最特化的概念,
映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。,ParentAsInstance_MuchMoreSpecific_ChildAsClass,,,映射原语,
这些原语表明了OntoMapO支持的映射类型。,OntoMapO支持的映射类型,,,原语,
这些原语表明了OntoMapO支持的映射类型。,OntoMapO支持的映射类型,,,OntoMap,
但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。,OntoMap,,,创建映射,
但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。,OntoMap,,,OntoMap,
因此，OntoMap更多只是提供了一个映射的表示框架。,OntoMap,,,映射的表示框架,
因此，OntoMap更多只是提供了一个映射的表示框架。,OntoMap,,,一个概念的映射的表示框架,
和5）OBSERVER。,OBSERVER,,,概念/产品,
OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。,OBSERVER系统,,,解决分布式数据库的异构问题,
OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。,OBSERVER系统,,,观察者系统,
OBSERVER使用基于组件的方法发现本体映射。,OBSERVER,,,基于组件的方法发现本体映射,
它使用多个预先定义的本体来表示异构数据库的模式。,OWL_2_QL,,,表示异构数据库的模式,
映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。,本体间互操作,,,映射,
OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。,OBSERVER,,,两个组件本体之间的1∶1映射,
OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。,OBSERVER,,,等价,
但是，该方法的本体映射依靠手工建立。,本体映射,,,手工建立,
6）InfoSleuth。,InfoSleuth,,,SPO三元组,
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,,,基于主体的系统,
"InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。",InfoSleuth,,,基于主体的系统,
本体间的映射是概念间的关系。,本体间的映射,,,概念间的关系,
本体的映射由一个特殊的被称为“资源主体”的类完成。,本体的映射,,,“资源主体”的类,
一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。,资源主体,,,本体映射的规则集,
7）基于虚拟文档的本体匹配。,基于虚拟文档的本体匹配,,,本体匹配,
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,本体元素,,,词汇,
本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。,本体元素,,,使用的词汇,
元素还可以通过自身注释中的简单语句，对其含义进行补充说明。,元素,,,补充说明,
此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。,语义描述,,,文本形式,
此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。,语义描述,,,语义描述,
因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。,本体中元素,,,虚拟文档表示相应的元素,
一个元素的虚拟文档包含3种。,一个元素的虚拟文档,,,3种,
"①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。",Des(e),,,元素自身的描述文本,
"①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。",Des（e）,,,元素的描述文本,
②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,空节点的描述文档,,,Des（e）,
②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,空节点的描述文档Des（e）,,,对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。,
在此过程中，越远的元素会被赋予越小的描述权重。,描述权重,,,在此过程中，越远的元素,
③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。,元素的邻居,,,根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本,
③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。,元素的邻居,,,element's neighbor,
注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。,邻居的描述方式,,,空节点的描述方式,
注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。,空节点,,,empty node,
在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。,虚拟文档,,,给定一个元素e,
在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。,虚拟文档,,,构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。,
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,语义描述文档相似度,,,两元素的语义描述文档相似度,
两元素的语义描述文档相似度越高，它们相匹配的可能性越大。,语义描述文档相似度,,,semantic description document similarity,
描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。,相似度计算,,,相同类型的文档中进行的,
描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。,相似度计算,,,calculate the similarity,
"虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,…,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。",虚拟文档的表示形式,,,带权重的词汇集合,
"虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,…,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。",向量空间模型,,,文本向量空间模型,
基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。,基于虚拟文档的方法,,,方法思想直观，易于实现,
（2）本体映射的综合方法总结。,本体映射的综合方法总结。,,,本体映射方法,
考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。,本体映射,,,多种映射方法,
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,多种方法,,,改善映射质量,
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,多种方法,,,权衡,
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,引入一些方法,,,降低原有算法的效率,
但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。,多种方法,,,combine methods,
此外，将各种映射方法的结果进行综合也很重要。,综合,,,各种映射方法的结果,
5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。,本体映射管理,,,捕获异构本体间的关系,
5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。,本体映射管理,,,map management,
要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。,多本体管理,,,对多本体进行有效的管理,
管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。,管理多个本体,,,好处,
管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。,管理多个本体,,,manage multiple ontologies,
这里讨论如何通过组织映射来达到管理异构的多本体的目的。,组织映射,,,通过组织映射来达到管理异构的多本体的目的,
实际上，在数据库等领域中就有针对模式或模型管理的研究。,模式或模型管理,,,数据库等领域中就有针对模式或模型管理的研究。,
他们指出，模型间的映射和操作是模型管理的核心问题。,模型管理的核心问题,,,模型间的映射和操作,
他们指出，模型间的映射和操作是模型管理的核心问题。,模型间的映射和操作,,,model management core problem,
"在本体研究领域，一些工作分析了本体管理的挑战[87,88]。",本体研究领域的工作,,,分析本体管理的挑战,
这些研究将本体管理的任务分为两方面。,本体管理的任务,,,两方面,
一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。,本体库系统,,,增强本体管理,
一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。,本体库系统,,,ontology library system,
另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。,本体版本或演化,,,研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。,
另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。,本体版本或演化,,,ontology version or evolution,
Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。,Stoffel_K等人设计的一个处理大规模本体的系统,,,为在短时间内给出对大规模本体的复杂查询回答,
Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。,本体管理系统,,,企业级的本体管理系统,
Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。,OntoManager,,,本体管理系统,
Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。,OntoManager,,,本体管理系统,
显然，这些工作都关注本体的表示、存储和维护。,本体的表示、存储和维护,,,工作,
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,本体融合的五大方法,,,处理单个本体,
而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。,本体映射或演化问题,,,"only deal with single ontology, no consideration of multiple ontology mapping or evolution",
但这些工作为管理多个本体打下了基础。,OWL_2_CR,,,为管理多个本体打下了基础,
Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。,PROMPTDiff,,,处理版本管理框架,
Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。,PROMPTDiff,,,处理版本管理框架,
PROMPTDiff只使用结构不同检测两个版本的不同。,PROMPTDiff,,,结构不同检测两个版本的不同。,
而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。,本体变化描述,,,log changes、conceptual relationship and transmission set,
Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。,单个本体演化,,,Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架,
Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。,本体演化的框架,,,变化说明语言,
Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。,变化说明语言,,,CHANGE_LANGUAGE,
从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。,本体管理工作,,,关注本体演化或本体版本变化问题,
这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。,多本体的潜在能量,,,管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。,
与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。,Xu_Baowen,,,从功能角度来探讨多本体管理,
传统的本体管理通常是二层结构：本体存储层和应用层。,本体存储层,,,传统的本体管理,
传统的本体管理通常是二层结构：本体存储层和应用层。,本体存储层,,,ontology storage layer,
传统的本体管理通常是二层结构：本体存储层和应用层。,应用层,,,application layer,
二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。,二层架构的多本体管理,,,过于粗糙,
二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。,二层架构的多本体管理,,,overlay multi-ontology management,
Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。,本体间的映射,,,管理多本体的映射来处理这些问题,
Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。,本体间的映射,,,bridge_ontology,
这样的管理方式具有灵活的特点，适应动态Web环境。,管理方式,,,适应动态Web环境,
然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。,多本体,,,提供面向应用的通用功能，避免使用多本体时的大量重复工作,
Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。,Xu_Baowen,,,五层体系结构的多本体管理框架,
框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。,框架,,,本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层,
五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。,五层的多本体管理体系结构,,,面向发挥多本体功能,
五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。,五层的多本体管理体系结构,,,Five-tier multi-ontology management architecture,
各层的具体功能如下：①本体库层。,各层的具体功能,,,本体库层,
本体库层存放不同渠道获得的本体。,本体库层,,,不同渠道获得的本体,
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体,,,创建者与创建时间不同，模型和本体语言上具有差异,
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体,,,ontology,
本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。,本体语言,,,本体模型语言,
②本体表示层。,本体表示层,,,本体层,
不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。,本体语言的语法、逻辑模型和表达能力,,,差异,
这种转换会造成一些信息的损失。,信息损失,,,这种转换,
通常少许的非关键本体信息在转换中丢失是可容忍的。,非关键本体信息,,,转换中丢失,
③桥本体层。,桥本体层,,,SPO三元组,
多本体间常常重叠，其间往往有关联。,多本体,,,多本体间常常重叠，其间往往有关联。,
为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。,生成的桥本体,,,为使用多本体而避免本体集成,
桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。,桥本体,,,特殊的本体，可表示本体间概念和关系的12种不同映射,
桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。,桥本体,,,一特殊的本体，可表示本体间概念和关系的12种不同映射,
"在这层中，利用文献[62,36]的方法生成本体间的映射。",本体间的映射,,,利用文献,
桥的生成是半自动化的，并在桥本体中组织管理。,桥的生成,,,半自动化的,
本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。,本体间映射生成过程,,,语义冗余和冲突,
Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。,Xu_Baowen,,,分析多本体环境的语义一致性检查问题和冗余化简算法,
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,良性回路,,,将引入桥后的多本体中的回路,
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,良性回路,,,benign loop,
对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。,恶性回路,,,malignant loop,
前者是由于引入等价桥后造成的，通过算法可消除。,等价类,,,引入等价桥后造成的,
后者是由于原始本体中的错误或引入不当的桥造成的。,后者,,,原始本体中的错误或引入不当的桥,
算法能够找到环路，但区分恶性和良性环路需要人工参与。,算法,,,找到环路,
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,,,经过语义检查的多本体环境,
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,,,ensure the mapping in the graph is without redundancy,
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,,,保证该图中的映射是无冗余的,
经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。,语义化简,,,保证整个多本体环境的连通性,
本体间映射抽取出来，可通过桥本体进行管理。,本体间映射,,,桥本体进行管理,
当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。,增量更新算法,,,为减少重新生成映射的代价,
④多本体功能层。,多本体功能层,,,本体功能层,
多本体的管理能提供满足应用需求的一些主要功能。,多本体的管理,,,能提供满足应用需求的一些主要功能,
第一，桥本体中的桥提供了大量的简单和复杂的本体映射。,桥本体中的桥,,,大量的简单和复杂的本体映射,
通过这些映射，很容易实现异构本体间的互操作问题。,映射,,,异构本体间的互操作问题,
第二，利用多本体间的桥，能实现跨不同本体的推理。,多本体间的桥,,,跨不同本体的推理,
第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。,桥本体,,,信息检索,
第四，还可以从多本体中抽取满足需求的子本体。,第四,,,从多本体中抽取满足需求的子本体,
第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。,本体,,,语义标注,
⑤多本体应用层。,多本体应用层,,,本体应用层,
在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。,应用层,,,多本体的功能,
5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。,本体映射,,,ontology mapping,
大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。,本体,,,大本体难以驾驭,
使用整个本体会大大增加系统的复杂性和降低效率。,本体的缺点,,,使用整个本体会大大增加系统的复杂性和降低效率。,
因此，从源本体中抽取一个小的子本体能让系统更有效。,从源本体中抽取一个小的子本体,,,让系统更有效,
子本体抽取是一个新的研究领域。,子本体抽取,,,一个新的研究领域,
Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。,物化本体视图抽取的顺序抽取过程,,,Wouters_C等人提出物化本体视图抽取的顺序抽取过程,
Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。,物化本体视图抽取的顺序抽取过程,,,顺序抽取过程,
随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。,分布式方法,,,降低从大的复杂本体中抽取子本体的代价,
Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。,Bhatt_M等人,,,分析语义完整性问题,
Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。,PROMPTFactor本体抽取工具,,,从单个本体中获得语义独立的子本体,
Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。,PROMPTFactor,,,从单个本体中获得语义独立的子本体,
当前的方法都是从单个本体中抽取子本体。,抽取子本体,,,当前的方法,
但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。,子本体,,,多本体环境下的应用,
从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。,多本体中抽取子本体,,,知识重用,
Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。,Kang_Dazhou,,,从多本体中抽取子本体的方法,
抽取子本体是一种重要的知识重用手段。,抽取子本体,,,知识重用手段,
本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。,本体映射,,,多本体间的联系,
本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。,本体映射,,,ontology mapping,
在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。,本体映射和匹配结果,,,语义搜索和智能问答,
在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。,本体映射和匹配结果,,,ontology mapping and matching results,
5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。,实例层的融合与匹配,,,知识融合,
5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。,实例层的融合与匹配,,,matching on actual application,
实例匹配的过程虽然与本体匹配有相似之处，但实例匹配通常是一个大规模数据处理问题，需要在匹配过程中解决其中的时间复杂度和空间复杂度问题，其难度和挑战更大。,实例匹配,,,本体匹配,
5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。,本体,,,知识表示,
人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。,本体,,,描述通用知识的大规模本体,
与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。,本体,,,整合、归纳和分享领域内的专业知识,
这些本体的规模正随着人类知识的增长而变得越来越大。,本体,,,人类知识的增长,
近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。,建立大规模本体间映射的需求,,,建立不同领域知识间交叉和基于不同本体系统间交互的需求,
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,映射系统,,,无法在用户可接受的时间内给出满意的映射结果,
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,映射系统,,,往往会由于匹配过程申请过大的内存空间而导致系统崩溃,
然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。,映射系统,,,map system,
因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。,本体映射问题,,,目前本体映射研究中的一个挑战性难题,
因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。,本体映射,,,ontology mapping,
本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。,大规模本体映射方法,,,提出一种新的大规模本体映射方法,
从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。,本体,,,ontology,
这些大本体总体上可划分为三类：通用本体，即用于描述人类通用知识、语言知识和常识知识的本体，如Cyc、WordNet和SUMO等；领域本体，各个领域中的研究人员也建立了很多专业领域中的本体，如生物医学领域中的基因本体和统一医学语言系统本体UMLS；企业应用本体，为了有效管理、维护和利用拥有的大量数据，很多企业都利用本体对自身的海量数据进行重组，以便为用户提供更高效和智能的服务。,本体,,,ontology,
出于商业保密的目的，这些企业本体通常并不公开。,本体,,,出于商业保密的目的，这些企业本体通常并不公开。,
大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。,大规模本体,,,机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用,
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,概念,,,concept,
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,关系,,,relation,
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,实例,,,instance,
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,公理,,,axiom,
表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。,本体,,,ontology,
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,,,元素数庞大,
从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。,大规模知识图谱,,,实例数据较多,
基于不同大规模知识图谱的系统间可能需要进行交互。,基于不同大规模知识图谱的系统,,,交互,
一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。,应用集成,,,借助映射对多个知识图谱进行集成,
随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。,本体,,,UMLS本体中的语义信息,
随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。,本体,,,ontology,
总之，大规模知识图谱间的异构现象依然普遍存在。,大规模知识图谱间的异构现象,,,普遍存在,
在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。,大规模知识图谱匹配,,,建立大规模知识图谱间的匹配,
大规模知识图谱匹配是极具挑战性的任务。,大规模知识图谱匹配,,,极具挑战性的任务,
Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。,Reed,,,SENSUS,
Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。,Lenat,,,WordNet,
Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。,Reed,,,UMLS,
显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。,自动化知识图谱匹配,,,人工和半自动的方法,
显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。,自动化知识图谱匹配,,,automated knowledge graph matching,
"传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。",分治法,,,处理大规模模式匹配,
"传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。",分治法,,,divide and conquer,
然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。,知识图谱匹配,,,传统模式匹配的分治方法,
在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。,参与评估的18个映射系统,,,2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务,
2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。,完成anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务,,,2008年参与OAEI评估的13个映射系统,
由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。,公开的系统,,,不能处理大规模知识图谱匹配问题,
大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。,大规模知识图谱匹配问题,,,对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验,
1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。,知识图谱匹配,,,空间复杂度挑战,
1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。,空间复杂度挑战,,,space complexity challenge,
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配中的主要数据结构,,,空间复杂度,
通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。,知识图谱匹配中的主要数据结构,,,相似矩阵,
当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。,操作系统内存不足的错误,,,操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误,
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,相似矩阵,,,存储该矩阵所需的空间,
很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。,相似矩阵,,,similarity matrix,
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,知识图谱匹配,,,数据结构，并利用有效的存储压缩策略,
因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。,数据结构,,,data structure,
目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。,知识图谱匹配,,,现有计算机存储能力,
目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。,知识图谱匹配,,,knowledgemetmatching,
因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。,空间复杂度,,,大规模知识图谱匹配,
因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。,空间复杂度,,,spo,
2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。,知识图谱匹配系统的执行时间,,,匹配计算过程,
2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。,知识图谱匹配系统的执行时间,,,matching system time,
为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。,相似度,,,similarity,
虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。,匹配方法,,,O(nlog(n))复杂度的匹配方法,
虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。,匹配方法,,,O(nlog(n))复杂度的匹配方法,
此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。,匹配器,,,计算元素相似度的速度,
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,匹配系统的总时间复杂度,,,O(n2t),
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,计算两元素相似度过程的时间复杂度,,,t,
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,时间复杂度,,,t,
令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。,匹配系统的总时间复杂度,,,O(n2t),
因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。,降低大规模知识图谱匹配问题的时间复杂度,,,减少匹配元素对的相似度计算次数,
因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。,降低大规模知识图谱匹配问题的时间复杂度,,,减少匹配元素对的相似度计算次数,
3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。,匹配方法的时间复杂度和空间复杂度,,,降低匹配结果质量挑战,
此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。,有效的匹配算法,,,对知识图谱进行全局分析和整理,
然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。,概念/知识图谱的五大用途或特点,,,处理知识图谱,
然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。,简化或近似处理,,,simplify or approximate processing,
最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。,分治的策略,,,将大规模知识图谱匹配问题转换为多个小规模匹配问题,
最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。,分治,,,divide and conquer,
尽管目前能处理该问题的映射系统还较少，但一些研究者已进行了积极尝试，其中包括集成通用本体用于机器翻译[104]，建立Web_Directory之间的映射用于信息检索[105]，以及匹配生物医学领域的本体用于不同医学系统间信息交互[106-108]等。,本体,,,ontology,
最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。,知识图谱匹配任务,,,处理该问题的方法,
最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。,OAEI评估,,,每年都得到改进,
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,大规模知识图谱匹配方法,,,基于快速相似度计算的方法,
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,大规模知识图谱匹配方法,,,基于规则的方法,
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,大规模知识图谱匹配方法,,,基于分治的方法,
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,基于快速相似度计算的方法,,,基于规则的方法,
本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。,基于规则的方法,,,基于分治的方法,
就目前来看，现有的大规模知识图谱匹配系统都能克服空间复杂度问题，因为匹配过程中需要的大量空间可以借助数据压缩技术（如将稀疏矩阵压缩存储）、外部数据库或临时文件等方式解决。,知识图谱匹配系统,,,克服空间复杂度问题,
因此，下面着重分析三类方法的时间复杂度。,三类方法,,,分析时间复杂度,
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,,,降低每次相似度计算的时间复杂度,
5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。,基于快速相似度计算的实例匹配方法,,,基于快速相似度计算的实例匹配方法,
基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。,基于快速相似度计算的方法,,,匹配器,
很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。,文本相似的匹配算法,,,基于文本相似的匹配算法,
大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。,结构匹配器,,,概念层次或元素邻居文本相似的启发式规则计算相似度,
大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。,结构匹配器,,,structural matcher,
采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。,采用上述思想的系统,,,处理一些大规模知识图谱匹配问题,
首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。,匹配器,,,知识图谱中少量的信息构造匹配线索,
首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。,匹配器,,,match-maker,
其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。,系统效率,,,相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响,
其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。,系统效率,,,system efficiency,
Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。,Mork和Bernstein,,,对FMA和GALEN两个大规模本体进行匹配,
Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。,Mork和Bernstein,,,对FMA和GALEN两个大规模本体进行匹配,
Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。,Web_Directory,,,匹配方法,
Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。,Web_Directory的匹配,,,统计共享实例,
此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。,相似度计算,,,寻找最佳的相似函数和阈值,
5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。,基于规则的实例匹配方法,,,寻找匹配规则,
但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。,规则匹配方法,,,人工构建的规则来保证结果质量,
但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。,规则匹配方法,,,rule matching method,
基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。,基于规则的方法,,,扩展到处理大规模知识图谱中的实例匹配,
基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。,基于规则的方法,,,based on rule method,
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,基于EM算法的半监督学习框架,,,实例匹配过程,
上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。,基于EM算法的半监督学习框架,,,semi-supervised learning framework based on EM algorithm,
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,OWL_2_RL,,,迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对,
该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。,SPO,,,schema,
具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。,等价,,,owl:sameAs,
该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。,基于图的指标度量匹配的精确度,,,EM算法的目标似然函数,
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,匹配对的匹配置信度,,,集成不同规则的置信度,
在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。,匹配对的匹配置信度,,,integrate different rules of confidence,
该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。,DEMPSTER_规则,,,集成同一个匹配对的不同置信度,
图5-12基于规则挖掘的实例匹配过程[112]在进一步介绍该方法之前，需要定义一些基础概念。,基于规则挖掘的实例匹配过程,,,基于规则挖掘,
定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。,实例等价,,,定义5.12（实例等价）记作～I,
定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。,实例等价,,,～I,
"URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。",e1,,,等价的URI不同的两个实例,
"URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。",等价,,,equivalence,
"定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。",匹配,,,定义5.13（匹配）,
"定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。",匹配,,,match,
如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。,预处理完成后实例,,,属性-值对信息,
然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。,种子匹配对,,,导入系统中驱动发现新的匹配,
然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。,种子匹配对,,,seed matching pair,
重复迭代步骤直至满足终止条件。,重复迭代,,,迭代,
前面提到，该框架通过学习规则来推导实例之间的等价关系。,OWL_2_CRS,,,通过学习规则来推导实例之间的等价关系,
首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。,属性等价关系,,,挖掘,
首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。,等价实例,,,find new equivalent instances,
"实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。",实例等价,,,推导出规则,
"实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。",等价,,,equivalence,
"（p（e,o）是三元组＜e,p,o＞的函数式表示，o1≃o2表示o1和o2指向同一实例或者字面值相等）。",p,,,三元组,
"（p（e,o）是三元组＜e,p,o＞的函数式表示，o1≃o2表示o1和o2指向同一实例或者字面值相等）。",等价,,,equivalence,
这样的规则可以推导出大量的等价实例，从而完成实例匹配。,等价实例推导,,,实例匹配,
"定义5.14（属性-值对等价）给定两个隐含等价属性（p1,p2）和两个值（o1,o2），属性-值对＜p1,o1＞和＜p2,o2＞等价当且仅当＜o1,o2＞∈～I（o1,o2为实例），或者o1=o2（o1,o2为字面值），记作～P。",属性-值对等价,,,定义5.14（属性-值对等价）,
"定义5.14（属性-值对等价）给定两个隐含等价属性（p1,p2）和两个值（o1,o2），属性-值对＜p1,o1＞和＜p2,o2＞等价当且仅当＜o1,o2＞∈～I（o1,o2为实例），或者o1=o2（o1,o2为字面值），记作～P。",等价,,,equivalence,
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",属性-值对集,,,给定一个实例e和属性集合P,
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",属性-值对集,,,property-value pair set,
"将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",给定一个实例e和属性集合P,,,"属性集合P给定一个实例e和属性集合P属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。",
"定义5.15（等价属性-值对集）给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞），两个键值对集等价当且仅当存在一个从到的双射f∈～P，记作～S。",等价属性-值对集,,,"给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞）",
"定义5.15（等价属性-值对集）给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞），两个键值对集等价当且仅当存在一个从到的双射f∈～P，记作～S。",等价属性-值对集,,,equivalence attribute-value pair set,
"定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。",等价属性对集,,,逆功能属性集,
"定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。",等价属性对集,,,InverseFunctional_Property_Suite,
定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。,逆功能属性集规则,,,基于逆功能属性集eps,
定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。,等价,,,IFPS_Rule,
"对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。",扩展的逆功能属性集规则,,,IFPS规则,
"对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。",等价,,,IFPS规则,
"对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。",扩展的逆功能属性集规则,,,基于逆功能属性集eps,
"对于所有eps里的属性对＜pi1,pi2＞,EIFPS规则有如下形式：根据以上定义，该方法实现了一个基于EM算法的实例匹配框架，输入为待匹配三元组、初始匹配对阈值，输出为匹配结果集与IFPS规则集。",EIFPS,,,基于EM算法的实例匹配框架,
该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,EM算法迭代,,,E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,
该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,E步,,,根据已经获得的EIFPS规则计算实例对应的置信度,
该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。,M步,,,根据现有的匹配结果挖掘EIFPS规则,
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,匹配图,,,估计算法的匹配进度,
这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。,匹配图,,,无向带权图,
根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。,匹配图,,,EIPFS规则集合,
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EM算法中的似然函数,,,提取出的匹配图和实际匹配图的相似程度,
"EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。",EM算法中的似然函数,,,提取出的匹配图和实际匹配图的相似程度,
采用准确度优先策略，可以得到以下的近似公式，用精确度来代表在一个EIPFS规则集合下，提取出来的对应图和真正的对应图之间的关系：最后，求出的匹配图M的精确度等于M中被连接的成分除以M中边的数量：L（θ;M）≈Precision（M|θ）同一个匹配对可能会由不同的EIFPS规则导出，该匹配对有多个匹配置信度，因此集成两个置信度是一个很有必要的工作。,精确度,,,Precision（M|θ）,
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,向量空间模型,,,集成向量空间模型,
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,取两者之间的较大值,,,取较大值,
传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。,两次匹配的信息,,,利用了两次匹配的信息,
这里给出了另外的两种集成方式，具体如下：第1种是基于概率理论：conf1⊕conf2=1−（1−conf1）（1−conf2）第2种利用了一种特殊性形式下的贝叶斯理论的泛化理论（Dempster-Shafertheory）：该方法先后用在DBpedia、GeoNames、LinkedMDB、GeoSpecies等知识图谱间进行实例匹配。,等价,,,基于概率理论,
这里给出了另外的两种集成方式，具体如下：第1种是基于概率理论：conf1⊕conf2=1−（1−conf1）（1−conf2）第2种利用了一种特殊性形式下的贝叶斯理论的泛化理论（Dempster-Shafertheory）：该方法先后用在DBpedia、GeoNames、LinkedMDB、GeoSpecies等知识图谱间进行实例匹配。,等价,,,Dempster-Shafertheory,
该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。,实例匹配问题,,,zhishi.me等知识图谱构建,
5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。,基于分治的实例匹配方法,,,分治处理方法,
采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。,分治处理,,,O(kn'2t'),
由此可见，系统效率取决于能将原有问题划分为多少个小规模。,系统效率,,,将原有问题划分为多少个小规模,
最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。,分治策略,,,将大规模本体划分为若干个小知识图谱,
"分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。",分治法,,,处理大规模数据库模式和XML模式匹配问题,
Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。,Rahm和Do,,,基于模式片段的大规模模式匹配分治解决方法,
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,模式的片段分解方法,,,划分大规模知识图谱,
这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。,模式的片段分解方法,,,片段分解方法,
本体模块化方法是对大规模本体进行划分的一种直观手段。,本体模块化方法,,,对大规模本体进行划分,
已有多种本体模块化方法被提出。,本体模块化方法,,,已有多种,
Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。,大本体自动划分为多个模块,,,语义封装的概念,
Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。,ε-connection,,,语义封装的概念,
然而，这种方法在实际应用中效果并不好。,SPO,,,概念/产品,
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,GALEN,,,将GALEN划分为2个模块,
例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。,NCI本体,,,将NCI本体划分为17个模块,
Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。,确保局部正确性和完整性模块化算法,,,确保局部正确性和完整性模块化算法,
Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。,确保局部正确性和完整性模块化算法,,,确保局部正确性和完整性模块化算法,
"此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。",本体模块化工作,,,获得描述特定元素集含义的模块,
"此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。",本体模块化工作,,,获得描述特定元素集含义的模块,
Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。,本体模块化方法,,,给出一种本体模块化方法,
Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。,本体模块化方法,,,本体模块化方法,
总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。,模块化工作,,,不以服务大规模本体映射为目的,
总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。,模块化工作,,,非以服务大规模本体映射为目的,
特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。,概念/模块化方法,,,知识图谱中大量的实例,
目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。,Malasco,,,分治思想处理大规模本体映射的典型系统,
Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。,Malasco,,,Paulheim提出的一种基于分治思想的大规模OWL本体映射系统,
Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。,Malasco,,,基于分治思想的大规模OWL本体映射系统,
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,,,基于RDF声明的朴素划分算法,
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,,,模块化算法,
Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。,Malasco,,,基于Grau的ε-connection模块化算法,
Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。,覆盖模块化,,,cover module,
Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。,模块化方法,,,处理大规模本体映射问题,
Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。,Falcon-AO,,,基于结构的本体划分方法解决大规模本体映射问题,
该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。,本体划分,,,聚类方法将本体中的元素划分为不相交的若干个集合,
该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。,本体划分,,,ontology partitioning,
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,本体块匹配,,,基于预先计算的参照点，对不同的本体块进行匹配,
接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。,相似度计算,,,"based on precomputed reference points, match different ontology blocks",
该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。,本体的划分算法,,,合适大小的集合,
该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。,本体元素的划分,,,将本体元素划分为合适大小的集合,
Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。,Falcon-AO,,,映射结果质量无明显损失,
基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。,基于本体划分的分治处理方法,,,较为直观,
基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。,分治处理方法,,,基于本体划分的分治处理方法,
一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。,模块大小,,,边界信息损失,
一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。,模块大小,,,边界信息损失,
Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。,覆盖模块优化方法,,,对该缺点的补救处理,
Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。,Lily,,,实例匹配,
Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。,匹配点,,,锚点,
该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。,该方法的优点,,,实现过程简单,
该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。,该方法的优点,,,避免划分知识图谱造成的语义信息损失,
1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。,基于属性规则的分块方法,,,概念/产品,
1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。,基于属性规则的分块方法,,,基于属性规则的分块,
类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。,实体消解,,,关系数据库领域和自然语言处理领域中的实体消解,