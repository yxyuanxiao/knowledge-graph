input,subject,subject_type,relation,object,object_type
知识抽取和知识挖掘对于知识图谱的构建及应用具有重要的意义。,知识抽取,,,知识图谱的构建及应用,
本章将首先介绍知识抽取的技术和方法，然后介绍知识内容挖掘和知识结构挖掘。,本章,,,知识抽取的技术和方法,
本章将首先介绍知识抽取的技术和方法，然后介绍知识内容挖掘和知识结构挖掘。,知识内容挖掘,,,knowledge content mining,
本章将首先介绍知识抽取的技术和方法，然后介绍知识内容挖掘和知识结构挖掘。,知识结构挖掘,,,knowledge structure mining,
知识抽取的数据源可以是结构化数据（如链接数据、数据库）、半结构化数据（如网页中的表格、列表）或者非结构化数据（即纯文本数据）。,知识抽取,,,结构化数据,
知识抽取的数据源可以是结构化数据（如链接数据、数据库）、半结构化数据（如网页中的表格、列表）或者非结构化数据（即纯文本数据）。,知识抽取,,,半结构化数据,
知识抽取的数据源可以是结构化数据（如链接数据、数据库）、半结构化数据（如网页中的表格、列表）或者非结构化数据（即纯文本数据）。,知识抽取,,,非结构化数据,
面向不同类型的数据源，知识抽取涉及的关键技术和需要解决的技术难点有所不同。,知识抽取,,,不同类型的数据源,
知识抽取的概念最早在20世纪70年代后期出现于NLP研究领域，是指自动化地从文本中发现和抽取相关信息，并将多个文本碎片中的信息进行合并，将非结构化数据转换为结构化数据，包括某一特定领域的模式、实体关系或RDF三元组。,知识抽取,,,NLP研究领域,
给定一段关于苹果公司的文字描述，知识抽取方法可以自动获取关于苹果公司的结构化信息，包括其总部地址、创始人以及创立时间。,知识抽取方法,,,自动获取关于苹果公司的结构化信息,
给定一段关于苹果公司的文字描述，知识抽取方法可以自动获取关于苹果公司的结构化信息，包括其总部地址、创始人以及创立时间。,知识抽取方法,,,自动获取关于苹果公司的结构化信息,
图4-1知识抽取的典型例子具体地，知识抽取包括以下子任务：1.命名实体识别从文本中检测出命名实体，并将其分类到预定义的类别中，例如人物、组织、地点、时间等。,知识抽取,,,命名实体识别,
2.关系抽取从文本中识别抽取实体及实体之间的关系。,关系抽取,,,从文本中识别抽取实体及实体之间的关系,
例如，从句子“[王思聪]是万达集团董事长[王健林]的独子”中识别出实体“[王健林]”和“[王思聪]”之间具有“父子”关系。,王思聪,,,万达集团董事长王健林的独子,
3.事件抽取识别文本中关于事件的信息，并以结构化的形式呈现。,事件抽取,,,识别文本中关于事件的信息，并以结构化的形式呈现。,
例如，从恐怖袭击事件的新闻报道中识别袭击发生的地点、时间、袭击目标和受害人等信息。,信息抽取,,,从恐怖袭击事件的新闻报道中识别袭击发生的地点、时间、袭击目标和受害人等信息。,
4.1.2知识抽取相关竞赛一些重要的竞赛对知识抽取技术的发展起到了巨大的推动作用。,知识抽取相关竞赛,,,重要的竞赛,
这些竞赛一般与学术会议同时举办，在明确定义知识抽取相关任务的基础上，提供标准评测数据和评测指标，吸引了大量的参与者。,知识抽取,,,竞赛,
本节将介绍知识抽取相关的重要竞赛。,知识抽取相关的重要竞赛,,,本节将介绍,
"1.消息理解会议（Message_Understanding_Conference,MUC）MUC由美国国防部高级研究计划局（DARPA）启动并资助，目的是鼓励和开发更好的信息抽取方法。",MUC,,,美国国防部高级研究计划局（DARPA）启动并资助的消息理解会议,
"1.消息理解会议（Message_Understanding_Conference,MUC）MUC由美国国防部高级研究计划局（DARPA）启动并资助，目的是鼓励和开发更好的信息抽取方法。",消息理解会议,,,"Message_Understanding_Conference,MUC",
1987—1998年，MUC会议共举办了七届。,MUC,,,MUC会议,
MUC不仅仅是学术会议，其更重要的是在于对信息抽取系统的评测。,MUC,,,学术会议,
在每届MUC会议前，组织者向参加者提供消息文本的样例和信息抽取任务的说明；参加者开发参赛系统并提交系统的输出结果。,MUC会议前的样例和信息抽取任务的说明,,,向参加者提供消息文本的样例和信息抽取任务的说明,
各个系统的结果与标准结果比对后得到最终的评测结果，参与者最后在会议上交流技术和感受。,参与者,,,交流技术和感受,
在MUC的评测中，召回率（Recall）和精确率（Precision）是评价信息抽取系统性能的两个重要评价指标。,召回率,,,评价信息抽取系统性能的两个重要评价指标,
在MUC的评测中，召回率（Recall）和精确率（Precision）是评价信息抽取系统性能的两个重要评价指标。,召回率,,,Recall,
在MUC的评测中，召回率（Recall）和精确率（Precision）是评价信息抽取系统性能的两个重要评价指标。,精确率,,,Precision,
召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。,召回率,,,系统抽取的正确结果占标准结果的比例,
召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。,精确率,,,系统抽取的正确结果占其抽取的所有结果的比例,
召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。,召回率,,,recall,
召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。,精确率,,,precision,
为了综合两个方面的因素考量系统的性能，通常基于召回率和准确率计算F1值。,F1值,,,基于召回率和准确率计算,
为了综合两个方面的因素考量系统的性能，通常基于召回率和准确率计算F1值。,F1值,,,综合两个方面的因素考量系统的性能,
MUC会议积极推动了命名实体识别和共指消解等技术的进步与发展。,MUC会议,,,命名实体识别和共指消解等技术的进步与发展,
MUC定义的一系列规范以及确立的评价体系也已经成为知识抽取领域的标准。,MUC,,,知识抽取领域的标准,
"2.自动内容抽取（Automatic_Content_Extraction,ACE）ACE是一项由美国国家标准技术研究所（NIST）组织的评测会议，该会议从1999年至2008年共举办了八次评测。",ACE,,,NIST组织的评测会议,
"2.自动内容抽取（Automatic_Content_Extraction,ACE）ACE是一项由美国国家标准技术研究所（NIST）组织的评测会议，该会议从1999年至2008年共举办了八次评测。",ACE,,,自动内容抽取,
ACE与MUC解决的问题类似，但是ACE对MUC定义的任务进行了融合、分类和细化。,ACE,,,MUC解决的问题,
ACE与MUC解决的问题类似，但是ACE对MUC定义的任务进行了融合、分类和细化。,ACE,,,ACM,
ACE评测涉及英语、阿拉伯语和汉语三种语言，主要包括以下任务：（1）实体检测和跟踪。,ACE评测,,,英语、阿拉伯语和汉语三种语言,
ACE评测涉及英语、阿拉伯语和汉语三种语言，主要包括以下任务：（1）实体检测和跟踪。,ACE评测,,,英语、阿拉伯语和汉语三种语言,
"这是ACE最基础和核心的任务，该任务要求识别文本中的实体，实体类型包括人物（Person,PER）、组织（Organization,ORG）、设施（Facility,FAC）、地缘政治实体（Geographical_Political_Entity,GPE）和位置（Location,LOC）等。",实体识别,,,ACE的任务,
"这是ACE最基础和核心的任务，该任务要求识别文本中的实体，实体类型包括人物（Person,PER）、组织（Organization,ORG）、设施（Facility,FAC）、地缘政治实体（Geographical_Political_Entity,GPE）和位置（Location,LOC）等。",ACE,,,实体任务,
（2）关系检测与表征。,SPO三元组,,,关系检测与表征。,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,关系,,,五大类,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,五大类关系,,,role关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,五大类关系,,,部分整体关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,五大类关系,,,位于关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,五大类关系,,,邻近关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,五大类关系,,,社会关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,角色关系,,,角色关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,部分整体关系,,,部分整体关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,位于关系,,,位于关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,邻近关系,,,邻近关系,
该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。,社会关系,,,社会关系,
（3）事件检测与表征。,事件检测与表征,,,SPO三元组,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,实体参与的五类事件,,,交互（interaction）事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,实体参与的五类事件,,,移动（movement）事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,实体参与的五类事件,,,转移（transfer）事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,实体参与的五类事件,,,创建（creation）事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,实体参与的五类事件,,,销毁（destruction）事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,五类事件,,,interaction事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,五类事件,,,movement事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,五类事件,,,transfer事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,五类事件,,,creation事件,
该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。,五类事件,,,destruction事件,
任务要求自动标注每个事件的文本提及或锚点，并按类型和子类型对其进行分类；最后，还需要根据类型特定的模板进一步确定事件参数和属性。,信息抽取,,,自动标注每个事件的文本提及或锚点，并按类型和子类型对其进行分类；最后，还需要根据类型特定的模板进一步确定事件参数和属性。,
任务要求自动标注每个事件的文本提及或锚点，并按类型和子类型对其进行分类；最后，还需要根据类型特定的模板进一步确定事件参数和属性。,等价,,,等价,
"3.知识库填充（Knowledge_Base_Population,KBP）KBP评测由文本分析会议（Text_Analysis_Conference,TAC）主办，其目标是开发和评估从非结构化文本中获取知识填充知识库的技术。",KBP评测,,,TAC主办的知识库填充,
"3.知识库填充（Knowledge_Base_Population,KBP）KBP评测由文本分析会议（Text_Analysis_Conference,TAC）主办，其目标是开发和评估从非结构化文本中获取知识填充知识库的技术。",知识库填充,,,"Knowledge_Base_Population,KBP",
KBP评测从2009年开始，每年举办一次，截至2017年，已经举办了九届。,KBP评测,,,每年举办一次,
KBP评测覆盖了知识库填充的独立子任务以及被称为“冷启动”的端到端知识库构建任务。,KBP评测,,,知识库填充的独立子任务以及被称为“冷启动”的端到端知识库构建任务,
"独立子任务主要包括以下四个方面：（1）实体发现与链接（Entity_Discovery_and_Linking,EDL）。",独立子任务,,,实体发现与链接,
"独立子任务主要包括以下四个方面：（1）实体发现与链接（Entity_Discovery_and_Linking,EDL）。",独立子任务,,,"Entity_Discovery_and_Linking,EDL",
主要的EDL任务是在评估文档集合中提取特定个人（PER）、组织（ORG）、设施（FAC）、地缘政治实体（GPE）和位置（LOC）实体的名称和提及，并将每个提及链接到其对应的KB节点。,主要的EDL任务,,,评估文档集合中提取特定个人（PER）、组织（ORG）、设施（FAC）、地缘政治实体（GPE）和位置（LOC）实体的名称和提及,
主要的EDL任务是在评估文档集合中提取特定个人（PER）、组织（ORG）、设施（FAC）、地缘政治实体（GPE）和位置（LOC）实体的名称和提及，并将每个提及链接到其对应的KB节点。,主要的EDL任务,,,extract specific person (PER)、organization (ORG)、facility (FAC)、geopolitical entity (GPE) and location (LOC) entities' names and mentions and link each mention to its corresponding KB node,
"（2）槽填充（Slot_Filling,SF）。",槽填充,,,SPO三元组,
插槽填充任务是搜索文档集合以填充特定实体的特定属性（“插槽”）值。,插槽填充任务,,,搜索文档集合以填充特定实体的特定属性（“插槽”）值,
（3）事件跟踪（Event_Track）。,事件跟踪,,,SPO三元组,
事件跟踪旨在从非结构化文本中提取关于事件的信息，使其作为结构化知识库的输入。,事件跟踪,,,从非结构化文本中提取关于事件的信息，使其作为结构化知识库的输入,
该任务具体包括事件块（Event_Nugget）任务（检测和链接事件块）和事件参数（Event_Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。,事件块,,,Event_Nugget,
该任务具体包括事件块（Event_Nugget）任务（检测和链接事件块）和事件参数（Event_Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。,任务,,,检测和链接事件块,
该任务具体包括事件块（Event_Nugget）任务（检测和链接事件块）和事件参数（Event_Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。,事件参数,,,提取属于同一事件的事件参数,
该任务具体包括事件块（Event_Nugget）任务（检测和链接事件块）和事件参数（Event_Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。,任务,,,链接属于同一事件的参数,
"（4）信念和情感（Belief_and_Sentiment,BeSt）。",信念和情感,,,SPO三元组,
信仰和情感跟踪检测实体对另一个实体、关系或事件的信念和情绪。,信仰和情感跟踪,,,检测实体对另一个实体、关系或事件的信念和情绪。,
端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。,实体,,,entity,
端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。,槽关系,,,entity attribute（“槽”）,
端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。,事件,,,event,
端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。,事件参数,,,event parameter,
端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。,情绪,,,mood,
"4.语义评测（Semantic_Evaluation,SemEval）SemEval是由ACL-SIGLEX组织的国际权威的词义消歧评测，目标是增进人们对词SenseEval，于1998年举办第一届。",语义评测,,,SemEval,
"4.语义评测（Semantic_Evaluation,SemEval）SemEval是由ACL-SIGLEX组织的国际权威的词义消歧评测，目标是增进人们对词SenseEval，于1998年举办第一届。",语义评测,,,SemEval,
截至2017义与多义现象的理解。,义,,,义与多义现象,
该评测前期被称为年，已经成功举办了十一届。,评测,,,年,
早期评测比较关注词义消歧问题，后来出现了更多文本语义理解的任务，包括语义角色标注、情感分析、跨语言语义分析等。,早期评测,,,早期评测比较关注词义消歧问题,
早期评测比较关注词义消歧问题，后来出现了更多文本语义理解的任务，包括语义角色标注、情感分析、跨语言语义分析等。,文本语义理解,,,包括语义角色标注、情感分析、跨语言语义分析等,
在前文介绍的知识抽取领域的评测竞赛中，评测数据大多属于非结构化文本数据。,评测数据,,,非结构化文本数据,
本节将对这一类知识抽取技术和方法进行概要介绍，具体包括面向文本数据的实体抽取、关系抽取和事件抽取。,知识抽取技术或方法,,,面向文本数据的实体抽取、关系抽取和事件抽取,
本节将对这一类知识抽取技术和方法进行概要介绍，具体包括面向文本数据的实体抽取、关系抽取和事件抽取。,面向文本数据的实体抽取,,,entity extraction for text data,
4.2.1实体抽取实体抽取又称命名实体识别，其目的是从文本中抽取实体信息元素，包括人名、组织机构名、地理位置、时间、日期、字符值和金额值等。,实体抽取,,,命名实体识别,
4.2.1实体抽取实体抽取又称命名实体识别，其目的是从文本中抽取实体信息元素，包括人名、组织机构名、地理位置、时间、日期、字符值和金额值等。,实体抽取,,,entity extraction,
实体抽取是解决很多自然语言处理问题的基础，也是知识抽取中最基本的任务。,实体抽取,,,知识抽取中最基本的任务,
想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。,从文本中进行实体抽取,,,识别和定位实体,
想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。,从文本中进行实体抽取,,,将识别的实体分类到预定义的类别中去,
想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。,从文本中进行实体抽取,,,extract entities from text,
想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。,识别和定位实体,,,identify and locate entities,
想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。,将识别的实体分类,,,classify the recognized entities,
例如，给定一段新闻报道中的句子“北京时间10月25日，骑士后来居上，在主场以119∶112击退公牛”。,新闻报道中的句子,,,给定一段新闻报道中的句子,
实体抽取旨在获取如图4-2所示的结果。,实体抽取,,,获取如图4-2所示的结果,
例句中的“北京”“10月25日”分别为地点和时间类型的实体，而“骑士”和“公牛”均为组织实体。,地点实体,,,地点类型的实体,
例句中的“北京”“10月25日”分别为地点和时间类型的实体，而“骑士”和“公牛”均为组织实体。,时间实体,,,时间类型的实体,
例句中的“北京”“10月25日”分别为地点和时间类型的实体，而“骑士”和“公牛”均为组织实体。,组织实体,,,组织实体,
实体抽取问题的研究开展得比较早，该领域也积累了大量的方法。,实体抽取,,,研究,
总体上，可以将已有的方法分为基于规则的方法、基于统计模型的方法和基于深度学习的方法。,已有的方法,,,基于规则的方法,
总体上，可以将已有的方法分为基于规则的方法、基于统计模型的方法和基于深度学习的方法。,已有的方法,,,基于统计模型的方法,
总体上，可以将已有的方法分为基于规则的方法、基于统计模型的方法和基于深度学习的方法。,已有的方法,,,基于深度学习的方法,
图4-2实体抽取举例1.基于规则的方法早期的命名实体识别方法主要采用人工编写规则的方式进行实体抽取。,基于规则的方法,,,早期的命名实体识别方法,
这类方法首先构建大量的实体抽取规则，一般由具有一定领域知识的专家手工构建。,实体抽取,,,构建大量的实体抽取规则,
这类方法首先构建大量的实体抽取规则，一般由具有一定领域知识的专家手工构建。,实体抽取,,,entity extraction,
然后，将规则与文本字符串进行匹配，识别命名实体。,命名实体识别,,,规则,
这种实体抽取方式在小数据集上可以达到很高的准确率和召回率，但随着数据集的增大，规则集的构建周期变长，并且移植性较差。,实体抽取方式,,,小数据集上的准确率和召回率,
这种实体抽取方式在小数据集上可以达到很高的准确率和召回率，但随着数据集的增大，规则集的构建周期变长，并且移植性较差。,实体抽取方式,,,概念/产品,
2.基于统计模型的方法基于统计模型的方法利用完全标注或部分标注的语料进行模型训练，主要采用的模型包括隐马尔可夫模型（Hidden_Markov_Model）、条件马尔可夫模型（Conditional_MarkovModel）、最大熵模型（Maximum_Entropy_Model）以及条件随机场模型（ConditionalRandom_Fields）。,基于统计模型的方法 ,,,基于统计模型的方法的五大核心方法,
2.基于统计模型的方法基于统计模型的方法利用完全标注或部分标注的语料进行模型训练，主要采用的模型包括隐马尔可夫模型（Hidden_Markov_Model）、条件马尔可夫模型（Conditional_MarkovModel）、最大熵模型（Maximum_Entropy_Model）以及条件随机场模型（ConditionalRandom_Fields）。,基于统计模型的方法 ,,,基于统计模型的方法,
该类方法将命名实体识别作为序列标注问题处理。,命名实体识别,,,序列标注问题处理,
与普通的分类问题相比，序列标注问题中当前标签的预测不仅与当前的输入特征相关，还与之前的预测标签相关，即预测标签序列是有强相互依赖关系的。,序列标注问题中当前标签的预测,,,强相互依赖关系,
与普通的分类问题相比，序列标注问题中当前标签的预测不仅与当前的输入特征相关，还与之前的预测标签相关，即预测标签序列是有强相互依赖关系的。,序列标注问题中当前标签的预测,,,strongly dependent relationship,
从自然文本中识别实体是一个典型的序列标注问题。,从自然文本中识别实体,,,序列标注问题,
基于统计模型构建命名实体识别方法主要涉及训练语料标注、特征定义和模型训练三个方面。,基于统计模型构建命名实体识别方法,,,训练语料标注,
基于统计模型构建命名实体识别方法主要涉及训练语料标注、特征定义和模型训练三个方面。,基于统计模型构建命名实体识别方法,,,特征定义,
基于统计模型构建命名实体识别方法主要涉及训练语料标注、特征定义和模型训练三个方面。,基于统计模型构建命名实体识别方法,,,模型训练,
（1）训练语料标注。,训练语料标注,,,SPO三元组,
为了构建统计模型的训练语料，人们一般采用Inside–Outside–Beginning（IOB）或Inside–Outside（IO）标注体系对文本进行人工标注。,Inside–Outside–Beginning（IOB）,,,Inside–Outside–Beginning,
为了构建统计模型的训练语料，人们一般采用Inside–Outside–Beginning（IOB）或Inside–Outside（IO）标注体系对文本进行人工标注。,Inside–Outside（IO）,,,Inside–Outside,
在IOB标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。,IOB标注体系,,,标记实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）,
在IOB标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。,B,,,实体名称的起始词,
在IOB标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。,I,,,实体名称的后续词,
在IOB标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。,D,,,实体名称的外部词,
而在IO标注体系中，文本中的词被标记为实体名称内部词（I）或实体名称外部词（D）。,实体名称内部词（I）,,,IO标注体系,
而在IO标注体系中，文本中的词被标记为实体名称内部词（I）或实体名称外部词（D）。,实体名称内部词,,,I,
而在IO标注体系中，文本中的词被标记为实体名称内部词（I）或实体名称外部词（D）。,实体名称外部词,,,D,
表4-1以句子“苹果公司是一家美国的跨国公司”为例，给出了IOB和IO实体标注示例。,IOB,,,实体标注示例,
表4-1IOB和IO实体标注示例（2）特征定义。,IOB,,,特征定义,
在训练模型之前，统计模型需要计算每个词的一组特征作为模型的输入。,统计模型,,,计算每个词的一组特征作为模型的输入,
在训练模型之前，统计模型需要计算每个词的一组特征作为模型的输入。,统计模型的输入,,,一组特征,
这些特征具体包括单词级别特征、词典特征和文档级特征等。,单词级别特征,,,特征,
单词级别特征包括是否首字母大写、是否以句点结尾、是否包含数字、词性、词的n-gram等。,单词级别特征,,,概念/产品,
单词级别特征包括是否首字母大写、是否以句点结尾、是否包含数字、词性、词的n-gram等。,单词级别特征,,,英文名,
词典特征依赖外部词典定义，例如预定义的词表、地名列表等。,词典特征,,,外部词典定义,
文档级特征基于整个语料文档集计算，例如文档集中的词频、同现词等。,文档级特征,,,整个语料文档集计算,
斯坦福大学的NER[1]是一个被广泛使用的命名实体识别工具，具有较高的准确率。,斯坦福大学的NER,,,命名实体识别工具,
定义何种特征对于命名实体识别结果有较大的影响，因此不同命名实体识别算法使用的特征有所不同。,命名实体识别,,,不同命名实体识别算法使用的特征,
（3）模型训练。,模型训练,,,SPO三元组,
"隐马尔可夫模型（Hidden_Markov_Model,HMM）和条件随机场（Conditional_Random_Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。",隐马尔可夫模型,,,统计学习模型,
"隐马尔可夫模型（Hidden_Markov_Model,HMM）和条件随机场（Conditional_Random_Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。",条件随机场,,,统计学习模型,
"隐马尔可夫模型（Hidden_Markov_Model,HMM）和条件随机场（Conditional_Random_Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。",隐马尔可夫模型,,,Hidden_Markov_Model,
"隐马尔可夫模型（Hidden_Markov_Model,HMM）和条件随机场（Conditional_Random_Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。",条件随机场,,,Conditional_Random_Field,
HMM是一种有向图概率模型，模型中包含了隐藏的状态序列和可观察的观测序列。,HMM,,,有向图概率模型,
HMM是一种有向图概率模型，模型中包含了隐藏的状态序列和可观察的观测序列。,HMM,,,隐马尔可夫模型,
每个状态代表了一个可观察的事件，观察到的事件是状态的随机函数。,状态,,,观察到的事件是状态的随机函数,
每个状态代表了一个可观察的事件，观察到的事件是状态的随机函数。,观察到的事件,,,观察到的事件的随机函数,
HMM模型结构如图4-3所示，每个圆圈代表一个随机变量，随机变量xt是t时刻的隐藏状态；随机变量yt是t时刻的观测值，图中的箭头表示条件依赖关系。,HMM模型,,,结构,
HMM模型结构如图4-3所示，每个圆圈代表一个随机变量，随机变量xt是t时刻的隐藏状态；随机变量yt是t时刻的观测值，图中的箭头表示条件依赖关系。,HMM模型,,,Hidden Markov Model,
图4-3HMM模型结构在应用于命名实体识别问题时，HMM模型中的状态对应词的标记，标注问题可以看作是对给定的观测序列进行序列标注。,HMM模型结构,,,应用于命名实体识别问题,
"基于HMM的有代表性的命名实体识别方法可参考文献[2,3]。",基于HMM的有代表性的命名实体识别方法,,,参考文献,
CRF是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型。,CRF,,,给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型,
CRF是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型。,CRF,,,条件随机场,
在序列标注问题中，线性链CRF是常用的模型，其结构如图4-4所示。,线性链CRF,,,常用的模型,
在序列标注问题中，线性链CRF是常用的模型，其结构如图4-4所示。,线性链CRF,,,线性链条件随机场,
在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。,状态序列变量x,,,标记序列,
在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。,y,,,待标注的观测序列,
在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。,状态序列变量,,,x,
在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。,标记序列,,,y,
图4-4线性链CRF模型结构给定训练数据集，模型可以通过极大似然估计得到条件概率模型；当标注新数据时，给定输入序列y，模型输出使条件概率P（x|y）最大化的x*。,线性链CRF模型结构,,,极大似然估计得到条件概率模型,
图4-4线性链CRF模型结构给定训练数据集，模型可以通过极大似然估计得到条件概率模型；当标注新数据时，给定输入序列y，模型输出使条件概率P（x|y）最大化的x*。,线性链CRF模型结构,,,给定输入序列y，模型输出使条件概率P（x|y）最大化的x*,
图4-4线性链CRF模型结构给定训练数据集，模型可以通过极大似然估计得到条件概率模型；当标注新数据时，给定输入序列y，模型输出使条件概率P（x|y）最大化的x*。,图4-4线性链CRF模型结构,,,图4-4线性链CRF模型结构,
美国斯坦福大学开发的命名实体识别工具Stanford_NER是基于CRF的代表性系统[1]。,Stanford_NER,,,基于CRF的代表性系统,
3.基于深度学习的方法随着深度学习方法在自然语言处理领域的广泛应用，深度神经网络也被成功应用于命名实体识别问题，并取得了很好的效果。,基于深度学习的方法,,,命名实体识别,
与传统统计模型相比，基于深度学习的方法直接以文本中词的向量为输入，通过神经网络实现端到端的命名实体识别，不再依赖人工定义的特征。,基于深度学习的方法,,,基于深度学习的方法直接以文本中词的向量为输入，通过神经网络实现端到端的命名实体识别,
与传统统计模型相比，基于深度学习的方法直接以文本中词的向量为输入，通过神经网络实现端到端的命名实体识别，不再依赖人工定义的特征。,传统统计模型,,,基于深度学习的方法,
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",命名实体识别的神经网络,,,"卷积神经网络（Convolutional_NeuralNetwork,CNN）",
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",命名实体识别的神经网络,,,"循环神经网络（Recurrent_Neural_Network,RNN）",
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",命名实体识别的神经网络,,,引入注意力机制（Attention_Mechanism）的神经网络。,
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",卷积神经网络,,,Convolutional_NeuralNetwork,
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",循环神经网络,,,Recurrent_Neural_Network,
"目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。",命名实体识别的神经网络,,,Attention_Mechanism的神经网络,
一般地，不同的神经网络结构在命名实体识别过程中扮演编码器的角色，它们基于初始输入以及词的上下文信息，得到每个词的新向量表示；最后再通过CRF模型输出对每个词的标注结果。,编码器,,,基于初始输入以及词的上下文信息，得到每个词的新向量表示,
（1）LSTM-CRF模型。,LSTM-CRF模型,,,LSTM模型,
"该模型使用了长短时记忆神经网络（Long_Shot-Term_Memory_Neural_Network,LSTM）与CRF相结合进行命名实体识别。","长短时记忆神经网络（Long_Shot-Term_Memory_Neural_Network,LSTM）",,,模型,
"该模型使用了长短时记忆神经网络（Long_Shot-Term_Memory_Neural_Network,LSTM）与CRF相结合进行命名实体识别。",长短时记忆神经网络,,,Long_Shot-Term_Memory_Neural_Network,
"该模型使用了长短时记忆神经网络（Long_Shot-Term_Memory_Neural_Network,LSTM）与CRF相结合进行命名实体识别。",CRF,,,结合进行命名实体识别,
该模型自底向上分别是Embedding层、双向LSTM层和CRF层。,双向LSTM层,,,该模型,
该模型自底向上分别是Embedding层、双向LSTM层和CRF层。,自底向上,,,Embedding层,
该模型自底向上分别是Embedding层、双向LSTM层和CRF层。,自底向上,,,双向LSTM层,
该模型自底向上分别是Embedding层、双向LSTM层和CRF层。,自底向上,,,CRF层,
Embedding层是句子中词的向量表示，作为双向LSTM的输入，通过词向量学习模型获得。,Embedding层,,,句子中词的向量表示,
Embedding层是句子中词的向量表示，作为双向LSTM的输入，通过词向量学习模型获得。,Embedding层,,,向量表示,
双向LSTM层通过一个正向LSTM和一个反向LSTM，分别计算每个词考虑左侧和右侧词时对应的向量，然后将每个词的两个向量进行连接，形成词的向量输出；最后，CRF层以双向LSTM输出的向量作为输入，对句子中的命名实体进行序列标注。,双向LSTM层,,,计算每个词考虑左侧和右侧词时对应的向量,
双向LSTM层通过一个正向LSTM和一个反向LSTM，分别计算每个词考虑左侧和右侧词时对应的向量，然后将每个词的两个向量进行连接，形成词的向量输出；最后，CRF层以双向LSTM输出的向量作为输入，对句子中的命名实体进行序列标注。,CRF层,,,对句子中的命名实体进行序列标注。,
经过实验对比发现，双向LSTM与CRF组合的模型在英文测试数据上取得了与传统统计方法最好结果相近的结果，而传统方法中使用了大量的人工定义的特征以及外部资源；在德语测试数据上，深度学习模型取得了比统计学习方法更优的结果。,双向LSTM,,,双向长短期记忆模型,
经过实验对比发现，双向LSTM与CRF组合的模型在英文测试数据上取得了与传统统计方法最好结果相近的结果，而传统方法中使用了大量的人工定义的特征以及外部资源；在德语测试数据上，深度学习模型取得了比统计学习方法更优的结果。,CRF,,,条件随机场,
图4-5LSTM-CRF命名实体识别模型[4]（2）LSTM-CNNs-CRF模型。,LSTM-CRF命名实体识别模型,,,LSTM-CNNs-CRF模型。,
MA_Xuezhe等人发表于ACL2016的论文提出了将双向LSTM、CNN和CRF相结合的序列标注模型[5]，并成功地应用于命名实体识别问题中。,MA_Xuezhe,,,MA_Xuezhe等人,
该模型与LSTM-CRF模型十分相似，不同之处是在Embedding层中加入了每个词的字符级向量表示。,ELMo,,,Embedding层中加入了每个词的字符级向量表示,
该模型与LSTM-CRF模型十分相似，不同之处是在Embedding层中加入了每个词的字符级向量表示。,Embedding层,,,加入每个词的字符级向量表示,
模型Embedding层中每个词的向量输入由预训练获得的词向量和CNN获得的字符级向量连接而成，通过双向LSTM和CRF层获得词的标注结果。,模型Embedding层中每个词的向量输入,,,预训练获得的词向量和CNN获得的字符级向量连接而成,
LSTM-CNNs-CRF序列标注模型框架如图4-7所示。,LSTM-CNNs-CRF序列标注模型,,,模型框架,
图4-6获取词语字符级向量表示的CNN模型[5]图4-7LSTM-CNNs-CRF序列标注模型框架[5]（3）基于注意力机制的神经网络模型。,图4-6获取词语字符级向量表示的CNN模型,,,CNN模型,
图4-6获取词语字符级向量表示的CNN模型[5]图4-7LSTM-CNNs-CRF序列标注模型框架[5]（3）基于注意力机制的神经网络模型。,图4-7LSTM-CNNs-CRF序列标注模型框架,,,LSTM-CNNs-CRF序列标注模型,
在自然语言处理领域，基于注意力机制的神经网络模型最早应用于解决机器翻译问题，注意力机制可以帮助扩展基本的编码器-解码器模型结构，让模型能够获取输入序列中与下一个目标词相关的信息。,基于注意力机制的神经网络模型,,,解决机器翻译问题,
在命名实体识别问题方面，Marek_Rei等人在COLING2016的论文中提出了基于注意力机制的词向量和字符级向量组合方法[6]。,Marek_Rei,,,基于注意力机制的词向量和字符级向量组合方法,
该方法认为除了将词作为句子基本元素学习得到的特征向量，命名实体识别还需要词中的字符级信息。,命名实体识别,,,将词作为句子基本元素学习得到的特征向量,
因此，该方法除了使用双向LSTM得到词的特征向量，还基于双向LSTM计算词的字符级特征向量。,双向LSTM,,,基于双向LSTM计算词的字符级特征向量,
因此，该方法除了使用双向LSTM得到词的特征向量，还基于双向LSTM计算词的字符级特征向量。,双向LSTM,,,基于双向LSTM计算词的字符级特征向量,
假设输入词为“big”，该方法将词中的字符看作一个序列，然后通过正、反向的LSTM计算字符序列的最终状态和，两者相连得到词“big”的字符级向量h∗。,等价,,,等价,
h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。,h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加,,,计算获得z,
h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。,非线性层,,,得到m,
h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。,加权相加,,,与“big”的词向量x进行加权相加,
h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。,权重z,,,通过一个两层的神经网络计算获得的,
在得到句子中每个词的新向量之后，模型使用CRF对句子中的命名实体进行序列标注。,CRF,,,序列标注,
注意力机制的引入使得模型可以动态地确定每个词的词向量和字符级向量在最终特征中的重要性，有效地提升了命名识别的效果。,注意力机制,,,命名识别的效果,
注意力机制的引入使得模型可以动态地确定每个词的词向量和字符级向量在最终特征中的重要性，有效地提升了命名识别的效果。,注意力机制,,,attention mechanism,
与基于词向量和字符级向量拼接的方法相比，基于注意力机制的方法在八个数据集上都获得了最好的实验结果。,基于注意力机制的方法,,,基于词向量和字符级向量拼接的方法获得最好的实验结果,
与基于词向量和字符级向量拼接的方法相比，基于注意力机制的方法在八个数据集上都获得了最好的实验结果。,基于注意力机制的方法,,,基于向量拼接的方法,
图4-8基于注意力机制的词向量和字符级向量组合方法[6]4.2.2关系抽取关系抽取是知识抽取的重要子任务之一，面向非结构化文本数据，关系抽取是从文本中抽取出两个或者多个实体之间的语义关系。,基于注意力机制的词向量和字符级向量组合方法,,,基于注意力机制的词向量和字符级向量组合方法,
关系抽取与实体抽取密切相关，一般在识别出文本中的实体后，再抽取实体之间可能存在的关系。,关系抽取,,,实体抽取,
关系抽取与实体抽取密切相关，一般在识别出文本中的实体后，再抽取实体之间可能存在的关系。,关系抽取,,,entity relation extraction,
目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。,关系抽取方法,,,基于模板的关系抽取方法,
目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。,关系抽取方法,,,基于监督学习的关系抽取方法,
目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。,关系抽取方法,,,基于弱监督学习的关系抽取方法,
目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。,基于模板的关系抽取方法,,,基于模板的关系抽取,
1.基于模板的关系抽取方法早期的实体关系抽取方法大多基于模板匹配实现。,基于模板的关系抽取方法,,,早期的实体关系抽取方法,
该类方法基于语言学知识，结合语料的特点，由领域专家手工编写模板，从文本中匹配具有特定关系的实体。,中向量方法,,,基于语言学知识，结合语料的特点，由领域专家手工编写模板，从文本中匹配具有特定关系的实体,
该类方法基于语言学知识，结合语料的特点，由领域专家手工编写模板，从文本中匹配具有特定关系的实体。,类方法,,,基于语言学知识结合语料的特点领域专家手工编写模板从文本中匹配具有特定关系的实体,
在小规模、限定领域的实体关系抽取问题上，基于模板的方法能够取得较好的效果。,基于模板的方法,,,在小规模、限定领域的实体关系抽取问题上,
假设想从文本中自动抽取具有“夫妻”关系的实体，并且观察到包含“夫妻”关系的例句。,抽取“夫妻”关系的实体,,,观察包含“夫妻”关系的例句,
板：●例句1:[姚明]与妻子[叶莉]还有女儿姚沁蕾并排坐在景区的游览车上，画面十分温馨●例句2:[徐峥]老婆[陶虹]晒新写真可以简单地将上述句子中的实体替换为变量，从而得到如下能够获取“夫妻”关系的模●模板1:[X]与妻子[Y]……●模板2:[X]老婆[Y]……利用上述模板在文本中进行匹配，可以获得新的具有“夫妻”关系的实体。,板,,,board,
为了进一步提高模板匹配的准确率，还可以将句法分析的结果加入模板中。,模板匹配,,,进一步提高模板匹配的准确率,
基于模板的关系抽取方法的优点是模板构建简单，可以比较快地在小规模数据集上实现关系抽取系统。,基于模板的关系抽取方法的优点,,,关系抽取系统,
基于模板的关系抽取方法的优点是模板构建简单，可以比较快地在小规模数据集上实现关系抽取系统。,基于模板的关系抽取方法的优点,,,模板构建简单,
基于模板的关系抽取方法的优点是模板构建简单，可以比较快地在小规模数据集上实现关系抽取系统。,基于模板的关系抽取方法的优点,,,比较快地在小规模数据集上实现关系抽取系统,
但是，当数据规模较大时，手工构建模板需要耗费领域专家大量的时间。,模板,,,构建模板,
此外，基于模板的关系抽取系统可移植性较差，当面临另一个领域的关系抽取问题时，需要重新构建模板。,基于模板的关系抽取系统,,,可移植性较差,
最后，由于手工构建的模板数量有限，模板覆盖的范围不够，基于模板的关系抽取系统召回率普遍不高。,基于模板的关系抽取系统,,,召回率不高,
2.基于监督学习的关系抽取方法基于监督学习的关系抽取方法将关系抽取转化为分类问题，在大量标注数据的基础上，训练有监督学习模型进行关系抽取。,基于监督学习的关系抽取方法,,,将关系抽取转化为分类问题,
2.基于监督学习的关系抽取方法基于监督学习的关系抽取方法将关系抽取转化为分类问题，在大量标注数据的基础上，训练有监督学习模型进行关系抽取。,基于监督学习的关系抽取方法,,,基于监督学习的关系抽取,
在上述步骤中，关系抽取特征的定义对于抽取的结果具有较大的影响，因此大量的研究工作围绕关系抽取特征的设计展开。,关系抽取特征,,,设计关系抽取工作,
在上述步骤中，关系抽取特征的定义对于抽取的结果具有较大的影响，因此大量的研究工作围绕关系抽取特征的设计展开。,关系抽取特征,,,design,
根据计算特征的复杂性，可以将常用的特征分为轻量级、中等量级和重量级三大类。,常用的特征,,,根据计算特征的复杂性,
轻量级特征主要是基于实体和词的特征，例如句子中实体前后的词、实体的类型以及实体之间的距离等。,轻量级特征,,,基于实体和词的特征,
中等量级特征主要是基于句子中语块序列的特征。,中等量级特征,,,基于句子中语块序列的特征,
重量级特征一般包括实体间的依存关系路径、实体间依存树结构的距离以及其他特定的结构信息。,重量级特征,,,实体间的依存关系路径、实体间依存树结构的距离以及其他特定的结构信息,
重量级特征一般包括实体间的依存关系路径、实体间依存树结构的距离以及其他特定的结构信息。,重量级特征,,,important feature,
"例如，对于句子“Forward_[motion]_of_the_vehicle_through_the_air_caused_a_[suction]_on_thetube”，轻量级的特征可以是实体[motion]和[suction]、实体间的词road{of,the,vehicle,through,the,air,caused,a}等；重量级的特征可以包括依存树中的路径“caused→nsubj→实体1”“caused→dobj→实体2”等。",轻量级特征,,,实体[motion]和[suction],
"例如，对于句子“Forward_[motion]_of_the_vehicle_through_the_air_caused_a_[suction]_on_thetube”，轻量级的特征可以是实体[motion]和[suction]、实体间的词road{of,the,vehicle,through,the,air,caused,a}等；重量级的特征可以包括依存树中的路径“caused→nsubj→实体1”“caused→dobj→实体2”等。",重量级特征,,,依存树中的路径“caused→nsubj→实体1”“caused→dobj→实体2”等。,
draft传统的基于监督学习的关系抽取是一种依赖特征工程的方法，近年来有多个基于深度学习的关系抽取模型被研究者们提出。,基于监督学习的关系抽取,,,依赖特征工程的方法,
深度学习的方法不需要人工构建各种特征，其输入一般只包括句子中的词及其位置的向量表示。,深度学习,,,不需要人工构建各种特征,
目前，已有的基于深度学习的关系抽取方法主要包括流水线方法和联合抽取方法两大类。,基于深度学习的关系抽取方法,,,流水线方法,
目前，已有的基于深度学习的关系抽取方法主要包括流水线方法和联合抽取方法两大类。,基于深度学习的关系抽取方法,,,联合抽取方法,
流水线方法将识别实体和关系抽取作为两个分离的过程进行处理，两者不会相互影响；关系抽取在实体抽取结果的基础上进行，因此关系抽取的结果也依赖于实体抽取的结果。,关系抽取,,,实体抽取的结果,
流水线方法将识别实体和关系抽取作为两个分离的过程进行处理，两者不会相互影响；关系抽取在实体抽取结果的基础上进行，因此关系抽取的结果也依赖于实体抽取的结果。,关系抽取,,,实体抽取的结果,
流水线方法将识别实体和关系抽取作为两个分离的过程进行处理，两者不会相互影响；关系抽取在实体抽取结果的基础上进行，因此关系抽取的结果也依赖于实体抽取的结果。,关系抽取,,,entity recognition and relation extraction,
联合抽取方法将实体抽取和关系抽取相结合，在统一的模型中共同优化；联合抽取方法可以避免流水线方法存在的错误积累问题。,联合抽取方法,,,实体抽取和关系抽取相结合,
联合抽取方法将实体抽取和关系抽取相结合，在统一的模型中共同优化；联合抽取方法可以避免流水线方法存在的错误积累问题。,联合抽取方法,,,联合抽取方法将实体抽取和关系抽取相结合，在统一的模型中共同优化,
（1）基于深度学习的流水线关系抽取方法●CR-CNN模型[7]。,CR-CNN模型,,,基于深度学习的流水线关系抽取方法,
（1）基于深度学习的流水线关系抽取方法●CR-CNN模型[7]。,CR-CNN模型,,,基于深度学习的流水线关系抽取方法,
给定输入的句子，CR-CNN模型首先将句子中的词映射到长度为dw的低维向量，每个词的向量包含了词向量和位置向量两部分。,CR-CNN模型,,,将句子中的词映射到长度为dw的低维向量,
然后，模型对固定大小滑动窗口中的词的向量进行卷积操作，为每个窗口生成新的长度为dc的特征向量；对所有的窗口特征向量求最大值，模型最终得到整个句子的向量表示dx。,模型的向量表示,,,卷积操作,
然后，模型对固定大小滑动窗口中的词的向量进行卷积操作，为每个窗口生成新的长度为dc的特征向量；对所有的窗口特征向量求最大值，模型最终得到整个句子的向量表示dx。,模型,,,滑动窗口中的词的向量进行卷积操作,
在进行关系分类时，CR-CNN模型计算句子向量和每个关系类型向量的点积，得到实体具有每种预定义关系的分值。,CR-CNN模型,,,进行关系分类,
在进行关系分类时，CR-CNN模型计算句子向量和每个关系类型向量的点积，得到实体具有每种预定义关系的分值。,CR-CNN模型,,,计算句子向量和每个关系类型向量的点积,
CR-CNN模型在SemEval-2010_Task_8数据集上获得了84.1%的F1值，这个结果优于当时最好的非深度学习方法。,CR-CNN模型,,,SemEval-2010_Task_8,
图4-9CR-CNN模型[7]●Attention_CNNs模型[8]。,CR-CNN模型,,,Attention_CNNs模型[8],
图4-9CR-CNN模型[7]●Attention_CNNs模型[8]。,CR-CNN模型,,,Attention_CNNs模型,
Wang等人提出的多层注意力卷积神经网络（Multi-levelAttention_CNN），将注意力机制引入到神经网络中，对反映实体关系更重要的词语赋予更大的权重，借助改进后的目标函数提高关系提取的效果。,多层注意力卷积神经网络,,,注意力机制引入到神经网络中,
Wang等人提出的多层注意力卷积神经网络（Multi-levelAttention_CNN），将注意力机制引入到神经网络中，对反映实体关系更重要的词语赋予更大的权重，借助改进后的目标函数提高关系提取的效果。,多层注意力卷积神经网络,,,Multi-levelAttention_CNN,
其模型的结构如图4-10所示，在输入层，模型引入了词与实体相关的注意力，同时还在池化和混合层引入了针对目标关系类别的注意力。,模型的结构,,,图4-10所示,
在SemEval-2010_Task_8数据集上，该模型获得了88%的F1值。,SemEval-2010_Task_8,,,在SemEval-2010_Task_8数据集上，该模型获得了88%的F1值。,
●Attention_BLSTM模型[9]。,Attention_BLSTM模型,,,概念/产品,
Attention_BLSTM模型如图4-11所示，它包含两个LSTM网络，从正向和反向处理输入的句子，从而得到每个词考虑左边和右边序列背景的状态向量；词的两个状态向量通过元素级求和产生词的向量表示。,Attention_BLSTM模型,,,Attention-based Bi-directional Long Short-Term Memory,
在双向LSTM产生的词向量基础上，该模型通过注意力层组合词的向量产生句子向量，进而基于句子向量将关系分类。,双向LSTM产生的词向量,,,关系分类,
在双向LSTM产生的词向量基础上，该模型通过注意力层组合词的向量产生句子向量，进而基于句子向量将关系分类。,双向LSTM产生的词向量,,,基于句子向量将关系分类,
注意力层首先计算每个状态向量的权重，然后计算所有状态向量的加权和得到句子的向量表示。,注意力层,,,计算句子的向量表示,
注意力层首先计算每个状态向量的权重，然后计算所有状态向量的加权和得到句子的向量表示。,注意力层,,,计算每个状态向量的权重,
实验结果表明，增加注意力层可以有效地提升关系分类的结果。,增加注意力层,,,关系分类的结果,
实验结果表明，增加注意力层可以有效地提升关系分类的结果。,增加注意力层,,,improve the result of relation classification,
图4-10Attention_CNNs模型的结构[8]图4-11Attention_BLSTM模型[9]在关系抽取问题方面，还有许多其他属于流水线方法的深度学习模型。,Attention_CNNs,,,注意力_卷积神经网络模型,
在流水线关系抽取方法中，实体抽取和关系抽取两个过程是分离的。,实体抽取,,,流水线关系抽取方法,
在流水线关系抽取方法中，实体抽取和关系抽取两个过程是分离的。,实体抽取,,,entity extraction,
在流水线关系抽取方法中，实体抽取和关系抽取两个过程是分离的。,关系抽取,,,relation extraction,
联合关系抽取方法则是将实体抽取和关系抽取相结合，图4-13展示的是一个实体抽取和关系抽取的联合模型[13]。,联合关系抽取方法,,,将实体抽取和关系抽取相结合,
联合关系抽取方法则是将实体抽取和关系抽取相结合，图4-13展示的是一个实体抽取和关系抽取的联合模型[13]。,联合关系抽取方法,,,将实体抽取和关系抽取相结合,
该模型主要由三个表示层组成：词嵌入层（嵌入层）、基于单词序列的LSTM-RNN层（序列层）以及基于依赖性子树的LSTM-RNN层（依存关系层）。,嵌入层,,,embedding layer,
该模型主要由三个表示层组成：词嵌入层（嵌入层）、基于单词序列的LSTM-RNN层（序列层）以及基于依赖性子树的LSTM-RNN层（依存关系层）。,序列层,,,based on word sequence LSTM-RNN layer,
该模型主要由三个表示层组成：词嵌入层（嵌入层）、基于单词序列的LSTM-RNN层（序列层）以及基于依赖性子树的LSTM-RNN层（依存关系层）。,依存关系层,,,based on dependency sub-tree LSTM-RNN layer,
在解码过程中，模型在序列层上构建从左到右的实体识别，并实现依存关系层上的关系分类，其中每个基于子树的LSTM-RNN对应于两个被识别实体之间的候选关系。,依存关系层上的关系分类,,,模型在序列层上构建从左到右的实体识别，并实现依存关系层上的关系分类,
在解码过程中，模型在序列层上构建从左到右的实体识别，并实现依存关系层上的关系分类，其中每个基于子树的LSTM-RNN对应于两个被识别实体之间的候选关系。,基于子树的LSTM-RNN,,,基于子树的LSTM-RNN对应的两个被识别实体之间的候选关系,
在对整个模型结构进行解码之后，模型参数通过基于时间的反向传播进行更新。,模型结构解码,,,基于时间的反向传播更新模型参数,
在依存关系层堆叠在序列层上，因此嵌入层和序列层被实体识别和关系分类任务共享，共享参数受实体和关系标签的共同影响。,嵌入层,,,embedding layer,
该联合模型在SemEval-2010_Task8数据集上获得了84.4%的F1值；将WordNet作为外部知识后，该模型可以获得85.6%的F1值。,联合模型,,,SemEval-2010_Task8数据集上的F1值,
该联合模型在SemEval-2010_Task8数据集上获得了84.4%的F1值；将WordNet作为外部知识后，该模型可以获得85.6%的F1值。,联合模型,,,将WordNet作为外部知识后模型的F1值,
该联合模型在SemEval-2010_Task8数据集上获得了84.4%的F1值；将WordNet作为外部知识后，该模型可以获得85.6%的F1值。,联合模型,,,Joint Model,
图4-13实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。,基于弱监督学习的关系抽取方法,,,基于监督学习的关系抽取方法,
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,,,只利用少量的标注数据进行模型学习,
当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。,弱监督学习方法,,,weak supervision learning,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,远程监督方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,Bootstrapping方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,远程监督方法,
基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。,基于弱监督学习的关系抽取方法,,,Bootstrapping方法,
（1）远程监督方法。,远程监督方法,,,SPO三元组,
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督,,,非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力,
远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。,远程监督方法,,,remote supervision method,
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,,,基本假设,
远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。,远程监督方法,,,remote supervision,
例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。,实体关系创始人,,,乔布斯，苹果公司,
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,,,一般步骤,
因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。,远程监督关系抽取方法,,,remote supervision relation extraction method,
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,,,利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量,
远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。,远程监督关系抽取方法,,,remote supervision relation extraction method,
但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。,语义漂移,,,基于远程监督的假设,
为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。,远程监督实体关系抽取方法,,,围绕如何克服训练数据中的噪声问题展开,
最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。,多示例学习,,,解决样例错误标注的问题,
下面介绍两个具有代表性的模型。,OWL_2_CR,,,OWL_2,
Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。,APCNNs,,,基于句子级注意力和实体描述的神经网络关系抽取模型,
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,,,模型,
模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。,PCNNs,,,Piecewise_Convolutional_Neural_Networks,
关系的分类是基于包特征上的Softmax分类器实现的。,基于包特征上的Softmax分类器,,,关系的分类,
关系的分类是基于包特征上的Softmax分类器实现的。,基于包特征上的Softmax分类器,,,based on the features of the package,
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,APCNNs模型,,,多示例学习,
APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。,多示例学习的策略,,,多示例学习的策略,
实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。,远程监督关系抽取,,,实验结果,
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,,,多示例学习策略,
图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。,APCNNs,,,多示例学习策略,
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,,,基于强化学习的关系分类模型,
针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。,CNN-RL,,,基于强化学习的关系分类模型,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型,,,样例选择器,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,CNN-RL模型,,,关系分类器,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,样例选择器,,,example selector,
CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。,关系分类器,,,relation classifier,
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,,,关系分类器从句子级特征对关系进行分类,
样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。,样例选择器,,,from sample to classify the relationship,
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,,,强化学习的方式,
整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。,样例选择器,,,基于一个随机策略,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,语义角色分类模型,,,在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,句子级卷积神经网络,,,sentence-level convolution neural network,
在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。,样例包级关系分类模型,,,example-level relation classification model,
图4-15CNN-RL模型[15]（2）Bootstrapping方法。,CNN-RL模型,,,Bootstrapping方法,
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping方法,,,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,
Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。,Bootstrapping,,,利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中,
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping,,,从文本中抽取关系的大量实例,
通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。,Bootstrapping,,,自底向上,
有很多实体关系抽取系统都采用了Bootstrapping方法。,实体关系抽取系统,,,Bootstrapping方法,
Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。,DIPER,,,Bootstrapping方法的系统,
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,,,Snowball关系抽取系统,
Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。,Agichtein等人,,,设计实现了Snowball关系抽取系统,
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,,,关系抽取,
在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。,Snowball,,,自动评价新实例的可信度，并保留最可靠的实例加入种子集合,
Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。,KnowItAll,,,关系抽取,
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,基于Bootstrapping的系统,,,关系抽取,
此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。,基于Bootstrapping的系统,,,加入更合理的模板描述、限制条件和评分策略,
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,,,从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能,
例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。,NELL系统,,,NELL,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,关系抽取系统构建成本低,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,适合大规模的关系抽取任务,
Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。,Bootstrapping方法的优点,,,发现新关系的能力,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,对初始种子较为敏感,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,存在语义漂移问题,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping的不足之处,,,结果准确率较低,
但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。,Bootstrapping,,,自举,
4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。,事件,,,事件是指发生的事情,
事件的发生可能是因为一个动作的产生或者系统状态的改变。,事件的发生,,,一个动作的产生或者系统状态的改变,
事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。,事件抽取,,,从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来,
基于一段苹果公司举办产品发布会的新闻报道，可以通过事件抽取方法自动获取报道事件的结构化信息，包括事件类型、涉及公司、发生时间及地点、所发布的产品。,事件抽取,,,自动获取报道事件的结构化信息,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,识别事件触发词及事件类型,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,抽取事件元素的同时判断其角色,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,抽出描述事件的词组或句子,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,事件属性标注,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,事件共指消解,
一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。,事件抽取,,,event extraction,
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取方法,,,流水线方法,
图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。,事件抽取方法,,,联合抽取方法,
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,,,基于分类的子任务,
1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。,事件抽取的流水线方法,,,pipeline method of event extraction,
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,分类器,,,事件触发词分类器,
一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。,事件触发词分类器,,,event trigger word classifier,
判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。,判断词汇是否为事件触发词,,,基于触发词信息对事件类别进行分类。,
（2）元素分类器。,元素分类器,,,概念/产品,
判断词组是否为事件的元素。,判断词组是否为事件的元素。,,,SPO三元组,
（3）元素角色分类器。,元素角色分类器,,,SPO三元组抽取,
判定事件元素的角色类别。,判定事件元素的角色类别。,,,概念/产品,
（4）属性分类器。,属性分类器,,,概念/产品,
判定事件的属性。,spo,,,判定事件的属性,
（5）可报告性分类器。,可报告性分类器,,,SPO三元组,
判定是否存在值得报告的事件实例。,报告事件实例的判定,,,存在值得报告的事件实例,
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类常用的分类特征,,,在事件抽取过程中,
表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。,触发词分类常用的分类特征,,,分类特征,
各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。,各个阶段的分类器,,,机器学习算法中的不同分类器,
表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。,事件的联合抽取方法,,,事件抽取的流水线方法,
为了解决这一问题，一些研究工作提出了事件的联合抽取方法。,事件的联合抽取方法,,,研究工作提出,
在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。,联合抽取方法,,,事件的所有相关信息同时抽取出来,
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取方法,,,联合推断或联合建模的方法,
一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。,联合事件抽取,,,联合推断或联合建模,
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,,,建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,
联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。,联合推断方法,,,联合推断,
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模,,,基于概率图模型进行联合建模获得事件抽取的总体结果,
联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。,联合建模,,,基于概率图模型进行联合建模,
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合建模方法,,,联合事件抽取模型,
具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。,联合建模方法,,,Qi_Li等人提出的联合事件抽取模型,
该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。,事件抽取,,,将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取,
在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。,袭击,,,Attack,
此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。,流水线方法,,,局部的分类器,
为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。,联合抽取模型,,,克服局部分类器的不足,
例如，在图4-18的句子中，事件死亡（Die）和事件（Attack）的提及“died”和“fired”共享了三个参数；基于这种情况，可以定义形如图4-19所示的事件抽取全局特征。,事件抽取全局特征,,,基于“died”和“fired”共享了三个参数,
例如，在图4-18的句子中，事件死亡（Die）和事件（Attack）的提及“died”和“fired”共享了三个参数；基于这种情况，可以定义形如图4-19所示的事件抽取全局特征。,事件抽取全局特征,,,event extraction global feature,
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,,,整体的结构中学习得到，从而使用全局的信息来提升局部的预测,
这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。,全局特征,,,global feature,
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,联合抽取模型,,,结构预测问题,
联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。,集束搜索,,,bundle search,
图4-17联合事件抽取方法图4-18事件触发词和事件元素示例图4-19事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。,联合事件抽取方法,,,基于深度学习的方法被提出,
图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。,基于动态多池化卷积神经网络的事件抽取模型,,,基于动态多池化卷积神经网络的事件抽取模型,
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,YuboChen,,,EMNLP-2015,
该模型由YuboChen等人于2015年发表在ACL会议上[21]。,YuboChen,,,YuboChen等人,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,词向量学习,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,词汇级特征抽取,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,句子级特征抽取,
模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。,模型总体,,,分类器输出,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词向量学习,,,无监督方式学习词的向量表示,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,词汇级特征抽取,,,基于词的向量表示获取事件抽取相关的词汇线索,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,句子级特征抽取,,,动态多池化卷积神经网络获取句子的语义组合特征,
其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。,分类器输出,,,产生事件元素的角色类别,
在CNN方法的结果。,CNN方法,,,抽取概念,
ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。,面向结构化数据的知识抽取,,,从数据库这种结构化数据中抽取知识,
在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。,标准,,,将数据库数据转化为RDF数据、OWL本体,
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,R2RML,,,W3C的RDB2RDF工作组于2012年发布的两个推荐的RDB2RDF映射语言,
W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。,R2RML,,,直接映射,
DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。,DM和R2ML映射语言,,,定义关系数据库中的数据如何转换为RDF数据的各种规则,
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,,,规范,
4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。,直接映射,,,direct mapping,
它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。,SPARQL查询,,,实现RDF图或定义虚拟图,
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,,,关系数据库表结构和数据直接转换为RDF图,
直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。,直接映射,,,direct mapping,
直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。,直接映射的基本规则,,,直接映射的五大基本规则,
下面给出一个简单的例子，解释直接映射的基本思路。,直接映射,,,概念/产品,
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL创建表,,,通过SQL语句创建图4-21中的两个数据库表,
首先，假设通过SQL语句创建图4-21中的两个数据库表。,SQL语句,,,创建图4-21中的两个数据库表,
"创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。",基于直接映射标准,,,based on direct mapping standard,
"创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。",People表,,,数据库表,
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,,,IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,
主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。,主语,,,subject,
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,谓词,,,IRI前缀和表名、列名连接形成,
每列的谓词是由IRI前缀和表名、列名连接形成的IRI。,谓词,,,IRI前缀和表名、列名连接形成的IRI,
这些值是从列值的词汇形式形成的RDF文字。,列值的词汇形式形成的RDF文字,,,属于RDF文字,
这些值是从列值的词汇形式形成的RDF文字。,列值的词汇形式形成的RDF文字,,,RDF文字,
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,三元组,,,会生成一个三元组,
每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,三元组,,,一个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。,
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,被引用三元组的行标识符,,,宾语,
这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。,宾语,,,被引用三元组的行标识符（例如<Addresses/ID=18>）。,
直接映射不会为NULL值生成三元组。,直接映射,,,为NULL值生成三元组,
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML映射语言,,,用于表示从关系数据库到RDF数据集的自定义映射的语言,
4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。,R2RML,,,R2RML映射语言,
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,OWL_ONR,,,在RDF数据模型下查看现有关系型数据的能力,
这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。,映射,,,map,
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,RDF图,,,数据库的直接映射,
在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。,数据库的直接映射,,,direct mapping of database,
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,,,关系数据定制视图,
然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。,R2RML,,,在关系数据上灵活定制视图,
每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。,R2RML映射,,,针对特定的数据库模式和目标词汇量身定制,
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,,,关系数据库,
R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。,R2RML映射,,,R2RML mapping,
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,R2RML映射,,,逻辑表（Logic_Tables）从数据库中检索数据,
R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。,逻辑表,,,Logic_Tables,
一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。,一个逻辑表,,,数据库中的一个表、视图或有效的SQL语句查询,
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,三元组映射,,,将逻辑表中每一行映射为若干RDF三元组的规则,
每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。,三元组映射,,,Triples_Map,
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,“逻辑表”,,,为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础,
“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。,“逻辑表”,,,logical table,
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射的规则,,,主语映射和多个谓词-宾语映射,
三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。,三元组映射的规则,,,一个主语映射和多个谓词-宾语映射,
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,,,基于数据库表中的主键生成RDF三元组中的主语,
主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。,主语映射,,,from logical table generate all RDF triples of subject,
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,,,谓词映射和宾语映射,
谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。,谓词-宾语映射,,,predicate-object mapping,
图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。,图4-22中给出的一个示例数据库,,,两个表,
将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。,R2RML视图,,,将上述数据库映射为RDF数据,
将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。,R2RML,,,将上述数据库映射为RDF数据,
用于创建R2RML视图的SQL语句如下所示。,创建R2RML视图的SQL语句,,,用于创建R2RML视图的SQL语句,
用于DEPT表数据转换的R2RML映射文档如下所示。,R2RML映射文档,,,用于DEPT表数据转换,
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,EMP,,,将EMP和DEPT表进行连接,
此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。,等价,,,等价,
"4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。",SPARQL,,,基于本体的数据库访问,
"4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。",SPARQL,,,"Ontology_Based_Database_Access,OBDA",
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA系统,,,表4-3列出了这些系统的主要特性,
这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。,OBDA,,,Ontology-based Data Access,
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,,,OBDA系统的主要特性对比,
表4-3OBDA系统的主要特性对比（1）D2RQ[22]。,D2RQ,,,数据到资源的查询,
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,,,较早开发和发布的OBDA系统,
D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。,D2RQ,,,较早开发和发布的OBDA系统,
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,,,HTTP_Server,
其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。,D2R_Server,,,等价,
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,,,可定制的D2RQ映射文件,
D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。,D2R_Server,,,D2R Server,
基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。,基于D2RQ映射,,,Web端的请求重写为SQL查询,
此外，D2RQ系统还部分支持R2RML映射。,D2RQ系统,,,支持R2RML映射,
（2）Mastro[23]。,Mastro,,,SPO三元组,
Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。,Mastro,,,基于Java语言开发的OBDA系统,
Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。,Mastro数据源管理器,,,支持与最流行的商业和非商业DBMS的交互。,
除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。,Elasticsearch,,,为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持,
图4-23D2RQ平台框架[22]图4-24Mastro系统结构[23]（3）Ultrawrap[24]。,D2RQ平台,,,图4-23D2RQ平台框架,
Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。,Ultrawrap,,,商业化系统,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,,,建立数据库到RDF和OWL的映射,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,编译器,,,建立数据库到RDF和OWL的映射,
其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。,服务器,,,在数据库上执行SPARQL查询,
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,,,执行SPARQL查询,
Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。,Ultrawrap,,,执行SPARQL查询,
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,,,Ultrawrap系统结构（4）,
图4-25Ultrawrap系统结构（4）Morph-RDB[25]。,Morph-RDB,,,Ultrawrap,
Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。,Morph-RDB,,,R2RML规范,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,,,数据升级,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,Morph-RDB,,,查询转换,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,数据升级,,,data upgrade,
Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。,查询转换,,,SPARQL to SQL,
Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。,Morph-RDB,,,各种优化技术来生成高效的SQL查询,
（5）Ontop[26]。,Ontop,,,SPO三元组抽取,
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,,,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具,
Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。,Ontop,,,将关系数据库作为虚拟的RDF图进行SPARQL查询的工具,
Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。,Ontop,,,基于Apache许可证的开源工具,
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,,,将本体中的词汇（类和属性）通过映射链接到数据源,
通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。,Ontop,,,将本体中的词汇通过映射链接到数据源,
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,,,R2RML映射,
Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。,Ontop,,,支持R2RML映射,
图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。,Ontop,,,系统结构,
自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。,半结构化数据,,,知识获取的来源,
目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。,面向此类数据的知识抽取方法,,,知识获取,
4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。,面向百科类数据的知识抽取,,,维基百科为代表的百科类数据,
在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。,词条页面,,,半结构化数据,
图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。,维基百科词条页面结构,,,构建大规模知识图谱的重要数据来源,
目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。,知识图谱,,,基于维基百科,
在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。,基于百科数据构建知识图谱,,,从百科数据中抽取结构化语义信息,
DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。,DBpedia,,,维基百科的机构化版本,
得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。,DBpedia,,,知识图谱,
截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。,DBpedia英文版,,,一个本体中进行分类,
截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。,DBpedia英文版,,,DBpedia English,
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,,,DBpedia数据集,
此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。,DBpedia,,,DBpedia,
DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。,DBpedia,,,DBpedia,
根据抽样评测，DBpedia中RDF三元组的正确率达88%。,DBpedia中RDF三元组的正确率,,,抽样评测,
图4-28所示为DBpedia知识抽取的总体框架。,DBpedia知识抽取,,,知识抽取的总体框架,
框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。,框架的主要组成部分,,,页面集合、目标数据、提取器、解析器、提取作业、知识提取管理器,
图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。,标签,,,Labels,
图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。,摘要,,,Abstracts,
●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。,信息框,,,从词条页面的信息框中抽取实体的结构化信息,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,一般抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,基于映射的抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,一般抽取,
信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。,信息框抽取,,,基于映射的抽取,
信息框的一般抽取直接将信息框中的信息转换为RDF三元组。,信息框的一般抽取,,,将信息框中的信息转换为RDF三元组,
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,三元组,,,subject,
三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。,主语,,,主语,
然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。,抽取方式,,,等价处理属性名和信息框模板同义异名问题,
图4-29信息框示例[27]4.4.2面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。,信息框,,,面向Web网页的知识抽取,
从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。,信息的获取,,,HTML中的标记区分,
图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。,包装器,,,从网页中获取结构化信息,
包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。,包装器,,,能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,手工方法,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,包装器归纳方法,
包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。,包装器,,,自动抽取方法,
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,基于包装器抽取网页信息的框架,,,手工方法,
图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。,基于包装器抽取网页信息的框架,,,基于包装器抽取网页信息的框架,
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法的抽取,,,查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式,
手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。,手工方法,,,manual method,
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,,,XML路径语言,
XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。,XPath,,,XML路径语言,
借助它可以获取网页中元素的位置，从而获取需要的信息。,spo,,,概念/产品,
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,CSS选择器,,,通过CSS元素实现对网页中元素的定位，并获取元素信息,
在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。,CSS选择器,,,CSS元素,
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,包装器归纳方法,,,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法,
分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。,包装器归纳方法,,,基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取,
典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。,典型的包装器归纳流程,,,网页清洗、网页标注、包装器空间生成、包装器评估,
（1）网页清洗。,网页清洗,,,信息检索中概念的五大用途,
纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。,TIDY,,,纠正和清理网页不规范的HTML、XML标记,
（2）网页标注。,网页标注,,,SPO三元组,
在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。,标注,,,给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据,
例如，在图4-30的例子中，如果需要抽取页面上“华为P10”产品的信息和价格，则可以在产品信息和价格所在的标签里打上一个特殊的标记作为标注。,标注,,,在产品信息和价格所在的标签里打上一个特殊的标记作为标注,
例如，在图4-30的例子中，如果需要抽取页面上“华为P10”产品的信息和价格，则可以在产品信息和价格所在的标签里打上一个特殊的标记作为标注。,标注,,,特殊的标记,
（3）包装器空间生成。,包装器空间生成,,,SPO三元组,
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,,,归纳形成若干个子集,
基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。,基于标注的数据生成XPath集合空间,,,基于标注的数据生成XPath集合空间,
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,,,使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,
归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。,归纳,,,induction,
（4）包装器评估。,包装器评估,,,SPO三元组,
包装器可以通过准确率和召回率进行评估。,包装器,,,评估,
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,,,评估包装器性能,
使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。,准确率,,,计算包装器输出标注的相同项的数量除以包装器输出标注的总数量,
准确率和召回率越高，表示包装器的质量越好。,准确率,,,包装器的质量,
准确率和召回率越高，表示包装器的质量越好。,准确率,,,precision,
准确率和召回率越高，表示包装器的质量越好。,召回率,,,recall,
3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。,自动抽取方法包装器,,,归纳方法,
此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。,包装器,,,维护工作量,
自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。,自动抽取方法,,,不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题,
在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。,相似的网页,,,相似的网页首先通过聚类被分成若干组,
在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。,应用包装器,,,数据抽取,
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,表4-5,,,信息抽取方法的对比,
上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。,信息抽取,,,information extraction,
表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。,知识内容挖掘,,,知识内容挖掘,
4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。,实体链接,,,知识内容挖掘,
4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。,实体链接,,,entity linking,
实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。,实体链接,,,将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础,
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,实体链接,,,通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接,
通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。,实体链接,,,entity link,
实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。,实体链接,,,entity linking,
图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。,实体链接,,,实体指称识别,
图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。,实体链接,,,entity linking,
该步骤主要通过命名实体识别技术或者词典匹配技术实现。,命名实体识别技术,,,属于中文信息处理,
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,,,本章前面已经介绍过,
命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。,命名实体识别技术,,,命名实体识别技术,
2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。,候选实体生成,,,确定文本中的实体指称可能指向的实体集合,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,知识库中的多个实体,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,entity designation,
例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。,实体指称,,,entities,
生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。,生成实体指称的候选实体,,,表层名字扩展,
某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,表层名字扩展技术,,,从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,
某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。,表层名字扩展技术,,,从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）,
然后，可以利用这些扩展形式形成实体提及的候选实体集合。,扩展形式,,,实体提及的候选实体集合,
表层名字扩展可以采用启发式的模式匹配方法实现。,表层名字扩展,,,启发式的模式匹配方法实现,
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,,,提取实体提及邻近括号中的缩写作为扩展结果,
例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。,模式,,,提取实体提及邻近括号中的缩写作为扩展结果,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,从文本中抽取复杂的实体名称缩写,,,有监督学习的技术,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,模式匹配,,,模式匹配,
除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。,有监督学习的技术,,,从文本中抽取复杂的实体名称缩写,
（2）基于搜索引擎的方法。,基于搜索引擎的方法,,,基于搜索引擎的SPO三元组抽取方法,
将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。,搜索引擎,,,将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体,
例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。,实体指称,,,搜索关键词提交至谷歌搜索引擎并将其返回结果中的维基百科页面作为候选实体,
此外，维基百科自有的搜索功能也可以用于生成候选实体。,维基百科自有的搜索功能,,,生成候选实体,
（3）构建查询实体引用表。,查询实体引用表,,,构建,
很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。,实体链接系统,,,基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系,
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用,,,键-值,
实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。,实体引用,,,entity reference,
在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。,引用表,,,从表中获得其候选实体,
维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。,实体提及,,,title of a wiki article page,
维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。,维基百科页面中的链接,,,提取实体和实体提及的对应关系,
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,候选实体消歧,,,为每一个实体指称确定其指向的实体,
表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。,候选实体消歧,,,candidate entity disambiguation,
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,,,排序问题,
一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。,候选实体消歧,,,排序问题进行求解,
下面介绍每类方法中具有代表性的工作。,每类方法中具有代表性的工作,,,介绍每类方法中具有代表性的工作,
[32]（1）基于图的方法。,基于图的方法,,,基于图的数据挖掘方法,
基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。,基于图的方法,,,将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理,
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图（Referent_Graph）协同实体链接方法,,,Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法,
该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。,基于参照图（Referent_Graph）协同实体链接方法,,,基于参照图协同实体链接方法,
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,实体提及,,,entity mention,
Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。,实体,,,entity,
在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。,Han_PageRank算法,,,实体消歧的初始依据并在参照图上进行传递,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧目标函数,,,基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,实体消歧目标函数,,,entity disambiguation target function,
最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。,目标实体,,,entity disambiguation result,
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,实体链接系统,,,基于图的方法进行候选实体消歧的实体链接系统,
采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。,实体链接系统,,,基于图的方法进行候选实体消歧的实体链接系统,
图4-34参照图[33]（2）基于概率生成模型的方法。,基于概率生成模型的方法,,,基于概率生成模型的问答系统,
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型,,,实体提及和实体的联合概率进行建模,
基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。,基于概率生成模型,,,based on probability generation model,
在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。,实体-提及概率生成模型,,,entity-mention probability generation model,
图4-35实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael_Jeffrey_Jordan]和[Michael_I.Jordan]；然后，模型依据给定实体e实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael_Jordan]；最后，模型依据给定实体e上下文的条件概率P（c|e）输出实体提及的上下文。,实体提及的名称,,,实体提及,
"根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。",实体联合概率,,,"P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）",
当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。,候选实体消歧,,,基于主题模型的方法,
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,,,对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果,
基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。,实体-主题模型,,,entity-topic model,
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,,,生成关于主题、实体名称和实体上下文的全局知识,
实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。,实体-主题模型,,,entity-topic model,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,E维狄利克雷分布抽样,,,基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,K维狄利克雷分布抽样,,,基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,V维狄利克雷分布抽样,,,基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,E维狄利克雷分布抽样,,,得到每个主题z中实体的分布φz,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,K维狄利克雷分布抽样,,,每个实体e名称的分布ψe,
首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。,V维狄利克雷分布抽样,,,实体e上下文词的分布ξe,
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,实体-主题模型,,,推断获得实体消歧所需的决策信息,
通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。,吉布斯抽样算法,,,吉布斯抽样,
图4-36实体-主题模型[37]（4）基于深度学习的方法。,实体-主题模型,,,基于深度学习的方法,
在候选实体消歧过程中，准确计算实体的相关度十分重要。,准确计算实体的相关度,,,候选实体消歧过程,
因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,评价实体与实体的相关度,,,在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。,
Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。,实体语义相关度计算模型,,,基于深度神经网络的实体语义相关度计算模型,
在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。,实体E,,,输入层,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,语义层上实体的表示,,,经过词散列层进行降维，然后经过多层神经网络的非线性变换,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,两个实体的相关度,,,它们语义层表示向量的余弦相似度,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入,,,词散列层进行降维,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,基于词袋和独热表示的输入,,,多层神经网络的非线性变换,
基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。,语义层上实体的表示,,,语义层上实体的表示,
"图4-37实体提及生成过程示例[38]4.5.2知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive_Logic_Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。",归纳逻辑程序设计,,,"Inductive_Logic_Programming,ILP",
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,实体关系,,,二元谓词描述的事实,
知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。,实体关系,,,二元谓词描述的事实,
"给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。",ILP系统,,,学习获得描述目标谓词的逻辑规则集合,
FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。,FOIL,,,早期具有代表性的ILP系统,
下面通过一个例子介绍FOIL的规则学习过程。,FOIL的规则学习过程,,,例子介绍FOIL的规则学习过程,
设有规则学习问题如表4-6所示。,规则学习,,,设有规则学习问题,
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,背景知识,,,描述某一家庭的成员关系,
背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。,等价,,,等价,
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,,,规则学习,
"FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。",FOIL,,,FOIL,
表4-7列出了FOIL学习单个规则的过程。,FOIL学习单个规则的过程,,,表4-7,
表4-7列出了FOIL学习单个规则的过程。,FOIL,,,Fact-Only-If-Else-Last,
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,,,概念/规则覆盖正例,
当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。,FOIL,,,"Factoid, Opinion, Instance, and Label",
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,FOIL,,,规则学习问题,
表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。,等价,,,等价,
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,,,扩展规则体的每一步,
在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。,FOIL,,,FOIL_Gain,
FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。,FOIL_Gain,,,形式等同的增益,
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL_Gain评价函数,,,基于FOIL_Gain评价函数,
基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。,FOIL,,,基于FOIL_Gain评价函数,
在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。,Progol,,,早期的ILP系统,
多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。,ILP系统,,,小规模的数据集,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,FOIL-D,,,FOIL-D,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,PILP,,,PILP,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,QuickFOIL,,,QuickFOIL,
因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。,分布式并行的ILP系统,,,分布式并行的ILP系统,
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,,,关联规则挖掘的方法,
最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。,AMIE,,,关联规则挖掘的方法,
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE+,,,发布者发布的升级系统,
在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。,AMIE+,,,AMIE的升级系统,
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",PRA,,,将关系路径作为特征的知识图谱链接预测算法,
"2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。",路径排序算法,,,PRA,
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,,,通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系,
PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。,PRA,,,概念/产品,
"如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。",HinesWard,,,NFL,
"如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。",等价,,,等价,
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,关系路径,,,常识知识,
实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。,等价,,,equivalence,
在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。,PRA,,,自动发现有用的关系路径来构建预测模型,
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,图4-38示例知识图谱子图,,,图4-38,
图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。,图4-38示例知识图谱子图,,,图4-38示例知识图谱子图,
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径,,,连接特定实体对,
因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。,关系路径,,,connection specific entity pairs,
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,,,连接实体对的特征选择,
PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。,PRA,,,概念/产品,
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,,,基于随机游走计算路径准确度和覆盖度,
"为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。",PRA,,,基于随机游走特征选择方法,
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,P（si→Gi;π）,,,随机游走能够抵达目标实体的概率,
式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,P（si→Gi;π）,,,以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。,
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,PRA,,,准确度和覆盖度,
PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。,等价,,,equal,
（2）特征计算。,特征计算,,,SPO三元组,
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,PRA,,,为每个实体对计算其特征值,
在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。,等价,,,equivalence,
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,,,从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值,
"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",PRA,,,"给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。",
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,实体对,,,通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值,
通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。,实体对在每个特征关系路径上的可达概率,,,entities'probability on each feature relation path,
（3）关系分类。,SPO三元组,,,关系分类,
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,,,为每个目标关系训练一个分类模型,
基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。,PRA,,,基于训练样例和它们的特征为每个目标关系训练一个分类模型,
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,利用训练完的模型,,,预测知识图谱中任意两个实体间是否存在某特定关系,
利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。,预测知识图谱中任意两个实体间是否存在某特定关系,,,利用训练完的模型,
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,PRA,,,逻辑回归分类模型,
关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。,关系分类,,,任何一种分类模型,
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,,,训练逻辑回归模型的过程,
PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。,PRA,,,概率回归分析,
图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。,PRA,,,在NELL数据集上进行链接预测时获得的重要关系路径和相应解释,
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,本实践,,,OpenKG,
该框架遵循Apache开源协议。,OWL_2_QRL,,,Apache开源协议,
4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。,DeepDive,,,DeepDive,
在具体应用中，可以选择使用因子图模型或神经网络模型。,因子图模型,,,具体应用,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,文件名,,,file_name,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,命令,,,command,
图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。,脚本文件,,,script_file,