input,subject,subject_type,relation,object,object_type
第2章知识图谱表示与建模漆桂林东南大学，潘志霖阿伯丁大学，陈华钧浙江大学知识图谱表示（Knowledge_Graph_Representation）指的是用什么语言对知识图谱进行建模，从而可以方便知识计算。,知识图谱表示,,,对知识图谱进行建模,
第2章知识图谱表示与建模漆桂林东南大学，潘志霖阿伯丁大学，陈华钧浙江大学知识图谱表示（Knowledge_Graph_Representation）指的是用什么语言对知识图谱进行建模，从而可以方便知识计算。,知识图谱表示,,,Knowledge_Graph_Representation,
从图的角度来看，知识图谱是一个语义网络，即一种用互联的节点和弧表示知识的一个结构[1]。,知识图谱,,,语义网络,
从图的角度来看，知识图谱是一个语义网络，即一种用互联的节点和弧表示知识的一个结构[1]。,知识图谱,,,语义网络,
语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。,节点,,,概念,
语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。,节点,,,属性,
语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。,节点,,,事件,
语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。,节点,,,实体,
语义网络中的语义主要体现在图中边的含义。,语义网络中的语义,,,边的含义,
为了给这些边赋予语义，研究人员提出了术语语言（Terminological_Language），并最终提出了描述逻辑（Description_Logic），描述逻辑是一阶谓词逻辑的一个子集，推理复杂度是可判定的。,描述逻辑,,,一阶谓词逻辑,
为了给这些边赋予语义，研究人员提出了术语语言（Terminological_Language），并最终提出了描述逻辑（Description_Logic），描述逻辑是一阶谓词逻辑的一个子集，推理复杂度是可判定的。,描述逻辑,,,Description_Logic,
W3C采用了以描述逻辑为逻辑基础的本体语言OWL作为定义Web术语的标准语言。,OWL,,,定义Web术语的标准语言,
W3C采用了以描述逻辑为逻辑基础的本体语言OWL作为定义Web术语的标准语言。,OWL,,,描述逻辑为逻辑基础的本体语言,
W3C还推出了另外一种用于表示Web本体的语言RDF_Schema（简称RDFS）。,RDFS,,,W3C推出的另一种用于表示Web本体的语言,
目前基于向量的知识表示开始流行，这类表示将知识图谱三元组中的主谓宾表示成数值向量，通过向量的知识表示，可以采用统计或者神经网络的方法进行推理，对知识图谱中的实体直接的关系进行预测。,基于向量的知识表示的推理,,,知识图谱三元组中的主谓宾表示成数值向量,
目前基于向量的知识表示开始流行，这类表示将知识图谱三元组中的主谓宾表示成数值向量，通过向量的知识表示，可以采用统计或者神经网络的方法进行推理，对知识图谱中的实体直接的关系进行预测。,向量的知识表示的推理,,,基于向量的知识表示,
本章将对知识表示的常见方法进行介绍，并且讨论如何用这些知识表示方法对知识进行建模。,本章内容,,,知识表示的常见方法,
2.1什么是知识表示20世纪90年代，MIT_AI实验室的R.Davis定义了知识表示的五大用途或特点：●客观事物的机器标示（A_KR_is_a_Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。,知识表示的五大用途或特点,,,定义客观实体的机器指代或指称,
2.1什么是知识表示20世纪90年代，MIT_AI实验室的R.Davis定义了知识表示的五大用途或特点：●客观事物的机器标示（A_KR_is_a_Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。,知识表示的五大用途或特点,,,客观事物的机器标示,
●一组本体约定和概念模型（A_KR_is_a_Set_of_Ontological_Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。,一组本体约定和概念模型,,,知识表示,
●一组本体约定和概念模型（A_KR_is_a_Set_of_Ontological_Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。,一组本体约定和概念模型,,,A_KR_is_a_Set_of_Ontological_Commitments,
●支持推理的表示基础（A_KR_is_a_Theory_of_Intelligent_Reasoning），即知识表示还需要提供机器推理的模型与方法。,支持推理的表示基础,,,知识表示,
●用于高效计算的数据结构（A_KR_is_a_medium_for_Efficient_Computation），即知识表示也是一种用于高效计算的数据结构。,知识表示的五大用途或特点,,,用于高效计算的数据结构,
●人可理解的机器语言（A_KR_is_a_Medium_of_Human_Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。,知识表示的五大用途或特点,,,人可理解的机器语言（A_KR_is_a_Medium_of_Human_Expression）,
●人可理解的机器语言（A_KR_is_a_Medium_of_Human_Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。,知识表示的五大用途或特点,,,人可理解的机器语言,
有关知识表示的研究可以追溯到人工智能的早期研究。,有关知识表示的研究,,,人工智能的早期研究,
例如，认知科学家M.RossQuillian和Allan_M.Collins提出了语义网络的知识表示方法[2-3]，以网络的方式描述概念之间的语义关系。,语义网络的知识表示方法,,,概念之间的语义关系,
例如，认知科学家M.RossQuillian和Allan_M.Collins提出了语义网络的知识表示方法[2-3]，以网络的方式描述概念之间的语义关系。,语义网络的知识表示方法,,,语义网络,
典型的语义网络如WordNet属于词典类的知识库，主要定义名词、动词、形容词和副词之间的语义关系。,WordNet,,,词典类的知识库,
典型的语义网络如WordNet属于词典类的知识库，主要定义名词、动词、形容词和副词之间的语义关系。,语义网络,,,WordNet,
20世纪70年代，随着专家系统的提出和商业化发展，知识库构建和知识表示更加得到重视。,知识库构建,,,知识表示,
传统的专家系统通常包含知识库和推理引擎（InferenceEngine）两个核心模块。,传统的专家系统,,,知识库和推理引擎（InferenceEngine）两个核心模块,
传统的专家系统通常包含知识库和推理引擎（InferenceEngine）两个核心模块。,知识库,,,KnowledgeBase,
传统的专家系统通常包含知识库和推理引擎（InferenceEngine）两个核心模块。,推理引擎,,,InferenceEngine,
无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化的语义定义。,语义网络,,,语义理论模型,
无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化的语义定义。,框架语言,,,形式化的语义定义,
无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化的语义定义。,产生式规则,,,缺少严格的语义理论模型和形式化的语义定义,
为了解决这一问题，人们开始研究具有较好的理论模型基础和算法复杂度的知识表示框架。,知识表示的五大用途或特点,,,较好的理论模型基础和算法复杂度的知识表示框架,
比较有代表性的是描述逻辑语言（Description_Logic）[4]。,描述逻辑语言,,,描述逻辑,
比较有代表性的是描述逻辑语言（Description_Logic）[4]。,描述逻辑语言,,,Description_Logic,
描述逻辑是目前大多数本体语言（如OWL）的理论基础。,本体语言,,,描述逻辑,
第一个描述逻辑语言是1985年由RonaldJ.Brachman等提出的KL-ONE[5]。,KL-ONE,,,第一个描述逻辑语言,
第一个描述逻辑语言是1985年由RonaldJ.Brachman等提出的KL-ONE[5]。,KL-ONE,,,第一个描述逻辑语言,
描述逻辑主要用于刻画概念（Concepts）、属性（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑描述Logic_Statement）等知识表达要素。,描述逻辑,,,刻画概念（Concepts）、属性（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑描述Logic_Statement）等知识表达要素,
描述逻辑主要用于刻画概念（Concepts）、属性（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑描述Logic_Statement）等知识表达要素。,描述逻辑,,,描述逻辑,
与传统专家系统的知识表示语言不同，描述逻辑家族更关心知识表示能力和推理计算复杂性之间的关系，并深入研究了各种表达构件的组合带来的查询、分类、一致性检测等推理计算的计算复杂度问题。,描述逻辑家族,,,关心知识表示能力和推理计算复杂性之间的关系,
语义网的基础数据模型RDF受到了元数据模型、框架系统和面向对象语言等多方面的影响，其最初是为人们在Web上发布结构化数据提供一个标准的数据描述框架。,语义网的基础数据模型RDF,,,为人们在Web上发布结构化数据提供一个标准的数据描述框架,
与此同时，语义网进一步吸收描述逻辑的研究成果，发展出了用OWL系列标准化本体语言。,语义网,,,描述逻辑的研究成果,
无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于以符号逻辑为基础的知识表示方法。,早期专家系统时代的知识表示方法,,,以符号逻辑为基础的知识表示方法,
无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于以符号逻辑为基础的知识表示方法。,早期专家系统时代的知识表示方法,,,以符号逻辑为基础的知识表示方法,
无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于以符号逻辑为基础的知识表示方法。,语义网时代的知识表示模型,,,以符号逻辑为基础的知识表示方法,
符号知识表示的特点是易于刻画显式、离散的知识，因而具有内生的可解释性。,符号知识表示的特点,,,易于刻画显式、离散的知识，因而具有内生的可解释性,
符号知识表示的特点是易于刻画显式、离散的知识，因而具有内生的可解释性。,符号知识表示的特点,,,易于刻画显式、离散的知识，因而具有内生的可解释性,
但由于人类知识还包含大量不易于符号化的隐性知识，完全基于符号逻辑的知识表示通常由于知识的不完备而失去鲁棒性，特别是推理很难达到实用。,知识表示的鲁棒性,,,基于符号逻辑的知识表示,
由此催生了采用连续向量的方式来表示知识的研究。,连续向量的方式来表示知识,,,采用连续向量的方式来表示知识的研究,
基于向量的方式表示知识的研究由来已有。,基于向量的方式表示知识的研究,,,基于向量表示知识的研究,
随着表示学习的发展，以及自然语言处理领域词向量等嵌入（Embedding）技术手段的出现，启发了人们用类似于词向量的低维稠密向量的方式表示知识。,表示学习,,,表示知识,
随着表示学习的发展，以及自然语言处理领域词向量等嵌入（Embedding）技术手段的出现，启发了人们用类似于词向量的低维稠密向量的方式表示知识。,表示学习,,,表示学习的发展,
通过嵌入将知识图谱中的实体和关系投射到一个低维的连续向量空间，可以为每一个实体和关系学习出一个低维度的向量表示。,向量空间,,,将知识图谱中的实体和关系投射到一个低维的连续向量空间,
通过嵌入将知识图谱中的实体和关系投射到一个低维的连续向量空间，可以为每一个实体和关系学习出一个低维度的向量表示。,向量空间,,,embedding,
这种基于连续向量的知识表示可以实现通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜在假设，这些隐式知识通常是人的主观不易于观察和总结出来的。,基于连续向量的知识表示,,,通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜在假设,
这种基于连续向量的知识表示可以实现通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜在假设，这些隐式知识通常是人的主观不易于观察和总结出来的。,基于连续向量的知识表示,,,基于连续向量的知识表示,
更为重要的是，知识图谱嵌入也通常作为一种类型的先验知识辅助输入很多深度神经网络模型中，用来约束和监督神经网络的训练过程。,知识图谱嵌入,,,先验知识辅助输入很多深度神经网络模型中，用来约束和监督神经网络的训练过程,
更为重要的是，知识图谱嵌入也通常作为一种类型的先验知识辅助输入很多深度神经网络模型中，用来约束和监督神经网络的训练过程。,知识图谱嵌入,,,knowledge graph embedding,
如图2-1所示为基于离散符号的知识表示与基于连续向量的知识表示对比。,基于离散符号的知识表示,,,基于连续向量的知识表示对比,
如图2-1所示为基于离散符号的知识表示与基于连续向量的知识表示对比。,基于离散符号的知识表示,,,基于离散符号的知识表示,
图2-1基于离散符号的知识表示与基于连续向量的知识表示对比综上所述，与传统人工智能相比，知识图谱时代的知识表示方法已经发生了很大的变化。,知识表示方法,,,基于离散符号的知识表示与基于连续向量的知识表示对比,
由于知识表示涉及大量传统人工智能的内容，并有其明确、严格的内涵及外延定义，为避免混淆，在本书中主要侧重于知识图谱的表示方法的介绍，因此用“知识表示”和“知识图谱的表示方法”加以了区分。,知识表示,,,“知识表示”,
2.2人工智能早期的知识表示方法知识是智能的基础。,知识,,,智能的基础,
人类智能往往依赖有意或无意运用已知的知识。,人类智能,,,依靠已知的知识,
人类智能往往依赖有意或无意运用已知的知识。,人类智能的运用,,,已知知识,
与此类似，人工智能系统需要获取并运用知识。,人工智能系统,,,获取并运用知识,
这里有两个核心问题：怎么表示知识？怎样在计算机中高效地存储与处理知识？本章主要阐述第一个核心问题。,本章,,,阐述第一个核心问题,
2.2.1一阶谓词逻辑一阶谓词逻辑（或简称一阶逻辑）（First_Order_Logic）是公理系统的标准形式逻辑。,一阶谓词逻辑,,,公理系统的标准形式逻辑,
不同于命题逻辑（Propositional_Logic），一阶逻辑支持量词（Quantifier）和谓词（Predicate）。,一阶逻辑,,,命题逻辑,
不同于命题逻辑（Propositional_Logic），一阶逻辑支持量词（Quantifier）和谓词（Predicate）。,一阶逻辑,,,First-Order_Logic,
例如，在命题逻辑里，以下两个句子是不相关的命题：“John_MaCarthy是图灵奖得主”（p）、“Tim_Berners-Lee是图灵奖得主”（q）。,p,,,命题逻辑,
例如，在命题逻辑里，以下两个句子是不相关的命题：“John_MaCarthy是图灵奖得主”（p）、“Tim_Berners-Lee是图灵奖得主”（q）。,等价,,,等价,
但是，在一阶逻辑里，可以用谓词和变量表示知识，例如，图灵奖得主（x）表示x是图灵奖得主。,一阶逻辑,,,用谓词和变量表示知识,
但是，在一阶逻辑里，可以用谓词和变量表示知识，例如，图灵奖得主（x）表示x是图灵奖得主。,一阶逻辑,,,first-order logic,
"这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。",图灵奖得主,,,一元谓词,
"这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。",一元谓词,,,Predicate,
"这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。",x,,,变量,
"这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。",图灵奖得主（x）,,,一个原子公式,
Ø图灵奖得主（x）是一个否定公式（Negated_Formula）。,图灵奖得主（x）,,,否定公式（Negated_Formula）,
在上面的例子中，若x为John_MaCarthy，图灵奖得主（x）为第一个命题p。,图灵奖得主,,,第一个命题p,
在上面的例子中，若x为John_MaCarthy，图灵奖得主（x）为第一个命题p。,图灵奖得主,,,第一个命题p,
若x为Tim_Berners-Lee，图灵奖得主（x）为第二个命题q。,图灵奖得主,,,Tim_Berners-Lee,
若x为Tim_Berners-Lee，图灵奖得主（x）为第二个命题q。,图灵奖得主,,,第二个命题q,
1.一阶谓词逻辑优点●结构性。,一阶谓词逻辑优点,,,结构性,
能把事物的属性以及事物间的各种语义联想显式地表示出来。,概念/SPO,,,能把事物的属性以及事物间的各种语义联想显式地表示出来。,
●严密性。,SPO,,,概念/产品,
有形式化的语法和语义，以及相关的推理规则。,本体,,,形式化的语法和语义以及相关的推理规则,
●可实现性。,SPO,,,可实现性,
可以转换为计算机内部形式，以便用算法实现。,概念/转换,,,计算机内部形式,
2.一阶谓词逻辑缺点●有限的可用性。,一阶谓词逻辑缺点,,,有限的可用性。,
一阶逻辑的逻辑归结只是半可判定性的。,一阶逻辑,,,半可判定性,
●无法表示不确定性知识。,OWL_2_CRS,,,无法表示不确定性知识,
2.2.2霍恩子句和霍恩逻辑霍恩子句（Horn_Clause）得名于逻辑学家Alfred_Horn[6]。,霍恩子句,,,霍恩逻辑,
2.2.2霍恩子句和霍恩逻辑霍恩子句（Horn_Clause）得名于逻辑学家Alfred_Horn[6]。,霍恩子句,,,Horn_Clause,
一个子句是文字的析取。,子句,,,文字的析取,
霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。,霍恩子句,,,带有最多一个肯定（positive）文字的子句,
霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。,霍恩子句,,,Horn clause,
例如，Øp1∨…∨Øpn∨_q是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→q。,霍恩子句,,,等价地写为（p1∧…∧pn）→q,
Alfred_Horn于1951年撰文指出这种子句的重要性。,Alfred_Horn,,,撰文指出这种子句的重要性,
霍恩逻辑（Horn_Logic）是一阶逻辑的子集。,霍恩逻辑,,,一阶逻辑,
基于霍恩逻辑的知识库是一个霍恩规则的集合。,基于霍恩逻辑的知识库,,,霍恩规则的集合,
基于霍恩逻辑的知识库是一个霍恩规则的集合。,基于霍恩逻辑的知识库,,,基于霍恩规则的集合,
"一个霍恩规则由原子公式构成：B1∧…∧Bn→H，其中H是头原子公式，B1,…,Bn是体原子公式。",霍恩规则,,,原子公式构成,
"一个霍恩规则由原子公式构成：B1∧…∧Bn→H，其中H是头原子公式，B1,…,Bn是体原子公式。",霍恩规则,,,Horn规则,
事实是霍恩规则的特例，它们是没有体原子公式且没有变量的霍恩Berners-Lee）是一个事实，可以简写为图灵奖得主规则。,事实,,,霍恩规则的特例,
事实是霍恩规则的特例，它们是没有体原子公式且没有变量的霍恩Berners-Lee）是一个事实，可以简写为图灵奖得主规则。,霍恩规则的特例,,,Horn的特例,
例如，→图灵奖得主（Tim（Tim_Berners-Lee）。,图灵奖得主,,,Tim（Tim_Berners-Lee）,
1.霍恩逻辑的优点●结构性。,霍恩逻辑的优点,,,结构性,
能把事物的属性以及事物间的各种语义联想显式地表示出来。,概念/SPO,,,能把事物的属性以及事物间的各种语义联想显式地表示出来。,
●严密性。,SPO,,,概念/产品,
有形式化的语法和语义，以及相关的推理规则。,本体,,,形式化的语法和语义以及相关的推理规则,
●易实现性。,易实现性,,,SPO三元组,
可判定，可以转换为计算机内部形式，以便用算法实现。,可判定,,,转换为计算机内部形式，以便用算法实现。,
2.霍恩逻辑的缺点●有限的表达能力。,霍恩逻辑的缺点,,,有限的表达能力,
不能定义类表达式，不能够任意使用量化。,类表达式,,,不能定义类表达式,
不能定义类表达式，不能够任意使用量化。,不能定义类表达式,,,cannot define class expression,
不能定义类表达式，不能够任意使用量化。,不能够任意使用量化,,,cannot use quantification arbitrarily,
●无法表示不确定性知识。,OWL_2_CRS,,,无法表示不确定性知识,
2.2.3语义网络语义网络是由Quillian等人提出用于表达人类的语义知识并且支持推理[3]。,语义网络,,,用于表达人类的语义知识并且支持推理,
2.2.3语义网络语义网络是由Quillian等人提出用于表达人类的语义知识并且支持推理[3]。,语义网络,,,semantic network,
语义网络又称联想网络，它在形式上是一个带标识的有向图。,语义网络,,,联想网络,
语义网络又称联想网络，它在形式上是一个带标识的有向图。,语义网络,,,联想网络,
图中“节点”用以表示各种事物、概念、情况、状态等。,节点,,,概念/产品,
每个节点可以带有若干属性。,节点,,,属性,
节点与节点间的“连接弧”（称为联想弧）用以表示各种语义联系、动作。,节点,,,“连接弧”,
节点与节点间的“连接弧”（称为联想弧）用以表示各种语义联系、动作。,节点,,,“连接弧”,
语义网络的单元是三元组：（节点1，联想弧，节点2）。,语义网络的单元,,,三元组,
语义网络的单元是三元组：（节点1，联想弧，节点2）。,三元组,,,三元组：（节点1，联想弧，节点2）。,
例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。,Tim_Berners-Lee,,,图灵奖得主,
例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。,Tim_Berners-Lee,,,互联网,
例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。,Tim_Berners-Lee,,,图灵奖得主,
例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。,Tim_Berners-Lee,,,互联网,
由于所有的节点均通过联想弧彼此相连，语义网络可以通过图上的操作进行知识推理。,语义网络,,,图上的操作进行知识推理,
由于所有的节点均通过联想弧彼此相连，语义网络可以通过图上的操作进行知识推理。,语义网络,,,semantic network,
1.语义网络的优点1）联想性。,语义网络的优点,,,联想性,
它最初是作为人类联想记忆模型提出来的。,联想记忆模型,,,作为人类联想记忆模型提出,
2）易用性。,2）易用性。,,,SPO三元组,
3）结构性。,SPO,,,结构性,
语义网络是一种结构化的知识表示方法，对数据子图特别有效。,语义网络,,,结构化的知识表示方法,
它能把事物的属性以及事物间的各种语义联想显式地表示出来。,概念/语义联想,,,事物的属性以及事物间的各种语义联想,
2.语义网络的缺点1）无形式化语法。,语义网络的缺点,,,无形式化语法,
语义网络表示知识的手段多种多样，虽然灵活性很高，但同时也由于表示形式的不一致提高了对其处理的复杂性。,语义网络,,,表示知识的手段多种多样,
语义网络表示知识的手段多种多样，虽然灵活性很高，但同时也由于表示形式的不一致提高了对其处理的复杂性。,语义网络表示知识的手段,,,semantic network representation knowledge,
例如，“每个学生都读过一本书”可以表示为多种不同的语义网络，例如图2-2和图2-3中的语义网络。,语义网络,,,表示为多种不同的语义网络,
例如，“每个学生都读过一本书”可以表示为多种不同的语义网络，例如图2-2和图2-3中的语义网络。,语义网络,,,"semantic network, ",
在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。,GS,,,一般事件,
在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。,g,,,GS中的一个具体例子,
在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。,s,,,学生这个概念的一个个体,
在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。,r,,,读这个概念的一个个体,
在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。,b,,,书这个概念的一个个体,
而图2-3则把“每个学生都读过一本书”表示成：任何一个学生s1都是属于读过一本书这个概念的元素。,任何一个学生s1,,,属于读过一本书这个概念的元素,
图2-3表示“每个学生都读过一本书”的语义网络2）无形式化语义。,语义网络,,,“每个学生都读过一本书”的语义网络,
图2-3表示“每个学生都读过一本书”的语义网络2）无形式化语义。,等价,,,等价,
与一阶谓词逻辑相比，语义网络没有公认的形式表示体系。,语义网络,,,一阶谓词逻辑,
与一阶谓词逻辑相比，语义网络没有公认的形式表示体系。,语义网络,,,语义网络,
一个给定的语义网络表达的含义完全依赖处理程序如何对它进行解释。,语义网络,,,解释,
通过推理网络而实现的推理不能保证其正确性。,推理网络,,,通过推理网络而实现的推理,
此外，目前采用量词（包括全称量词和存在量词）的语义网络表示法在逻辑上是不充分的，不能保证不存在二义性。,量词,,,quantifier,
2.2.4框架框架（Frame）最早由Marvin_Minsky在1975年提出[7]，目标是更好地理解视觉推理和自然语言处理。,框架,,,视觉推理和自然语言处理,
2.2.4框架框架（Frame）最早由Marvin_Minsky在1975年提出[7]，目标是更好地理解视觉推理和自然语言处理。,框架,,,Frame,
其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类似于框架的结构存储在记忆中。,框架存储,,,人们对现实世界中各种事物的认识,
当面临一个新事物时，就从记忆中找出一个合适的框架，并根据实际情况对其细节加以修改、补充，从而形成对当前事物的认识。,框架思维,,,根据实际情况对其细节加以修改、补充,
框架是一种描述对象（事物、事件或概念等）属性的数据结构。,框架,,,描述对象属性的数据结构,
框架是一种描述对象（事物、事件或概念等）属性的数据结构。,框架,,,描述对象属性的数据结构,
在框架理论中，类是知识表示的基本单位。,类,,,知识表示的基本单位,
每个类有一些槽，每个槽又可分为若干“侧面”。,类,,,槽侧面,
一个槽用于表示描述对象的一个属性，而一个侧面用语表示槽属性的一个方面，槽和侧面都可以有属性值，分别称为槽值和侧面值。,侧面,,,槽属性的一个方面,
一个槽用于表示描述对象的一个属性，而一个侧面用语表示槽属性的一个方面，槽和侧面都可以有属性值，分别称为槽值和侧面值。,侧面,,,side,
除此之外，框架还允许给属性设默认值，以及设立触发器以维护框架。,框架,,,给属性设默认值,
除此之外，框架还允许给属性设默认值，以及设立触发器以维护框架。,框架,,,设立触发器以维护框架,
除此之外，框架还允许给属性设默认值，以及设立触发器以维护框架。,框架,,,frame,
1）下面是框架的基本组成的一个示例：2）表2-1给出一个带变量框架实例。,框架的组成,,,一个示例,
如果把框架“tx未遂杀人案”的变量赋值，可以得到下面的一个框架实例，如表2-2所示。,tx未遂杀人案,,,框架实例,
表2-1带变量框架实例表2-2变量赋值框架实例1.框架的优点1）结构性：能把事物的属性以及事物间的各种语义联想显式地表示出来。,框架的优点,,,结构性,
表2-1带变量框架实例表2-2变量赋值框架实例1.框架的优点1）结构性：能把事物的属性以及事物间的各种语义联想显式地表示出来。,框架的优点,,,结构性,
2）框架对于知识的描述比较全面，支持默认值以及触发器。,框架,,,知识的描述比较全面,
2.框架的缺点1）框架的构建成本非常高，对知识库的质量要求非常高。,框架的缺点,,,构建成本非常高，对知识库的质量要求非常高。,
2）默认值会增大推理的复杂度。,默认值,,,推理的复杂度,
3）无法表示不确定性知识。,SPO,,,无法表示不确定性知识,
2.2.5描述逻辑描述逻辑是一阶逻辑的一个可判定子集。,描述逻辑,,,一阶逻辑的一个可判定子集,
最初由Ronald_J.Brachman在1985年提出。,OWL_2_QL,,,Ronald_J.Brachman,
描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。,描述逻辑,,,一阶逻辑对语义网络和框架进行形式化后的产物。,
描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。,描述逻辑,,,description logic,
描述逻辑一般支持一元谓词和二元谓词。,描述逻辑,,,一元谓词和二元谓词,
描述逻辑一般支持一元谓词和二元谓词。,一元谓词,,,unary predicate,
描述逻辑一般支持一元谓词和二元谓词。,二元谓词,,,binary predicate,
一元谓词称为类，二元谓词称为关系。,一元谓词,,,类,
一元谓词称为类，二元谓词称为关系。,一元谓词,,,类,
一元谓词称为类，二元谓词称为关系。,二元谓词,,,关系,
描述逻辑的重要特征是同时具有很强的表达能力和可判定性。,描述逻辑,,,很强的表达能力,
描述逻辑的重要特征是同时具有很强的表达能力和可判定性。,描述逻辑,,,很强的可判定性,
描述逻辑近年来受到广泛关注，被选为W3C互联网本体语言（OWL）的理论基础。,描述逻辑,,,W3C互联网本体语言（OWL）,
1.描述逻辑的优点1）结构性。,描述逻辑的优点,,,结构性,
能把事物的属性以及事物间的各种语义联想显式地表示出来。,概念/SPO,,,能把事物的属性以及事物间的各种语义联想显式地表示出来。,
2）严密性。,2）严密性。,,,SPO三元组,
有形式化的语法和语义，以及相关的推理规则。,本体,,,形式化的语法和语义以及相关的推理规则,
3）多样性。,多样性,,,SPO三元组,
具有大量可判定的扩展，以满足不同应用场景的需求。,知识问答,,,可判定的扩展,
4）易实现性。,易实现性,,,SPO三元组,
可判定，可以转换为计算机内部形式，以便用算法实现。,可判定,,,转换为计算机内部形式，以便用算法实现。,
2.描述逻辑的缺点1）有限的表达能力。,描述逻辑的缺点,,,有限的表达能力,
不支持显式使用变量，不能够任意使用量化。,SPO,,,不支持显式使用变量,
不支持显式使用变量，不能够任意使用量化。,SPO,,,supports explicit use of variables,
不支持显式使用变量，不能够任意使用量化。,SPO,,,cannot use quantification arbitrarily,
2）无法表示不确定性知识。,SPO,,,无法表示不确定性知识,
2.3互联网时代的语义网知识表示框架随着语义网的提出，知识表示迎来了新的契机和挑战，契机在于语义网为知识表示提供了一个很好的应用场景，挑战在于面向语义网的知识表示需要提供一套标准语言可以用来描述Web的各种信息。,面向语义网的知识表示,,,提供一套标准语言可以用来描述Web的各种信息,
早期Web的标准语言HTML和XML无法适应语义网对知识表示的要求，所以W3C提出了新的标准语言RDF、RDFS和OWL。,RDF,,,三维语言,
这两种语言的语法可以跟XML兼容。,两种语言的语法,,,XML兼容,
下面详细介绍这几种语言。,下面详细介绍这几种语言,,,语言,
2.3.1RDF和RDFSRDF是W3C的RDF工作组制定的关于知识图谱的国际标准。,RDF,,,知识图谱的国际标准,
RDF是W3C一系列语义网标准的核心，如图2-4所示。,RDF,,,W3C一系列语义网标准的核心,
RDF是W3C一系列语义网标准的核心，如图2-4所示。,RDF,,,W3C一系列语义网标准的核心,
●表示组（Representation）包括URI/IRI、XML和RDF。,表示组,,,URI/IRI、XML和RDF,
●表示组（Representation）包括URI/IRI、XML和RDF。,表示组,,,Representation,
前两者主要是为RDF提供语法基础。,OWL_2_RDF_语法,,,为RDF提供语法基础,
●推理组（Reasoning）包括RDF-S、本体OWL、规则RIF和统一逻辑。,推理组,,,RDF-S、本体OWL、规则RIF和统一逻辑,
●推理组（Reasoning）包括RDF-S、本体OWL、规则RIF和统一逻辑。,推理组,,,Reasoning,
统一逻辑目前还没有定论。,统一逻辑,,,还没有定论,
●信任组和用户互动组。,信任组,,,用户互动组,
图2-4对W3C的语义网标准栈做了分组。,语义网标准栈,,,W3C,
目前，跟知识图谱最相关的有：图2-4W3C的语义网标准栈及其分组2006年，人们开始用RDF发布和链接数据，从而生成知识图谱，比较知名的有DBpedia、Yago和Freebase。,知识图谱,,,knowledge graph,
2009年，Tim_Berners-Lee为进一步推动语义网开放数据的发展，进一步提出了开放链接数据的五星级原则，如表2-3所示。,开放链接数据的五星级原则,,,进一步推动语义网开放数据的发展，进一步提出,
表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。,实现五星级原则的四个步骤,,,使用URIs对事物命名,
表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。,实现五星级原则的四个步骤,,,使用HTTP_URIs，以方便搜索,
表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。,实现五星级原则的四个步骤,,,使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询,
表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。,实现五星级原则的四个步骤,,,链接不同的图谱（例如通过owl:sameAs），以方便数据重用,
表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。,五星级原则,,,实现五星级原则的四个步骤,
2007年，不少开放图谱实现与DBpedia链接。,开放图谱,,,DBpedia,
如图2-5为开放链接数据早期的发展。,开放链接数据,,,早期的发展,
图2-5开放链接数据早期的发展1.RDF简介在RDF中，知识总是以三元组的形式出现。,RDF,,,开放链接数据早期的发展,
图2-5开放链接数据早期的发展1.RDF简介在RDF中，知识总是以三元组的形式出现。,RDF,,,三元组,
"每一份知识可以被分解为如下形式：(subject,predicate,object)。",知识,,,每一份知识,
"例如，“IBM邀请Jeff_Pan作为讲者，演讲主题是知识图谱”可以写成以下RDF三元组：（IBM-Talk,speaker,Jeff）,（IBM-Talk,theme,KG）。",IBM-Talk,,,讲者,
"例如，“IBM邀请Jeff_Pan作为讲者，演讲主题是知识图谱”可以写成以下RDF三元组：（IBM-Talk,speaker,Jeff）,（IBM-Talk,theme,KG）。",IBM-Talk,,,知识图谱,
RDF中的主语是一个个体（Individual），个体是类的实例。,RDF中的主语,,,个体,
RDF中的主语是一个个体（Individual），个体是类的实例。,主语,,,个体,
RDF中的谓语是一个属性。,谓语,,,属性,
属性可以连接两个个体，或者连接一个个体和一个数据类型的实例。,属性,,,连接两个个体或者连接一个个体和一个数据类型的实例,
"换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。",RDF中的宾语,,,个体,
"换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。",RDF中的宾语,,,数据类型的实例,
"换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。",宾语,,,individual,
"换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。",宾语,,,数据类型的实例,
如果把三元组的主语和宾语看成图的节点，三元组的谓语看成边，那么一个RDF知识库则可以被看成一个图或一个知识图谱，如图2-6所示。,RDF知识库,,,图或知识图谱,
如果把三元组的主语和宾语看成图的节点，三元组的谓语看成边，那么一个RDF知识库则可以被看成一个图或一个知识图谱，如图2-6所示。,三元组,,,一个RDF知识库,
三元组则是图的单元。,三元组,,,图的单元,
在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。,三元组,,,RDF,
在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。,三元组,,,triple,
在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。,主谓宾,,,subject,
在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。,全局标识URI,,,object,
图2-6一个RDF知识库可以被看成一个图图2-7三元组的全局标识URI全局标识URI可以被简化成前缀URI，如图2-8所示。,RDF知识库,,,图,
图2-6一个RDF知识库可以被看成一个图图2-7三元组的全局标识URI全局标识URI可以被简化成前缀URI，如图2-8所示。,RDF知识库,,,一个RDF知识库,
RDF允许没有全局标识的空白节点（Blank_Node）。,RDF,,,没有全局标识的空白节点,
RDF允许没有全局标识的空白节点（Blank_Node）。,RDF,,,Reside Free and Dynamic,
空白节点的前缀为“_”。,空白节点,,,“_”,
例如，Jeff是某一次关于KG讲座的讲者，如图2-9所示。,Jeff,,,一次关于KG讲座的讲者,
图2-8前缀URI图2-9没有全局标识的空白节点RDF是抽象的数据模型，支持不同的序列化格式，例如RDF/XML、Turtle和N-Triple，如图2-10所示。,RDF,,,抽象的数据模型,
图2-8前缀URI图2-9没有全局标识的空白节点RDF是抽象的数据模型，支持不同的序列化格式，例如RDF/XML、Turtle和N-Triple，如图2-10所示。,RDF,,,抽象的数据模型,
图2-10不同的序列化格式2.开放世界假设不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。,开放世界假设,,,RDF,
图2-10不同的序列化格式2.开放世界假设不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。,开放世界假设,,,open world assumption,
图2-10不同的序列化格式2.开放世界假设不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。,经典数据库,,,closed world assumption,
也就是说，RDF的开放性特点和要求。,RDF的开放性特点,,,要求,
（IBM-图谱里的知识有可能是不完备的，这符合Web讲座只有一位讲者。,IBM-图谱里的知识,,,不完备,
"换一个角度，（IBM-Talk,speaker,Jeff）并不意味着Talk,speaker,Jeff）意味着IBM讲座至少有一位讲者。",IBM-Talk,,,概念/产品,
"换一个角度，（IBM-Talk,speaker,Jeff）并不意味着Talk,speaker,Jeff）意味着IBM讲座至少有一位讲者。",IBM-Talk,,,IBM讲座,
采用开放世界假设意味着RDF图谱可以被分布式储存，如图2-11所示。,RDF图谱,,,分布式储存,
采用开放世界假设意味着RDF图谱可以被分布式储存，如图2-11所示。,采用开放世界假设,,,RDF图谱可以被分布式储存,
IBM图2-11RDF图谱可以被分布式储存同时，分布式定义的知识可以自动合并，如图2-12所示。,RDF图谱,,,分布式储存,
IBM图2-11RDF图谱可以被分布式储存同时，分布式定义的知识可以自动合并，如图2-12所示。,RDF图谱,,,RDF图,
图2-12分布式定义的知识可以自动合并3.RDFS简介RDF用到了类以及属性描述个体之间的关系。,RDFS,,,用到了类以及属性描述个体之间的关系,
图2-12分布式定义的知识可以自动合并3.RDFS简介RDF用到了类以及属性描述个体之间的关系。,RDF,,,描述个体之间的关系,
这些类和属性由模式（schema）定义。,类和属性,,,模式（schema）定义,
RDF_Schema（RDF模式，简称RDFS）提供了对类和属性的简单描述，从而给RDF数据提供词汇建模的语言。,RDF_Schema,,,对类和属性的简单描述,
RDF_Schema（RDF模式，简称RDFS）提供了对类和属性的简单描述，从而给RDF数据提供词汇建模的语言。,RDF_Schema,,,RDF模式,
更丰富的定义则需要用到OWL本体描述语言。,OWL本体描述语言,,,更丰富的定义,
RDFS提供了最基本的对类和属性的描述元语：●rdf:type：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。,rdfs:subClassOf,,,指定类的父类,
RDFS提供了最基本的对类和属性的描述元语：●rdf:type：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。,rdfs:subPropertyOf,,,指定属性的父属性,
RDFS提供了最基本的对类和属性的描述元语：●rdf:type：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。,rdfs:domain,,,指定属性的定义域,
RDFS提供了最基本的对类和属性的描述元语：●rdf:type：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。,rdfs:range,,,指定属性的值域,
举例来说，下面的三元组表示用户自定义的元数据Author是Dublin_Core的元数据Creator的子类，如图2-13所示。,Author,,,Dublin_Core的元数据Creator的子类,
举例来说，下面的三元组表示用户自定义的元数据Author是Dublin_Core的元数据Creator的子类，如图2-13所示。,等价,,,equivalence,
举例来说，下面的三元组表示用户自定义的元数据Author是Dublin_Core的元数据Creator的子类，如图2-13所示。,英文名,,,英文名,
RDF_Schema通过这样的方式描述不同词汇集的元数据之间的关系，从而为网络上统一格式的元数据交换打下基础。,RDF_Schema,,,描述不同词汇集的元数据之间的关系,
下面用图2-14说明RDFS，为了简便，边的标签省略了RDF或者RDFS。,RDFS,,,OWL,
知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。,知识,,,数据层面的知识,
知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。,知识,,,模式层面的知识,
知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。,知识,,,data层面的知识,
知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。,知识,,,模式层面的知识,
图2-13Author是Creator的子类图2-14RDFS示例2.3.2OWL和OWL2Fragments前面介绍了RDF和RDFS，通过RDF（S）可以表示一些简单的语义，但在更复杂的场景下，RDF（S）语义的表达能力显得太弱，还缺少常用的特征：（1）对于局部值域的属性定义。,Author,,,Creator,
RDF（S）中通过rdfs:range定义了属性的值域，该值域是全局性的，无法说明该属性应用于某些具体的类时具有的特殊值域限制，如无法声明父母至少有一个孩子。,rdfs:range,,,属性的值域,
RDF（S）中通过rdfs:range定义了属性的值域，该值域是全局性的，无法说明该属性应用于某些具体的类时具有的特殊值域限制，如无法声明父母至少有一个孩子。,属性的值域,,,rdfs:range,
（2）类、属性、个体的等价性。,类,,,属性、个体的等价性,
（2）类、属性、个体的等价性。,等价,,,equivalence,
（2）类、属性、个体的等价性。,属性,,,property,
（2）类、属性、个体的等价性。,个体,,,individual,
RDF（S）中无法声明两个类或多个类、属性和个体是等价还是不等价，如无法声明Tim-Berns_Lee和T.B.Lee是同一个人。,RDF（S）,,,RDF（S）,
（3）不相交类的定义。,不相交类的定义,,,概念/产品,
在RDF（S）中只能声明子类关系，如男人和女人都是人的子类，但无法声明这两个类是不相交的。,男人,,,人的子类,
在RDF（S）中只能声明子类关系，如男人和女人都是人的子类，但无法声明这两个类是不相交的。,女人,,,人的子类,
在RDF（S）中只能声明子类关系，如男人和女人都是人的子类，但无法声明这两个类是不相交的。,等价,,,subclass,
（4）基数约束。,SPO,,,概念/产品,
即对某属性值可能或必需的取值范围进行约束，如说明一个人有双亲（包括两个人），一门课至少有一名教师等。,属性约束,,,对某属性值可能或必需的取值范围进行约束,
即对某属性值可能或必需的取值范围进行约束，如说明一个人有双亲（包括两个人），一门课至少有一名教师等。,等价,,,equivalence,
（5）关于属性特性的描述。,属性特性,,,关于属性特性的描述。,
即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。,属性,,,声明属性的某些特性,
即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。,传递性,,,transitivity,
即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。,函数性,,,functional,
即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。,对称性,,,symmetry,
即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。,一个属性的逆属性,,,another property,
为了得到一个表达能力更强的本体语言，W3C提出了OWL语言扩展RDF（S），作为在语义网上表示本体的推荐语言。,OWL语言扩展RDF（S）,,,在语义网上表示本体的推荐语言,
为了得到一个表达能力更强的本体语言，W3C提出了OWL语言扩展RDF（S），作为在语义网上表示本体的推荐语言。,OWL语言扩展RDF（S）,,,在语义网上表示本体的推荐语言,
1.OWL的语言特征如图2-15所示，OWL1.0有OWL_Lite、OWL_DL、OWL_Full三个子语言，三个子语言的特征和使用限制举例如表2-4所示。,OWL_Lite,,,OWL轻型,
图2-15OWL_1.0的主要子语言表2-4三个子语言的特征和使用限制举例可以采用以下原则选择这些语言：●选择OWL_Lite还是OWL_DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；●选择OWL_DL还是OWL_Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；●当使用OWL_Full而不是OWL_DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL_Full的系统实现。,OWL_Lite,,,OWL_lite,
图2-15OWL_1.0的主要子语言表2-4三个子语言的特征和使用限制举例可以采用以下原则选择这些语言：●选择OWL_Lite还是OWL_DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；●选择OWL_DL还是OWL_Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；●当使用OWL_Full而不是OWL_DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL_Full的系统实现。,OWL_DL,,,OWL_DL,
图2-15OWL_1.0的主要子语言表2-4三个子语言的特征和使用限制举例可以采用以下原则选择这些语言：●选择OWL_Lite还是OWL_DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；●选择OWL_DL还是OWL_Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；●当使用OWL_Full而不是OWL_DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL_Full的系统实现。,OWL_Full,,,OWL_full,
OWL的子语言与RDF有以下关系。,OWL的子语言,,,RDF,
首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。,OWL_Full,,,RDF的扩展,
首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。,OWL_Full,,,RDF的扩展,
首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。,OWL_Lite,,,一个约束化的RDF的扩展,
首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。,OWL_Full文档,,,所有的OWL文档,
首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。,RDF文档,,,一个OWL文档,
2.OWL的重要词汇（1）等价性声明。,OWL的重要词汇,,,等价性声明,
2.OWL的重要词汇（1）等价性声明。,等价性声明,,,equivalence statement,
声明两个类、属性和实例是等价的。,三元组,,,声明两个类、属性和实例是等价的。,
如：exp：运动员owl:equivalentClass_exp：体育选手exp：获得_owl:equivalentProperty_exp：取得exp：运动员A_owl:sameIndividualAs_exp：小明以上三个三元组分别声明了两个类、两个属性以及两个个体是等价的，exp_是命名空间_http://www.example.org_的别称，命名空间是唯一识别的一套名字，用来避免名字冲突，在OWL中可以是一个URL。,exp,,,exp：运动员,
（2）属性传递性声明。,属性传递性声明,,,SPO三元组,
声明一个属性是传递关系。,传递关系,,,声明一个属性,
例如，exp:ancestor_rdf:typeowl:TransitiveProperty指的是exp:ancestor_是一个传递关系。,ancestor_rdf:typeowl:TransitiveProperty,,,属于传递关系,
例如，exp:ancestor_rdf:typeowl:TransitiveProperty指的是exp:ancestor_是一个传递关系。,exp:ancestor_rdf:type,,,owl:TransitiveProperty,
如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。,a_exp,,,传递,
如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。,a_exp,,,ancestor_b,
如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。,b_exp,,,ancestor_c,
如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。,a_exp,,,ancestor_c,
例如exp：小明exp:ancestor_exp：小林；exp：小林_exp:ancestor_exp：小志，根据上述声明，可以推出exp：小明exp:ancestor_exp：小志。,exp：小明,,,ancestor_exp：小林,
（3）属性互逆声明。,属性互逆声明,,,SPO三元组,
声明两个属性有互逆的关系。,互逆的关系,,,声明两个属性,
例如，exp:ancestor_owl:inverseOfexp:descendant指的是exp:ancestor和exp:descendant是互逆的。,exp:ancestor_owl:inverseOf,,,exp:descendant,
例如，exp:ancestor_owl:inverseOfexp:descendant指的是exp:ancestor和exp:descendant是互逆的。,等价,,,互逆,
如果exp：小明exp:ancestor_exp：小林，根据上述声明，可以推出exp：小林_exp:descendant_exp：小明。,exp：小明,,,ancestor_exp：小林,
（4）属性的函数性声明。,属性的函数性声明,,,SPO三元组,
声明一个属性是函数。,属性,,,函数,
例如，exp:hasMother_rdf:typeowl:FunctionalProperty指的是exp:hasMother是一个函数，即一个生物只能有一个母亲。,exp:hasMother_rdf:typeowl:FunctionalProperty,,,exp:是一个函数,
例如，exp:hasMother_rdf:typeowl:FunctionalProperty指的是exp:hasMother是一个函数，即一个生物只能有一个母亲。,exp:hasMother_rdf:type,,,owl:FunctionalProperty,
（5）属性的对称性声明。,属性的对称性声明,,,SPO三元组,
声明一个属性是对称的。,属性,,,对称的,
例如rdf:typeowl:SymmetricProperty指的是exp:friend是一个具有对称性的属性；如果exp：小明exp:friendexp：小林，根据上述声明，有exp：小林_exp:friend_exp：小明。,rdf:typeowl:SymmetricProperty,,,exp:friend,
例如rdf:typeowl:SymmetricProperty指的是exp:friend是一个具有对称性的属性；如果exp：小明exp:friendexp：小林，根据上述声明，有exp：小林_exp:friend_exp：小明。,等价,,,owl:SymmetricProperty,
exp:friend（6）属性的全称限定声明。,exp:friend,,,属性的全称限定声明。,
声明一个属性是全称限定。,属性,,,全称限定,
如：exp:Person_owl:allValuesFrom_exp:Womenexp:Person_owl:onProperty_exp:hasMother这个说明exp:hasMother_在主语属于exp:Person类的条件下，宾语的取值只能来自exp:Women类。,exp:hasMother,,,exp:Person_owl:allValuesFrom_exp:Women,
如：exp:Person_owl:allValuesFrom_exp:Womenexp:Person_owl:onProperty_exp:hasMother这个说明exp:hasMother_在主语属于exp:Person类的条件下，宾语的取值只能来自exp:Women类。,exp:hasMother,,,exp:AllValuesFrom,
如：exp:Person_owl:allValuesFrom_exp:Womenexp:Person_owl:onProperty_exp:hasMother这个说明exp:hasMother_在主语属于exp:Person类的条件下，宾语的取值只能来自exp:Women类。,exp:Person,,,exp:onProperty,
（7）属性的存在限定声明。,属性的存在限定声明。,,,SPO三元组,
声明一个属性是存在限定。,属性,,,存在限定,
如：exp:SemanticWebPaper_owl:someValuesFrom_exp:AAAIexp:SemanticWebPaper_owl:onProperty_exp:publishedIn这个说明exp:publishedIn在主语属于exp:SemanticWebPaper类的条件下，宾语的取值部分来自exp:AAAI类。,exp:SemanticWebPaper_owl:someValuesFrom_exp:AAAI,,,exp:AAAI,
上面的三元组相当于：关于语义网的论文部分发表在AAAI上。,关于语义网的论文,,,AAAI,
（8）属性的基数限定声明。,属性的基数限定声明。,,,SPO三元组,
声明一个属性的基数。,属性的基数,,,SPO,
如：exp:Person_owl:cardinality“1”^^xsd:integerexp:Person_owl:onProperty_exp:hasMother指的是exp:hasMother在主语属于exp:Person类的条件下，宾语的取值只能有一个，“1”的数据类型被声明为xsd:integer，这是基数约束，本质上属于属性的局部约束。,exp:hasMother,,,exp:Person_owl:cardinality“1”^^xsd:integer,
如：exp:Person_owl:cardinality“1”^^xsd:integerexp:Person_owl:onProperty_exp:hasMother指的是exp:hasMother在主语属于exp:Person类的条件下，宾语的取值只能有一个，“1”的数据类型被声明为xsd:integer，这是基数约束，本质上属于属性的局部约束。,基数约束,,,属于属性的局部约束,
（9）相交的类声明。,相交的类声明,,,SPO三元组,
声明一个类是等价于两个类相交。,类,,,两个类相交,
如：exp:Mother_owl:intersectionOf_tmp_tmp_rdf:type_rdfs:Collection_tmp_rdfs:member_exp:Person_tmp_rdfs:member_exp:HasChildren指tmp是临时资源，它是exp:Person和exp:HasChildren两个类的交集。,exp:Mother_owl,,,exp:intersectionOf,
如：exp:Mother_owl:intersectionOf_tmp_tmp_rdf:type_rdfs:Collection_tmp_rdfs:member_exp:Person_tmp_rdfs:member_exp:HasChildren指tmp是临时资源，它是exp:Person和exp:HasChildren两个类的交集。,exp:Mother_owl:intersectionOf_tmp_tmp,,,exp:Person和exp:HasChildren两个类的交集,
exp:HasChildren。,SPO三元组,,,属于概念/产品,
上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。,rdfs:Collection,,,容器,
上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。,rdfs:Collection,,,容器,
上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。,exp:Person,,,人,
上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。,exp:Mother,,,母亲,
表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。,OWL,,,OWL2,
表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。,OWL,,,OWL2,
表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。,OWL版本,,,OWL,
OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。,OWL2,,,OWL的子语言,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2,,,OWL_2_RL,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2,,,OWL_2_QL,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2,,,OWL_2_EL,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2的子语言,,,OWL_2_RL,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2的子语言,,,OWL_2_QL,
OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。,OWL2的子语言,,,OWL_2_EL,
OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。,OWL_2_QL,,,专为基于本体的查询设计的,
OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。,OWL_2_QL,,,Query_Language,
它的查询复杂度是AC0，非常适合大规模处理。,Elasticsearch,,,AC0,
它是基于描述逻辑DL-Lite定义的。,OWL_2_QL,,,基于描述逻辑DL-Lite,
表2-6给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,,,表2-6,
表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。,OWL_2_QL,,,多项式推理的OWL,
表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。,OWL_2_EL,,,OWL_2_EQ,
与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。,OWL_2_EL,,,概念术语描述本体推理,
OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。,OWL_2_EL,,,Ptime-Complete,
表2-7给出了OWL_2_QL词汇总结。,OWL_2_QL词汇总结,,,表2-7,
表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female⊓∃likes.Movie⊓∃hasSon.(Student⊓∃attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。,OWL_2_EL,,,复杂的概念,
表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female⊓∃likes.Movie⊓∃hasSon.(Student⊓∃attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。,OWL_2_EL,,,OWL_2_EQ,
下面给出一个例子。,SPO,,,概念/三元组抽取,
假设有一个本体，包含以下公理：公理1.Apple⊑∃beInvestedBy.(Fidelity⊓BlackStone)：苹果由富达和黑石投资。,Apple,,,∃beInvestedBy.(Fidelity⊓BlackStone),
假设有一个本体，包含以下公理：公理1.Apple⊑∃beInvestedBy.(Fidelity⊓BlackStone)：苹果由富达和黑石投资。,Apple,,,苹果,
公理2.∃beFundedBy.Fidelity⊑InnovativeCompanies：借助富达融资的公司都是创新企业。,Fidelity,,,借助富达融资的公司都是创新企业,
公理3.∃beFundedBy.BlackStone⊑InnovativeCompanies：借助黑石融资的公司都是创新企业。,BlackStone,,,借助黑石融资的公司都是创新企业,
公理4.beInvestedBy⊑beFundedBy：投资即是帮助融资。,beInvestedBy,,,beFundedBy,
由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,公理5,,,Apple,
由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,等价,,,Apple⊑∃beInvestedBy.Fidelity,
由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,等价,,,由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity,
由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。,等价,,,由公理6和公理2可以推出公理7:Apple,
还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。,OWL_2_RL,,,OWL2子语言,
还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。,OWL_2_RL,,,OWL2推理复杂度是多项式时间的子语言,
OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。,OWL_2_RL,,,RDFS的表达能力,
OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。,OWL_2_RL,,,OWL_2_RDFS扩展了RDFS的表达能力,
OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。,OWL_2_RL推理,,,前向链推理,
OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。,OWL_2_RL推理,,,前向链推理,
"下面给出两个OWL_2_RL上的推理规则：p_rdfs:domain_x,spo⇒s_rdf:type_xp_rdfs:range_x,spo⇒o_rdf:type_x其中，s、p、o、x为变量。",p_rdfs:domain_x,,,推理规则的等价,
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,规则,,,如果属性p的定义域是类x，而且实例s和o有关系p,
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,如果属性p的定义域是类x,,,if the domain of property p is class x,
第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。,实例s和o有关系p,,,instance s and o have relationship p,
第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。,第二条规则,,,如果属性p的值域是类x，而且实例s和o有关系p,
第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。,等价,,,equivalent,
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:hasChild_rdfs:domain_exp:Person,,,exp:Helen,
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:hasChild_rdfs:domain_exp:Person,,,exp:Helen_exp:hasChild_exp:Jack,
"例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。",exp:Helen,,,英文名,
OWL_2_RL允许的核心词汇有：●rdfs:subClassOf；●rdfs:subPropertyOf；●rdfs:domain；●rdfs:range；●owl:TransitiveProperty；●owl:FunctionalProperty；●owl:sameAs；●owl:equivalentClass；●owl:equivalentProperty；●owl:someValuesFrom；●owl:allValuesFrom。,OWL_2_RL,,,OWL_2_RL,
OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。,OWL_2_RL的前向链推理复杂度,,,PTIME完备,
OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。,OWL_2_RL的前向链推理复杂度,,,PTIME完备,
2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。,SPARQL,,,查询RDF数据,
2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。,SPARQL,,,查询RDF数据的标准语法,
1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。,SPARQL知识图谱查询,,,变量、RDF中的资源,
1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。,SPARQL知识图谱查询,,,SPARQL knowledge graph query,
下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。,SPARQL查询,,,查询所有选修CS328课程的学生,
下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。,SPARQL查询,,,查询所有选修CS328课程的学生,
2.常见的SPARQL查询算子（1）OPTIONAL。,SPARQL查询算子,,,常见的,
2.常见的SPARQL查询算子（1）OPTIONAL。,SPARQL查询算子,,,OPTIONAL,
可选算子，指的是在这个算子覆盖范围的查询语句是可选的。,可选算子,,,在这个算子覆盖范围的查询语句是可选的,
例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。,查询所有选修CS328课程的学生姓名,,,查询学生姓名,
例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。,查询所有选修CS328课程的学生姓名,,,查询学生的邮箱,
OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。,OPTIONAL关键字,,,没有邮箱则依然返回学生姓名，邮箱处空缺,
OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。,OPTIONAL,,,等价,
（2）FILTER。,FILTER,,,SPO,
过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。,过滤算子,,,覆盖范围的查询语句可以用来过滤查询结果,
例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。,spo,,,查询学生姓名、选修课程以及他们的年龄,
（3）UNION。,UNION,,,SPO,
并算子，指的是将两个查询的结果合并起来。,并算子,,,将两个查询的结果合并起来,
例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。,SPO,,,查询选修课程CS328或CS909的学生姓名以及邮件,
注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。,邮件,,,返回记录,
注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。,邮件,,,email,
需要注意UNION和OPTIONAL的区别。,UNION,,,集合运算,
下面给出一个SPARQL查询的例子。,SPARQL查询,,,SPO,
给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。,SPARQL查询,,,查询所有的收购关系,
给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。,等价,,,equivalence,
表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。,查询,,,SPARQL查询,
"假设有下面两条规则：hold_share（X,Y）:-control（X,Y）conn_trans（Y,Z）:-hold_share（X,Y）,hold_share（X,Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。",hold_share,,,规则,
"假设有下面两条规则：hold_share（X,Y）:-control（X,Y）conn_trans（Y,Z）:-hold_share（X,Y）,hold_share（X,Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。",等价,,,"if X controls Y, then X holds Y",
"假设有下面两条规则：hold_share（X,Y）:-control（X,Y）conn_trans（Y,Z）:-hold_share（X,Y）,hold_share（X,Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。",等价,,,如果X同时控股Y和Z，那么Y和Z具备关联交易。,
通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。,SPARQL查询,,,嵌套查询,
通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。,SPARQL查询,,,SPARQL查询重写技术,
2.3.4语义Markup表示语言语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。,语义Markup表示语言,,,在网页中嵌入语义Markup的方法和表示语言,
被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5MicroData。,Schema.Org,,,语义Markup语言,
1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。,JSON-LD,,,基于JSON表示和传输链接数据的方法,
1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。,JSON-LD,,,JavaScript_Object_Notation_for_Linked_Data,
JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。,JSON-LD,,,通过JSON表示有向图,
JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。,JSON-LD,,,在一个文档中混合表示链接数据及非链接数据,
JSON-LD的语法和JSON兼容。,JSON-LD,,,JSON,
下面是一个简单的JSON例子：JSON文档表示一个人。,JSON,,,一个人,
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,name,,,人的名字,
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,name,,,人的名字,
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,homepage,,,主页,
人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。,image,,,某种照片,
当然，机器不理解“name”和“image”这样的术语。,语义网,,,属于本体,
JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。,JSON-LD,,,统一的术语表示,
如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。,JSON-LD,,,围绕某类知识提供共享的术语,
如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。,语义网技术,,,semantic web technology,
例如，每个数据集不应该围绕“name”重复发明概念。,数据集,,,“不应该围绕“name”重复发明概念”,
但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。,JSON-LD的实现,,,没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。,
Stores），而是以简2.RDFaRDFa（Resource_Description_Framework_in_attributes）是一种早期网页语义标记语言。,RDFa,,,早期网页语义标记语言,
Stores），而是以简2.RDFaRDFa（Resource_Description_Framework_in_attributes）是一种早期网页语义标记语言。,RDFa,,,Resource_Description_Framework_in_attributes,
RDFa也是W3C推荐标准。,RDFa,,,W3C推荐标准,
它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。,XML,,,扩充XHTML的几个属性,
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,,,将RDF的三元组嵌入在XHTML文档中,
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,,,符合标准的使用端可以从RDFa文件中提取出这些RDF三元组,
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,,,将RDF的三元组嵌入在XHTML文档中,
与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。,RDFa,,,符合标准的使用端可以从RDFa文件中提取出这些RDF三元组,
RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。,RDFa,,,在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。,
上面的代码示例中用到了RDFa属性中的about属性和property属性。,about,,,RDFa属性,
这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。,代码示例,,,一篇文章,
这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。,一段代码示例,,,一段代码示例说明了一篇文章,
RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。,RDFa,,,优化搜索，提升访问体验以及网页数据的关联,
3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。,HTML5_Microdata,,,在网页标记语言中嵌入机器可读的属性数据,
微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。,微数据,,,自定义词汇表、带作用域的键值对给DOM做标记,
微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。,微数据,,,microdata,
微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。,微数据,,,给那些已经在页面上可见的数据施加额外的语义,
下面是一个HTML5Microdata的示例。,HTML5Microdata,,,HTML5的语义化数据,
这个例子给出了Person类下一个叫Andy的人的照片和URL地址。,Person,,,一个叫Andy的人,
通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。,HTML5Microdata,,,从网页上提取微数据实体、属性及属性值,
2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。,知识图谱,,,不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架,
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,框架,,,描述术语、表达能力、数据格式等方面的考虑,
这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。,框架,,,frame,
这里以三个最典型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。,知识图谱,,,不同的知识图谱项目选用的知识表示框架,
为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。,为便于比较分析,,,RDF、OWL的描述术语和表达能力,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,FreebaseFreebase的知识表示框架,,,对象-Object,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,FreebaseFreebase的知识表示框架,,,事实-Facts,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,FreebaseFreebase的知识表示框架,,,类型-ID,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,FreebaseFreebase的知识表示框架,,,MIDTypes,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,FreebaseFreebase的知识表示框架,,,属性-Properties,
2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。,Freebase,,,Freebase的知识表示框架,
“Object”代表实体。,“Object”,,,实体,
每一个“Object”有唯一的（Machine_ID）。,Object,,,每一个“Object”,
每一个“Object”有唯一的（Machine_ID）。,Object,,,对象,
一个“Object”可以有一个或多个“Types”。,Object,,,一个或多个Types,
“Properties”用来描述“Facts”。,“Properties”,,,“Facts”,
例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。,Barack_Obama,,,Object,
例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。,“Barack_Obama”,,,Object,
这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。,“/government/us_president”,,,/government/us_president,
"Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。",Freebase,,,复合值类型处理多元关系,
"Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。",复合值类型,,,"Compound_Value_Types,CVT",
type如图2-16所示，示例的CVT描述了关于Obama的任职期限的多元关系“government_position_held”。,government_position_held,,,CVT的示例,
这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。,多元关系,,,多个子二元关系,
一个CVT就是有唯一MID的Object，也可以有多个Types。,CVT,,,有唯一MID的Object,
一个CVT就是有唯一MID的Object，也可以有多个Types。,CVT,,,多个Types,
为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。,Freebase,,,Object,
Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。,Wikidata,,,Wikipedia,
Entities类似于OWL:Things，代指最顶层的对象。,Entities,,,OWL:Things,
每一个Entity都有一个独立的维基页面。,Entity,,,独立的维基页面,
Entities主要有两类：Items和Properties。,Entities,,,Items,
Entities主要有两类：Items和Properties。,Entities,,,Properties,
Items类似于RDF中的Instance，代指实例对象。,Items,,,实例对象,
Properties和Statements分别等价于RDF中的Property和Statement。,Properties,,,RDF中的Property,
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,一个Item的页面,,,别名-aliases,
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,一个Item的页面,,,外部链接-Sitelinks,
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,别名,,,aliases,
通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。,外部链接,,,Sitelinks,
一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。,Statement,,,一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank,
一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。,Statement,,,一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank,
修饰-Qualifiers用于处理复杂的多元表示。,Qualifiers,,,用于处理复杂的多元表示,
如一个陈述“spouse:Jane_Belson”描述了一个二元关系。,spo,,,三元组,
如一个陈述“spouse:Jane_Belson”描述了一个二元关系。,等价,,,等价,
可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。,Qualifiers,,,刻画多元关系,
可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。,Qualifiers,,,给这个陈述增加多个附加信息来刻画多元关系,
引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。,引用,,,标识每个陈述的来源或出处,
引用也是一种Qualifiers，通常添加到Statements的附加信息中。,引用,,,Qualifiers,
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata,,,多种数值类型,
Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。,Wikidata,,,Wikidata,
Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。,Wikidata,,,给每个Statement增加三种权重,
Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。,Wikidata,,,Wikidata,
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,Wikidata,,,定义三种Snacks,
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertyValueSnack,,,属性值小吃,
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertyNoValueSnack,,,属性无值小吃,
Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。,PropertySomeValueSnack,,,属性有些值小吃,
PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。,PropertyNoValueSnack,,,类似于OWL中的Negation,
"PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。",PropertySomeValueSnack,,,类似于OWL中的存在量词someValuesFrom,
"PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。",PropertySomeValueSnack,,,someValuesFrom,
of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。,of_England_had_no_I_Wikidata,,,URI机制,
of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。,of_England_had_no_I_Wikidata,,,URI机制,
其中，<id>可以是一个Property，如P234。,P234,,,一个Property,
2.4.3ConceptNet5ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-Phrases、断言-Assertions、关系-Relations、边-Edges。,概念-Concepts,,,概念概念概念概念,
Concepts由Words或Phrases组成，构成了图谱中的节点。,Concepts,,,Words或Phrases,
Concepts由Words或Phrases组成，构成了图谱中的节点。,Concepts,,,Words或Phrases,
与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。,Concepts,,,从自然语言文本中提取出来的,
与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。,Concepts,,,概念,
Assertions描述了Concepts之间的关系，类似于RDF中的Statements。,Assertions,,,Concepts之间的关系,
Assertions描述了Concepts之间的关系，类似于RDF中的Statements。,Assertions,,,Concepts之间的关系,
Edges类似于RDF中的Property。,Edges,,,RDF中的Property,
一个Concepts包含多条边，而一条边可能有多个产生来源。,一个Concepts,,,多条边,
一个Concepts包含多条边，而一条边可能有多个产生来源。,一条边,,,多个产生来源,
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,“化妆Cause漂亮”的断言,,,文本抽取,
例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。,“化妆Cause漂亮”的断言,,,用户的手工输入,
来源越多，该断言就越可靠。,断言,,,来源越多，该断言就越可靠。,
ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。,ConceptNet5,,,根据来源的多少和可靠程度计算每个断言的置信度。,
ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。,ConceptNet5,,,根据来源的多少和可靠程度计算每个断言的置信度。,
ConceptNet5示例如图2-17所示。,ConceptNet5,,,概念/产品,
"ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。",ConceptNet5,,,21个预定义的、多语言通用的关系,
"ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。",ConceptNet5,,,ConceptNet 5,
on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。,ConceptNet5,,,对URI进行了精心的设计,
URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,URI,,,考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,
URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。,URI,,,Uniform Resource Identifier,
其中，n代指这是一个名词，basement用于区分歧义。,n,,,一个名词,
其中，n代指这是一个名词，basement用于区分歧义。,n,,,一个名词,
在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。,ConceptNet5,,,处理表示“x_is_the_first_argument_of_y”这类多元关系的问题,
在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。,边的附加信息,,,边的属性,
图2-18ConceptNet5的知识表示结构2.5知识图谱的向量表示方法与前面所述的表示方法不同的是，本节要描述的方法是把知识图谱中的实体和关系映射到低维连续的向量空间，而不是使用基于离散符号的表达方式。,ConceptNet5,,,概念语义网络的五大版本,
2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。,知识图谱的表示方法,,,三元组的方法对知识进行组织,
2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。,知识图谱的表示方法,,,三元组的方法对知识进行组织,
在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。,节点,,,在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系,
虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。,离散的符号化的表达方式,,,将数据结构化,
知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。,知识,,,基于离散符号的方法进行表达,
数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。,长尾分布,,,long tail distribution,
从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。,知识图谱,,,改进传统的表示方法,
2.5.2词的向量表示方法在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。,词的向量表示方法,,,"介绍有关知识图谱的向量表示方法之前,在此先介绍词的表示方法。",
2.5.2词的向量表示方法在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。,词的向量表示方法,,,词的表示方法,
在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。,向量空间映射,,,将词映射到向量空间,
在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。,向量空间,,,vector space,
知识图谱中的向量表示方法也在此次有所借鉴。,知识图谱中的向量表示方法,,,此次,
1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。,向量的维度,,,传统的独热编码（One-Hot_Encoding）方法,
1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。,向量的维度,,,整个词表的大小,
对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。,向量的向量,,,独热表示的向量,
对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。,向量的向量,,,独热表示的向量,
如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。,词Rome,,,独热编码,
如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。,独热编码,,,one-hot-encoding,
这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。,向量的维度,,,稀疏性非常强,
这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。,向量的维度,,,编码出向量的维度,
"2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。",词袋模型,,,对文本中词的表示方法,
"2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。",词袋模型,,,"Bag-of-Words,BoW",
该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。,文本向量,,,词袋法,
该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。,文本向量,,,text vector,
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,向量的维度,,,表示每个词出现次数的向量,
具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。,向量,,,向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数,
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,Rome,,,doc1,
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,Rome,,,罗马,
如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。,Paris,,,巴黎,
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,词向量,,,基于上下文的稠密向量表示法,
图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。,词向量,,,基于上下文的稠密向量表示法,
产生词向量的手段主要有三种：●Count-based。,产生词向量的手段,,,Count-based,
基于计数的方法，简单说就是记录文本中词的出现次数。,基于计数的方法,,,记录文本中词的出现次数,
●Predictive。,Predictive,,,概念/产品,
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,,,通过上下文预测中心词或中心词预测上下文,
基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。,基于预测的方法,,,based on prediction method,
●Task-based。,SPO,,,Task-based,
基于任务的，也就是通过任务驱动的方法。,基于任务的,,,通过任务驱动的方法,
通过对词向量在具体任务上的表现效果对词向量进行学习。,词向量,,,具体任务上的表现效果,
对词向量的产生方法到现在为止有较多的研究，在本章中并不展开讨论，下面简单介绍经典的开源工具word2vec[8]中包含的CBoW和Skip-gram两个模型。,word2vec,,,word2vec,
CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。,CBoW,,,连续词袋模型,
CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。,CBoW,,,连续词袋模型,
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,,,用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息,
其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。,上下文预测中心词,,,用上下文预测中心词,
"如图2-21（a）所示，其中wn是中心词，wn−2,wn−1,wn+1,wn+2为该中心词的上下文的词。",wn,,,中心词,
"如图2-21（a）所示，其中wn是中心词，wn−2,wn−1,wn+1,wn+2为该中心词的上下文的词。",等价,,,等价,
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,投影层,,,将上下文词的独热表示与词向量矩阵E相乘,
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,投影层,,,projection layer,
将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。,输出,,,output,
整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。,连续词袋模型,,,窗口在训练语料上进行滑动,
整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。,连续词袋模型,,,continuous bag of words model,
Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。,Skip-gram,,,用中心词来预测上下文词,
Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。,Skip-gram,,,Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。,
如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。,向量矩阵中得到中心词的词向量,,,投影层,
如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。,投影层,,,projection layer,
图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。,CBoW模型,,,在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系,
图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。,CBoW,,,连续空间中的一些关系,
vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。,Roma,,,Rome,
vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。,Italy,,,is-capital-of,
vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。,Paris,,,France,
通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。,Roma,,,is-capital-of关系,
通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。,Roma,,,意大利,
这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。,向量,,,空间平移性,
这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。,空间平移性,,,spatial shiftness,
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",图2-22词向量在连续空间中的关系,,,知识图谱中的关系,
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",关系,,,relation,
"图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。",三元组,,,triple,
2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。,知识图谱嵌入的概念,,,解决前面提到的知识图谱表示的挑战,
2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。,知识图谱嵌入的概念,,,embedding of knowledge graph,
对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。,连续向量的表达,,,计算机中语义的表达,
把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph（Representation_Learning）、知识表示学习。,知识图谱嵌入,,,知识表示学习,
把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph（Representation_Learning）、知识表示学习。,知识图谱嵌入,,,Knowledge_Graph（Representation_Learning）,
Embedding）、知识图谱的向量表示、知识图谱的表示学习类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。,知识图谱嵌入,,,机器学习的方法对模型进行学习,
Embedding）、知识图谱的向量表示、知识图谱的表示学习类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。,知识图谱嵌入,,,knowledge graph embedding,
在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。,词向量,,,学习一定的语义层信息,
"类似于词向量，经典的知识图谱嵌入模型TransE的设计思想就是，如果一个三元组（h,r,t）成立，那么它们需要符合h+r≈t关系，例如：vec（Rome）+vec（is−capital−of）≈vec（Italy）所以，在知识图谱嵌入的学习过程中，不同的模型从不同的角度把相应的语义信息嵌入知识图谱的向量表示中，如图2-23所示。",TransE,,,transE,
图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。,知识图谱嵌入的优点,,,用向量表达实体和关系的知识图谱嵌入方法,
使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。,向量的表达方式,,,提高应用时的计算效率,
使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。,向量的表达方式,,,向量空间,
用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。,知识图谱,,,向量表示,
因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。,图算法,,,下游应用输入,
因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。,下游应用,,,input,
将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。,知识图谱嵌入,,,下游应用的预训练向量输入,
将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。,知识图谱嵌入,,,knowledge graph embedding,
如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。,知识图谱的嵌入方法,,,"提高计算的效率,增加下游应用的多样性,并可以作为预训练,为下游模型提供语义支持,所以对其展开的研究具有很大的应用价值和前景。",
如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。,知识图谱的嵌入方法,,,embedding methods of knowledge graph,
2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。,知识图谱嵌入模型,,,根据知识图谱中所有已知的三元组训练模型,
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,用来训练的三元组,,,被用来训练,
对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。,概念/方法,,,等价,
所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。,知识图谱嵌入,,,利用一些除知识图谱之外的额外信息训练知识图谱嵌入,
所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。,知识图谱嵌入,,,knowledge graph embedding,
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,额外的信息,,,实体类型,
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,额外的信息,,,关系路径,
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,等价,,,Entity_Types,
这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。,等价,,,Relation_Paths,
根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。,知识图谱嵌入,,,将知识图谱嵌入的方法分类,
1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。,转移距离模型,,,衡量向量化后的知识图谱中三元组的合理性问题,
1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。,转移距离模型,,,Translational_Distance_Model,
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,得分函数,,,设计得分函数,
这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。,得分函数,,,evaluate the rationality of transferring the head entity to the tail entity,
受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。,头实体,,,词与词在向量空间的语义层面关系,
也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。,头实体,,,向量空间,
也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。,头实体,,,head entity,
也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。,尾实体,,,tail entity,
"TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。",TransE,,,向量的转移向量,
"TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。",TransE,,,Translation_vector,
也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。,三元组,,,关系head+relation≈tail,
也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。,关系head,,,关系头,
也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。,关系tail,,,关系尾,
2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。,语义匹配模型,,,转移距离模型,
2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。,语义匹配模型,,,Semantic_Matching_Models,
该方向的模型主要是RESCAL[13]以及它的延伸模型。,该方向的模型,,,RESCAL以及它的延伸模型,
RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。,核心张量,,,将整个知识图谱编码为一个三维张量,
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,由核心张量和因子矩阵还原的结果,,,对应三元组成立的概率,
由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。,对应三元组成立的概率,,,对应三元组成立的概率,
其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。,DistMul,,,得分函数,
其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。,DistMul,,,得分函数,
但因为是对角矩阵，所以存在h⊺diag（r）t=t⊺diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。,对角矩阵,,,diagonal matrix,
ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。,ComplEx模型,,,不考虑交换律,
ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。,ComplEx模型,,,ComplEx模型,
也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。,非对称的关系,,,三元组中的头实体和尾实体调换位置后可以得到不同的分数,
也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。,非对称的关系,,,将三元组中的头实体和尾实体调换位置后可以得到不同的分数,
3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。,考虑附加信息的模型,,,仅仅依靠知识库中的三元组构造知识图谱嵌入的模型,
3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。,考虑附加信息的模型,,,考虑附加信息的模型,
实体类型是一种容易考虑的额外信息。,实体类型,,,容易考虑的额外信息,
在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。,Rome,,,city,
在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。,Italy,,,country,
"最简单的考虑实体类型的方法是在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如（Rome,IsA,city）（Italy,IsA,Country）这样的三元组。",IsA,,,实体类型的考虑方法,
"最简单的考虑实体类型的方法是在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如（Rome,IsA,city）（Italy,IsA,Country）这样的三元组。",等价,,,IsA,
当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。,三元组,,,将属性信息考虑到向量表示中,
也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。,方法,,,考虑相同类型的实体需要在向量表示上更加接近,
"关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is−capital−of,Italy）（Italy,is−country−of,Europe）.从Rome到Europe的关系路径就是一条is−capital−of→is−country−of关系链。",关系路径,,,实体之间的多跳关系,
"关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is−capital−of,Italy）（Italy,is−country−of,Europe）.从Rome到Europe的关系路径就是一条is−capital−of→is−country−of关系链。",关系路径,,,Multi-hop_Relationships,
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,向量表达方式,,,考虑如何用相同的向量表达方式来表达路径,
当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。,等价,,,等价,
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+⋯+rlp=r1∙r2∙⋯∙rlci=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,相加,,,p=r1+r2+⋯+rl,
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+⋯+rlp=r1∙r2∙⋯∙rlci=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,相乘,,,p=r1∙r2∙⋯∙rl,
在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+⋯+rlp=r1∙r2∙⋯∙rlci=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,RNN,,,c=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。,
对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。,知识库中存在的三元组,,,两个实体间的关系路径p,
对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。,关系路径,,,p需要和原本两个实体间关系的向量表示相接近,
文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。,文本描述,,,对实体有一些简要的文本描述,
除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。,知识问答系统,,,外部的文本信息和语料库,
除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。,知识库,,,knowledge base,
Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。,Wang[18],,,在知识图谱嵌入的过程中使用文本信息的联合模型,
Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。,知识模型,,,知识模型的联合模型,
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,知识模型,,,TransE的变种,
其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。,文本模型,,,Skip-gram模型的变种,
联合模型在训练时降低来自三个子模型的损失之和。,联合模型,,,降低来自三个子模型的损失之和,
"图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）说明了两个不同的关系之间的关系。",Logical_Rules,,,附加信息,
"图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）说明了两个不同的关系之间的关系。",等价,,,equivalence,
"图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）说明了两个不同的关系之间的关系。",英文名,,,equivalence,
Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。,软标签预测阶段,,,Soft_Label_Prediction,
Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。,嵌入修正阶段,,,Embedding_Rectification,
简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。,知识图谱嵌入,,,规则学习和知识图谱嵌入学习,
简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。,知识图谱嵌入,,,knowledge graph embedding,
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入的应用,,,知识图谱嵌入的发展,
2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。,知识图谱嵌入的应用,,,application of knowledge graph embedding,
本小节将简单介绍一些典型的应用。,本小节,,,典型的应用,
1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。,链接预测,,,链接预测（Link_Prediction）,
1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。,链接预测,,,Link_Prediction,
"简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全任务，被称为链接预测。",链接预测,,,知识图谱的补全任务,
"简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全任务，被称为链接预测。",链接预测,,,link prediction,
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,,,排序,
当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。,知识图谱嵌入,,,knowledge graph embedding,
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",链接预测,,,知识图谱中每个实体都放在尾实体的位置上并且放入相应的知识图谱嵌入模型的得分函数中计算不同实体作为该三元组的尾实体的得分,
"例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。",链接预测,,,link-prediction,
链接预测也常被用于评测知识图谱嵌入。,链接预测,,,评测知识图谱嵌入,
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,评估某种嵌入模型在链接预测上的能力,,,比较常见的参数,
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,平均等级,,,Mean_Rank,
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,平均倒数等级,,,Mean_Reciprocal_Rank,
一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。,命中前n,,,Hist@n,
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,三元组分类,,,给定一个完整的三元组，判断三元组的真假,
2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。,三元组分类,,,Triple_Classification,
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱向量,,,计算三元组的得分,
这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。,知识图谱向量,,,knowldge graph embedding,
3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。,实体对齐,,,实体解析,
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,删除同一个知识库中冗余的实体,,,该任务,
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,删除同一个知识库中冗余的实体,,,delete redundant entities in the same knowledge base,
该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。,从异构的数据源中找到相同的实体,,,find the same entity from heterogeneous data sources,
"一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。",知识图谱嵌入的得分函数,,,判断x、y两个实体指代同一个对象有多大可能,
"一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。",等价,,,equalTo,
也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。,向量表示判断,,,根据实体的向量表示判断,
也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。,根据实体的向量表示判断,,,根据实体的向量表示判断,
"4.问答系统利用知识图谱完成问答系统是该任务的一个研究方向，该任务的重心是对某一个具体的通过自然语言表达的问题，使用知识图谱中的三元组对其进行回答，如下：A:Where_is_the_capital_of_Italy？Q:Rome（Rome,is-capital-of,Italy）A:Who_is_the_president_of_USA？Q:Donald_Trump（Donald_Trump,is-president-of,USA）文献[9]介绍了一种借助知识图谱嵌入完成该问题的方法。",问答系统,,,answer_a_specific_question_using_knowledge_graph,
简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。,得分函数,,,设计一种得分函数,
简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。,得分函数,,,"design a scoring function, make the problem vector representation and its correct answer vector representation score higher",
"S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））⊺（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。","S（q,a）",,,"得分函数S（q,a）",
"S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））⊺（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。","S（q,a）",,,"被设计出来的得分函数S（q,a）=（Wφ（q））⊺（Wψ（a））",
简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。,Wφ（q）,,,向量表示问题的向量表示,
简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。,Wφ,,,向量表示问题的向量,
简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。,Wψ,,,向量表示答案的向量,
"当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。",得分函数S,,,期望得到一个较高的分数,
"当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。",得分函数S,,,expect high score when a is the correct answer of q,
5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。,推荐系统,,,对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品,
协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。,协同过滤算法,,,对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果,
协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。,协同过滤算法,,,Collaborative_Filtering,
在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。,推荐系统,,,知识图谱嵌入的发展,
例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。,向量表示,,,vector representation,
2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。,本章小结,,,知识图谱的表示与建模方法,
目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。,开放知识图谱的表示语言,,,RDF、RDFS和OWL,
除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。,SPARQL,,,查询语言,
除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。,语义Markup语言,,,本章,
除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。,SPARQL,,,查询语言,