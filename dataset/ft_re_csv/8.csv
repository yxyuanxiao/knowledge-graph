input,subject,subject_type,relation,object,object_type
第8章知识问答丁力海知智能，杨成彪南京柯基数据科技有限公司知识问答通过自然语言对话的形式帮助人们从知识库中获取知识，它不但是知识图谱的核心应用之一，也是自然语言处理的重要研究方向。,知识问答,,,知识图谱的核心应用之一，也是自然语言处理的重要研究方向。,
随着新技术的不断涌现，知识问答技术取得了长足的进步，在工业界也有广泛的应用。,知识问答技术,,,工业界广泛的应用,
本章介绍知识问答系统的基本概念、发展历史、评价体系以及最新进展。,知识问答系统,,,基本概念、发展历史、评价体系以及最新进展,
8.1知识问答概述知识问答系统是一个拟人化的智能系统，它接收使用自然语言表达的问题，理解用户的意图，获取相关的知识，最终通过推理计算形成自然语言表达的答案并反馈给用户。,知识问答系统,,,智能系统,
例如，用户想了解“特朗普是哪里人”时，可以在网上搜索关键词“特朗普”，找到相关的百科网页，进而通过阅读文章定位出“纽约”是他的出生地。,搜索关键词特朗普,,,找到相关的百科网页,
如果换一种思路，用户拿这个问题问身边的人，也许直接就会听到“纽约”这个答案。,问答问答系统,,,用户问身边的人听到纽约这个答案,
"8.1.1知识问答的基本要素知识问答或问答（Question_Answering,QA）是对话的一种形态。",知识问答,,,"问答（Question_Answering,QA）",
它强调以自然语言问答为交互形式从智能体获取知识，不但要求智能体能够理解问题的语义，还要求基于自身掌握的知识和推理计算能力形成答案。,知识问答智能体,,,以自然语言问答为交互形式从智能体获取知识,
问答是一种典型的智能行为，例如著名的图灵测试就是考验能否通过自然语言对话的方式判定答题者是人还是机器。,问答,,,智能行为,
在采用对话方式与用户沟通时，众多问答系统都需要使用一定的知识来解答问题，所以说问答系统实质上就是知识问答，本文后续也不再区分问答系统和知识问答系统。,问答系统,,,知识问答,
也有工作将知识库编码到计算模型中，例如逻辑规则、机器学习模型和深度学习模型。,知识库,,,将知识库编码到计算模型,
"图8-1问答系统的四大要素8.1.2知识问答的相关工作信息检索（Information_Retrieval,IR）或搜索以关键词搜索为代表，帮助用户发现包含搜索关键词的网页或文档。",信息检索,,,"Information_Retrieval,IR",
"图8-1问答系统的四大要素8.1.2知识问答的相关工作信息检索（Information_Retrieval,IR）或搜索以关键词搜索为代表，帮助用户发现包含搜索关键词的网页或文档。",搜索,,,关键词搜索,
近来的信息检索技术也在逐步利用语义信息，例如支持查询扩展[1]、语义相似度匹配[2]以及基于知识图谱的实体识别[3]。,信息检索技术,,,逐步利用语义信息,
但是搜索与知识问答有明显差异。,搜索,,,知识问答,
第一，搜索以文档来承载答案，用户需要阅读搜索找到的文档来发现相关答案，而问答直接将答案交付给用户，而且答案通常来自已经结构化的数据或抽取后结构化的数据，而且结构化数据可以用列表的形式返回，也支持进一步的数据统计分析。,搜索,,,问答,
第一，搜索以文档来承载答案，用户需要阅读搜索找到的文档来发现相关答案，而问答直接将答案交付给用户，而且答案通常来自已经结构化的数据或抽取后结构化的数据，而且结构化数据可以用列表的形式返回，也支持进一步的数据统计分析。,搜索,,,search,
第一，搜索以文档来承载答案，用户需要阅读搜索找到的文档来发现相关答案，而问答直接将答案交付给用户，而且答案通常来自已经结构化的数据或抽取后结构化的数据，而且结构化数据可以用列表的形式返回，也支持进一步的数据统计分析。,问答,,,answer the question directly,
第二，搜索侧重更简单的用户体验，用户的知识检索诉求主要通过关键词而不是完整的句子，这样需要用户掌握一定的搜索技巧。,搜索,,,简单的用户体验,
例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。,搜索技巧和搜索关键词组合,,,大学教授和中学生会采用不同的搜索技巧和搜索关键词组合,
例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。,搜索技巧,,,search skills,
例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。,搜索关键词组合,,,search key words combination,
例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。,大学教授,,,大学教授,
例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。,中学生会,,,中学生会,
问答则会尝试理解不同自然语言表达方式中固有的语义，然后形成知识查询。,问答,,,知识查询,
第三，当用户的问题比较复杂，需要通过多个页面的知识来回答时，搜索是无法完成的。,搜索,,,知识问答系统,
例如，需要寻找“在华盛顿的数据挖掘公司”，而公司的地址信息（？公司位于华盛顿）和公司的专业信息（？公司业务数据挖掘）恰好在两个不同网页上，搜索引擎是无能为力的。,搜索引擎的缺点或不足,,,无法查找两个不同网页上不同的信息,
数据库查询（Database_Query）同样可以帮助用户获取知识，但是知识问答和数据库查询仍然存在一定差异。,数据库查询,,,知识问答,
第一，数据库查询通常需要用户熟悉结构化数据的组织（Schema），知道如何指代数据中的概念（包括实体名、属性名等），掌握数据库查询语言（包括使用JOIN等复杂操作逻辑），而知识问答降低了对这些知识的要求，人们可以用自然语言来查询数据。,数据库查询,,,知识问答,
值得注意的是，自然语言查询需要处理歧义现象，例如“Listall_employees_in_the_company_with_a_driving_license”（“列举有驾照的公司的雇员”），可以是找“有驾照的公司”也可以是“有驾照的公司雇员”，从常识判断只有后者才是用户的真正意图。,自然语言查询,,,处理歧义现象,
值得注意的是，自然语言查询需要处理歧义现象，例如“Listall_employees_in_the_company_with_a_driving_license”（“列举有驾照的公司的雇员”），可以是找“有驾照的公司”也可以是“有驾照的公司雇员”，从常识判断只有后者才是用户的真正意图。,自然语言查询,,,natural-language-query,
类似的中文歧义的现象也很多，例如“南京市长江大桥”“教育部长江学者”都需要不同的语义理解歧义消解的方案。,中文歧义,,,类似的中文歧义的现象也很多,
第二，数据库对知识库有严格限制，要求数据必须结构化存储。,数据库,,,知识库,
然而，大量知识存在于文本中而非数据库中，知识问答并不限制知识库的类型。,知识问答,,,知识库的类型,
然而，大量知识存在于文本中而非数据库中，知识问答并不限制知识库的类型。,知识问答,,,knowledge question,
第三，数据库查询结果不一定能形成用户可使用的最终答案。,数据库查询结果,,,形成用户可使用的最终答案,
例如，数据库查询可以查到城市的编码，还需要再查询编码表得到城市的名称，而知识问答则需要直接返回城市的名称。,数据库查询,,,查询城市的编码,
例如，数据库查询可以查到城市的编码，还需要再查询编码表得到城市的名称，而知识问答则需要直接返回城市的名称。,知识问答,,,直接返回城市的名称,
例如，数据库查询可以查到城市的编码，还需要再查询编码表得到城市的名称，而知识问答则需要直接返回城市的名称。,数据库查询,,,查到城市的编码,
例如，数据库查询可以查到城市的编码，还需要再查询编码表得到城市的名称，而知识问答则需要直接返回城市的名称。,知识问答,,,直接返回城市的名称,
知识问答、信息检索和数据库查询的对比如表8-1所示。,知识问答,,,信息检索,
知识问答、信息检索和数据库查询的对比如表8-1所示。,知识问答,,,数据库查询,
表8-1知识问答、信息检索和数据库查询的对比续表8.1.3知识问答应用场景2011年，IBM研发的超级计算机“沃森”在美国知识竞赛节目《危险边缘》中上演了“人机问答大战”，并一举战胜了两位顶尖的人类选手，成为人工智能发展史上又一标志性事件，如图8-2所示。,知识问答,,,IBM研发的超级计算机“沃森”在美国知识竞赛节目《危险边缘》中上演了“人机问答大战”，并一举战胜了两位顶尖的人类选手,
表8-1知识问答、信息检索和数据库查询的对比续表8.1.3知识问答应用场景2011年，IBM研发的超级计算机“沃森”在美国知识竞赛节目《危险边缘》中上演了“人机问答大战”，并一举战胜了两位顶尖的人类选手，成为人工智能发展史上又一标志性事件，如图8-2所示。,知识问答,,,knowledge question answering,
案例1.知识问答可以直接嵌入搜索引擎的结果页面，将问答的答案与搜索的结果列表同时展示。,知识问答,,,直接嵌入搜索引擎的结果页面，将问答的答案与搜索的结果列表同时展示,
图8-2“沃森”在《危险边缘》中获得冠军图8-3问答展示界面案例2.知识问答技术可以应用于智能对话系统、智能客服或智能助理（IntelligentAgent）[7]。,知识问答技术,,,智能对话系统、智能客服或智能助理,
除了帮助人们获取知识[8]，智能助理也可以跟人闲聊，帮助人执行任务（例如下订单、订酒店、叫外卖），将用户的问题转化为结构化查询，利用多轮对话补全用户的意图等[9]。,智能助理,,,帮助人们获取知识,
除了帮助人们获取知识[8]，智能助理也可以跟人闲聊，帮助人执行任务（例如下订单、订酒店、叫外卖），将用户的问题转化为结构化查询，利用多轮对话补全用户的意图等[9]。,智能助理,,,智能助理,
图8-4基于不同领域知识图谱的问答系统在对话中有不同的理解案例3.知识问答应用于阅读理解。,问答系统,,,对话中的理解,
各种答题机器人和对话机器人也是知识问答的一个重要应用方向。,答题机器人,,,知识问答,
以阅读理解为代表的应用也可以被看作是知识问答的特例，它主要限制了知识库的边界（虽然阅读理解的主体知识是指定的章，但是实现理解仍然需要语法、常用词汇概念以及常识等辅助），而问题的形式可以是选择题（判断哪个答案正确）、填空题（直接填写答案）抑或是简答题。,知识问答,,,以阅读理解为代表的应用,
以阅读理解为代表的应用也可以被看作是知识问答的特例，它主要限制了知识库的边界（虽然阅读理解的主体知识是指定的章，但是实现理解仍然需要语法、常用词汇概念以及常识等辅助），而问题的形式可以是选择题（判断哪个答案正确）、填空题（直接填写答案）抑或是简答题。,知识问答,,,knowledge question,
图8-5展示了一种阅读理解的应用场景，智能体以一段文章（passage）为知识库，针对问题从文章中寻找一段文字形成答案。,阅读理解,,,应用场景,
图8-5展示了一种阅读理解的应用场景，智能体以一段文章（passage）为知识库，针对问题从文章中寻找一段文字形成答案。,智能体,,,智能问答,
问答系统还有很多更深入的综述[10-14]。,问答系统,,,更深入的综述,
8.2.1问题类型与答案类型在知识问答中，首先可以通过对问题的类型（QuestionType）理解问答目标。,问题类型,,,知识问答,
8.2.1问题类型与答案类型在知识问答中，首先可以通过对问题的类型（QuestionType）理解问答目标。,问题类型,,,QuestionType,
问答系统可以针对问题类型，选择对应的知识库、处理逻辑来生成答案[15]。,问答系统,,,针对问题类型，选择对应的知识库、处理逻辑来生成答案,
问答系统可以针对问题类型，选择对应的知识库、处理逻辑来生成答案[15]。,问答系统,,,"question-answer system, QAS",
问题分类体系在很大程度上按照目标答案的差异而区分，所以这里将问题类型和答案类型合并，统一考虑为问题类型。,问题分类体系,,,目标答案的差异而区分,
问题分类体系在很大程度上按照目标答案的差异而区分，所以这里将问题类型和答案类型合并，统一考虑为问题类型。,问题类型,,,question type,
通过对问题的类型（也就是用户问题所期望的答案的类型）的分析，问答系统可以有针对性地选择有效的知识库和处理逻辑解答一类问题。,问答系统,,,分析问题类型的用途,
早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。,早期的工作,,,TREC测试集问题分类研究,
早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。,早期的工作,,,ISIQA问题类型分类体系,
早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。,早期的工作,,,更详细的综述,
早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。,TREC测试集问题分类研究,,,TREC test set problem classification study,
早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。,ISIQA问题类型分类体系,,,ISIQA problem type classification system,
LI等人[15]通过观察TREC的1000个问题的数据，从答案类型出发建立了一个问题分类体系，包含6个大类和50个细分类，并对各类问题的占比进行了统计。,问题分类体系,,,六个大类和50个细分类,
从统计结果中可以看出，TREC中的大部分问题都集中在这几类数据，占总体问题数量的78%。,TREC,,,问答系统,
其中，81个问题询问地点（LOCATION）、138个问题询问定义或描述（DESCRIPTION）、65个问题询问人物（HUMAN）、94个问题询问事物（例如动物、颜色、食品等）。,SPO,,,subject,
可见，在知识问答中，一个合理的分类体系能够体现出问题的类型分布，从而帮助开发者有针对性地设计问答解决方案，并形成良好的问答系统。,分类体系,,,知识问答,
图8-6ISI_QA问题类型分类体系及实例后续也出现了基于功能的问题分类体系。,ISI_QA问题类型分类体系及实例,,,问题分类体系及实例后续也出现了基于功能的问题分类体系。,
图8-6ISI_QA问题类型分类体系及实例后续也出现了基于功能的问题分类体系。,ISI_QA问题类型分类体系,,,Information_Seeking_Question_Category,
例如，在英文中一个以“Why”开头的问题侧重询问原因，而以“How”开头的问题侧重询问解决方式。,Why提问,,,询问原因,
例如，在英文中一个以“Why”开头的问题侧重询问原因，而以“How”开头的问题侧重询问解决方式。,How提问,,,询问解决方式,
例如，在英文中一个以“Why”开头的问题侧重询问原因，而以“How”开头的问题侧重询问解决方式。,Why开头的问题,,,询问原因,
例如，在英文中一个以“Why”开头的问题侧重询问原因，而以“How”开头的问题侧重询问解决方式。,How开头的问题,,,询问解决方式,
但是在中文里，带有“怎么样”这个词的问题，其意图有可能是询问原因，也有可能是询问解决方式。,带有“怎么样”这个词的问题,,,询问原因,
但是在中文里，带有“怎么样”这个词的问题，其意图有可能是询问原因，也有可能是询问解决方式。,带有“怎么样”这个词的问题,,,询问解决方式,
BU等人[18]根据百度知道的数据，建立了一个基于功能（Function-Based）的问题分类体系。,BU等人,,,基于功能的问题分类体系,
和LI等人[15]从答案类型出发构建分类体系类似，BU等人[18]从利用功能以达成用户目标的角度来构建分类体系。,BU等人,,,从利用功能以达成用户目标的角度来构建分类体系,
和LI等人[15]从答案类型出发构建分类体系类似，BU等人[18]从利用功能以达成用户目标的角度来构建分类体系。,BU等人,,,从利用功能以达成用户目标的角度来构建分类体系,
相比于LI等人[15]专注于面向事实的知识问答的分类，BU等人[18]提出的分类体系更面向通用问题。,BU等人提出的分类体系,,,专注于面向事实的知识问答的分类,
相比于LI等人[15]专注于面向事实的知识问答的分类，BU等人[18]提出的分类体系更面向通用问题。,BU等人,,,分类体系,
表8-2展示了BU等人[18]提出的问题分类体系机制，其中的事实类别和LI等人[15]提出的分类体系中的大部分类别相对应。,问题分类体系机制,,,BU等人提出的问题分类体系机制,
表8-2BU等人提出的问题分类机制[18]图8-7基于功能的问题分类体系在百度知道中的占比[18]综合分类体系的探索工作，本文从问答的功能出发，面向知识图谱问答的构建（即假定知识库的主题为知识图谱）整理出两种问题类型：事实性客观问题和主观深层次问题。,问题类型,,,面向知识图谱问答的构建,
（1）事实性客观问题。,SPO,,,事实性客观问题,
特点是语法结构简单（拥有明确的主谓宾结构，不包括例如并列、否定等复杂结构）、语义结构清晰（通常是关于某个事物或事件的简单描述性属性或关系型属性，可以通过简单的数据库查询解答）。,简单语句,,,语法结构简单,
特点是语法结构简单（拥有明确的主谓宾结构，不包括例如并列、否定等复杂结构）、语义结构清晰（通常是关于某个事物或事件的简单描述性属性或关系型属性，可以通过简单的数据库查询解答）。,简单语句,,,语义结构清晰,
特点是语法结构简单（拥有明确的主谓宾结构，不包括例如并列、否定等复杂结构）、语义结构清晰（通常是关于某个事物或事件的简单描述性属性或关系型属性，可以通过简单的数据库查询解答）。,简单,,,simple,
特点是语法结构简单（拥有明确的主谓宾结构，不包括例如并列、否定等复杂结构）、语义结构清晰（通常是关于某个事物或事件的简单描述性属性或关系型属性，可以通过简单的数据库查询解答）。,清晰,,,clear,
事实型问题是知识问答中处理频度较高的一种问题类型，其中包含了谓词型问题（答案是一个单一的对象）、列表型问题（返回的不止一个答案，而是一列答案）。,事实型问题,,,知识问答,
事实型问题是知识问答中处理频度较高的一种问题类型，其中包含了谓词型问题（答案是一个单一的对象）、列表型问题（返回的不止一个答案，而是一列答案）。,事实型问题,,,knowledge question type,
事实型问题是知识问答中处理频度较高的一种问题类型，其中包含了谓词型问题（答案是一个单一的对象）、列表型问题（返回的不止一个答案，而是一列答案）。,谓词型问题,,,single object,
事实型问题是知识问答中处理频度较高的一种问题类型，其中包含了谓词型问题（答案是一个单一的对象）、列表型问题（返回的不止一个答案，而是一列答案）。,列表型问题,,,a list of answers,
这两种主要是返回某些对象，从查询的角度来看，类似于数据库的Select操作。,SPO查询,,,返回某些对象,
这两种主要是返回某些对象，从查询的角度来看，类似于数据库的Select操作。,等价,,,返回某些对象,
而对错型的问题更像SPARQL中的Ask类型的查询。,对错型的问题,,,SPARQL中的Ask类型的查询,
实际上，这并不需要理解为一种“硬边界”的分类，也可能存在某些问题属于多个类别的情况。,分类,,,不需要理解为一种“硬边界”的分类,
包括除事实型问题之外的其他问题，例如观点型、因果型、解释型、关联型与比较型等。,SPO,,,其他问题,
这一类问题本身的语法结构并不复杂，但是这些问题需要一定的专业知识和主观的推理计算才能解答，而且这一类问题有时甚至不止一个答案，需要结合用户偏好和智能体的配置找到不同的最优解。,智能问答,,,question answering,
可以细分如下：①问解释（WHY），例如“为什么天空是蓝色的？”“为什么眼睛会近视？”②问方法（HOW），例如“怎么做戚风蛋糕？”“如何在Windows上创建一个文件夹？”③问专家意见（CONSULT），例如“左侧内踝骨折累及关节面多少天能下地走路？今年89岁。,问解释,,,WHY,
可以细分如下：①问解释（WHY），例如“为什么天空是蓝色的？”“为什么眼睛会近视？”②问方法（HOW），例如“怎么做戚风蛋糕？”“如何在Windows上创建一个文件夹？”③问专家意见（CONSULT），例如“左侧内踝骨折累及关节面多少天能下地走路？今年89岁。,问方法,,,HOW,
可以细分如下：①问解释（WHY），例如“为什么天空是蓝色的？”“为什么眼睛会近视？”②问方法（HOW），例如“怎么做戚风蛋糕？”“如何在Windows上创建一个文件夹？”③问专家意见（CONSULT），例如“左侧内踝骨折累及关节面多少天能下地走路？今年89岁。,问专家意见,,,CONSULT,
”④问推荐（RECOMMENDATION），例如“哪个歌手跟刘德华类似？”另外，问题类型并非问题理解中的唯一语义要素。,问推荐,,,问题类型,
问题焦点（Focus）指的是问句中出现的与答案实体或属性相关的元素，例如问句“In_which_city_was_Barack_Obama_born?”中的city，以及“What_is_the_population_of_Galway?”中的population。,问题焦点,,,问句中出现的与答案实体或属性相关的元素,
问题焦点（Focus）指的是问句中出现的与答案实体或属性相关的元素，例如问句“In_which_city_was_Barack_Obama_born?”中的city，以及“What_is_the_population_of_Galway?”中的population。,问题焦点,,,Focus,
问题主题（Topic）反映问题是关于哪些主题的，例如问句“What_is_the_height_of_Mount_Everest?”询问的是关于地理及山脉的信息，而“Which_organ_is_affected_by_the_Meniere's_disease?”的问题主题则是医疗方面的内容。,问题主题,,,概念/产品,
问题主题（Topic）反映问题是关于哪些主题的，例如问句“What_is_the_height_of_Mount_Everest?”询问的是关于地理及山脉的信息，而“Which_organ_is_affected_by_the_Meniere's_disease?”的问题主题则是医疗方面的内容。,问题主题,,,Topic,
8.2.2知识库类型从知识库的内容边界，或者知识库覆盖了哪些领域来看，知识问答可以分两类。,知识问答,,,知识库类型,
8.2.2知识库类型从知识库的内容边界，或者知识库覆盖了哪些领域来看，知识问答可以分两类。,知识问答,,,knowledge question and answer,
一是领域相关的问答系统，只回答与选定领域相关的问题。,问答系统,,,领域相关的问答系统,
这一类系统相对专注，需要领域专家的深入参与，虽然问题覆盖面小，但是答案的正确率高。,问答系统,,,专注，需要领域专家的深入参与,
这一类系统相对专注，需要领域专家的深入参与，虽然问题覆盖面小，但是答案的正确率高。,问答系统,,,question-answer system,
早期的成功问答系统都是与领域相关的。,早期的问答系统,,,与领域相关的问答系统,
近年来，企业的智能客服通常采用领域相关的问答系统，并且逐步转向基于知识图谱的解决方案。,智能客服,,,领域相关的问答系统,
二是领域无关的问答系统，基于开放知识库回答任意问题。,问答系统,,,领域无关的问答系统，基于开放知识库回答任意问题,
这一类系统答案虽然覆盖面大，但答案的正确率有限。,问答系统,,,属于一类系统答案虽然覆盖面大，但答案的正确率有限。,
开放域问答系统经常使用万维网数据（尤其是百科网站、社区问答等）作为数据源解答用户的问题。,开放问答系统,,,万维网数据,
由于用户的期望较高，开放问题结构并不总是简单，开放域知识相对稀疏等原因，实用产品的用户体验还有待提高。,实用产品的用户体验,,,开放问题结构的简单、开放域知识的稀疏、用户的期望较高,
从知识库的信息组织格式来看，知识库可以是基于文本表示，也可以采用其他组织形式。,知识库,,,基于文本表示,
从知识库的信息组织格式来看，知识库可以是基于文本表示，也可以采用其他组织形式。,知识库,,,其他组织形式,
从知识库的信息组织格式来看，知识库可以是基于文本表示，也可以采用其他组织形式。,知识库,,,基于文本表示,
从知识库的信息组织格式来看，知识库可以是基于文本表示，也可以采用其他组织形式。,知识库,,,其他组织形式,
第一，文本类知识库利用纯文本承载知识，也是最常见的知识组织形式。,文本类知识库,,,纯文本承载知识,
这类知识库不但支持基于搜索的问答系统，也可以与基于知识图谱的结构化抽取技术结合，支持基于语义查询的解决方案。,知识问答系统,,,基于搜索的问答系统,
另外，常见问答对（FAQ）或社区问答也是知识问答（尤其是智能客服）最容易获取的知识，可以直接通过问题匹配帮助用户获取答案。,问答对,,,知识问答,
另外，常见问答对（FAQ）或社区问答也是知识问答（尤其是智能客服）最容易获取的知识，可以直接通过问题匹配帮助用户获取答案。,问答对,,,FAQ,
另外，常见问答对（FAQ）或社区问答也是知识问答（尤其是智能客服）最容易获取的知识，可以直接通过问题匹配帮助用户获取答案。,社区问答,,,知识问答,
第二，半结构化或结构化的知识库。,半结构化或结构化的知识库,,,概念/产品,
这一类知识库侧重知识的细粒度组织，利用结构体现知识的语义。,知识库,,,细粒度组织,
这一类知识库侧重知识的细粒度组织，利用结构体现知识的语义。,知识库,,,面向细粒度组织的知识库,
电子表格、二维表或者关系数据库是最常见的结构化知识，实体和属性通过简单的二维表表示，大多数事实性客观问题都可以被此类知识解答。,电子表格,,,结构化知识,
电子表格、二维表或者关系数据库是最常见的结构化知识，实体和属性通过简单的二维表表示，大多数事实性客观问题都可以被此类知识解答。,电子表格,,,Excel,
图数据库，例如RDF、属性图、语义网络等，将通过节点、有向边来形成基于图的知识组织，并且利用节点和边的名称与上下文对接自然语言处理并支持语义相似度计算，同时还能支持复杂的结构化图查询机制。,图数据库,,,基于图的知识组织,
图数据库，例如RDF、属性图、语义网络等，将通过节点、有向边来形成基于图的知识组织，并且利用节点和边的名称与上下文对接自然语言处理并支持语义相似度计算，同时还能支持复杂的结构化图查询机制。,图数据库,,,RDF,
图数据库，例如RDF、属性图、语义网络等，将通过节点、有向边来形成基于图的知识组织，并且利用节点和边的名称与上下文对接自然语言处理并支持语义相似度计算，同时还能支持复杂的结构化图查询机制。,图数据库,,,属性图,
图数据库，例如RDF、属性图、语义网络等，将通过节点、有向边来形成基于图的知识组织，并且利用节点和边的名称与上下文对接自然语言处理并支持语义相似度计算，同时还能支持复杂的结构化图查询机制。,图数据库,,,语义网络,
第三，除文字外，知识也可以存储在图片、音频、视频等媒体中，这些都可以作为知识问答中答案的一部分，更有效地反馈给终端用户，从而丰富答案的表示并满足更多的交互场景需求。,知识问答中答案的一部分,,,丰富答案的表示并满足更多的交互场景需求,
第四，知识库并不限定于文本、符号系统或多媒体，也可以利用可计算的机器学习模型承载。,知识库,,,文本、符号系统或多媒体,
例如近年来出现的端到端的问答系统可以直接使用分布式表示模型记录习得的知识。,端到端的问答系统,,,分布式表示模型记录习得的知识,
另外，知识库的存储访问机制也是知识问答需要考虑的因素。,知识问答的存储访问机制,,,知识库的存储访问机制,
另外，知识库的存储访问机制也是知识问答需要考虑的因素。,知识问答的存储访问机制,,,知识库的存储访问机制,
知识问答的知识可以采用单一的集中数据存储（例如数据表、数据库），或者分布式存储（例如分布式数据、数据仓库），甚至是基于互联网的全网数据（例如Linked_Data）。,知识问答,,,单一的集中数据存储,
知识问答的知识可以采用单一的集中数据存储（例如数据表、数据库），或者分布式存储（例如分布式数据、数据仓库），甚至是基于互联网的全网数据（例如Linked_Data）。,知识问答,,,分布式存储,
知识问答的知识可以采用单一的集中数据存储（例如数据表、数据库），或者分布式存储（例如分布式数据、数据仓库），甚至是基于互联网的全网数据（例如Linked_Data）。,知识问答,,,基于互联网的全网数据,
知识问答的知识可以采用单一的集中数据存储（例如数据表、数据库），或者分布式存储（例如分布式数据、数据仓库），甚至是基于互联网的全网数据（例如Linked_Data）。,知识问答的知识,,,knowledge question,
8.2.3智能体类型智能体利用知识库实现推理。,智能体,,,知识库实现推理,
根据知识库表示形式的不同，目前的知识问答可以分为传统问答方法（符号表示）以及基于深度学习的问答方法（分布式表示）两种类型。,知识问答,,,传统问答方法,
根据知识库表示形式的不同，目前的知识问答可以分为传统问答方法（符号表示）以及基于深度学习的问答方法（分布式表示）两种类型。,知识问答,,,基于深度学习的问答方法,
根据知识库表示形式的不同，目前的知识问答可以分为传统问答方法（符号表示）以及基于深度学习的问答方法（分布式表示）两种类型。,问答方法,,,传统问答方法,
根据知识库表示形式的不同，目前的知识问答可以分为传统问答方法（符号表示）以及基于深度学习的问答方法（分布式表示）两种类型。,问答方法,,,基于深度学习的问答方法,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,传统问答方法,,,使用的主要技术,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,关键词检索,,,关键词检索,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,文本蕴涵推理,,,文本蕴涵推理,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,逻辑表达式,,,逻辑表达式,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,LSTM,,,LSTM,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,注意力模型,,,注意力模型,
传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。,记忆网络（Memory_Network）,,,记忆网络（Memory_Network）,
传统的知识库问答将问答过程切分为语义解析与查询两个步骤。,传统的知识问答,,,语义解析与查询两个步骤,
如图8-8所示，首先将问句“姚明的老婆出生在哪里”通过语义解析转化为SPARQL查询语句。,问句“姚明的老婆出生在哪里”,,,语义解析,
如图8-8所示，首先将问句“姚明的老婆出生在哪里”通过语义解析转化为SPARQL查询语句。,等价,,,等价,
这个例子中的难点是将问句中的“老婆”映射到知识图谱中的关系“配偶”，这也是传统的知识库问答研究的核心问题之一；再从知识库（知识图谱）中查询，得到问题的答案“上海”。,问句中的“老婆”,,,将问句中的“老婆”映射到知识图谱中的关系“配偶”,
不同于传统方法，基于分布式表示的知识库问答利用深度神经网络模型，将问题与知识库中的信息转化为向量表示，通过相似度匹配的方式完成问题与答案的匹配。,基于分布式表示的知识库问答,,,深度神经网络模型,
不同于传统方法，基于分布式表示的知识库问答利用深度神经网络模型，将问题与知识库中的信息转化为向量表示，通过相似度匹配的方式完成问题与答案的匹配。,基于分布式表示的知识库问答,,,基于分布式表示的问答,
首先，利用神经网络模型，将问题“姚明的老婆出生在哪里”表示成向量，这里使用的是一个递归神经网络的表达形式；然后取知识图谱中与实体“姚明”相关的实体向量，计算与问句向量的语义相似度，从而完成知识问答的过程。,知识问答,,,神经网络模型,
在整个过程中，并不需要确定问句中的“老婆”与知识图谱中的关系“配偶”的映射，这也是基于深度学习的问答方法的优势所在。,基于深度学习的问答方法,,,确定问句中的“老婆”与知识图谱中的关系“配偶”的映射,
在整个过程中，并不需要确定问句中的“老婆”与知识图谱中的关系“配偶”的映射，这也是基于深度学习的问答方法的优势所在。,基于深度学习的问答方法,,,基于深度学习的问答方法,
BASEBALL系统回答了有关一年内棒球比赛的问题。,BASEBALL系统,,,回答有关一年内棒球比赛的问题,
LUNAR在阿波罗月球任务期间提供了岩石样本分析数据的界面。,LUNAR,,,阿波罗月球任务期间提供了岩石样本分析数据的界面,
这些系统一般限定在特定领域，使用自然语言问题询问结构化知识库。,问答系统,,,特定领域，使用自然语言问题询问结构化知识库,
这些数据库与如今讲的关系数据库不同，更像基于逻辑表达式的知识库。,数据库,,,基于逻辑表达式的知识库,
如图8-10所示为早期NLIDB型问答系统的设计思想。,早期NLIDB型问答系统,,,设计思想,
依据文献[23]的介绍，NLIDB系统大多采用的模块包括：①实体识别（Named_EntityRecognition），通过查询领域词典识别命名实体；②语义理解（Question2Query），利用语法解析（例如词性分析，Part-Of-Speech）、动词分析（包括主动和被动）以及语义映射规则等技术，将问题解析成语义查询语句；③回答问题（Answer_Processing），通常通过简单查询和其他复杂操作（例如Count）获取答案。,NLIDB系统,,,Named_EntityRecognition,
依据文献[23]的介绍，NLIDB系统大多采用的模块包括：①实体识别（Named_EntityRecognition），通过查询领域词典识别命名实体；②语义理解（Question2Query），利用语法解析（例如词性分析，Part-Of-Speech）、动词分析（包括主动和被动）以及语义映射规则等技术，将问题解析成语义查询语句；③回答问题（Answer_Processing），通常通过简单查询和其他复杂操作（例如Count）获取答案。,NLIDB系统,,,Question2Query,
依据文献[23]的介绍，NLIDB系统大多采用的模块包括：①实体识别（Named_EntityRecognition），通过查询领域词典识别命名实体；②语义理解（Question2Query），利用语法解析（例如词性分析，Part-Of-Speech）、动词分析（包括主动和被动）以及语义映射规则等技术，将问题解析成语义查询语句；③回答问题（Answer_Processing），通常通过简单查询和其他复杂操作（例如Count）获取答案。,NLIDB系统,,,Answer_Processing,
这些工作中的语义理解部分各具特色，也就此奠定了后续问答系统中问题解析的基本套路，下面详细举例说明。,问答系统问题解析的基本套路,,,语义理解部分各具特色,
图8-10早期NLIDB型问答系统的设计思想（1）基于模式匹配（Pattern-Matching）。,早期NLIDB型问答系统,,,基于模式匹配,
基于模式匹配的语义理解可以直接将问题映射到查询。,基于模式匹配的语义理解,,,直接将问题映射到查询,
如图8-11所示，例子“...capital...<country>.....”中，变量“<country>”用来表示Country类型的一个实体，例如Italy，而“capital”是一个字符串。,<country>,,,Country类型的一个实体,
如图8-11所示，例子“...capital...<country>.....”中，变量“<country>”用来表示Country类型的一个实体，例如Italy，而“capital”是一个字符串。,“<country>”,,,表示Country类型的一个实体,
这个模板可以匹配不同的自然语言说法，例如“What_is_the_capital_of_Italy?”“Could_you_please_tell_me_what_is_thecapital_of_Italy?”，然后将问题映射到查询“Report_Capital_of_row_where_Country=Italy”（查询意大利的首都）。,模板,,,将问题映射到查询意大利的首都,
这个模板可以匹配不同的自然语言说法，例如“What_is_the_capital_of_Italy?”“Could_you_please_tell_me_what_is_thecapital_of_Italy?”，然后将问题映射到查询“Report_Capital_of_row_where_Country=Italy”（查询意大利的首都）。,SPO,,,schema,
这种语义理解技术简便灵活且不依赖过多的语法分析工具，后来发展为KBQA中基于模板的语义理解方案。,KBQA中基于模板的语义理解方案,,,语义理解技术,
这种语义理解技术简便灵活且不依赖过多的语法分析工具，后来发展为KBQA中基于模板的语义理解方案。,基于模板的语义理解方案,,,KBQA中基于模板的语义理解方案,
图8-11基于模板匹配的NLIDB解决方案[23]（2）基于语法解析（Syntactic-Parsing）。,基于模板匹配的NLIDB解决方案,,,基于语法解析（Syntactic-Parsing）。,
基于语法解析的语义理解将自然语言的复杂语义转化为逻辑表达式。,基于语法解析的语义理解,,,语义理解,
如图8-12所示为展示了LUNAR系统利用语法树解析初步解析问题。,LUNAR系统,,,利用语法树解析初步解析问题,
句法分析器的树状结果仍然需要人工生成的语义规则和领域知识来理解，进而转化成一种中间层的逻辑表达式。,句法分析器的树状结果,,,语义规则和领域知识来理解进而转化成一种中间层的逻辑表达式,
句法分析器的树状结果仍然需要人工生成的语义规则和领域知识来理解，进而转化成一种中间层的逻辑表达式。,句法分析器的树状结果,,,syntactic analyzer,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,主语,,,基于Context-Free_Grammar（CFG）的语法,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,主语,,,S,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,名词短语,,,NP,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,名词短语,,,一个名词短语（NP）,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,名词短语,,,一个确定词（Det）,
通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。,名词短语,,,一个名词（N）,
"这样，“which_rock_contains_magnesium”就可以解析为后面的语法分for_every_X,“rock”映射到（is析结果，进而通过一系列转换规则，例如“which”映射到rock_X），形成最终的数据库查询。",which_rock_contains_magnesium,,,语法分for_every_X,
不少后来的系统也在系统的可移植性上有一些进展，包括允许为某一个新领域重新定制词典，构建通用知识表示语言来表达语义规则。,可移植性,,,后来的系统,
不少后来的系统也在系统的可移植性上有一些进展，包括允许为某一个新领域重新定制词典，构建通用知识表示语言来表达语义规则。,可移植性,,,portability,
有些系统甚至还可以允许用户通过交互界面添加新词汇和映射规制，包括LUNAR系统后期提出的MRL语言[23]，将自然语言问题转化为一种基于中间表示语言的逻辑查询表达式。,MRL语言,,,将自然语言问题转化为一种基于中间表示语言的逻辑查询表达式,
有些系统甚至还可以允许用户通过交互界面添加新词汇和映射规制，包括LUNAR系统后期提出的MRL语言[23]，将自然语言问题转化为一种基于中间表示语言的逻辑查询表达式。,MRL语言,,,基于中间表示语言的逻辑查询表达式,
这种中间表示语言承载了高层次世界概念以及用户问题的含义，独立于数据库存储结构，可以进一步转换成数据查询的表达式从而获取答案。,中间表示语言,,,高层次世界概念以及用户问题的含义,
这种中间表示语言承载了高层次世界概念以及用户问题的含义，独立于数据库存储结构，可以进一步转换成数据查询的表达式从而获取答案。,中间表示语言,,,middle expression language,
这一类方案后来演进为KBQA中基于语义解析（Semantic_Parsing）的语义理解方法。,语义解析（Semantic_Parsing）的语义理解方法,,,KBQA中基于语义解析（Semantic_Parsing）的语义理解方法,
这一类方案后来演进为KBQA中基于语义解析（Semantic_Parsing）的语义理解方法。,语义理解方法,,,基于语义解析（Semantic_Parsing）的语义理解方法,
语法树分析为处理更为复杂的问题以及简单问题的语法变形提供了便利，但是这也同时依赖语法分析工具的正确性（包括词性分析、语法依存分析）。,语法树分析,,,处理更为复杂的问题以及简单问题的语法变形,
另外，当词汇具有多重词性时，也存在潜在问题。,词汇的缺点,,,潜在问题,
所以，还需要附加一些规则调整语法解析出来的查询。,SPO,,,语法解析出来的查询,
"图8-12LUNAR系统利用语法树解析初步解析问题[23]8.3.2IRQA：基于信息检索的问答系统基于信息检索的问答系统（Information_Retrieval_based_Question-Answering_System,IRQA）[6]的核心思想是根据用户输入的问题，结合自然语言处理以及信息检索技术，在给定文档集合或者互联网网页中筛选出相关的文档，从结果文档内容抽取关键文本作为候选答案，最后对候选答案进行排序返回最优答案。",基于信息检索的问答系统,,,基于信息检索的问答系统核心思想,
"图8-12LUNAR系统利用语法树解析初步解析问题[23]8.3.2IRQA：基于信息检索的问答系统基于信息检索的问答系统（Information_Retrieval_based_Question-Answering_System,IRQA）[6]的核心思想是根据用户输入的问题，结合自然语言处理以及信息检索技术，在给定文档集合或者互联网网页中筛选出相关的文档，从结果文档内容抽取关键文本作为候选答案，最后对候选答案进行排序返回最优答案。",基于信息检索的问答系统,,,"Information_Retrieval_based_Question-Answering_System,IRQA",
（2）段落检索与排序（Passage_Retrieval_And_Ranking）。,段落检索与排序,,,SPO三元组,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,信息检索,,,基于提取出的关键词进行信息检索,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,基于提取出的关键词进行信息检索,,,based on extracting keywords to do information retrieval,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,对检索出的文档进行排序,,,sort the documents,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,把排序之后的文档分割成合适的段落,,,split the sorted documents into suitable paragraphs,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,对新的段落进行再排序,,,re-sort the new paragraphs,
基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。,找到最优答案,,,find the best answer,
（3）答案处理（Answer_Processing）。,答案处理,,,SPO三元组,
最后根据排序后的段落，结合问题处理阶段定义的答案类型抽取答案，形成答案候选集；最终对答案候选集排序，返回最优解。,答案抽取,,,问题处理阶段定义的答案类型抽取答案,
最后根据排序后的段落，结合问题处理阶段定义的答案类型抽取答案，形成答案候选集；最终对答案候选集排序，返回最优解。,答案候选集,,,answer candidate set,
最后根据排序后的段落，结合问题处理阶段定义的答案类型抽取答案，形成答案候选集；最终对答案候选集排序，返回最优解。,最优解,,,return,
此方法以文档为知识库，没有预先的知识抽取工作。,知识问答,,,没有预先的知识抽取工作。,
KBQA实际上是20世纪七八十年代对NLIDB工作的延续，其中很多技术都借鉴和沿用了以前的研究成果。,KBQA,,,对NLIDB工作的延续,
其中，主要的差异是采用了相对统一的基于RDF表示的知识图谱，并且把语义理解的结果映射到知识图谱的本体后生成SPARQL查询解答问题。,知识问答系统,,,基于RDF表示的知识图谱,
其中，主要的差异是采用了相对统一的基于RDF表示的知识图谱，并且把语义理解的结果映射到知识图谱的本体后生成SPARQL查询解答问题。,SPARQL查询解答问题,,,问答系统,
通过本体可以将用户问题映射到基于概念拓扑图表示的查询表达式，也就对应了知识图谱中某种子图。,查询表达式,,,本体将用户问题映射到基于概念拓扑图表示的查询表达式,
通过本体可以将用户问题映射到基于概念拓扑图表示的查询表达式，也就对应了知识图谱中某种子图。,本体,,,ontology,
KBQA的核心问题Question2Query是找到从用户问题到知识图谱子图的最合理映射。,Question2Query,,,找到从用户问题到知识图谱子图的最合理映射,
KBQA的核心问题Question2Query是找到从用户问题到知识图谱子图的最合理映射。,Question2Query,,,找到从用户问题到知识图谱子图的最合理映射,
QALD（Question_Answering_on_Linked_Data）[38]是2011年开始针对KBQA问答系统的评测活动。,QALD,,,针对KBQA问答系统的评测活动,
文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。,Question2Query,,,问题解析,
文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。,Question2Query,,,词汇关联,
文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。,Question2Query,,,歧义消解,
文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。,Question2Query,,,构建查询,
文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。,Question2Query,,,分布式知识库,
（1）问题分析。,SPO,,,问题分析,
主要利用词典、词性分析、分词、实体识别、语法解析树分析、句法依存关系分析等传统NLP技术提取问题的结构特征，并且基于机器学习和规则提取分析句子的类型和答案类型。,SPO,,,传统NLP技术提取问题的结构特征,
知识图谱通常可以为NLP工具提供领域词典，支持实体链接；同时，知识图谱的实体和关系也可以分别用于序列化标注和远程监督，支持对文本领域语料的结构化抽取，进一步增补领域知识图谱。,知识图谱,,,NLP工具提供领域词典，支持实体链接,
知识图谱通常可以为NLP工具提供领域词典，支持实体链接；同时，知识图谱的实体和关系也可以分别用于序列化标注和远程监督，支持对文本领域语料的结构化抽取，进一步增补领域知识图谱。,知识图谱,,,knowledge graph,
（2）词汇关联。,词汇关联,,,SPO三元组,
主要针对在问题分析阶段尚未形成实体链接的部分形成与知识库的链接，包括关系属性、描述属性、实体分类的链接。,概念/实体链接,,,问题分析阶段尚未形成实体链接的部分形成与知识库的链接,
主要针对在问题分析阶段尚未形成实体链接的部分形成与知识库的链接，包括关系属性、描述属性、实体分类的链接。,SPO,,,三元组,
"例如“cities”映射到实体分类“城市”,“is_married果）。",“cities”,,,实体分类“城市”,
"例如“cities”映射到实体分类“城市”,“is_married果）。",等价,,,等价,
to”映射到关系“spouse”。,“to”,,,关系“spouse”,
也包括一些多义词，例如“Apple”（公司还是水（3）歧义消解。,多义词,,,包括一些,
也包括一些多义词，例如“Apple”（公司还是水（3）歧义消解。,等价,,,等价,
一方面是对候选的词汇、查询表达式排序选优，一方面通过语义的容斥关系去掉不可能的组合。,候选的词汇、查询表达式排序选优,,,对候选的词汇、查询表达式排序选优,
一方面是对候选的词汇、查询表达式排序选优，一方面通过语义的容斥关系去掉不可能的组合。,候选的词汇、查询表达式排序选优,,,对候选的词汇、查询表达式排序选优,
一方面是对候选的词汇、查询表达式排序选优，一方面通过语义的容斥关系去掉不可能的组合。,通过语义的容斥关系去掉不可能的组合。,,,通过语义的容斥关系去掉不可能的组合。,
例如，苹果手机是不能吃的，所以吃苹果中苹果的“电器”选项应去掉。,苹果手机,,,不能吃的,
在很多系统中，歧义消解与构建查询紧密结合：先生成大量可能的查询，然后通过统计方法和机器学习选优。,歧义消解,,,生成查询,
（4）构建查询。,SPO,,,构建查询。,
基于问题解析结果，可以通过自定义转化规则或者特定（语义模型+语法规则）将问题转化为查询语言表达式，形成对知识库的查询。,基于问题解析结果,,,将问题转化为查询语言表达式形成对知识库的查询,
基于问题解析结果，可以通过自定义转化规则或者特定（语义模型+语法规则）将问题转化为查询语言表达式，形成对知识库的查询。,基于问题解析结果，可以通过自定义转化规则或者特定（语义模型+语法规则）将问题转化为查询语言表达式,,,"based on question analysis results, you can convert rules or specific (semantic model + grammar rules) questions into query language expression, form the knowledge base query.",
QALD的大多系统使用SPARQL表达查询。,QALD,,,SPARQL表达查询,
注意查询语言不仅能表达匹配子图的语义，还能承载一些计算统计功能（average、count函数）。,注意查询语言,,,表达匹配子图的语义，还能承载一些计算统计功能（average、count函数）。,
"8.3.4CommunityQA/FAQ-QA：基于问答对匹配的问答系统基于常见问答对（Frequently_Asked_Question,FAQ-QA[24]）以及社区问答（Community_Question_Answering,CQA）[25]都依赖搜索问答FAQ库（许多问答对<Q,A>的集合）来发现以前问过的类似问题，并将找到的问答对的答案返回给用户。",FAQ-QA,,,问答对基于问答对匹配的问答系统,
"8.3.4CommunityQA/FAQ-QA：基于问答对匹配的问答系统基于常见问答对（Frequently_Asked_Question,FAQ-QA[24]）以及社区问答（Community_Question_Answering,CQA）[25]都依赖搜索问答FAQ库（许多问答对<Q,A>的集合）来发现以前问过的类似问题，并将找到的问答对的答案返回给用户。",问答对,,,FAQ-QA,
"8.3.4CommunityQA/FAQ-QA：基于问答对匹配的问答系统基于常见问答对（Frequently_Asked_Question,FAQ-QA[24]）以及社区问答（Community_Question_Answering,CQA）[25]都依赖搜索问答FAQ库（许多问答对<Q,A>的集合）来发现以前问过的类似问题，并将找到的问答对的答案返回给用户。",问答库,,,FAQ库,
FAQ与CQA都是以问答对来组织知识，而且问答对的质量很高，不但已经是自然语言格式，而且受到领域专家或者社区的认可。,FAQ,,,CQA,
FAQ与CQA都是以问答对来组织知识，而且问答对的质量很高，不但已经是自然语言格式，而且受到领域专家或者社区的认可。,FAQ,,,问答式知识问答,
FAQ与CQA都是以问答对来组织知识，而且问答对的质量很高，不但已经是自然语言格式，而且受到领域专家或者社区的认可。,CQA,,,问答式知识问答,
二者的差异包括：答案的来源是领域专家还是社区志愿者，答案质量分别由专家自身的素质或者社区答案筛选机制保障。,答案的可靠性,,,领域专家提供或者社区志愿者提供答案,
二者的差异包括：答案的来源是领域专家还是社区志愿者，答案质量分别由专家自身的素质或者社区答案筛选机制保障。,答案的来源,,,领域专家,
二者的差异包括：答案的来源是领域专家还是社区志愿者，答案质量分别由专家自身的素质或者社区答案筛选机制保障。,答案质量,,,专家自身的素质,
基于FAQ-QA的核心是计算问题之间的语义相似性。,基于FAQ-QA,,,计算问题之间的语义相似性,
"重复问题发现（DuplicateQuestion_Detection,DQD）仅限于疑问句，这是短文本相似度计算的一个特例。",重复问题发现,,,短文本相似度计算的一个特例,
"重复问题发现（DuplicateQuestion_Detection,DQD）仅限于疑问句，这是短文本相似度计算的一个特例。",短文本相似度计算,,,"DuplicateQuestion_Detection,DQD",
事实上，语义相似性面临两个挑战：（1）“泛化”。,语义相似性,,,语义相似性面临两个挑战,
相同的语义在自然语言表达中有众多的表示方式，不论从词汇还是语法结构上都可以有显著差异，例如“How_do_I_add_a_vehicle_to_this_policy?”和“What_should_I_do_to_extend_this_policy_for_my_new_car?”。,相同的语义,,,自然语言表达,
相同的语义在自然语言表达中有众多的表示方式，不论从词汇还是语法结构上都可以有显著差异，例如“How_do_I_add_a_vehicle_to_this_policy?”和“What_should_I_do_to_extend_this_policy_for_my_new_car?”。,相同的语义,,,same meaning,
（2）“歧义”。,“歧义”,,,SPO,
两个近似的句子可以具有完全不同的语义，例如“教育部/长江学者”和“教育部长/江学者”。,“教育部/长江学者”,,,近似的句子,
语义相似度计算一直是NLP研究的前沿。,语义相似度计算,,,NLP研究的前沿,
一种类型的方法试图通过利用语义词典（例如WordNet）计算词汇相似度，这些语义相似网络来自语言学家的经验总结，受限于特定的语言；另一种方法将此任务作为统计机器翻译问题处理，并采用平行语料学习逐字或短语翻译概率，这种方法需要大量的平行问题集学习翻译概率，通常很难或成本高昂。,语义相似度计算,,,计算词汇相似度,
一种类型的方法试图通过利用语义词典（例如WordNet）计算词汇相似度，这些语义相似网络来自语言学家的经验总结，受限于特定的语言；另一种方法将此任务作为统计机器翻译问题处理，并采用平行语料学习逐字或短语翻译概率，这种方法需要大量的平行问题集学习翻译概率，通常很难或成本高昂。,语义相似网络,,,语义词典,
Rodrigues_J_A等人[26]基于两个测试数据集（AskUbnuntu领域相关问题集，和Quora领域无关）对比了基于规则（JCRD_Jacard）、基于传统机器学习以及基于深度学习的方法。,基于规则,,,JCRD_Jacard,
Rodrigues_J_A等人[26]基于两个测试数据集（AskUbnuntu领域相关问题集，和Quora领域无关）对比了基于规则（JCRD_Jacard）、基于传统机器学习以及基于深度学习的方法。,基于传统机器学习,,,基于规则,
Rodrigues_J_A等人[26]基于两个测试数据集（AskUbnuntu领域相关问题集，和Quora领域无关）对比了基于规则（JCRD_Jacard）、基于传统机器学习以及基于深度学习的方法。,基于深度学习,,,基于传统机器学习,
发现基于深度学习的方法在领域问题上效果显著，但是开放领域问题中效果与传统方法接近（甚至有所下降）。,基于深度学习的方法,,,领域问题效果显著,
SemEval2017年[27]评测结果指出，英文句子相似度计算的最佳结果已经达到F1=0.85。,英文句子相似度计算,,,SemEval2017评测结果指出,
所以，在工业应用中，为了满足领域知识问答的体验，结合有限的高度结构化的领域数据与大量相关的文本领域知识，需要更通用的问答框架，以取长补短。,问答框架,,,工业应用,
1.DeepQA:IRQA主导的混合框架如图8-14所示的DeepQA[28]综合IRQA和KBQA形成混合问答系统的架构图，Watson系统的问题处理大致分成四阶段：图8-14DeepQA综合IRQA和KBQA形成混合问答系统的架构图[13]（1）问题处理（Question_Processing）。,DeepQA,,,IRQA主导的混合框架,
主要是理解问题的类型，解析问题语义元素等。,概念/SPO,,,理解问题的类型,
主要是理解问题的类型，解析问题语义元素等。,概念/SPO,,,解析问题语义元素,
（2）候选答案生成（Candidate_Answer_Generation）。,候选答案生成,,,信息检索,
不仅从网络上搜索相关文档并抽取答案，还从知识库直接查询答案，然后合并构成答案候选集。,答案抽取,,,从知识库直接查询答案，然后合并构成答案候选集。,
（3）候选答案评分（Candidate_Answer_Scoring）。,候选答案评分,,,SPO三元组抽取,
针对每个候选答案选取一些重要特征，并对各个特征打分并形成答案的特征向量。,答案的特征向量,,,针对每个候选答案选取一些重要特征，并对各个特征打分并形成,
针对每个候选答案选取一些重要特征，并对各个特征打分并形成答案的特征向量。,答案的特征向量,,,answer_feature_vector,
Watson会利用很多信息源的佐证对候选答案进行打分，例如答案类型（Lexical_Answer_Type）、答案中的时空信息等。,Watson,,,信息源的佐证对候选答案进行打分,
Watson会利用很多信息源的佐证对候选答案进行打分，例如答案类型（Lexical_Answer_Type）、答案中的时空信息等。,Watson,,,问答系统,
以答案类型的人的问答为例，如果已知每个历史人物的出生日期和去世日期（从百科知识图谱获取），同时要求查找一个历史人物并且提到时间范围，则候选答案中非同时期的人物可以被认为是无关的。,候选答案,,,非同时期的人物,
以答案类型的人的问答为例，如果已知每个历史人物的出生日期和去世日期（从百科知识图谱获取），同时要求查找一个历史人物并且提到时间范围，则候选答案中非同时期的人物可以被认为是无关的。,候选答案中非同时期的人物,,,irrelevant,
（4）答案融合及排序（Confidence_Merging_And_Ranking）。,答案融合及排序,,,概念/产品,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,答案融合,,,答案排序,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,融合,,,merge,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,新的答案候选集,,,new answer candidate set,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,再排序,,,re-sort,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,逻辑回归分类器模型,,,logistic regression classifier model,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,每个候选答案,,,each candidate answer,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,计算置信度,,,calculate confidence,
首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。,返回置信度最高的答案,,,return the answer with highest confidence,
总之，Watson架构的创新点是同时从IRQA和KBQA获取大量候选答案，并以大量答案佐证作为特征形成答案特征评分向量，这一点正是单独IRQA系统和KBQA系统没有做到的。,Watson架构,,,同时从IRQA和KBQA获取大量候选答案并以大量答案佐证形成答案特征评分向量,
2.QALD-Hybrid-QA:KBQA主导的混合框架在QALD-6启动的Hybrid_QA要求KBQA可以同时利用知识图谱数据和文本数据。,Hybrid_QA,,,QALD-6启动的混合框架,
2.QALD-Hybrid-QA:KBQA主导的混合框架在QALD-6启动的Hybrid_QA要求KBQA可以同时利用知识图谱数据和文本数据。,QALD-Hybrid-QA,,,KBQA主导的混合框架在QALD-6启动的Hybrid_QA要求KBQA可以同时利用知识图谱数据和文本数据。,
自然语言先转化为SPARQL查询，但是并非所有SPARQL查询中的三元组特征（TriplePattern）都可以对应到知识图谱中的词汇，也并非所有知识都可以从掌握的知识图谱中查到，有一部分知识还需要从文档中抽取关系得到解答。,SPARQL查询中的三元组特征（TriplePattern）,,,知识图谱中的词汇,
这样可以避免前期过度的文本抽取工作，也能适应现实中更常见的图谱和文本混合的知识库。,知识图谱,,,前期过度的文本抽取工作,
这样可以避免前期过度的文本抽取工作，也能适应现实中更常见的图谱和文本混合的知识库。,知识图谱,,,适应现实中更常见的图谱和文本混合的知识库,
注意，在OpenIE抽取的三元组中，大量谓语predicate是没有经过归一融合的。,OpenIE,,,归一融合,
然后利用平行语料模型将问句中的关系映射到抽取三元组的谓语上。,平行语料模型,,,将问句中的关系映射到抽取三元组的谓语上,
然后利用平行语料模型将问句中的关系映射到抽取三元组的谓语上。,问句中的关系,,,映射到抽取三元组的谓语上,
例如，“front_man_of”映射到“lead_vocalist_of”上。,“front_man_of”,,,“lead_vocalist_of”,
图8-15基于SPARQL的混合问答系统的架构[29]3.Frankenstein：问答系统的流水线架构Frankenstein[32]通过对60多种KBQA系统的研究，将KBQA分成基于四类核心模块的流水线，其架构如图8-16所示。,基于四类核心模块的问答系统的流水线架构,,,Frankenstein,
模块化的流水线设计有利于将复杂的QA系统分解为细粒度可优化的部分，而且形成了可插拔的体系，便于系统优化更新。,模块化的流水线,,,将复杂的QA系统分解为细粒度可优化的部分，而且形成了可插拔的体系，便于系统优化更新,
但是这样的流水线有两点要求：尽量使用统一的知识表示，例如基于Ontology/Schema，这样才能保证各模块在接口上可以复用；模块的分解目前只考虑了Question2Query中针对结构化查询的部分，未覆盖非结构化文本的问答。,Question2Query,,,针对结构化查询的部分,
但是这样的流水线有两点要求：尽量使用统一的知识表示，例如基于Ontology/Schema，这样才能保证各模块在接口上可以复用；模块的分解目前只考虑了Question2Query中针对结构化查询的部分，未覆盖非结构化文本的问答。,Question2Query,,,问答问答,
"这个框架首先制定了一个可配置的流水线框架，并且分解出KBQA的四个主要模块：的知识库以及通用的RDF图8-16问答系统流水线的架构[32]（1）命名实体识别与消解歧义（Named_Entity_Disambiguation,NED）。",问答系统流水线,,,问答系统流水线,
从问题的文本中标记其中涉及的实体。,SPO,,,抽取三元组,
"（2）实体关系映射（Relation_Linking,RL）。",实体关系映射,,,"Relation_Linking,RL",
将问题文本提及的关系映射到知识库的实体属性或实体关系上。,将问题文本提及的关系映射到知识库的实体属性或实体关系上。,,,知识问答系统,
"（3）实体分类映射（Class_Linking,CL）。",实体分类映射,,,概念/产品,
将问题所需答案的类型映射到知识库的实体分类上。,问题所需答案的类型,,,知识库的实体分类上,
"（4）构建查询（Query_Building,QB）。",查询构建,,,构建查询,
基于上述语义理解的结果综合后形成SPARQL查询。,SPARQL查询,,,基于上述语义理解的结果综合,
同时，框架也利用分类器技术（QA_Pipeline_Classifier）支持流水线自动配置，也就是说从29个不同的模块（18个NED、5个RL、2个CL、2个QB），针对每一个特定的KBQA问答系统选取最优的流水线组合。,QA_Pipeline,,,分类器技术,
同时，框架也利用分类器技术（QA_Pipeline_Classifier）支持流水线自动配置，也就是说从29个不同的模块（18个NED、5个RL、2个CL、2个QB），针对每一个特定的KBQA问答系统选取最优的流水线组合。,QA_Pipeline_Classifier,,,分类器技术,
如图8-17所示，对于“What_is_the_capital_of_Canada?”，理想的NED组件应该将关键字“Canada”识别为命名实体，并将其映射到相应的DBpedia资源，即dbr:Canada。,NED组件,,,将关键字“Canada”识别为命名实体，并将其映射到相应的DBpedia资源，即dbr:Canada,
如图8-17所示，对于“What_is_the_capital_of_Canada?”，理想的NED组件应该将关键字“Canada”识别为命名实体，并将其映射到相应的DBpedia资源，即dbr:Canada。,NED,,,命名实体,
然后，RL模块需要找到知识图谱中对应的实体关系，因此“capital”映射到dbo:capital。,“capital”,,,dbo:capital,
然后，RL模块需要找到知识图谱中对应的实体关系，因此“capital”映射到dbo:capital。,等价,,,map to dbo:capital,
最后，QB模块综合上述结果形成SPARQL查询SELECT_DISTINCT?uri_WHERE{dbr:Canadadbo:capital?uri.}。,等价,,,map to dbo:capital,
最后，QB模块综合上述结果形成SPARQL查询SELECT_DISTINCT?uri_WHERE{dbr:Canadadbo:capital?uri.}。,等价,,,等价,
图8-17问答系统流水线举例说明[32]8.4知识问答的评价方法8.4.1问答系统的评价指标1.功能评价指标问答系统通常可以通过一组预定的测试问题集以及一组预定的维度来评价。,问答系统的评价指标,,,问答系统的评价指标,
问答系统的功能评价重点关注返回的答案，正确的答案应当同时具备正确度及完备度，正确但内容不完整的答案被称为不准确答案，没有足够证据及论证表明答案与问题相关性的则是无支撑答案，当答案与问题完全无关时，意味着答案是错误的。,问答系统的功能评价,,,evaluate the function of question-answering system,
答案评价通常可以从如下角度考虑：（1）正确性。,答案评价,,,从如下角度考虑,
答案是否正确地回答了问题，例如问美国总统是谁，回答“女克林顿”就错了。,答案,,,回答错误的概念/产品,
（2）精确度。,精确度,,,SPO三元组,
答案是否缺失信息，例如问美国总统是谁，回答“布什”可能存在二义性，到底是老布什，还是小布什；答案中是否包含了多余的信息，同样的问题，“特朗普在纽约州出生”就包含了多余的信息。,答案,,,二义性,
答案是否缺失信息，例如问美国总统是谁，回答“布什”可能存在二义性，到底是老布什，还是小布什；答案中是否包含了多余的信息，同样的问题，“特朗普在纽约州出生”就包含了多余的信息。,答案,,,多余的信息,
答案是否缺失信息，例如问美国总统是谁，回答“布什”可能存在二义性，到底是老布什，还是小布什；答案中是否包含了多余的信息，同样的问题，“特朗普在纽约州出生”就包含了多余的信息。,等价,,,equivalence,
答案是否缺失信息，例如问美国总统是谁，回答“布什”可能存在二义性，到底是老布什，还是小布什；答案中是否包含了多余的信息，同样的问题，“特朗普在纽约州出生”就包含了多余的信息。,英文名,,,English name,
（3）完整性。,完整性,,,SPO三元组,
如果答案是一个列表，应当返回问题要求的所有答案。,答案,,,返回问题要求的所有答案,
如果答案是一个列表，应当返回问题要求的所有答案。,答案,,,answer,
例如，列举美国总统，应该把所有满足条件的人都列举出来。,列举美国总统,,,把所有满足条件的人都列举出来,
（4）可解释性。,SPO,,,可解释性,
在给出答案的同时，也给出引文或证明说明答案与问题的关联。,给出答案,,,给出引文或证明说明答案与问题的关联,
根据TREC的测试结果，考虑与未考虑文章支持度的测试结果差距可达十几个百分点。,考虑与未考虑文章支持度的测试结果差距,,,TREC的测试结果,
（5）用户友好性。,用户友好性,,,SPO三元组,
答案质量由人工评分，很多非事实性问题并非一个唯一的答案，所以需要人工判定答案的质量。,答案质量,,,人工评分,
答案质量由人工评分，很多非事实性问题并非一个唯一的答案，所以需要人工判定答案的质量。,答案质量,,,answer quality,
如果答案被认为没错就按质量打分，Fair为1分、Good为2分、Excellent为3分，如果答不上来或答错则算零分。,质量打分,,,按质量打分,
如果答案被认为没错就按质量打分，Fair为1分、Good为2分、Excellent为3分，如果答不上来或答错则算零分。,质量打分,,,Fair,
如果答案被认为没错就按质量打分，Fair为1分、Good为2分、Excellent为3分，如果答不上来或答错则算零分。,质量打分,,,Good,
如果答案被认为没错就按质量打分，Fair为1分、Good为2分、Excellent为3分，如果答不上来或答错则算零分。,质量打分,,,Excellent,
（6）额外的评价维度。,额外的评价维度,,,概念/产品,
当答案类型更为复杂时，例如有排序、统计、对比等更多的要求，还应该有额外的评价维度。,答案类型,,,更多的要求,
除了上述针对答案的评价，也有针对解答过程复杂程度的评价，例如Semantic_Tractability[33]，用于反映问答之间的词表差异性；AnswerLocality[34]，答案是否零碎地分布在不同的文本或数据集录中；Derivability34，问题的答案是否是某种确定性答案，还是含蓄的、不确定的描述；Semantic_Complexity，问题涉及的语义复杂程度。,Semantic_Tractability,,,问答之间的词表差异性,
除了上述针对答案的评价，也有针对解答过程复杂程度的评价，例如Semantic_Tractability[33]，用于反映问答之间的词表差异性；AnswerLocality[34]，答案是否零碎地分布在不同的文本或数据集录中；Derivability34，问题的答案是否是某种确定性答案，还是含蓄的、不确定的描述；Semantic_Complexity，问题涉及的语义复杂程度。,AnswerLocality,,,答案是否零碎地分布在不同的文本或数据集录中,
除了上述针对答案的评价，也有针对解答过程复杂程度的评价，例如Semantic_Tractability[33]，用于反映问答之间的词表差异性；AnswerLocality[34]，答案是否零碎地分布在不同的文本或数据集录中；Derivability34，问题的答案是否是某种确定性答案，还是含蓄的、不确定的描述；Semantic_Complexity，问题涉及的语义复杂程度。,Derivability,,,问题的答案是否是某种确定性答案,
除了上述针对答案的评价，也有针对解答过程复杂程度的评价，例如Semantic_Tractability[33]，用于反映问答之间的词表差异性；AnswerLocality[34]，答案是否零碎地分布在不同的文本或数据集录中；Derivability34，问题的答案是否是某种确定性答案，还是含蓄的、不确定的描述；Semantic_Complexity，问题涉及的语义复杂程度。,Semantic_Complexity,,,问题涉及的语义复杂程度,
常用的问答指标采用F1（综合正确率和召回率）和P@1（第一个答案是否正确的比率）。,问答指标,,,F1,
常用的问答指标采用F1（综合正确率和召回率）和P@1（第一个答案是否正确的比率）。,问答指标,,,P@1,
常用的问答指标采用F1（综合正确率和召回率）和P@1（第一个答案是否正确的比率）。,问答指标,,,F1,
常用的问答指标采用F1（综合正确率和召回率）和P@1（第一个答案是否正确的比率）。,问答指标,,,P@1,
2.性能评价指标除了功能评价指标，参考UsbeckR等人[35]的评价体系，问答系统从性能角度可以考虑如下指标：（1）问答系统的响应时间（Response_Time）。,问答系统的响应时间,,,性能评价指标,
2.性能评价指标除了功能评价指标，参考UsbeckR等人[35]的评价体系，问答系统从性能角度可以考虑如下指标：（1）问答系统的响应时间（Response_Time）。,问答系统的响应时间,,,Response_Time,
问答系统对用户输入或者请求做出反应的时间。,问答系统,,,反应时间,
问答系统的响应时间是评价系统性能的一个非常重要的指标，如果响应时间过长，会使系统的可用性很低。,问答系统的响应时间,,,评价系统性能,
问答系统的响应时间是评价系统性能的一个非常重要的指标，如果响应时间过长，会使系统的可用性很低。,问答系统的响应时间,,,evaluate the performance of a system,
一般问答系统的响应时间应控制在1s以内。,问答系统,,,响应时间,
（2）问答系统的故障率（Error_Rate）。,问答系统的故障率,,,SPO,
在限定时间内给出答案即可，不考虑答案是否正确。,问答系统,,,限定时间内给出答案,
系统返回错误或者系统运行过程中发生错误数的统计。,系统性能监控,,,系统返回错误或者系统运行过程中发生错误数的统计,
系统返回错误或者系统运行过程中发生错误数的统计。,系统返回错误,,,system return error,
系统返回错误或者系统运行过程中发生错误数的统计。,系统运行过程中发生错误数,,,system run error,
8.4.2问答系统的评价数据集1.TREC_QA：评价IRQATREC_QA[36]是美国标准计量局在1999—2007年针对问答系统设定的年度评价体系，本文关注其问答的核心任务（MAIN_TASK）。,TREC_QA,,,评价IRQA,
8.4.2问答系统的评价数据集1.TREC_QA：评价IRQATREC_QA[36]是美国标准计量局在1999—2007年针对问答系统设定的年度评价体系，本文关注其问答的核心任务（MAIN_TASK）。,TREC_QA,,,评价IRQATREC_QA,
此评价体系主要针对基于搜索的问答解决方案（IRQA）。,评价体系,,,基于搜索的问答解决方案（IRQA）,
问题集主要来自搜索引擎的查询日志（也有少部分问题由人工设计）。,问题集,,,搜索引擎的查询日志,
问题集主要来自搜索引擎的查询日志（也有少部分问题由人工设计）。,问题集,,,人工设计,
知识库主要采用跨度几年的主流媒体的新闻。,知识库,,,主流媒体的新闻,
问答系统返回的结果包括两部分<答案，文档ID>，前者为字符串，后者为问题答案来源的文档的ID。,问答系统返回的结果,,,两部分<答案，文档ID>,
问答系统返回的结果包括两部分<答案，文档ID>，前者为字符串，后者为问题答案来源的文档的ID。,问答系统返回的结果,,,问答系统返回的结果包括两部分<答案，文档ID>，前者为字符串，后者为问题答案来源的文档的ID。,
评价方法主要是选取大约1000个测试问题，由1～3人标注评价答案的正确性（答案是否正确回答了问题）、精准度（答案中是否包含多余的内容）以及对应文章的支持度（对应的文章是否支持该答案）。,评价方法,,,选取大约1000个测试问题，由1～3人标注评价答案的正确性（答案是否正确回答了问题）、精准度（答案中是否包含多余的内容）以及对应文章的支持度（对应的文章是否支持该答案）,
评价方法主要是选取大约1000个测试问题，由1～3人标注评价答案的正确性（答案是否正确回答了问题）、精准度（答案中是否包含多余的内容）以及对应文章的支持度（对应的文章是否支持该答案）。,评价方法,,,选取大约1000个测试问题，由1～3人标注评价答案的正确性（答案是否正确回答了问题）、精准度（答案中是否包含多余的内容）以及对应文章的支持度（对应的文章是否支持该答案）,
评价指标区分了单一答案和列表答案的评价方法。,评价指标,,,区分了单一答案和列表答案的评价方法。,
2.TREC_LIVE_QA：评价CQA社区问答TREC_LIVE_QA也[37]是美国标准计量局在2015—2107年从更真实的网络问答出发，主要面向CQA社区问答解决方案的评价体系。,TREC_LIVE_QA,,,评价体系,
2.TREC_LIVE_QA：评价CQA社区问答TREC_LIVE_QA也[37]是美国标准计量局在2015—2107年从更真实的网络问答出发，主要面向CQA社区问答解决方案的评价体系。,TREC_LIVE_QA,,,评价CQA社区问答TREC_LIVE_QA也,
问题集主要来自Yahoo_Answer的实时新问题。,问题集,,,Yahoo_Answer的实时新问题,
知识库主要来自Yahoo_Answer的社区问答数据，以及过往标注的千余条数据。,知识库,,,Yahoo_Answer的社区问答数据以及过往标注的千余条数据。,
评价方法主要选取大约1000个测试问题，每个问题要求在1min内回答。,评价方法,,,选取大约1000个测试问题，每个问题要求在1min内回答,
评价方法主要选取大约1000个测试问题，每个问题要求在1min内回答。,评价方法,,,evaluation method,
"由于问题类型不限于简单知识问答，所有的答案由1～3人标注并直接按答案质量打{0,1,2,3}分。",问答评分系统,,,简单知识问答,
"由于问题类型不限于简单知识问答，所有的答案由1～3人标注并直接按答案质量打{0,1,2,3}分。",标注答案质量,,,按答案质量打1～3分,
另外，评价系统也针对测试问题，获取赛后的社区人工答案做类似的评价，然后对比自动生成的答案和人工产生的答案的体验差异。,评价系统,,,针对测试问题获取赛后的社区人工答案做类似的评价,
另外，评价系统也针对测试问题，获取赛后的社区人工答案做类似的评价，然后对比自动生成的答案和人工产生的答案的体验差异。,评价系统,,,evaluation system,
3.QALD：评价KBQAQALD[38]是指2011—2017年的链接数据的问答系统评测（Question_Answering_onLinked_Data），为自然语言问题转化为可用的SPARQL查询以及基于语义万维网标准的知识推理提供了一系列的评价体系和测试数据集，对QALD的工作做了详细介绍。,QALD,,,Question_Answering_onLinked_Data,
QALD的主要任务如下：给定知识库（一个或多个RDF数据集以及其他知识源）和问题（自然语言问题或关键字），返回正确的答案或返回这些答案的SPARQL查询。,QALD,,,给定知识库（一个或多个RDF数据集以及其他知识源）和问题（自然语言问题或关键字），返回正确的答案或返回这些答案的SPARQL查询,
QALD的主要任务如下：给定知识库（一个或多个RDF数据集以及其他知识源）和问题（自然语言问题或关键字），返回正确的答案或返回这些答案的SPARQL查询。,QALD,,,问答查询语言,
这样，QALD可以利用工业相关的实际任务评价现有的系统，并且找到现有系统中的瓶颈与改进方向，进而深入了解如何开发处理海量RDF数据方法。,QALD,,,工业相关的实际任务评价现有的系统，并且找到现有系统中的瓶颈与改进方向，进而深入了解如何开发处理海量RDF数据方法。,
这样，QALD可以利用工业相关的实际任务评价现有的系统，并且找到现有系统中的瓶颈与改进方向，进而深入了解如何开发处理海量RDF数据方法。,QALD,,,工业相关的实际任务评价现有的系统,
这些海量数据分布在不同的数据集之间，并且它们是异构的、有噪声的，甚至结构是不一致的。,数据集,,,分布在不同的数据集之间，并且它们是异构的、有噪声的，甚至结构是不一致的。,
4.SQuAD：评价端到端的问答系统解决方案SQuAD[39]是斯坦福大学推出的一个大规模阅读理解数据集，由众多维基百科文章中的众包工作者提出的问题构成，每个问题的答案都是相应阅读段落的一段文字或跨度。,SQuAD,,,SQuAD,
2017—2018年，国内也有不少类似的阅读理解比赛，例如搜狗问答。,搜狗问答,,,阅读理解比赛,
SQuAD评价指标主要分两部分：（1）精准匹配。,SQuAD评价指标,,,精准匹配,
正确匹配标准答案，目前效果最好的算法达到74.5%，人类表现是82.3%。,算法,,,目前效果最好的算法,
这个指标准确地匹配任何一个基本事实答案的预测百分比。,这个指标准确地匹配任何一个基本事实答案的预测百分比。,,,属于概念/产品,
（2）F1值。,F1值,,,信息检索质量评价指标,
这个指标衡量了预测和基本事实答案之间的平均重叠数。,指标的构成,,,衡量了预测和基本事实答案之间的平均重叠数,
在给定问题的F1，然后对所有问题求平均值。,F1,,,给定问题的F1,
2018年3月，谷歌公司的所有基础正确答案中取最大值QAnet[40]达到了F1=89.737，非常接近人工对比指标F1=91.221。,QAnet,,,谷歌公司的基础正确答案,
2018年3月，谷歌公司的所有基础正确答案中取最大值QAnet[40]达到了F1=89.737，非常接近人工对比指标F1=91.221。,QAnet,,,谷歌公司的所有基础正确答案中取最大值,
在此之前，斯坦福大学还发布过Web_Question数据集[41]。,斯坦福大学问答数据集,,,斯坦福大学发布过Web_Question数据集,
在Web_Questions数据集上的F1值为31.3%，后续不少研究者在Web_Questions提出了一些新Jain提出的Factual的有效模型，F1值逐年更新。,F1值,,,在Web_Questions数据集上的F1值为31.3%,
在Web_Questions数据集上的F1值为31.3%，后续不少研究者在Web_Questions提出了一些新Jain提出的Factual的有效模型，F1值逐年更新。,F1,,,Factual的有效模型,
在Web_Questions数据集上的F1值为31.3%，后续不少研究者在Web_Questions提出了一些新Jain提出的Factual的有效模型，F1值逐年更新。,Jain,,,在Web_Questions数据集上的F1值为31.3%,
目前，效果最好的模型是Sarthak_Memory_Network模型[42]，该模型的平均精确度为55.2%，平均召回率为64.9%，平均精确度和平均召回率的F1值为59.7%，平均F1值为55.7%。,Sarthak_Memory_Network模型,,,效果最好的模型,
目前，效果最好的模型是Sarthak_Memory_Network模型[42]，该模型的平均精确度为55.2%，平均召回率为64.9%，平均精确度和平均召回率的F1值为59.7%，平均F1值为55.7%。,Sarthak_Memory_Network模型,,,Sarthak_Memory_Network,
5.Quora_QA：评价问题相似度计算Quora于2017年在Kaggle发布的数据集包含约40万个问题对，每个问题包含两个问题ID和原始文本，另外还有一个数字标记这两个问题是否等价，即对应到同一个意图的上。,Quora_QA,,,评价问题相似度计算,
5.Quora_QA：评价问题相似度计算Quora于2017年在Kaggle发布的数据集包含约40万个问题对，每个问题包含两个问题ID和原始文本，另外还有一个数字标记这两个问题是否等价，即对应到同一个意图的上。,Quora_QA,,,评价问题相似度计算Quora于2017年在Kaggle发布的数据集,
这个数据集主要用于验证社区问答或FAQ问答的语义相似度计算算法，目前在Kaggle上的竞赛结果最优者的Logloss已经达到0.11。,语义相似度计算算法,,,验证社区问答或FAQ问答的语义相似度计算,
这个数据集主要用于验证社区问答或FAQ问答的语义相似度计算算法，目前在Kaggle上的竞赛结果最优者的Logloss已经达到0.11。,语义相似度计算算法,,,semantic similarity algorithm,
这个数据集来自社区问答网站Quora，这种规模抽样的数据的确存在少量噪声问题且话题分布并不一定与Quora网站的问题分布一致。,Quora,,,社区问答网站,
"另外，社区问答中只有少量问题是真正等价，因此通过C(n,2)随机组合抽取两个问题，绝大多数问题对也不应该等价。",等价问答,,,社区问答,
"另外，社区问答中只有少量问题是真正等价，因此通过C(n,2)随机组合抽取两个问题，绝大多数问题对也不应该等价。",等价,,,equivalence,
"另外，社区问答中只有少量问题是真正等价，因此通过C(n,2)随机组合抽取两个问题，绝大多数问题对也不应该等价。",英文名,,,"C(n,2)",
这40万条数据首先加入了大量正例（等价的问题对），然后利用“related_question”关系添加了负例（相关但不等价的问题对），这样才形成一个相对平衡的训练数据集。,正例,,,加入大量正例,
这40万条数据首先加入了大量正例（等价的问题对），然后利用“related_question”关系添加了负例（相关但不等价的问题对），这样才形成一个相对平衡的训练数据集。,负例,,,添加负例,
Elkhan_Dadashov[43]在Quora_QA数据集上尝试了多种不同的LSTM模型，最好的模型的F1值达到了79.5%，准确率还到了83.8%。,Elkhan_Dadashov,,,在Quora_QA数据集上尝试了多种不同的LSTM模型，最好的模型的F1值达到了79.5%，准确率还到了83.8%。,
6.SemEval：词义消歧评测SemEval是由ACL词汇与语义小组组织的词汇与语义计算领域的国际权威技术竞赛。,SemEval,,,词义消歧评测,
6.SemEval：词义消歧评测SemEval是由ACL词汇与语义小组组织的词汇与语义计算领域的国际权威技术竞赛。,SemEval,,,词义消歧评测,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,词汇语义评测任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,推特语义分析任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,空间角色标注任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,组合名词的自由复述任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,文本蕴涵识别任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,中文信息处理大赛,,,多语种的词义消歧任务,
从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。,信息检索语言,,,Information Retrieval Language,
2018的Sameval比赛包含12个任务，主要包括以下几方面的内容：（1）推特情感与创造性语句分析。,Sameval比赛,,,2018的Sameval比赛包含12个任务,
该部分的处理对象来自推特的社交文本数据，其中涵盖英语、阿拉伯语以及西班牙语等多种语言的文本。,推特的社交文本数据,,,处理对象,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,分析的定位,,,情感分析,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,分析的定位,,,符号预测,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,分析的定位,,,反讽语义识别,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,情感分析,,,emotion analysis,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,符号预测,,,symbol prediction,
分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。,反讽语义识别,,,irony semantic recognition,
（2）实体关联。,SPO,,,实体关联,
该部分包含两个子任务。,该部分,,,子任务,
一个子任务是多人对话中的人物识别，目标是识别对话中提及的所有人物。,一个子任务,,,多人对话中的人物识别,
一个子任务是多人对话中的人物识别，目标是识别对话中提及的所有人物。,一个子任务是多人对话中的人物识别,,,recognize all the characters in a multi-person dialogue,
值得一提的是，这些人物并不一定是对话中的某个谈话者，可能是他们提及的其他人。,人物,,,对话中的某个谈话者,
值得一提的是，这些人物并不一定是对话中的某个谈话者，可能是他们提及的其他人。,谈话者,,,interlocutor,
如图8-18所示的多人对话场景，Ross提到的“mom”并不是参与对话的某人，而是Judy。,多人对话场景,,,Ross提到的“mom”并不是参与对话的某人，而是Judy,
如何有效地识别出对话中提及人物的字符具体指向什么人物实体，是本任务需要解决的重要问题之一。,对话中提及人物的字符,,,有效识别出人物实体,
另一个子任务则是面向事件的识别以及分析，针对给定的问题，从给定文本中找出问题相关的一个事件或多个事件，以及参与角色之间的关系。,面向事件的识别以及分析,,,概念/产品,
另一个子任务则是面向事件的识别以及分析，针对给定的问题，从给定文本中找出问题相关的一个事件或多个事件，以及参与角色之间的关系。,面向事件的识别以及分析,,,event or multiple events,
图8-18多人对话场景示例（3）信息抽取。,多人对话,,,信息抽取,
该部分介绍的信息抽取包含关系（关系抽取与分类）、时间（基于语义分析的时间标准化）等。,信息抽取,,,关系（关系抽取与分类）、时间（基于语义分析的时间标准化）,
如图8-19所示为时间信息的语义解析示例，对于文本“metevery_other_Saturday_since_March_6”，其中的时间信息被解析为时间点与时间段并标准化表示出来。,时间信息的语义解析示例,,,时间信息的语义解析,
如图8-19所示为时间信息的语义解析示例，对于文本“metevery_other_Saturday_since_March_6”，其中的时间信息被解析为时间点与时间段并标准化表示出来。,时间点,,,every_other_Saturday_since_March_6,
图8-19时间信息的语义解析示例（4）词汇语义学。,时间信息的语义解析,,,词汇语义学,
图8-19时间信息的语义解析示例（4）词汇语义学。,词汇语义学,,,semantic analysis,
该部分从词汇语义的角度入手，提出了用于反映词汇之间高度关系的上位调发现以及判别属性识别。,上位调发现以及判别属性识别,,,词汇语义,
该部分从词汇语义的角度入手，提出了用于反映词汇之间高度关系的上位调发现以及判别属性识别。,上位调发现,,,overlap discovery,
该部分从词汇语义的角度入手，提出了用于反映词汇之间高度关系的上位调发现以及判别属性识别。,属性识别,,,attribute recognition,
与传统计算词汇语义相似不同，本任务关注词的语义相异性，目标是预测一个词是其他词的一个判别属性。,本任务,,,预测一个词是其他词的一个判别属性,
与传统计算词汇语义相似不同，本任务关注词的语义相异性，目标是预测一个词是其他词的一个判别属性。,本任务,,,预测一个词是其他词的一个判别属性,
例如，给定词语“香蕉”与“苹果”，词语“红色”可以作为判别属性区分两者的相异性。,判别属性,,,区分两者的相异性,
例如，给定词语“香蕉”与“苹果”，词语“红色”可以作为判别属性区分两者的相异性。,等价,,,相异性,
红色是苹果的一个颜色属性，但是与香蕉无关。,红色,,,苹果的颜色属性,
红色是苹果的一个颜色属性，但是与香蕉无关。,红色,,,颜色属性,
红色是苹果的一个颜色属性，但是与香蕉无关。,苹果,,,一个颜色属性,
红色是苹果的一个颜色属性，但是与香蕉无关。,香蕉,,,无关,
（5）阅读理解与推理。,阅读理解与推理,,,SPO三元组,
该部分由两个子任务构成，一个子任务是研究任务包括如何利用常识完成文本阅读理解，另一个子任务是通过推理方式对给定的由声明和理由组成的论点，从两个候选论据中选出正确的论据。,研究任务,,,如何利用常识完成文本阅读理解,
该部分由两个子任务构成，一个子任务是研究任务包括如何利用常识完成文本阅读理解，另一个子任务是通过推理方式对给定的由声明和理由组成的论点，从两个候选论据中选出正确的论据。,研究任务,,,文本阅读理解,
该部分由两个子任务构成，一个子任务是研究任务包括如何利用常识完成文本阅读理解，另一个子任务是通过推理方式对给定的由声明和理由组成的论点，从两个候选论据中选出正确的论据。,子任务,,,推理方式组成论点,
8.5KBQA前沿技术目前还存在两个很大的困难阻碍着KBQA系统被广泛应用。,KBQA系统,,,被广泛应用,
一个困难是现有的自然语言理解技术在处理自然语言的歧义性和复杂性方面还显得比较薄弱。,自然语言理解技术,,,处理自然语言的歧义性和复杂性方面还显得比较薄弱,
例如，有时候一句话系统可以理解，但是换一个说法就不能理解了。,一句话系统,,,理解,
例如，有时候一句话系统可以理解，但是换一个说法就不能理解了。,一句话系统,,,理解,
另一个困难是此类系统需要大量的领域知识来理解自然语言问题，而这些一般都需要人工输入。,问答系统,,,需要大量的领域知识来理解自然语言问题,
另一个困难是此类系统需要大量的领域知识来理解自然语言问题，而这些一般都需要人工输入。,本体语义检索,,,ontology semantic retrieval,
一些系统需要开发一个专用于一个领域的基于句法或者语义的语法分析器。,基于句法或者语义的语法分析器,,,系统需要开发一个专用于一个领域的,
许多系统都引入了一个用户词典或者映射规则，用来将用户的词汇或说法映射到系统本体的词汇表或逻辑表达式中。,用户词典,,,将用户的词汇或说法映射到系统本体的词汇表或逻辑表达式中,
通常还需要定义一个世界模型（World_Model），来指定词典或本体中词汇的上下位关系和关系参数类型的限制。,世界模型,,,定义词汇上下位关系和关系参数类型的限制,
通常还需要定义一个世界模型（World_Model），来指定词典或本体中词汇的上下位关系和关系参数类型的限制。,世界模型,,,World_Model,
这些工作都是非常消耗人力的。,信息检索,,,信息检索的五大用途,
以下围绕KBQA的关键阶段——“构建查询”，说明KBQA面临的挑战，然后介绍几种典型的解决方案。,KBQA的关键阶段——“构建查询”,,,构建查询面临的挑战,
8.5.1KBQA面临的挑战图8-20反映了KBQA中一个简化的“问题→答案”映射过程，自然语言问题在关联知识库之前，需要转换成结构化查询，利用查询从知识图谱中找到答案后，还需要考虑一个自然语言答案生成的过程。,KBQA,,,“问题→答案”映射过程,
这个过程中的主要挑战在于如何将自然语言表达映射到知识库的查询，也就是Question2Query语义理解。,Question2Query,,,将自然语言表达映射到知识库的查询,
图8-20问题到答案的映射过程1.多样的概念映射机制也就是将自然语言表达的查询语义映射知识库的原子查询。,多样的概念映射机制,,,将自然语言表达的查询语义映射知识库的原子查询,
图8-20问题到答案的映射过程1.多样的概念映射机制也就是将自然语言表达的查询语义映射知识库的原子查询。,多样的概念映射机制,,,diversified concept mapping mechanism,
自然语言的表达的语义包罗万象，常见语义映射现象如表8-3所示。,自然语言的表达的语义,,,语义映射现象,
自然语言的表达的语义包罗万象，常见语义映射现象如表8-3所示。,等价,,,equivalence,
表8-3常见的语义映射现象2.不完美的知识库首先，知识库未必全都是结构化的数据，还有大量的知识存在于文本中。,知识库,,,不完美的知识库,
表8-3常见的语义映射现象2.不完美的知识库首先，知识库未必全都是结构化的数据，还有大量的知识存在于文本中。,等价,,,equivalence,
这需要有动态知识抽取解决方案。,动态知识抽取,,,解决方案,
其次，知识库的知识组织机制各不相同，同样的知识在不同的知识库中未必会采用同样的结构，例如三元组（英国，加入欧盟的时间，1973）等价于四个三元组（事件1，加入方，英国）（事件1，被加入方，欧盟）（事件1，年份，1973）（事件1，类型，加入组织），这样也为查询制造了困难。,知识组织机制,,,不同的知识不同的知识库中未必会采用同样的结构,
再次，用户使用的语言以及知识库采用的工作语言也会影响语义理解，例如用中文查询英文的DBpedia，从中文的关系名称映射到英文的实体属性就不简单。,语义理解,,,semantic understanding,
再次，用户使用的语言以及知识库采用的工作语言也会影响语义理解，例如用中文查询英文的DBpedia，从中文的关系名称映射到英文的实体属性就不简单。,中文的关系名称,,,英文的实体属性,
最后，知识库本身并不是完整的，而用户的预期却是希望能找到答案，这样如何判定找不到答案从而避免答非所问也是很重要的。,知识问答,,,找不到答案从而避免答非所问,
3.泛化语义理解的预期当用户使用知识问答时，常见的抱怨就是同一个问题换一种说法就无法理解了。,泛化语义理解的预期,,,知识问答,
这个问题在智能客服中尤其明显，在保障精确度的前提下智能客服应该匹配尽量可解答的问题。,智能客服,,,保障精确度的前提下智能客服应该匹配尽量可解答的问题,
泛化问题通常可以从词语和句子两个层面来研究。,泛化问题,,,词语和句子两个层面来研究,
（1）词语层面的泛化匹配[44]。,词语层面的泛化匹配,,,概念/产品,
①命名实体的不同说法，例如“上海”对应“沪”，需要从网络或领域专家获取背景知识，而“交通银行股份有限公司”可以通过简单的规则得到简称“交通银行”。,“上海”,,,命名实体的不同说法,
②生成实体（日期，地址等）的不同说法。,生成实体（日期，地址等）的不同说法。,,,SPO三元组,
例如“2018年1月1日”和“2018年元旦”。,“2018年1月1日”,,,时间,
例如“2018年1月1日”和“2018年元旦”。,“2018年元旦”,,,时间,
注意，生成实体的识别和解析可以通过常规的语法分析工具达成，但是中英文数字的混合、语音识别错误等现象会令解析难度提升。,生成实体的识别和解析,,,常规的语法分析工具,
③实体分类和属性或关系的不同说法。,实体分类,,,属性的不同说法,
③实体分类和属性或关系的不同说法。,实体分类,,,关系的不同说法,
例如“还活着吗”对应“死亡日期”，这样的平行语料学习不但可以通过基于知识图谱的关系抽取结果来充实，也可以利用深度学习的分布式表示Embedding来计算。,基于知识图谱的关系抽取,,,平行语料学习,
另外，这些语料的目标是建立从自然语言表示到知识图谱表示的映射，所以部分词汇还应该直接映射到知识图谱的实体分类和实体（描述或关系）属性上。,语料的五大用途或特点,,,建立从自然语言表示到知识图谱表示的映射,
另外，这些语料的目标是建立从自然语言表示到知识图谱表示的映射，所以部分词汇还应该直接映射到知识图谱的实体分类和实体（描述或关系）属性上。,语料,,,建立从自然语言表示到知识图谱表示的映射,
还要注意对知识图谱本体的语义融合归一化处理，例如在Wikidata里没有统一的“水果”分类，这样就不能通过简单的实体分类获取完整的水果列表。,知识图谱本体,,,语义融合归一化处理,
（2）句子层面的泛化处理。,句子层面的泛化处理。,,,信息检索,
主要是判断问题的语义相似度（Question-QuestionSimilarity）[44]，常用思路通常采用语言模型、机器翻译模型、句子主题分析模型、句子结构相似度分析模型、基于知识图谱的句子成分相似度模型等，SemEval的Task1和Task3_SubTaskB[45]都对这一方面的关键技术做了评测。,语义相似度,,,判断问题的语义相似度,
句子问题相似度算法可以被封装为独立的计算模块，然后将语法分析和前面基于知识图谱的语义解析结果作为特征交给基于LSTM的模型[46]计算相似度。,句子问题相似度算法,,,独立的计算模块,
句子问题相似度算法可以被封装为独立的计算模块，然后将语法分析和前面基于知识图谱的语义解析结果作为特征交给基于LSTM的模型[46]计算相似度。,句子问题相似度算法,,,sentence question similarity algorithm,
8.5.2基于模板的方法基于模板（Template）或模式（Pattern）的问答系统定义了一组带变量的模板，直接匹配问题文本形成查询表达式。,基于模板的方法,,,基于模板（Template）或模式（Pattern）的问答系统定义了一组带变量的模板，直接匹配问题文本形成查询表达式。,
这样简化了问题分析的步骤，并且通过预制的查询模板替代了本体映射。,ELK,,,问题分析的步骤,
这样简化了问题分析的步骤，并且通过预制的查询模板替代了本体映射。,SPO,,,subject,
这样做的优势包括：简单可控，适于处理只有一个查询条件的简单问题；绕过了语法解析的脆弱性。,Elasticsearch,,,简单可控，适于处理只有一个查询条件的简单问题,
这个方案在工业中得到广泛的应用。,方案,,,工业中得到广泛的应用,
图8-21描述了一个TrueKnowledge[47]模板示例，其中包含了以下步骤，首先使用已知的模板成分匹配句子中的内容，包括疑问词（What、Which，反映问题的意图），以及部分已知的模板（is_a_present_central_form_of，某些固定表达词组），对于未知成分则使用变量字符加以替换（固定表达前后的a、y等），这种模板可以实现一对多的问题覆盖效果。,TrueKnowledge,,,TrueKnowledge,
图8-21TrueKnolwedge的模板举例[47]TBSL[48]在QALD_2012测评任务中提出了一种联合使用语义结构分析以及自然语言词汇—URI间映射的问答方法。,TBSL,,,TrueKnowledge,
根据模板匹配结果生成多组可能的SPARQL查询，通过筛选这些查询，最终生成答案并返回给用户。,根据模板匹配结果生成多组可能的SPARQL查询,,,生成答案并返回给用户,
根据模板匹配结果生成多组可能的SPARQL查询，通过筛选这些查询，最终生成答案并返回给用户。,SPO,,,semantic_pattern_oriented,
在基于模板的知识问答框架中，模板一般没有统一的标准或格式，只需结合知识图谱的结构以及问句的句式进行构建即可。,基于模板的知识问答框架,,,没有统一的标准或格式,
TBSL中的模板定义为SPARQL查询模板。,TBSL中的模板,,,SPARQL查询模板,
图8-22典型的TBSL框架流程TBSL方法有两个重要的步骤：模板生成和模板实例化。,TBSL方法,,,模板生成,
图8-22典型的TBSL框架流程TBSL方法有两个重要的步骤：模板生成和模板实例化。,TBSL方法,,,模板实例化,
模板生成步骤解析问句结构并生成对应的SPARQL查询模板，该查询模板中可能包含过滤和聚合操作。,模板生成步骤,,,解析问句结构并生成对应的SPARQL查询模板,
模板生成步骤解析问句结构并生成对应的SPARQL查询模板，该查询模板中可能包含过滤和聚合操作。,模板生成步骤,,,解析问句结构并生成对应的SPARQL查询模板,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,生成模板,,,获取自然语言问题中每个单词的词性标签,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,生成模板,,,基于词性标签和语法规则表示问句,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,生成模板,,,利用与领域相关或与领域无关的词汇辅助分析问题,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,生成模板,,,将语义表示转化为SPARQL模板,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,生成模板,,,get word category labels,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,基于词性标签和语法规则表示问句,,,based on word category labels and grammar rules to express questions,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,与领域相关或与领域无关的词汇,,,vocabulary related to or unrelated to the domain,
生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。,将语义表示转化为SPARQL模板,,,convert the semantic representation into SPARQL templates,
同一条自然语言问句可能对应着不止一条查询模板。,查询模板,,,同一条自然语言问句,
因此，TBSL就查询模板的排序也提出了一种方法：首先，每个实体根据字符串相似度以及显著度获得一个打分；其次，根据填充槽的多个实体的平均打分得到一个查询模板的分值。,查询模板的排序,,,TBSL,
因此，TBSL就查询模板的排序也提出了一种方法：首先，每个实体根据字符串相似度以及显著度获得一个打分；其次，根据填充槽的多个实体的平均打分得到一个查询模板的分值。,查询模板的排序,,,TBSL,
在此基础上，需要检查查询的实体类型。,查询的实体类型,,,检查查询的实体类型,
形式化来说，对于所有的三元组？xrdf:type<class>，对于查询三元组？xpe和ep?x，我们需要检查p的定义域（domain）和值域（range）是否与<class>一致。,三元组,,,查询三元组？xpe和ep?x,
形式化来说，对于所有的三元组？xrdf:type<class>，对于查询三元组？xpe和ep?x，我们需要检查p的定义域（domain）和值域（range）是否与<class>一致。,等价,,,equivalence,
模板实例化步骤将自然语言问句与知识库中的本体概念建立映射。,模板实例化步骤,,,将自然语言问句与知识库中的本体概念建立映射,
对于Resources和Classes，实体识别的常用方法主要有两点，一是用WordNet定义知识库中标签的同义词，二是计算字符串间的相似度。,实体识别,,,常用方法,
对于Resources和Classes，实体识别的常用方法主要有两点，一是用WordNet定义知识库中标签的同义词，二是计算字符串间的相似度。,实体识别,,,entity recognition,
对于Resources和Classes，实体识别的常用方法主要有两点，一是用WordNet定义知识库中标签的同义词，二是计算字符串间的相似度。,常用方法,,,两点,
对于属性标签，还需要与存储在模式库中的自然语言表示进行比较。,属性标签,,,与存储在模式库中的自然语言表示进行比较,
最高排位的实体将作为填充查询槽位的候选答案。,最高排位的实体,,,填充查询槽位的候选答案,
1.问题“列举所有的电影出品人”2.模板生成3.资源绑定TBSL仍然存在的缺点是创建的模板结构未必和知识图谱中的数据契合。,问题“列举所有的电影出品人”,,,创建模板结构,
另外，考虑到数据建模的各种可能性，对应到一个问题的潜在模板数量会非常的多，同时手工准备海量模板的代价也非常大。,问答系统,,,数据建模,
另外，考虑到数据建模的各种可能性，对应到一个问题的潜在模板数量会非常的多，同时手工准备海量模板的代价也非常大。,对应到一个问题的潜在模板数量,,,potential template numbers,
针对此问题，CUI等人[49]针对简单事实问答模板的大规模生成，在自动化处理方面做了进一步优化，如图8-23所示。,简单事实问答模板的大规模生成,,,自动化处理,
离线过程（Offline_Procedure）侧重基于问题生成模板。,离线过程,,,基于问题生成模板,
模板映射支持BFQ，即询问知识图谱中的三元组，例如“how_many_people_are_there_in_Honolulu?”（实体的描述属性）或者“what_is_the_capital_of_China”（实体的关系属性）。,模板映射,,,BFQ,
模板映射支持BFQ，即询问知识图谱中的三元组，例如“how_many_people_are_there_in_Honolulu?”（实体的描述属性）或者“what_is_the_capital_of_China”（实体的关系属性）。,BFQ,,,模板映射,
"同时，模板映射也支持有特色的问题：排序，例如“which_city_has_the_3rd_largest_population?”；对比，例如“which_city_has_more_people,Honolulu_or_New_Jersey?”；列表，例如“list_cities_ordered_by_population”。",模板映射,,,有特色的问题：排序,
"同时，模板映射也支持有特色的问题：排序，例如“which_city_has_the_3rd_largest_population?”；对比，例如“which_city_has_more_people,Honolulu_or_New_Jersey?”；列表，例如“list_cities_ordered_by_population”。",模板映射,,,对比,
"同时，模板映射也支持有特色的问题：排序，例如“which_city_has_the_3rd_largest_population?”；对比，例如“which_city_has_more_people,Honolulu_or_New_Jersey?”；列表，例如“list_cities_ordered_by_population”。",模板映射,,,列表,
"同时，模板映射也支持有特色的问题：排序，例如“which_city_has_the_3rd_largest_population?”；对比，例如“which_city_has_more_people,Honolulu_or_New_Jersey?”；列表，例如“list_cities_ordered_by_population”。",模板映射,,,template_mapping,
此外，复杂的问题可以利用语法分析技术，先将问题拆分为多个BFQ，然后再到本体中逐个映射到属性，最后再从这些结果中挑选合理的组合。,本体中概念的映射,,,语法分析技术,
此外，复杂的问题可以利用语法分析技术，先将问题拆分为多个BFQ，然后再到本体中逐个映射到属性，最后再从这些结果中挑选合理的组合。,BFQ,,,语义查询,
例如，“when_was_Barack_Obama's_wifeborn?”可以拆分为who's_Barack_Obama's_wife?（Michelle_Obama）和when_was_MichelleObama_born?（1964）。,when_was_Barack_Obama's_wifeborn?,,,查询美国前总统奥巴马妻子出生年份,
例如，“when_was_Barack_Obama's_wifeborn?”可以拆分为who's_Barack_Obama's_wife?（Michelle_Obama）和when_was_MichelleObama_born?（1964）。,when_was_Barack_Obama's_wifeborn?,,,who's_Barack_Obama's_wife?,
例如，“when_was_Barack_Obama's_wifeborn?”可以拆分为who's_Barack_Obama's_wife?（Michelle_Obama）和when_was_MichelleObama_born?（1964）。,who's_Barack_Obama's_wife?,,,Michelle_Obama,
例如，“when_was_Barack_Obama's_wifeborn?”可以拆分为who's_Barack_Obama's_wife?（Michelle_Obama）和when_was_MichelleObama_born?（1964）。,when_was_MichelleObama_born?,,,1964,
"离线过程采用E-M方法计算条件概率分布P（p|t）,p为属性，t为模板。",E-M方法,,,计算条件概率分布P（p|t）,
在线过程（Online_Procedure）侧重模板选择。,在线过程,,,模板选择,
通过概率计算给定问题的最优答案。,问答系统,,,通过概率计算给定问题的最优答案。,
基于给定问题q0，可以提取出c1个实体，每个实体至多有c2个实体分类，因而至多有c3个模板，这些实体至多有p个属性（p为知识库里的所有属性），而每个（实体，属性）c4个值。,实体,,,entity,
基于给定问题q0，可以提取出c1个实体，每个实体至多有c2个实体分类，因而至多有c3个模板，这些实体至多有p个属性（p为知识库里的所有属性），而每个（实体，属性）c4个值。,实体分类,,,entity category,
其中，c1、c2、c3、c4都是常数，所以寻求实体的时间复杂度为对最多对应O（p），这意味每个问题都能快速得到解答，文中报告在线过程回答单个问题的平均时间为79ms。,寻求实体的时间复杂度,,,对最多对应O（p）,
其中，c1、c2、c3、c4都是常数，所以寻求实体的时间复杂度为对最多对应O（p），这意味每个问题都能快速得到解答，文中报告在线过程回答单个问题的平均时间为79ms。,寻求实体的时间复杂度,,,O（p）,
要注意的是，这里还包括高效率的内存知识图谱查询引擎。,知识图谱查询引擎,,,高效率的内存知识图谱查询引擎,
这种基于BFQ模板的解决方案提升了自动化处理程度，基于2782个意图从语料中学习生成了2700万个模板。,基于BFQ模板的解决方案,,,提升自动化处理程度,
这种基于BFQ模板的解决方案提升了自动化处理程度，基于2782个意图从语料中学习生成了2700万个模板。,基于BFQ模板的解决方案,,,基于2782个意图从语料中学习生成了2700万个模板的解决方案,
当然，BFQ也未必能覆盖用户的所有问题。,BFQ,,,覆盖用户的所有问题,
图8-23CUI等人提出的基于模板的KBQA的架构图及示例[49]为了解决人工定义模板成本高的问题，Abujabal等人[50]提出了QUINT模型，可以基于语料自动学习模板，然后基于生成的模板将自然语言查询转换成知识库查询。,QUINT,,,基于语料自动学习模板,
该方法在WebQuestions数据集上取得了接近最好成绩的效果，在Free917数据集上取得了当时最好的效果，同时人工监督的工作量也是最少的。,SPO,,,等价,
总的来说，基于模板方法的优点是模板查询的响应速度快、准确率较高，可以回答相对复杂的复合问题，而缺点是模板结构通常无法与真实的用户问题相匹配。,基于模板方法的查询,,,优点,
总的来说，基于模板方法的优点是模板查询的响应速度快、准确率较高，可以回答相对复杂的复合问题，而缺点是模板结构通常无法与真实的用户问题相匹配。,基于模板方法的查询,,,基于模板方法的查询,
如果为了尽可能匹配上一个问题的多种不同表述，则需要建立庞大的模板库，耗时耗力且会降低查询效率。,向导,,,建立庞大的模板库,
8.5.3基于语义解析的方法基于语义解析的方法是指通过对自然语言查询的语法分析，将查询转换成逻辑表达式，然后利用知识库的语义信息将逻辑表达式转换成知识库查询，最终通过查询知识库得到查询结果。,基于语义解析的方法,,,知识问答系统,
8.5.3基于语义解析的方法基于语义解析的方法是指通过对自然语言查询的语法分析，将查询转换成逻辑表达式，然后利用知识库的语义信息将逻辑表达式转换成知识库查询，最终通过查询知识库得到查询结果。,基于语义解析的方法,,,基于语义解析的方法,
逻辑表达式是语义解析方法与基于模板的方法的主要差异。,逻辑表达式,,,语义解析方法与基于模板的方法的主要差异,
逻辑表达式是面向知识库的结构化查询，用于查找知识库中的实体及实体关系等知识。,逻辑表达式,,,面向知识库的结构化查询,
相比于模板预先生成且固定的表达方式，逻辑表达式作为人工智能知识表示的经典传承，具备更完备、灵活的知识查询生成体系，包括带参数的原子逻辑表达式，以及基于操作组合的复杂逻辑表达式。,逻辑表达式,,,人工智能知识表示的经典传承,
相比于模板预先生成且固定的表达方式，逻辑表达式作为人工智能知识表示的经典传承，具备更完备、灵活的知识查询生成体系，包括带参数的原子逻辑表达式，以及基于操作组合的复杂逻辑表达式。,逻辑表达式,,,logical expression,
原子级别的逻辑表达式通常可分为一元形式（unary）与二元形式（binary），其中一元形式匹配知识库中的实体，二元形式匹配实体之间的二元关系。,原子级别的逻辑表达式,,,一元形式,
原子级别的逻辑表达式通常可分为一元形式（unary）与二元形式（binary），其中一元形式匹配知识库中的实体，二元形式匹配实体之间的二元关系。,原子级别的逻辑表达式,,,二元形式,
原子级别的逻辑表达式通常可分为一元形式（unary）与二元形式（binary），其中一元形式匹配知识库中的实体，二元形式匹配实体之间的二元关系。,原子级别的逻辑表达式,,,unary,
原子级别的逻辑表达式通常可分为一元形式（unary）与二元形式（binary），其中一元形式匹配知识库中的实体，二元形式匹配实体之间的二元关系。,原子级别的逻辑表达式,,,binary,
这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。,原子逻辑表达式,,,进一步组合为复杂逻辑表达式,
这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。,原子逻辑表达式,,,atomicalogicalexpression,
这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。,连接（Join）,,,atomicalogicalexpression,
这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。,求交集（Intersection）,,,atomicalogicalexpression,
这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。,聚合统计（Aggregate）,,,atomicalogicalexpression,
自然语言转化逻辑表达式需要训练一个语法分析器将过程自动化。,自然语言转化逻辑表达式,,,训练一个语法分析器将过程自动化,
应注意两个关键步骤：资源映射和逻辑表达式生成。,资源映射,,,两个关键步骤,
应注意两个关键步骤：资源映射和逻辑表达式生成。,两个关键步骤,,,资源映射,
应注意两个关键步骤：资源映射和逻辑表达式生成。,两个关键步骤,,,逻辑表达式生成,
资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。,资源映射,,,简单映射,
资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。,资源映射,,,复杂映射,
资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。,简单映射,,,simple mapping,
资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。,复杂映射,,,complex mapping,
简单映射是指字符形式上比较相似的，一般可以通过字符串相似度匹配来找到映射关系，例如“出生”和“出生地”的映射。,简单映射,,,字符形式上比较相似的,
简单映射是指字符形式上比较相似的，一般可以通过字符串相似度匹配来找到映射关系，例如“出生”和“出生地”的映射。,简单映射,,,simple mapping,
复杂映射是指无法通过字符串匹配找到对应关系的映射，例如“老婆”与“配偶”的映射，这类映射在实际问答中出现的概率更高，一般可以采用基于统计的方法来找到映射关系。,复杂映射,,,无法通过字符串匹配找到对应关系的映射,
逻辑表达式生成即自底向上自动地将自然语言查询解析为语法树，语法树的根节点即是最终对应的逻辑表达式。,逻辑表达式生成,,,自底向上自动地将自然语言查询解析为语法树,
逻辑表达式生成即自底向上自动地将自然语言查询解析为语法树，语法树的根节点即是最终对应的逻辑表达式。,逻辑表达式生成,,,自底向上自动地将自然语言查询解析为语法树,
如图8-24所示，查询“where_was_Obamaborn”对应的逻辑表达式是Type.Location⊓PeopleBornHere.BarackObama，其中lexicon是指资源映射操作，PeopleBornHere和BarackObama用Join连接组合，此组合结果再与Type.Location用求交集组合成为最终的逻辑表达式。,查询“where_was_Obamaborn”对应的逻辑表达式,,,Type.Location⊓PeopleBornHere.BarackObama,
如图8-24所示，查询“where_was_Obamaborn”对应的逻辑表达式是Type.Location⊓PeopleBornHere.BarackObama，其中lexicon是指资源映射操作，PeopleBornHere和BarackObama用Join连接组合，此组合结果再与Type.Location用求交集组合成为最终的逻辑表达式。,lexicon,,,资源映射操作,
图8-24自然语言查询转换成逻辑表达式[41]训练语法分析器需要大量的标注数据，传统的方法是基于规则生成标注数据，通过手工编写规则虽然直接，但是存在较明显的局限性：一方面，规则的编写需要语言学专家完成，导致规则的建立效率低且成本高，还不具备扩展性；另一方面，这种人工规则可能仅适用于某一类语言甚至某一特定领域，泛化能力较弱。,语法分析器,,,基于规则生成标注数据,
为了改进传统方法的缺陷，有大量研究工作采用弱监督或者无监督的方法来训练语法分析器，一个经典的方法是Berant[41]提出利用“问题/答案对”数据结合Freebase作为语法分析器的训练集。,语法分析器,,,语义分析器,
此方法不需要逻辑表示式的专家人工标注数据，可以低成本地获得。,OWL_A_R_M,,,不需要逻辑表示式的专家人工标注数据，可以低成本地获得,
Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。,资源映射,,,Alignment,
Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。,桥接操作,,,Bridging,
Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。,组合操作,,,Composition,
Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。,候选逻辑表达式评估,,,Evaluation,
（1）资源映射。,资源映射,,,概念/产品,
自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。,自然语言实体到知识库实体的映射,,,简单映射,
自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。,自然语言实体到知识库实体的映射,,,简单映射,
自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。,自然语言关系短语到知识库关系的映射,,,复杂映射,
"例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。",Berant,,,将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth,
"例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。",等价,,,将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,
"例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。",等价,,,将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth,
如图8-25所示，左边的“grew_up_in”是三元组中的自然语言关系短语r1，右边的“DateOfBirth”是知识库中的关系r2。,r1,,,三元组中的自然语言关系短语r1,
如图8-25所示，左边的“grew_up_in”是三元组中的自然语言关系短语r1，右边的“DateOfBirth”是知识库中的关系r2。,等价,,,等价,
"统计所有自然语言三元组中符合r1[t1,t2]的实体对，得到集合F(r1)，统计知识库中符合r2[t1,t2]的实体对，得到集合F(r2)。",F(r1),,,"统计所有自然语言三元组中符合r1[t1,t2]的实体对",
通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,F(r1),,,通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,
通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,F(r2),,,通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,
通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,F(r1),,,比较集合F(r1),
通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,F(r2),,,比较集合F(r2),
通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,r1,,,通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。,
图8-25关系短语映射到知识库关系的方法[41]（2）桥接操作。,图8-25关系短语映射到知识库关系的方法,,,桥接操作,
图8-25关系短语映射到知识库关系的方法[41]（2）桥接操作。,桥接操作,,,bridge operation,
在完成资源映射后仍然存在一些问题，首先，例如go、have、do等轻动词（Light_Verb）由于在语法上使用相对自由，难以通过统计的方式直接映射到实体关系上；其次，部分知识库关系的出现频率较低，利用统计也较难找到准确的映射方式。,轻动词,,,实体关系,
这样就需要补充一个额外的二元关系将这些词两端的逻辑表达式连接起来，这就是桥接操作。,桥接操作,,,补充一个额外的二元关系将这些词两端的逻辑表达式连接起来,
这样就需要补充一个额外的二元关系将这些词两端的逻辑表达式连接起来，这就是桥接操作。,桥接操作,,,bridge operation,
如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University⊓Education.BarackObama的逻辑表达式。,“Obama”,,,BarackObama,
如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University⊓Education.BarackObama的逻辑表达式。,“college”,,,Type.University,
如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University⊓Education.BarackObama的逻辑表达式。,“Obama”,,,BarackObama,
如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University⊓Education.BarackObama的逻辑表达式。,“college”,,,Type.University,
由于知识库中的关系是有定义域和值域的，所以文献基于此特点在知识库中查找所有潜在的关系，例如Education的定义域和值域分别是Person和University，则Education可以是候选的桥接操作。,Education,,,桥接操作,
由于知识库中的关系是有定义域和值域的，所以文献基于此特点在知识库中查找所有潜在的关系，例如Education的定义域和值域分别是Person和University，则Education可以是候选的桥接操作。,桥接操作,,,Education,
这里针对每一种候选的桥接操作都会生成很多特征，基于这些特征训练分类器，用于最后的候选逻辑表达式评估。,桥接操作的生成特征,,,基于这些特征训练分类器，用于最后的候选逻辑表达式评估,
这里针对每一种候选的桥接操作都会生成很多特征，基于这些特征训练分类器，用于最后的候选逻辑表达式评估。,桥接操作,,,等价,
图8-26桥接操作示例[41]（3）组合操作。,桥接操作,,,组合操作,
即逻辑表达式间的连接、求交集以及聚合三种操作。,spo,,,逻辑表达式间的连接、求交集以及聚合三种操作。,
即逻辑表达式间的连接、求交集以及聚合三种操作。,SPO,,,逻辑表达式间的连接,
至于最终应该用哪种操作，作者同样通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估。,作者,,,通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估,
至于最终应该用哪种操作，作者同样通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估。,操作,,,evaluate,
（4）候选逻辑表达式评估。,候选逻辑表达式评估,,,SPO三元组,
即训练一个分类器，计算每一种候选逻辑表达式的概率，DiscriminativeLog-Linear模型，最终实现逻辑表达式的筛选。,DiscriminativeLog-Linear模型,,,训练一个分类器，计算每一种候选逻辑表达式的概率,
即训练一个分类器，计算每一种候选逻辑表达式的概率，DiscriminativeLog-Linear模型，最终实现逻辑表达式的筛选。,分类器,,,训练一个分类器,
Berant等人基于前面候选逻辑表达式生成过程中的所有特征，训练了一个8.5.4基于深度学习的传统问答模块优化基于深度学习的知识问答主要有两个方向，分别是利用深度学习对传统问答方法进行模块级的改进和基于深度学习的端到端问答模型。,基于深度学习的知识问答,,,基于深度学习的传统问答模块改进基于深度学习的知识问答,
深度学习可以直接用于改进传统问答流程的各个模块，包括语义解析、实体识别、意图分类和实体消歧等。,深度学习,,,改进传统问答流程的各个模块,
下面通过Yih[51]的工作，说明如何使用深度神经网络来提升知识问答的效果。,Yih,,,使用深度神经网络来提升知识问答的效果,
传统的基于语义解析的方法需要将问题转换成逻辑表达式，如图8-27所示。,基于语义解析的方法,,,将问题转换成逻辑表达式,
传统的基于语义解析的方法需要将问题转换成逻辑表达式，如图8-27所示。,基于语义解析的方法,,,基于语义解析的方法,
这类方法最大的问题是找到问题中自然语言短语与知识库的映射关系，Yih等人提出了一种语义解析的框架，首先基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。,语义解析的框架,,,基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。,
这类方法最大的问题是找到问题中自然语言短语与知识库的映射关系，Yih等人提出了一种语义解析的框架，首先基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。,语义解析的框架,,,Query_Graph,
因为查询图可以直接映射到Lambda_Calculus形式的逻辑表达式，并且在语义上与λ-DCS（Lambda_Dependency-Based_CompositionalSemantics）紧密相关，因此就可以将语义解析的过程转换成查询图生成的过程。,查询图,,,语义解析,
因为查询图可以直接映射到Lambda_Calculus形式的逻辑表达式，并且在语义上与λ-DCS（Lambda_Dependency-Based_CompositionalSemantics）紧密相关，因此就可以将语义解析的过程转换成查询图生成的过程。,查询图,,,query_graph,
图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。,实体,,,Grounded_Entity,
图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。,中间变量,,,ExistentialVariable,
图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。,聚合函数,,,Aggregation_Function,
图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。,Lambda变量,,,Lambda_Variable,
"这个例子对应的问句是“Who_first_voiced_Meg_on_Family_Guy?”，在不考虑聚合操作的情况下，该查询图对应的逻辑表达式是λx.∃y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)。",Family Guy,,,查询图,
"这个例子对应的问句是“Who_first_voiced_Meg_on_Family_Guy?”，在不考虑聚合操作的情况下，该查询图对应的逻辑表达式是λx.∃y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)。",等价,,,"λx.∃y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)",
图8-28查询图示例[51]下面介绍查询图的生成过程。,查询图,,,生成查询图,
第一步，选择一个主题实体（Topic_Entity）作为根节点，如图8-29（a）中可以选择s1“FamilyGuy”作为根节点。,根节点,,,选择一个主题实体（Topic_Entity）作为根节点,
第一步，选择一个主题实体（Topic_Entity）作为根节点，如图8-29（a）中可以选择s1“FamilyGuy”作为根节点。,等价,,,等价,
第二步，确定一条从根节点到Lambda变量（答案节点）的有向路径，路径上可以有一个或者多个中间变量，这条路径被称为核心推断链（Core_Inferential_Chain），如图8-29（b）所示从三条路径s3、s4、s5中选取s3作为核心推断链。,核心推断链,,,从三条路径s3、s4、s5中选取s3作为,
第二步，确定一条从根节点到Lambda变量（答案节点）的有向路径，路径上可以有一个或者多个中间变量，这条路径被称为核心推断链（Core_Inferential_Chain），如图8-29（b）所示从三条路径s3、s4、s5中选取s3作为核心推断链。,核心推断链,,,Core_Inferential_Chain,
核心推断链上除了根节点为实体，其他的都只能是变量，节点间的关系都是知识库中的关系。,核心推断链,,,实体,
"第三步，给查询图添加约束条件和聚合函数（AugmentingConstraints&Aggregations），形式上就是把其他的实体或者聚合函数节点通过知识库中的关系与核心推断链上的变量连接起来，如图8-29（c）所示对y增加两个限制argmin和character(y,MegGriffin)。",核心推断链,,,添加约束条件和聚合函数,
"第三步，给查询图添加约束条件和聚合函数（AugmentingConstraints&Aggregations），形式上就是把其他的实体或者聚合函数节点通过知识库中的关系与核心推断链上的变量连接起来，如图8-29（c）所示对y增加两个限制argmin和character(y,MegGriffin)。",等价,,,等价,
"图8-29查询图的生成过程[51]对于生成查询图的第二步，需要一种从众多候选核心推断链中选出最优核心推断链的方法，针对图8-29（b）的例子，要评估{cast-actor,writer-start,genre}三个谓语序列中哪个最接近问题中“Family_Guy”和“Who”的关系，该文献使用一个CNN网络将候选序列和问题文本中的关键词向量化，CNN结构如图8-30所示，通过语义相似度计算找到最优的核心推断链。",核心推断链,,,evaluate核心推断链中最优的核心推断链,
具体做法是将自然语言问题和谓语序列分别通过图8-30所示的网络得到两个300维的分布式表达，然后利用表达向量之间的相似度距离（如cosine距离）计算自然语言问题和谓语序列的语义相似度得分。,向量之间的相似度距离,,,计算自然语言问题和谓语序列的语义相似度得分,
具体做法是将自然语言问题和谓语序列分别通过图8-30所示的网络得到两个300维的分布式表达，然后利用表达向量之间的相似度距离（如cosine距离）计算自然语言问题和谓语序列的语义相似度得分。,语义相似度得分,,,semantic similarity score,
"该CNN网络的输入运用了词散列技术[52]，将句子中每个单词拆分成字母三元组，每个字母三元组对应一个向量，比如单词who可以拆为#-w-h,w-h-o,h-o-#，每个单词通过前后添加符号#来区分单词界限。",CNN网络的输入,,,词散列技术,
然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。,卷积层,,,向量进行卷积运算得到局部上下文特征向量ht,
然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。,最大池化层,,,提取最显著的局部特征,
然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。,卷积层,,,卷积运算得到局部上下文特征向量ht,
然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。,最大池化层,,,提取最显著的局部特征,
图8-30Yih[51]中的CNN结构8.5.5基于深度学习的端到端问答模型端到端的深度学习问答模型将问题和知识库中的信息均转化为向量表示，通过向量间的相似度计算的方式完成用户问题与知识库答案的匹配。,端到端的深度学习问答模型,,,基于深度学习的端到端问答模型,
图8-30Yih[51]中的CNN结构8.5.5基于深度学习的端到端问答模型端到端的深度学习问答模型将问题和知识库中的信息均转化为向量表示，通过向量间的相似度计算的方式完成用户问题与知识库答案的匹配。,端到端的深度学习问答模型,,,end-to-end deep learning question-answer model,
首先根据问题中的主题词在知识库中确定候选答案，然后把问题和知识库中的候选答案都通过神经网络模型映射到一个低维空间，得到它们的分布式向量（Distributed_Embedding），则可计算候选答案分布式向量与问题向量的相似度得分，找出相似度最高的候选答案作为最终答案。,向量相似度得分,,,找出相似度最高的候选答案作为最终答案,
首先根据问题中的主题词在知识库中确定候选答案，然后把问题和知识库中的候选答案都通过神经网络模型映射到一个低维空间，得到它们的分布式向量（Distributed_Embedding），则可计算候选答案分布式向量与问题向量的相似度得分，找出相似度最高的候选答案作为最终答案。,相似度,,,相似度最高的候选答案作为最终答案。,
该神经网络模型通过标注数据对进行训练，使得问题向量与知识库中正确答案的向量在低维空间的关联得分尽量高。,神经网络模型,,,对进行训练,
该神经网络模型通过标注数据对进行训练，使得问题向量与知识库中正确答案的向量在低维空间的关联得分尽量高。,向量,,,vector,
典型的工作有BordesA等人[53]提出的方法，为解决WebQuestions上数据量不够的问题，文献作者使用一些规则从Freebase、ClueWeb等知识库中构建了大量（问题，知识库答案）的标注数据用于训练模型。,BordesA等人,,,提出的方法,
如图8-31所示，自底向上计算。,自底向上计算,,,SPO三元组,
第一步，利用实体链接定位问题中的核心实体，对应到Freebase的实体；第二步，找到从问题中核心实体到候选答案实体的路径；第三步，生成候选答案的子图；第四步，分别将问题和答案子图映射成Embedding向量；第五步，进行点积运算，获得候选答案和问题之间的匹配度。,SPO三元组抽取,,,实体链接定位问题中的核心实体,
第一步，利用实体链接定位问题中的核心实体，对应到Freebase的实体；第二步，找到从问题中核心实体到候选答案实体的路径；第三步，生成候选答案的子图；第四步，分别将问题和答案子图映射成Embedding向量；第五步，进行点积运算，获得候选答案和问题之间的匹配度。,等价,,,map核心实体到候选答案实体,
"该方法取得了比Berant[41]更好的结果（F1=0.392,P@1=0.40）。",SPO,,,抽取三元组,
"该方法取得了比Berant[41]更好的结果（F1=0.392,P@1=0.40）。",SPO,,,等价,
图8-31BordesA等人提出方法的核心流程[53]另一个基于Multi-ColumnCNN[54]的工作，该工作同时训练自然语言问句词向量与知识库三元组，将问题与知识库映射到同一个语义空间。,Multi-ColumnCNN,,,同时训练自然语言问句词向量与知识库三元组，将问题与知识库映射到同一个语义空间,
该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。,答案路径,,,Answer_Path,
该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。,答案上下文,,,Answer_Context,
该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。,答案类型,,,Answer_Type,
"这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。",多列卷积神经网络,,,"多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）",
"这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。",多列卷积神经网络,,,Multi-Column_Convolutional_Neural_Network,
"这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。",多列卷积神经网络,,,Multi-Column_CNN,
该方法的核心流程如图8-32所示，对于问题“when_did_Avatarrelease_in_UK”，首先通过Multi-Column卷积神经网络提取该问题的三个分布式向量。,Multi-Column卷积神经网络问答系统,,,核心流程,
该方法的核心流程如图8-32所示，对于问题“when_did_Avatarrelease_in_UK”，首先通过Multi-Column卷积神经网络提取该问题的三个分布式向量。,Multi-Column卷积神经网络,,,Multi-Column CNN,
最后，通过分别点乘运算再求和的方式得到最终的答案-问题对得分。,问题对得分,,,分别点乘运算再求和的方式得到最终的答案,
最后，通过分别点乘运算再求和的方式得到最终的答案-问题对得分。,点乘运算,,,point multiplication,
"在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。",交叉验证,,,最好的效果,
"在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。",F1,,,准确率,
"在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。",P@1,,,查全率,
两个案例的基本框架一致，而知识问答增加了将自然语言问题转化为对应逻辑表达式以及查询语句的过程。,知识问答,,,将自然语言问题转化为对应逻辑表达式以及查询语句的过程,
因此，本小节通过一个简单案例介绍自然语言问题到Elasticsearch查询语句的转化，而用Elasticsearch查询语句进行查询即可得到问答结果。,本小节,,,自然语言问题到Elasticsearch查询语句的转化,
因此，本小节通过一个简单案例介绍自然语言问题到Elasticsearch查询语句的转化，而用Elasticsearch查询语句进行查询即可得到问答结果。,Elasticsearch查询语句,,,自然语言问题,
注意，真实的知识问答系统的语义理解远比本文方案复杂。,知识问答系统的语义理解,,,真实的知识问答系统的语义理解,
自然语言问题对应的查询类型同本书第7章中的语义检索，如表8-4所示，主要包含四种类型的查询，即实体检索、实体属性检索、实体属性的多跳检索以及多种属性条件检索实体。,语义检索,,,自然语言问题对应的查询类型,
自然语言问题对应的查询类型同本书第7章中的语义检索，如表8-4所示，主要包含四种类型的查询，即实体检索、实体属性检索、实体属性的多跳检索以及多种属性条件检索实体。,语义检索,,,semantic retrieval,
表8-4自然语言问题的四种类型自然语言问题转化为逻辑表达式的过程如下：（1）定义逻辑表达式模板。,自然语言问题的四种类型,,,转化为逻辑表达式的过程,
如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。,逻辑表达式的基本元素,,,三元组的成分,
如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。,逻辑表达式的基本元素,,,三元组的成分,
如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。,S,,,主语,
如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。,P,,,谓语,
如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。,O,,,宾语,
多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。,属性条件,,,多个属性条件之间,
多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。,属性条件,,,and,
多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。,属性条件,,,or,
<OP>表8-5自然语言问题对应的逻辑表达式模板（2）解析自然语言问题。,OP,,,自然语言问题对应的逻辑表达式模板,
从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。,从自然语言问题中识别出实体名、属性名和属性值等三类要素,,,识别出实体名、属性名和属性值等三类要素,
从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。,从自然语言问题中识别出实体名、属性名和属性值等三类要素,,,将实体名和属性名映射到知识库中的实体和属性,
从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。,实体名,,,entity name,
从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。,属性名,,,attribute name,
首先，实体和属性的识别可以采用词典的方法，例如从知识库中抽取所有的实体名和属性名，构建分词器的自定义词典。,分词器的自定义词典,,,从知识库中抽取所有的实体名和属性名,
首先，实体和属性的识别可以采用词典的方法，例如从知识库中抽取所有的实体名和属性名，构建分词器的自定义词典。,实体名的识别,,,entity name,
然后，对自然语言问题进行分词，可直接识别其中的属性名和实体名。,分词,,,直接识别属性名和实体名,
其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。,属性值的识别,,,模糊匹配的方法,
其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。,属性值的识别,,,分词后n-gram检索Elasticsearch的办法,
其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。,属性值的识别,,,模糊匹配的方法,
其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。,属性值的识别,,,分词后n-gram检索Elasticsearch的办法,
最后，查看自然语言问题中属性值和属性名的对应关系，当某属性值没有对应的属性名时，例如“（国籍是)中国(的)运动员”，缺省了“国籍”，就用该属性值对应的最频繁的属性名作为补全的属性名。,属性值的补全,,,缺省了“国籍”,
例如下面的两段代码，分别实现了属性名识别和实体名识别。,属性名识别,,,SPO三元组,
（3）后生成逻辑表达式。,后生成逻辑表达式,,,SPO三元组,
在识别出自然语言问题中所有的实体名、属性名和属性值后，依据它们的数目及位置，确定问题对应的查询类型，以便基于逻辑表达式模板生成对应的逻辑表达式。,逻辑表达式模板,,,基于实体名、属性名和属性值生成逻辑表达式,
在识别出自然语言问题中所有的实体名、属性名和属性值后，依据它们的数目及位置，确定问题对应的查询类型，以便基于逻辑表达式模板生成对应的逻辑表达式。,查询类型,,,基于逻辑表达式模板生成对应的逻辑表达式,
逻辑表达式生成流程如下：查询中含有实体名。,逻辑表达式生成流程,,,查询中含有实体名,
如果有多个属性名，那么是属性值的多跳检索；如果有一个属性名，则需判断实体名和属性名的位置及中间的连接词(“是”“在”“的”等)，若实体名在前，则是实体的属性查询，例如“姚明的身高”，若属性名在前，则是依据属性查询实体，例如“女儿是姚沁蕾”。,属性值的多跳检索,,,multiple jump retrieval,
如果有多个属性名，那么是属性值的多跳检索；如果有一个属性名，则需判断实体名和属性名的位置及中间的连接词(“是”“在”“的”等)，若实体名在前，则是实体的属性查询，例如“姚明的身高”，若属性名在前，则是依据属性查询实体，例如“女儿是姚沁蕾”。,依据属性查询实体,,,query entity according to attribute,
查询中没有实体名，则认为是依据属性查询实体，需要根据所有属性名和属性值位置的相对关系确定它们之间的对应关系。,依据属性查询实体,,,根据所有属性名和属性值位置的相对关系确定它们之间的对应关系,
查询中没有实体名，则认为是依据属性查询实体，需要根据所有属性名和属性值位置的相对关系确定它们之间的对应关系。,依据属性查询实体,,,according to the property query entity,
如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。,如果缺少属性名但有属性值,,,补全对应的属性名,
如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。,如果缺少属性值但有属性名,,,通过正则表达式识别出范围查询的属性值,
如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。,属性名,,,equivalent,
如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。,属性值,,,英文名,
工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。,文法解析器,,,工业应用中抽取属性,
工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。,文法解析器,,,grammar parser,
工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。,序列化标注,,,serialization labeling,
工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。,数字识别与解析,,,digital recognition and parsing,
在生成逻辑表达式之后，可基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询。,Elasticsearch查询,,,生成逻辑表达式,
在生成逻辑表达式之后，可基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询。,Elasticsearch查询模板,,,基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询,
本方法定义了一组Elasticsearch查询模板，基于该模板将逻辑表达式按照一定的层次结构自动转换成Elasticsearch查询语句。,本方法,,,一组Elasticsearch查询模板,
本方法定义了一组Elasticsearch查询模板，基于该模板将逻辑表达式按照一定的层次结构自动转换成Elasticsearch查询语句。,本方法,,,定义了一组Elasticsearch查询模板,
如表8-6所示，对于实体属性查询，包括多跳检索，都是先检索实体，然后获取对应的属性。,实体属性查询,,,先检索实体，然后获取对应的属性,
如表8-6所示，对于实体属性查询，包括多跳检索，都是先检索实体，然后获取对应的属性。,实体属性查询,,,entity attribute query,
如表8-7所示，对于多个属性条件检索实体，先为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询，表中part_query表示单个属性条件对应的部分查询。,part_query,,,为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询,
如表8-7所示，对于多个属性条件检索实体，先为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询，表中part_query表示单个属性条件对应的部分查询。,part_query,,,属性条件检索实体对应的查询,
gAnswer系统[55]是一个基于海量知识库的自然语言问答系统，针对用户的自然语言问题，能够输出SPARQL格式的知识库查询表达式以及查询答案的结果。,gAnswer系统,,,基于海量知识库的自然语言问答系统,
gAnswer系统[55]是一个基于海量知识库的自然语言问答系统，针对用户的自然语言问题，能够输出SPARQL格式的知识库查询表达式以及查询答案的结果。,gAnswer系统,,,基于海量知识库的自然语言问答系统,
gAnswer同时支持中文问答和英文问答。,gAnswer,,,中文问答和英文问答,
gAnswer参加了QALD-9的评测比赛，并取得了第一名的成绩。,gAnswer,,,QALD-9的评测比赛,
对于中文问答，使用PKUBASE知识库；对于英文问答，使用DBpedia知识库。,中文问答,,,PKUBASE知识库,
对于中文问答，使用PKUBASE知识库；对于英文问答，使用DBpedia知识库。,英文问答,,,DBpedia知识库,
本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。,本实践,,,OpenKG,
此外，我们给出了一个使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/。,gAnswer,,,使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/,
此外，我们给出了一个使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/。,gAnswer,,,英文问答,
如图8-33所示为gAnswer系统处理流程。,gAnswer系统处理流程,,,gAnswer系统,
主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。,构建语义查询图,,,构建语义查询图阶段,
主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。,构建语义查询图,,,build semantic query graph,
主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。,生成SPARQL查询,,,generate SPARQL query,
主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。,查询执行,,,query execution,
在构建语义查询图阶段，系统借助数据集的信息以及自然语言分析工具，对问句进行实体识别和关系抽取，构建语法依存树，并用这些结果构建对应的查询图。,语义查询图,,,构建语义查询图阶段,
在构建语义查询图阶段，系统借助数据集的信息以及自然语言分析工具，对问句进行实体识别和关系抽取，构建语法依存树，并用这些结果构建对应的查询图。,语义查询图,,,构建语义查询图,
这时，并不对其中的实体和关系做消歧处理，而是利用谓词词典，记录词或短语可能对应的谓词或实体。,谓词词典,,,记录词或短语可能对应的谓词或实体,
这时，并不对其中的实体和关系做消歧处理，而是利用谓词词典，记录词或短语可能对应的谓词或实体。,谓词词典,,,record词或短语可能对应的谓词或实体,
在生成SPARQL查询阶段，系统利用查询图生成多个SPARQL，并利用数据集中的部分信息对多个SPARQL进行过滤和优化，其中就包括歧义的消除。,查询图的生成,,,过滤和优化多个SPARQL,
在生成SPARQL查询阶段，系统利用查询图生成多个SPARQL，并利用数据集中的部分信息对多个SPARQL进行过滤和优化，其中就包括歧义的消除。,查询图,,,query graph,
在查询执行阶段，借助gStore系统返回的SPARQL查询结果，返回并展示给用户。,gStore系统返回的SPARQL查询结果,,,查询执行阶段,
图8-33gAnswer系统处理流程1.系统配置需求读者可以使用gAnswer系统构建自己的领域知识问答。,gAnswer系统,,,构建自己的领域知识问答,
在系统配置需求方面，gAnswer系统使用RDF格式的数据集，默认的中文数据集是PKUBASE，默认的英文数据集是DBpedia2016。,gAnswer,,,RDF格式的数据集,
在系统配置需求方面，gAnswer系统使用RDF格式的数据集，默认的中文数据集是PKUBASE，默认的英文数据集是DBpedia2016。,gAnswer系统,,,RDF格式的数据集,
gAnswer系统的运行需要借助支持SPARQL查询的图数据库系统来获取最终答案。,gAnswer系统,,,支持SPARQL查询的图数据库系统来获取最终答案,
在目前的版本中，使用gStore系统（http://openkg.cn/tool/gstore）。,gStore,,,目前版本的SPO三元组抽取,
gAnswer的部署还依赖一些外部工具包。,gAnswer,,,部署,
包括Maltparser、StanfordNLP，在生成SPARQL阶段，需要借助Lucene对辅助信息进行索引。,Lucene,,,生成SPARQL阶段，需要借助索引,
8.7本章小结本章介绍了问答系统的基本概念、主流方法以及评价体系，并详细阐述了知识图谱问答系统的主要方法与最新进展。,本章小结,,,问答系统的基本概念、主流方法以及评价体系,
知识问答以自然语言问答的方式简化了人们获取知识的过程，在知识检索过程中增加了泛化、联想、探索等智能化体验并拓展了知识获取的途径。,知识问答,,,自然语言问答的方式简化了人们获取知识的过程，在知识检索过程中增加了泛化、联想、探索等智能化体验并拓展了知识获取的途径,
KBQA作为知识问答的重要分支，一方面强化了针对结构化信息的检索能力，另一方面也可以利用知识图谱提升问题理解的准确性。,KBQA,,,知识问答,
深度学习技术在KBQA也起到了重要的作用，不但可以优化传统KBQA的各个模块，尤其是实体识别和语义相似度匹配，而且可以直接作为知识库表示支持端到端的知识问答。,深度学习技术,,,KBQA,
深度学习技术在KBQA也起到了重要的作用，不但可以优化传统KBQA的各个模块，尤其是实体识别和语义相似度匹配，而且可以直接作为知识库表示支持端到端的知识问答。,深度学习技术,,,deep learning technology,
正如万维网是开放的一样，多种多样的领域知识是不可能被任何一家企业垄断的，所以知识问答应该走万维网一样的开放路线，允许不同的参与者形成生态体系。,知识问答,,,开放,
参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。,知识问答,,,参与者,
参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。,参与者,,,participant,
参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。,垂直领域的网站,,,vertical website,