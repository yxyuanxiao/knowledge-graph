{"text": "知识图谱是一种用图模型来描述知识和建模世界万物之间的关联关系的技术方法[1]。"}
{"text": "知识图谱由节点和边组成。"}
{"text": "节点可以是实体，如一个人、一本书等，或是抽象的概念，如人工智能、知识图谱等。"}
{"text": "边可以是实体的属性，如姓名、书名，或是实体之间的关系，如朋友、配偶。"}
{"text": "知识图谱的早期理念来自Semantic_Web[2,3]（语义网），其最初理想是把基于文本链接的万维网转化成基于实体链接的语义网。"}
{"text": "1989年，Tim_Berners-Lee提出构建一个全球化的以“链接”为中心的信息系统（LinkedInformation_System）。"}
{"text": "任何人都可以通过添加链接把自己的文档链入其中。"}
{"text": "他认为，相比基于树的层次化组织方式，以链接为中心和基于图的组织方式更加适合互联网这种开放的系统。"}
{"text": "这一思想逐步被人们实现，并演化发展成为今天的World_Wide_Web。"}
{"text": "1994年，Tim_Berners-Lee又提出Web不应该仅仅只是网页之间的互相链接。"}
{"text": "实际上，网页中描述的都是现实世界中的实体和人脑中的概念。"}
{"text": "网页之间的链接实际包含语义，即这些实体或概念之间的关系；然而，机器却无法有效地从网页中识别出其中蕴含的语义。"}
{"text": "他于1998年提出了Semantic_Web的概念[4]。"}
{"text": "Semantic_Web仍然基于图和链接的组织方式，只是图中的节点代表的不只是网页，而是客观世界中的实体（如人、机构、地点等），而超链接也被增加了语义描述，具体标明实体之间的关系（如出生地是、创办人是等）。"}
{"text": "相对于传统的网页互联网，Semantic_Web的本质是数据的互联网（Web_of_Data）或事物的互联网（Web_of_Things）。"}
{"text": "在Semantic_Web被提出之后，出现了一大批新兴的语义知识库。"}
{"text": "如作为谷歌知识图谱后端的Freebase[5]，作为IBM_Waston后端的DBpedia[6]和Yago[7]，作为Amazon_Alexa后端的True_Knowledge，作为苹果Siri后端的Wolfram_Alpha，以及开放的Semantic_WebSchema——Schema.ORG[8]，目标成为世界最大开放知识库的Wikidata[9]等。"}
{"text": "尤其值得一提的是，2010年谷歌收购了早期语义网公司MetaWeb，并以其开发的Freebase作为数据基础之一，于2012年正式推出了称为知识图谱的搜索引擎服务。"}
{"text": "随后，知识图谱逐步在语义搜索[10,11]、智能问答[12-14]、辅助语言理解[15,16]、辅助大数据分析[17-19]、增强机器学习的可解释性[20]、结合图卷积辅助图像分类[21,22]等多个领域发挥出越来越重要的作用。"}
{"text": "如图1-1所示，知识图谱旨在从数据中识别、发现和推断事物与概念之间的复杂关系，是事物关系的可计算模型。"}
{"text": "知识图谱的构建涉及知识建模、关系抽取、图存储、关系推理、实体融合等多方面的技术，而知识图谱的应用则涉及语义搜索、智能问答、语言理解、决策分析等多个领域。"}
{"text": "构建并利用好知识图谱需要系统性地利用包括知识表示（Knowledge_Representation）、图数据库、自然语言处理、机器学习等多方面的技术。"}
{"text": "1.2知识图谱的发展历史知识图谱并非突然出现的新技术，而是历史上很多相关技术相互影响和继承发展的结Web、自然语言处理等，有着来自果，包括语义网络、知识表示、本体论、Semantic_Web、人工智能和自然语言处理等多方面的技术基因。"}
{"text": "从早期的人工智能发展历史来看，Semantic_Web是传统人工智能与Web融合发展的结果，是知识表示与推理在Web中的应用；RDF（Resource_Description_Framework，资源描述框架）、OWL（Web_OntologyLanguage，网络本体语言）都是面向Web设计实现的标准化的知识表示语言；而知识图谱则可以看作是Semantic_Web的一种简化后的商业实现，如图1-2所示。"}
{"text": "图1-2从语义网络到知识图谱在人工智能的早期发展流派中，符号派（Symbolism）侧重于模拟人的心智，研究怎样用计算机符号表示人脑中的知识并模拟心智的推理过程；连接派（Connectionism）侧重于模拟人脑的生理结构，即人工神经网络。"}
{"text": "符号派一直以来都处于人工智能研究的核心位置。"}
{"text": "近年来，随着数据的大量积累和计算能力的大幅提升，深度学习在视觉、听觉等感知处理中取得突破性进展，进而又在围棋等博弈类游戏、机器翻译等领域获得成功，使得人工神经网络和机器学习获得了人工智能研究的核心地位。"}
{"text": "深度学习在处理感知、识别和判断等方面表现突出，能帮助构建聪明的人工智能，但在模拟人的思考过程、处理常识知识和推理，以及理解人的语言方面仍然举步维艰。"}
{"text": "哲学家柏拉图把知识（Knowledge）定义为“Justified_True_Belief”，即知识需要满足三个核心要素：合理性（Justified）、真实性（True）和被相信（Believed）。"}
{"text": "简而言之，知识是人类通过观察、学习和思考有关客观世界的各种现象而获得并总结出的所有事实（Fact）、概念（Concept）、规则（Rule）或原则（Principle）的集合。"}
{"text": "人类发明了各种手段来描述、表示和传承知识，如自然语言、绘画、音乐、数学语言、物理模型、化学公式等。"}
{"text": "具有获取、表示和处理知识的能力是人类心智区别于其他物种心智的重要特征。"}
{"text": "人工智能的核心也是研究怎样用计算机易于处理的方式表示、学习和处理各种各样的知识。"}
{"text": "知识表示是现实世界的可计算模型（Computable_Model_of_Reality）。"}
{"text": "从广义上讲，神经网络也是一种知识表示形式，如图1-3所示。"}
{"text": "图1-3知识图谱帮助构建有学识的人工智能符号派关注的核心正是知识的表示和推理（KRR,Knowledge_and_Reasoning）。"}
{"text": "早在1960年，认知科学家Allan_M.Collins提出用语义网络（SemanticRepresentation_Network）研究人脑的语义记忆。"}
{"text": "例如，WordNet[23]是典型的语义网络，它定义了名词、动词、形容词和副词之间的语义关系。"}
{"text": "WordNet被广泛应用于语义消歧等自然语言处理领域。"}
{"text": "1970年，随着专家系统的提出和商业化发展，知识库（Knowledge_Base）构建和知识表示更加得到重视。"}
{"text": "专家系统的基本想法是：专家是基于大脑中的知识来进行决策的，因此人工智能的核心应该是用计算机符号表示这些知识，并通过推理机模仿人脑对知识进行处理。"}
{"text": "依据专家系统的观点，计算机系统应该由知识库和推理机两部分组成，而不是由函数等过程性代码组成。"}
{"text": "早期的专家系统最常用的知识表示方法包括基于框架的语言（Frame-based_Languages）和产生式规则（Production_Rules）等。"}
{"text": "框架语言主要用于描述客观世界的类别、个体、属性及关系等，较多地被应用于辅助自然语言理解。"}
{"text": "产生式规则主要用于描述类似于IF-THEN的逻辑结构，适合于刻画过程性知识。"}
{"text": "知识图谱与传统专家系统时代的知识工程有着显著的不同。"}
{"text": "与传统专家系统时代主要依靠专家手工获取知识不同，现代知识图谱的显著特点是规模巨大，无法单一依靠人工和专家构建。"}
{"text": "如图1-4所示，传统的知识库，如Douglas_Lenat从1984年开始创建的常识知识库Cyc，仅包含700万条[1]的事实描述（Assertion）。"}
{"text": "Wordnet主要依靠语言学专家定义名词、动词、形容词和副词之间的语义关系，目前包含大约20万条的语义关系。"}
{"text": "由著名人工智能专家Marvin_Minsky于1999年起开始构建的ConceptNet[24]常识知识库依靠了互联网众规模在百万级别，最新的包、专家创建和游戏三种方法，但早期的ConceptNet5.0也仅包含2800万个RDF三元组关系描述。"}
{"text": "谷歌和百度等现代知识图谱都已经包含超过千亿级别的三元组，阿里巴巴于2017年8月发布的仅包含核心商品数据的知识图谱也已经达到百亿级别。"}
{"text": "DBpedia已经包含约30亿个RDF三元组，多语种的大百科语义网络BabelNet包含19亿个RDF三元组[25],Yago3.0包含1.3亿个元组，Wikidata已经包含4265万条数据条目，元组数目也已经达到数十亿级别。"}
{"text": "截至目前，开放链接数据项目LinkedConceptNet_Open_Data[2]统计了其中有效的2973个数据集，总计包含大约1494亿个三元组。"}
{"text": "现代知识图谱对知识规模的要求源于“知识完备性”难题。"}
{"text": "冯·诺依曼曾估计单个个体大脑的全量知识需要2.4×1020个bits存储[26]。"}
{"text": "客观世界拥有不计其数的实体，人的主观世界还包含无法统计的概念，这些实体和概念之间又具有更多数量的复杂关系，导致大多数知识图谱都面临知识不完全的困境。"}
{"text": "在实际的领域应用场景中，知识不完全也是困扰大多数语义搜索、智能问答、知识辅助的决策分析系统的首要难题。"}
{"text": "图1-4现代知识图谱的规模化发展1.3知识图谱的价值知识图谱最早的应用是提升搜索引擎的能力。"}
{"text": "随后，知识图谱在辅助智能问答、自然语言理解、大数据分析、推荐计算、物联网设备互联、可解释性人工智能等多个方面展现出丰富的应用价值。"}
{"text": "1.辅助搜索互联网的终极形态是万物的互联，而搜索的终极目标是对万物的直接搜索。"}
{"text": "传统搜索引擎依靠网页之间的超链接实现网页的搜索，而语义搜索是直接对事物进行搜索，如人物、机构、地点等。"}
{"text": "这些事物可能来自文本、图片、视频、音频、IoT设备等各种信息资源。"}
{"text": "而知识图谱和语义技术提供了关于这些事物的分类、属性和关系的描述，使得搜索引擎可以直接对事物进行索引和搜索，如图1-5所示。"}
{"text": "图1-5知识图谱辅助搜索2.辅助问答人与机器通过自然语言进行问答与对话是人工智能实现的关键标志之一。"}
{"text": "除了辅助搜索，知识图谱也被广泛用于人机问答交互中。"}
{"text": "在产业界，IBM_Watson背后依托DBpedia和Yago等百科知识库和WordNet等语言学知识库实现深度知识问答。"}
{"text": "Amazon_Alex主要依靠True_Knowledge公司积累的知识图谱。"}
{"text": "度秘、Siri的进化版Viv、小爱机器人、天猫精灵背后都有海量知识图谱作为支撑。"}
{"text": "伴随着机器人和IoT设备的智能化浪潮的掀起，基于知识图谱的问答对话在智能驾驶、智能家居和智能厨房等领域的应用层出不穷。"}
{"text": "典型的基于知识图谱的问答技术或方法包括：基于语义解析、基于图匹配、基于模板学习、基于表示学习和深度学习以及基于混合模型等。"}
{"text": "在这些方法中，知识图谱既被用来辅助实现语义解析，也被用来匹配问句实体，还被用来训练神经网络和排序模型等。"}
{"text": "知识图谱是实现人机交互问答必不可少的模块。"}
{"text": "3.辅助大数据分析知识图谱和语义技术也被用于辅助进行数据分析与决策。"}
{"text": "例如，大数据公司Palantir基于本体融合和集成多种来源的数据，通过知识图谱和语义技术增强数据之间的关联，使得用户可以用更加直观的图谱方式对数据进行关联挖掘与分析。"}
{"text": "知识图谱在文本数据的处理和分析中也能发挥独特的作用。"}
{"text": "例如，知识图谱被广泛用来作为先验知识从文本中抽取实体和关系，如在远程监督中的应用。"}
{"text": "知识图谱也被用来辅助实现文本中的实体消歧（Entity_Disambiguation）、指代消解和文本理解等。"}
{"text": "近年来，描述性数据分析（Declarative_Data_Analysis）受到越来越多的重视。"}
{"text": "描述性数据分析是指依赖数据本身的语义描述实现数据分析的方法。"}
{"text": "不同计算性数据分析主要以建立各种数据分析模型，如深度神经网络，而描述性数据分析突出预先抽取数据的语义，建立数据之间的逻辑，并依靠逻辑推理的方法（如DataLog）来实现数据分析。"}
{"text": "4.辅助语言理解背景知识，特别是常识知识，被认为是实现深度语义理解（如阅读理解、人机问答等）必不可少的构件。"}
{"text": "一个典型的例子是Winograd_Schema_Challenge（WSC竞赛）。"}
{"text": "WSC由著名的人工智能专家Hector_Levesque教授提出，2016年，在国际人工智能大会IJCAI上举办了第一届WSC竞赛。"}
{"text": "WSC主要关注那些必须要叠加背景知识才能理解句子语义的NLP任务。"}
{"text": "例如，在下面这个例子中，当描述it是big时，人很容易理解it指代trophy；而当it与small搭配时，也很容易识别出it指代suitcase。"}
{"text": "The_trophy_would_not_fit_in_the_brown_suitcase_because_it_was_too_big（small）.What_wastoo_big（small）?Answer_0:the_trophy.Answer_1:the_suitcase这个看似非常容易的问题，机器却毫无办法。"}
{"text": "正如自然语言理解的先驱TerryWinograd所说的，当一个人听到一句话或看到一段句子的时候，会使用自己所有的知识和智能去理解。"}
{"text": "这不仅包括语法，也包括其拥有的词汇知识、上下文知识，更重要的是对相关事物的理解。"}
{"text": "5.辅助设备互联人机对话的主要挑战是语义理解，即让机器理解人类语言的语义。"}
{"text": "另外一个问题是机器之间的对话，这也需要技术手段来表示和处理机器语言的语义。"}
{"text": "语义技术也可被用来辅助设备之间的语义互联。"}
{"text": "OneM2M是2012年成立的全球最大的物联网国际标准化组织，其主要是为物联设备之间的互联提供“标准化黏合剂”。"}
{"text": "OneM2M关注了语义技术在封装设备数据的语义，并基于语义技术实现设备之间的语义互操作的问题。"}
{"text": "此外，OneM2M还关注设备数据的语义和人类语言的语义怎样适配的问题。"}
{"text": "如图1-6所示，一个设备产生的原始数据在封装了语义描述之后，可以更加容易地与其他设备的数据进行融合、交换和互操作，并可以进一步链接进入知识图谱中，以便支持搜索、推理和分析等任务。"}
{"text": "图1-6设备语义的封装1.4国内外典型的知识图谱项目从人工智能的概念被提出开始，构建大规模的知识库一直都是人工智能、自然语言理解等领域的核心任务之一。"}
{"text": "下面分别介绍早期的知识库项目、互联网时代的知识图谱、中文开放知识图谱和垂直领域知识图谱。"}
{"text": "1.4.1早期的知识库项目Cyc是持续时间最久、影响范围较广、争议也较多的知识库项目。"}
{"text": "Cyc最初的目标是要建立人类最大的常识知识库。"}
{"text": "典型的常识知识如“Every_is_a_plant”“Plants_dieeventually”等。"}
{"text": "Cyc知识库主要由术语（Term）和断言（Assertion）组成。"}
{"text": "术语包含概念、关系和实体的定义。"}
{"text": "断言用来建立术语之间的关系，既包括事实（Fact）描述，也包含规则（Rule）描述。"}
{"text": "最新的Cyc知识库已经包含有50万条术语和700万条断言。"}
{"text": "Cyc的主要特点是基于形式化的知识表示方法刻画知识。"}
{"text": "形式化的优势是可以支持复杂的推理，tree但过于形式化也导致知识库的扩展性和应用的灵活性不够。"}
{"text": "WordNet是最著名的词典知识库，由普林斯顿大学认知科学实验室从1985年开始开发。"}
{"text": "WordNet主要定义了名词、动词、形容词和副词之间的语义关系。"}
{"text": "例如，名词之间的上下位关系，如“猫科动物”是“猫”的上位词；动词之间的蕴涵关系，如“打鼾”蕴涵着“睡眠”等。"}
{"text": "ConceptNet最早源于MIT媒体实验室的OMCS（Open_Mind_Common_Sense）项目。"}
{"text": "与Cyc相比，ConceptNet采用了非形式化、更加接近自然语言的描述，而不是像Cyc一样采用形式化的谓词逻辑。"}
{"text": "与链接数据和谷歌知识图谱相比，ConceptNet比较侧重于词与词之间的关系。"}
{"text": "从这个角度来看，ConceptNet更加接近于WordNet，但是又比WordNet包含的关系类型多。"}
{"text": "1.4.2互联网时代的知识图谱互联网的发展为知识工程提供了新的机遇。"}
{"text": "在一定程度上，互联网的出现帮助传统知识工程突破了在知识获取方面的瓶颈。"}
{"text": "从1998年Tim_Berners_Lee提出语义网至今，涌现出了大量以互联网资源为基础的新一代知识库。"}
{"text": "这类知识库的构建方法可以分为三类：互联网众包、专家协作和互联网挖掘。"}
{"text": "Freebase是一个开放共享的、协同构建的大规模链接数据库。"}
{"text": "Freebase是由硅谷创业公司MetaWeb于2005年启动的一个语义网项目。"}
{"text": "2010年，谷歌收购了Freebase，并作为其知识图谱数据来源之一。"}
{"text": "Freebase主要采用社区成员协作方式构建，主要数据来源包括Wikipedia、世界名人数据库（NNDB）、开放音乐数据库（MusicBrainz）以及社区用户的贡献等。"}
{"text": "Freebase基于RDF三元组模型，底层采用图数据库进行存储。"}
{"text": "Freebase的一个特点是不对顶层本体做非常严格的控制，用户可以创建与编辑类和关系的定义。"}
{"text": "2016年，谷歌宣布将Freebase的数据和API服务都迁移至Wikidata，并正式关闭了Freebase。"}
{"text": "DBpedia意指数据库版本的Wikipedia，是早期的语义网项目，是从Wikipedia抽取出来的链接数据集。"}
{"text": "DBpedia采用了一个较为严格的本体，包含人、地点、音乐、电影、组织机构、物种、疾病等类定义。"}
{"text": "此外，DBpedia还与Freebase、OpenCYC、Bio2RDF等多个数据集建立了数据链接。"}
{"text": "DBpedia采用RDF语义数据模型，总共包含30亿个RDF三元组。"}
{"text": "Schema.org是从2011年开始，由Bing、Google、Yahoo和Yandex等搜索引擎公司共同支持的语义网项目。"}
{"text": "Schema.org支持各个网站采用语义标签（Semantic_Markup）的方式将语义化的链接数据嵌入到网页中。"}
{"text": "搜索引擎自动收集和归集这些数据，快速地从网页中抽取语义化的数据。"}
{"text": "Schema.org提供了一个词语本体，用于描述这些语义标签。"}
{"text": "目前，这个词汇本体已经包含600多个类和900多个关系，覆盖范围包括个人、组织机构、地点、时间、医疗、商品等。"}
{"text": "谷歌于2015年推出的定制化知识图谱支持个人和企业在其网页中增加包括企业联系方法、个人社交信息等在内的语义标签，并通过这种方式快速汇集高质量的知识图谱数据。"}
{"text": "谷歌的一份统计数据显示，超过31%的网页和1200万家网站已经使用了Schema.org发布语义化的链接数据。"}
{"text": "其他采用了部分Schema.org功能的还包括Cortana、Yandex、Pinterest、Siri等。"}
{"text": "Schema.org的本质是采用互联网众包的方式生成和收集高质量的知识图谱数据。"}
{"text": "Wikidata的目标是构建一个免费开放、多语言、任何人或机器都可以编辑修改的大规模链接知识库。"}
{"text": "Wikidata由Wikipedia于2012年启动，早期得到微软联合创始人PaulAllen、Gordon_Betty_Moore基金会以及谷歌的联合资助。"}
{"text": "Wikidata继承了Wikipedia的众包协作机制，但与Wikipedia不同的是，Wikidata支持以三元组为基础的知识条目（Item）的自由编辑。"}
{"text": "一个三元组代表一个关于该条目的陈述（Statement）。"}
{"text": "例如，可以给“地球”的条目增加“<地球，地表面积是，五亿平方公里>”的三元组陈述。"}
{"text": "截至2018年，Wikidata已经包含超过5000万个知识条目。"}
{"text": "BabelNet是类似于WordNet的多语言词典知识库。"}
{"text": "BabelNet的目标是解决WordNet在非英语语种中数据缺乏的问题。"}
{"text": "BabelNet采用的方法是将WordNet词典与Wikipedia集成。"}
{"text": "首先建立WordNet中的词与Wikipedia的页面标题的映射，然后利用Wikipedia中的多语言链接，再辅以机器翻译技术，给WordNet增加多种语言的词汇。"}
{"text": "BabelNet3.7包含了271种语言、1400万个同义词组、36.4万个词语关系和3.8亿个从Wikipedia中抽取的链接关系，总计超过19亿个RDF三元组。"}
{"text": "BabelNet集成了WordNet在词语关系上的优势和Wikipedia在多语言语料方面的优势，成功构建了目前最大规模的多语言词典知识库。"}
{"text": "NELL（Never-Ending_Language_Learner）是卡内基梅隆大学开发的知识库。"}
{"text": "NELL主要采用互联网挖掘的方法从Web中自动抽取三元组知识。"}
{"text": "NELL的基本理念是：给定一个初始的本体（少量类和关系的定义）和少量样本，让机器能够通过自学习的方式不断地从Web中学习和抽取新的知识。"}
{"text": "目前，NELL已经抽取了300多万条三元组知识。"}
{"text": "Yago是由德国马普研究所研制的链接数据库。"}
{"text": "Yago主要集成了Wikipedia、WordNet和GeoNames三个数据库的数据。"}
{"text": "Yago将WordNet的词汇定义与Wikipedia的分类体系进行了融合集成，使得Yago具有更加丰富的实体分类体系。"}
{"text": "Yago还考虑了时间和空间知识，为很多知识条目增加了时间和空间维度的属性描述。"}
{"text": "目前，Yago包含1.2亿条三元组知识。"}
{"text": "Yago也是IBM_Watson的后端知识库之一。"}
{"text": "MicrosoftConceptGraph是以概念层次体系为中心的知识图谱。"}
{"text": "与Freebase等知识图IsA关系为主。"}
{"text": "例如，给定一个概谱不同，ConceptGraph以概念定义和概念之间的念“Microsoft”,ConceptGraph返回一组与“微软”有IsA关系概念组“Company”“SoftwareCompany”“Largest_OS_Vender”等，被称为概念化“Conceptualization”。"}
{"text": "ConceptGraph可以用于短文本理解和语义消歧。"}
{"text": "例如，给定一个短文本“the_engineer_is_eating_the_apple”，可以利用ConceptGraph正确理解其中“apple”的含义是“吃的苹果”还是“苹果公司”。"}
{"text": "微软发布的第一个版本包含超过540万个概念、1255万个实体和8760万个关系。"}
{"text": "ConceptGraph主要通过从互联网和网络日志中挖掘数据进行构建。"}
{"text": "LOD（Linked_Open_Data）的初衷是为了实现Tim_Berners-Lee在2006年发表的有关链接数据（Linked_Data）作为语义网的一种实现的设想。"}
{"text": "LOD遵循了Tim提出的进行数据链接的四个规则，即：使用URI标识万物；使用HTTP_URI，以便用户可以（像访问网页一样）查看事物的描述；使用RDF和SPARQL标准；为事物添加与其他事物的URI链接，建立数据关联。"}
{"text": "LOD已经有1143个链接数据集，其中社交媒体、政府、出版和生命科学四个领域的数据占比超过了90%。"}
{"text": "56%的数据集对外至少与一个数据集建立了链接。"}
{"text": "被链接最多的是DBpedia的数据。"}
{"text": "LOD鼓励各个数据集使用公共的开放词汇和术语，但也允许使用各自的私有词汇和术语。"}
{"text": "在使用的术语中，有41%是公共的开放术语。"}
{"text": "1.4.3中文开放知识图谱OpenKG是一个面向中文域开放知识图谱的社区项目，主要目的是促进中文领域知识图谱数据的开放与互联。"}
{"text": "OpenKG.CN聚集了大量开放的中文知识图谱数据、工具及文献，如图1-7所示。"}
{"text": "典型的中文开放知识图谱数据包括百科类的Zhishi.me（狗尾草科技、东南大学）、CN-DBpedia（复旦大学）、XLore（清华大学）、Belief-Engine（中科院自动化所）、PKUPie（北京大学）、ZhOnto（狗尾草科技）等。"}
{"text": "OpenKG对这些主要百科数据进行了链接计算和融合工作，并通过OpenKG提供开放的Dump或开放访问API，完成的链接数据集也向公众完全免费开放。"}
{"text": "此外，OpenKG还对一些重要的知识图谱开源工具进行了收集和整理，包括知识建模工具Protege、知识融合工具Limes、知识问答工具YodaQA、知识抽取工具DeepDive等。"}
{"text": "图1-7OpenKG的主网站知识图谱Schema定义了知识图谱的基本类、术语、属性和关系等本体层概念。"}
{"text": "cnSchema.ORG是OpenKG发起和完成的开放的知识图谱Schema标准。"}
{"text": "cnSchema的词汇集包括了上千种概念分类（classes）、数据类型（data_types）、属性（propertities）和关系（relations）等常用概念定义，以支持知识图谱数据的通用性、复用性和流动性。"}
{"text": "结合中文的特点，复用、连接并扩展了Schema.org、Wikidata、Wikipedia等已有的知识图谱Schema标准，为中文领域的开放知识图谱、聊天机器人、搜索引擎优化等提供可供参考和扩展的数据描述和接口定义标准。"}
{"text": "通过cnSchema，开发者也可以快速对接上百万基于Schema.org定义的网站，以及Bot的知识图谱数据API。"}
{"text": "cnSchema主要解决如下三个问题：①Bots是搜索引擎后新兴的人机接口，对话中的信息粒度缩小到短文本、实体和关系，要求文本与结构化数据的结合，要求更丰富的上下文处理机制等，这都需要Schema的支持；②知识图谱Schema缺乏对中文的支持；③知识图谱的构建成本高，容易重新发明轮子，需要用合理的方法实现成本分摊。"}
{"text": "OpenBase.AI是OpenKG实现的类似于Wikidata的开放知识图谱众包平台。"}
{"text": "与WikiData不同，OpenBase主要以中文为中心，更加突出机器学习与众包的协同，将自动化的知识抽取、挖掘、更新、融合与群智协作的知识编辑、众包审核和专家验收等结合起来。"}
{"text": "此外，OpenBase还支持将图谱转化为Bots，允许用户选择算法、模型、图谱数据等定制生成Bots，即时体验新增知识图谱的作用。"}
{"text": "1.4.4垂直领域知识图谱领域知识图谱是相对于DBPedia、Yago、Wikidata、百度和谷歌等搜索引擎在使用的知识图谱等通用知识图谱而言的，它是面向特定领域的知识图谱，如电商、金融、医疗等。"}
{"text": "相比较而言，领域知识图谱的知识来源更多、规模化扩展要求更迅速、知识结构更加复杂、知识质量要求更高、知识的应用形式也更加广泛。"}
{"text": "如表1-1所示，从多个方面对通用知识图谱和领域知识图谱进行了比较分析。"}
{"text": "下面以电商、医疗、金融领域知识图谱为例，介绍领域知识图谱的主要特点及技术难点。"}
{"text": "表1-1通用知识图谱与领域知识图谱的比较1.电商领域知识图谱以阿里巴巴电商知识图谱为例[27]，最新发布的知识图谱规模已达到百亿级别。"}
{"text": "其知识图谱数据主要以阿里已有的结构化商品数据为基础，并与行业合作伙伴数据、政府工商管理数据、外部开放数据进行融合扩展。"}
{"text": "在知识表示方面，除简单的三元组外，还包含层次结构更加复杂的电商本体和面向业务管控的大量规则型知识。"}
{"text": "在知识的质量方面，对知识的覆盖面和准确性都有较高的要求。"}
{"text": "在应用形式方面，广泛支持商品搜索、商品导购、天猫精灵等产品的智能问答、平台的治理和管控、销售趋势的预测分析等多个应用场景。"}
{"text": "电商知识也具有较高的动态性特征，例如交易型知识和与销售趋势有关的知识都具有较强的时效性和时间性。"}
{"text": "2.医疗领域知识图谱医疗领域构建有大量的规模巨大的领域知识库。"}
{"text": "例如，仅Linked_Life_Data项目包含的RDF三元组规模就达到102亿个[3]，包含从基因、蛋白质、疾病、化学、神经科学、药物等多个领域的知识。"}
{"text": "再例如国内构建的中医药知识图谱[28]，通常需要融合各类基础医学、文献、医院临床等多种来源的数据，规模也达到20多亿个三元组。"}
{"text": "医学领域的知识结构更加复杂[29-31]，如医学语义网络UMLS包含大量复杂的语义关系，GeneOnto[29]则包含复杂的类层次结构。"}
{"text": "在知识质量方面，特别涉及临床辅助决策的知识库通常要求完全避免错误知识。"}
{"text": "3.金融领域知识图谱金融领域比较典型的例子如Kensho采用知识图谱辅助投资顾问和投资研究，国内以恒生电子为代表的金融科技机构以及不少银行、证券机构等也都在开展金融领域的知识图谱构建工作。"}
{"text": "金融知识图谱构建主要来源于机构已有的结构化数据和公开的公报、研报及新闻的联合抽取等。"}
{"text": "在知识表示方面，金融概念也具有较高的复杂性和层次性，并较多地依赖规则型知识进行投资因素的关联分析。"}
{"text": "在应用形式方面，则主要以金融问答和投顾投研类决策分析型应用为主。"}
{"text": "金融知识图谱的一个显著特点是高度动态性，且需要考虑知识的时效性，对金融知识的时间维度进行建模。"}
{"text": "由上面的例子可以看出，如图1-8所示，领域知识图谱具有规模巨大、知识结构更加复杂、来源更加多样、知识更加异构、具有高度的动态性和时效性、更深层次的推理需求等特点。"}
{"text": "图1-8规模化的知识图谱系统工程1.5知识图谱的技术流程知识图谱用于表达更加规范的高质量数据。"}
{"text": "一方面，知识图谱采用更加规范而标准的概念模型、本体术语和语法格式来建模和描述数据；另一方面，知识图谱通过语义链接增强数据之间的关联。"}
{"text": "这种表达规范、关联性强的数据在改进搜索、问答体验、辅助决策分析和支持推理等多个方面都能发挥重要的作用。"}
{"text": "知识图谱方法论涉及知识表示、知识获取、知识处理和知识利用多个方面。"}
{"text": "一般流程为：首先确定知识表示模型，然后根据数据来源选择不同的知识获取手段导入知识，接着综合利用知识推理、知识融合、知识挖掘等技术对构建的知识图谱进行质量提升，最后根据场景需求设计不同的知识访问与呈现方法，如语义搜索、问答交互、图谱可视化分析等。"}
{"text": "下面简要概述这些技术流程的核心技术要素。"}
{"text": "1.知识来源可以从多种来源获取知识图谱数据，包括文本、结构化数据库、多媒体数据、传感器数据和人工众包等。"}
{"text": "每一种数据源的知识化都需要综合各种不同的技术手段。"}
{"text": "例如，对于文本数据源，需要综合实体识别、实体链接、关系抽取、事件抽取等各种自然语言处理技术，实现从文本中抽取知识。"}
{"text": "结构化数据库如各种关系数据库，也是最常用的数据来源之一。"}
{"text": "已有的结构化数据库通常不能直接作为知识图谱使用，而需要将结构化数据定义到本体模型之间的语义映射，再通过编写语义翻译工具实现结构化数据到知识图谱的转化。"}
{"text": "此外，还需要综合采用实体消歧、数据融合、知识链接等技术，提升数据的规范化水平，增强数据之间的关联。"}
{"text": "语义技术也被用来对传感器产生的数据进行语义化。"}
{"text": "这包括对物联设备进行抽象，定义符合语义标准的数据接口；对传感数据进行语义封装和对传感数据增加上下文语义描述等。"}
{"text": "人工众包是获取高质量知识图谱的重要手段。"}
{"text": "例如，Wikidata和Schema.org都是较为典型的知识众包技术手段。"}
{"text": "此外，还可以开发针对文本、图像等多种媒体数据的语义标注工具，辅助人工进行知识获取。"}
{"text": "2.知识表示与Schema工程知识表示是指用计算机符号描述和表示人脑中的知识，以支持机器模拟人的心智进行推理的方法与技术。"}
{"text": "知识表示决定了图谱构建的产出目标，即知识图谱的语义描述框架（Description_Framework）、Schema与本体（Ontology）、知识交换语法（Syntax）、实体命名及ID体系。"}
{"text": "基本描述框架定义知识图谱的基本数据模型（DataModel）和逻辑结构（Structure），如国际万维网联盟（World_Wide_Web_Consortium,W3C）的RDF。"}
{"text": "Schema与本体定义知识图谱的类集、属性集、关系集和词汇集。"}
{"text": "交换语法定义知识实际存在的物理格式，如Turtle、JSON等。"}
{"text": "实体命名及ID体系定义实体的命名原则及唯一标识规范等。"}
{"text": "按知识类型的不同，知识图谱包括词（Vocabulary）、实体（Entity）、关系（Relation）、事件（Event）、术语体系（Taxonomy）、规则（Rule）等。"}
{"text": "词一级的知识以词为中心，并定义词与词之间的关系，如WordNet、ConceptNet等。"}
{"text": "实体一级的知识以实体为中心，并定义实体之间的关系、描述实体的术语体系等。"}
{"text": "事件是一种复合的实体。"}
{"text": "W3C的RDF把三元组（Triple）作为基本的数据模型，其基本的逻辑结构包含主语（Subject）、谓词（Predicate）、宾语（Object）三个部分。"}
{"text": "虽然不同知识库的描述框架的表述有所不同，但本质上都包含实体、实体的属性和实体之间的关系几个要素。"}
{"text": "3.知识抽取知识抽取按任务可以分为概念抽取、实体识别、关系抽取、事件抽取和规则抽取等。"}
{"text": "传统专家系统时代的知识主要依靠专家手工录入，难以扩大规模。"}
{"text": "现代知识图谱的构建通常大多依靠已有的结构化数据资源进行转化，形成基础数据集，再依靠自动化知识抽取和知识图谱补全技术，从多种数据来源进一步扩展知识图谱，并通过人工众包进一步提升知识图谱的质量。"}
{"text": "结构化和文本数据是目前最主要的知识来源。"}
{"text": "从结构化数据库中获取知识一般使用现有的D2R工具[32]，如Triplify、D2RServer、OpenLink、SparqlMap、Ontop等。"}
{"text": "从文本中获取知识主要包括实体识别和关系抽取。"}
{"text": "以关系抽取为例，典型的关系抽取方法可以分为基于特征模板的方法[33-35]、基于核函数的监督学习方法[36-44]、基于远程监督的方法[45,46]和基于深度学习的监督或远程监督方法，如简单CNN、MP-CNN、MWK-CNN、PCNN、PCNN+Att和MIMLCNN等[47-52]。"}
{"text": "远程监督的思想是，利用一个大型的语义数据库自动获取关系类型标签。"}
{"text": "这些标签可能是含有噪声的，但是大量的训练数据在一定程度上可以抵消这些噪声。"}
{"text": "另外，一些工作通过多任务学习等方法将实体和关系做联合抽取[46,53]。"}
{"text": "最新的一些研究则利用强化学习减少人工标注并自动降低噪声[54]。"}
{"text": "4.知识融合在构建知识图谱时，可以从第三方知识库产品或已有结构化数据中获取知识输入。"}
{"text": "例如，关联开放数据项目（Linked_Open_Data）会定期发布其经过积累和整理的语义知识数据，其中既包括前文介绍过的通用知识库DBpedia和Yago，也包括面向特定领域的知识库产品，如MusicBrainz和DrugBank等。"}
{"text": "当多个知识图谱进行融合，或者将外部关系数据库合并到本体知识库时，需要处理两个层面的问题：通过模式层的融合，将新得到的本体融入已有的本体库中，以及新旧本体的融合；数据层的融合，包括实体的指称、属性、关系以及所属类别等，主要的问题是如何避免实例以及关系的冲突问题，造成不必要的冗余。"}
{"text": "数据层的融合是指实体和关系（包括属性）元组的融合，主要是实体匹配或者对齐，由于知识库中有些实体含义相同但是具有不同的标识符，因此需要对这些实体进行合并处理[55,56]。"}
{"text": "此外，还需要对新增实体和关系进行验证和评估，以确保知识图谱的内容一致性和准确性，通常采用的方法是在评估过程中为新加入的知识赋予可信度值，据此进行知识的过滤和融合。"}
{"text": "实体对齐的任务包括实体消歧和共指消解，即判断知识库中的同名实体是否代表不同的含义以及知识库中是否存在其他命名实体表示相同的含义。"}
{"text": "实体消歧专门用于解决同名实体产生歧义的问题，通常采用聚类法，其关键问题是如何定义实体对象与指称项之间的相似度，常用方法有空间向量模型（词袋模型）[57]、语义模型[58]、社会网络模型[59]、百科知识模型[60]和增量证据模型[61]。"}
{"text": "一些最新的工作利用知识图谱嵌入方法进行实体对齐，并引入人机协作方式提升实体对齐的质量[62,63]。"}
{"text": "本体是针对特定领域中Schema定义、概念模型和公理定义而言的，目的是弥合词汇异构性和语义歧义的间隙，使沟通达成共识。"}
{"text": "这种共识往往通过一个反复的过程达到，每次迭代都是一次共识的修改。"}
{"text": "因此，本体对齐通常带来的是共识模式的演化和变化，本体对齐的主要问题之一也可以转化为怎样管理这种演化和变化[64]。"}
{"text": "常见的本体演化管理框架有KAON[65]、Conto-diff[66]、OntoView等。"}
{"text": "5.知识图谱补全与推理常用的知识图谱补全方法包括：基于本体推理的补全方法，如基于描述逻辑的推理[67-69]，以及相关的推理机实现，如RDFox、Pellet、RACER、HermiT、TrOWL等。"}
{"text": "这类推理主要针对TBox，即概念层进行推理，也可以用来对实体级的关系进行补全。"}
{"text": "另外一类的知识补全算法实现基于图结构和关系路径特征的方法，如基于随机游走获取路径特征的PRA算法[70]、基于子图结构的SFE算法[71]、基于层次化随机游走模型的PRA算法[72]。"}
{"text": "这类算法的共同特点是通过两个实体节点之间的路径，以及节点周围图的结构提取特征，并通过随机游走等算法降低特征抽取的复杂度，然后叠加线性的学习模型进行关系的预测。"}
{"text": "此类算法依赖于图结构和路径的丰富程度。"}
{"text": "更为常见的补全实现是基于表示学习和知识图谱嵌入的链接预测[73-80]，简单的如前面介绍最基本的翻译模型、组合模型和神经元模型等。"}
{"text": "这类简单的嵌入模型一般只能实现单步的推理。"}
{"text": "对于更为复杂的模型，如向量空间中引入随机游走模型的方法，在同一个向量空间中将路径与实体和关系一起表示出来再进行补全的模型[81,82]。"}
{"text": "文本信息也被用来辅助实现知识图谱的补全[83-88]。"}
{"text": "例如，Jointly(w)、Jointly(z)、DKRL、TEKE、SSP等方法将文本中的实体和结构化图谱中的实体对齐，然后利用双方的语义信息辅助实现关系预测或抽取。"}
{"text": "这类模型一般包含三个部分：三元组解码器、文本解码器和联合解码器。"}
{"text": "三元组解码器将知识图谱中的实体和关系转化为低维向量；文本解码器则要从文本语料库中学习实体（词）的向量表示；联合解码器的目的是要保证实体、关系和词的嵌入向量位于相同的空间中，并且集成实体向量和词向量。"}
{"text": "6.知识检索与知识分析基于知识图谱的知识检索的实现形式主要包括语义检索和智能问答。"}
{"text": "传统搜索引擎依靠网页之间的超链接实现网页的搜索，而语义搜索直接对事物进行搜索，如人物、机构、地点等。"}
{"text": "这些事物可能来自文本、图片、视频、音频、IoT设备等各种信息资源。"}
{"text": "而知识图谱和语义技术提供了关于这些事物的分类、属性和关系的描述，使得搜索引擎可以直接对事物进行索引和搜索。"}
{"text": "知识图谱和语义技术也被用来辅助做数据分析与决策。"}
{"text": "例如，大数据公司Plantir基于本体融合和集成多种来源的数据，通过知识图谱和语义技术增强数据之间的关联，使得用户可以用更加直观的图谱方式对数据进行关联挖掘与分析。"}
{"text": "近年来，描述性数据分析（Declarative_Data_Analysis）越来越受到重视[89]。"}
{"text": "描述性数据分析是指依赖数据本身的语义描述实现数据分析的方法。"}
{"text": "不同于计算性数据分析主要以建立各种数据分析模型，如深度神经网络，描述性数据分析突出预先抽取数据的语义，建立数据之间的逻辑，并依靠逻辑推理的方法（如DataLog）实现数据分析[90]。"}
{"text": "1.6知识图谱的相关技术知识图谱是交叉领域，涉及的相关领域包括人工智能、数据库、自然语言处理、机器学习、分布式系统等。"}
{"text": "下面分别从数据库系统、智能问答、机器推理、推荐系统、区块链与去中心化等角度介绍知识图谱有关的相关技术进展。"}
{"text": "1.6.1知识图谱与数据库系统随着知识图谱规模的日益增长，知识图谱数据管理问题愈加突出。"}
{"text": "近年来，知识图谱和数据库领域均认识到大规模知识图谱数据管理任务的紧迫性。"}
{"text": "由于传统关系数据库无法有效适应知识图谱的图数据模型，知识图谱领域形成了RDF数据的三元组库（TripleStore），数据库领域开发了管理属性图的图数据库（Graph_Database）。"}
{"text": "知识图谱的主要数据模型有RDF图（RDF_graph）和属性图（Property_Graph）两种；知识图谱查询语言可分为声明式（Declarative）和导航式（Navigational）两类。"}
{"text": "RDF三元组库主要是由Semantic_Web领域推动开发的数据库管理系统，其数据模型RDF图和查询语言SPARQL均遵守W3C标准。"}
{"text": "查询语言SPARQL从语法上借鉴了SQL语言，属于声明式查询语言。"}
{"text": "最新的SPARQL1.1版本[91]为有效查询RDF三元组集合设计Pattern）、属性路径了三元组模式（Triple（Property_Path）等多种查询机制。"}
{"text": "Pattern）、基本图模式（Basic_Graph图数据库是数据库领域为更好地存储和管理图模型数据而开发的数据库管理系统，其数据模型采用属性图，其上的声明式查询语言有：Cypher[92]、PGQL[93]和G-Core[94]。"}
{"text": "Cypher是开源图数据库Neo4j中实现的图查询语言。"}
{"text": "PGQL是Oracle公司开发的图查询语言。"}
{"text": "G-Core是由LDBC（Linked_Data_Benchmarks_Council）组织设计的图查询语言。"}
{"text": "考虑到关系数据库采用统一的查询语言SQL，目前学术和工业界关于开发统一图数据库语言的呼声越来越高。"}
{"text": "目前，基于三元组库和图数据库能够提供的知识图谱数据存储方案可分为三类：（1）基于关系的存储方案。"}
{"text": "包括三元组表、水平表、属性表、垂直划分、六重索引和DB2RDF等。"}
{"text": "三元组表是将知识图谱中的每条三元组存储为一行具有三列的记录（主语，谓语，宾语）。"}
{"text": "三元组表存储方案虽然简单明了，但三元组表的行数与知识图谱的边数一样，其问题是将知识图谱查询翻译为SQL后会产生大量三元组表的自连接操作，影响效率。"}
{"text": "水平表存储方案的每行记录存储知识图谱中一个主语的所有谓语和宾语，相当于知识图谱的邻接表。"}
{"text": "但其缺点在于所需列数目过多，表中产生大量空值，无法存储多值宾语等。"}
{"text": "属性表存储方案将同一类主语分配到一个表中，是对水平表存储方案的细化。"}
{"text": "属性表解决了三元组表的自连接问题和水平表的列数目过多问题。"}
{"text": "但对于真实大规模知识图谱，属性表的问题包括：所需属性表过多，复杂查询的多表连接效率，空值问题和多值宾语问题。"}
{"text": "垂直划分存储方案为知识图谱中的每种谓语建立一张两列的表（主语，宾语），表中存放由该谓语连接的主语和宾语，支持“主语-主语”作为连接条件的查询操作的快速执行。"}
{"text": "垂直划分有效解决了空值问题和多值宾语问题；但其仍有缺点，包括：大规模知识图谱的谓语表数目过多、复杂查询表连接过多、更新维护代价大等。"}
{"text": "六重索引存储方案是将三元组全部6种排列对应地建立为6张表。"}
{"text": "六重索引通过“空间交换时间”策略有效缓解了三元组表的自连接问题，但需要更多的存储空间开销和索引更新维护代价。"}
{"text": "DB2RDF存储方案[95]是一种较新的基于关系的知识图谱存储方案，是以往存储方案的一种权衡优化。"}
{"text": "三元组表的灵活性体现在“行维度”上，无论多少行三元组数据，表模式只有3列固定不变；DB2RDF方案将这种灵活性推广到了“列维度”，列名称不再和谓语绑定，将同一主语的所有谓语和宾语动态分配到某列。"}
{"text": "（2）面向RDF的三元组库。"}
{"text": "主要的RDF三元组库包括：商业系统Virtuoso、AllegroGraph、GraphDB和BlazeGraph，开源系统Jena、RDF-3X和gStore[96]。"}
{"text": "RDF4J目前是Eclipse基金会旗下的开源孵化项目，其功能包括RDF数据的解析、存储、推理和查询等。"}
{"text": "RDF4J本身提供内存和磁盘两种RDF存储机制，支持全部的SPARQL1.1查询和更新语言，可以使用与访问本地RDF库相同的API访问远程RDF库，支持所有主流的RDF数据格式，包括RDF/XML、Turtle、N-Triples、N-Quads、JSON-LD、TriG和TriX。"}
{"text": "RDF4J框架的主要特点是其模块化的软件架构设计。"}
{"text": "RDF-3X是德国马克斯·普朗克计算机科学研究所开发的三元组数据库，其特点是为RDF优化设计的物理存储方案和查询处理方法，是实现六重索引的典型系统。"}
{"text": "gStore是由北京大学、加拿大滑铁卢大学和香港科技大学联合研究项目开发的基于图RDF三元组数据库。"}
{"text": "gStore的底层存储使用RDF图对应的标签图（Signature_Graph）并建立“VS树”索引结构以加速查找。"}
{"text": "gStore系统提出建立“VS树”索引，其基本思想实际上是为标签图G*建立不同详细程度的摘要图（Summary_Graph）；利用“VS树”索引提供的摘要图，gStore系统提出可以大幅削减SPARQL查询的搜索空间，以加快查询速度。"}
{"text": "Virtuoso是由OpenLink公司开发的商业混合数据库产品，支持关系数据、对象-关系数据、RDF数据、XML数据和文本数据的统一管理。"}
{"text": "因为Virtuoso可以较为完善地支持W3C的Linked_Data系列协议，包括DBpedia在内的很多开放RDF知识图谱选择其作为后台存储系统。"}
{"text": "AllegroGraph是美国Franz公司开发的RDF三元组数据库。"}
{"text": "AllegroGraph遵循对W3C语义Web相关标准的严格支持，包括RDF、RDFS、OWL和SPARQL等。"}
{"text": "AllegroGraph对语义推理功能具有较为完善的支持。"}
{"text": "AllegroGraph除了三元组数据库的基本功能，还支持动态物化的RDFS++推理机、OWL2_RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析库、可视化RDF图浏览器等。"}
{"text": "GraphDB是由保加利亚的Ontotext软件公司开发的RDF三元组数据库。"}
{"text": "GraphDB实现了RDF4J框架的SAIL层，与RDF4JAPI无缝对接，也就是说，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。"}
{"text": "GraphDB的特色是良好支持RDF推理功能，其使用内置的基于规则的“前向链”（Forward-Chaining）推理机，由显式知识经过推理得到导出知识，对这些导出知识进行优化存储；导出知识会在知识库更新后相应地同步更新。"}
{"text": "Blazegraph是一个基于RDF三元组库的图数据库管理系统，在用户接口层同时支持RDF三元组和属性图模型，既实现了SPARQL语言，也实现了Blueprints标准及Gremlin语言。"}
{"text": "通过分布式动态分片B+树和服务总线技术，Blazegraph支持真正意义上的集群分布式存储和查询处理。"}
{"text": "正是缘于此，Blazegraph在与Neo4j和Titan的竞争中脱颖而出，被Wikidata选为查询服务的后台图数据库系统。"}
{"text": "Stardog是由美国Stardog_Union公司开发的RDF三元组数据库，支持RDF图数据模型、SPARQL查询语言、属性图模型、Gremlin图遍历语言、OWL2标准、用户自定义的推理与数据分析规则、虚拟图、地理空间查询以及多用编程语言与网络接口支持。"}
{"text": "Stardog虽然发布较晚，但其对OWL2推理机制具有良好的支持，同时具备全文搜索、GraphQL查询、路径查询、融合机器学习任务等功能，能够支持多种不同编程语言和Web访问接口，使得Stardog成了一个知识图谱数据存储和查询平台。"}
{"text": "（3）原生图数据库。"}
{"text": "Neo4j是用Java实现的开源图数据库。"}
{"text": "可以说Neo4j是目前流行程度最高的图数据库产品。"}
{"text": "Neo4j的不足之处在于其社区版是单机系统，虽然Neo4j企业版支持高可用性（High_availability）集群，但其与分布式图存储系统的最大区别在于每个节点上存储图数据库的完整副本（类似于关系数据库镜像的副本集群），而不是将图数据划分为子图进行分布式存储，而并非真正意义上的分布式数据库系统。"}
{"text": "如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。"}
{"text": "JanusGraph是在原有Titan系统基础上继续开发的开源分布式图数据库，目前是Linux基金会旗下的一个开源项目。"}
{"text": "JanusGraph的存储后端与查询引擎是分离的，由于其可使用分布式Bigtable存储库Cassandra或HBase作为存储后端，因此JanusGraph自然就成了分布式图数据库。"}
{"text": "JanusGraph的主要缺点是分布式查询功能仅限于基于Cassandra或HBase提供的分布式读写实现的简单导航查询，对于很多稍复杂的查询类型，目前还不支持真正意义上的分布式查询处理，例如子图匹配查询、正则路径查询等。"}
{"text": "OrientDB最初是由OrientDB公司开发的多模型数据库管理系统。"}
{"text": "OrientDB虽然支持图、文档、键值、对象、关系等多种数据模型，但其底层实现主要面向图和文档数据存储管理的需求设计。"}
{"text": "其存储层中数据记录之间的关联并不像关系数据库那样通过主外键的引用，而是通过记录之前直接的物理指针。"}
{"text": "Cayley是由谷歌公司工程师开发的一款轻量级开源图数据库，于2014年6月在GitHub上发布。"}
{"text": "Cayley的开发受到了Freebase知识图谱和谷歌知识图谱背后的图数据存储的影响，目标是成为开发者管理Linked_Data和图模型数据（语义Web、社会网络等）的有效工具之一。"}
{"text": "总体来讲，基于关系的存储系统继承了关系数据库的优势，成熟度较高，在硬件性能和存储容量满足的前提下，通常能够适应千万到十亿三元组规模的管理。"}
{"text": "官方测评显示，关系数据库Oracle_12c配上空间和图数据扩展组件（Spatial_and_Graph）可以管理的三元组数量高达1.08万亿条[97]。"}
{"text": "对于一般在百万到上亿三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。"}
{"text": "如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。"}
{"text": "近年来，以Neo4j为代表的图数据库系统发展迅猛，使用图数据库管理RDF三元组也是一种很好的选择；但目前大部分图数据库还不能直接支持RDF三元组存储，对于这种情况，可采用数据转换方式，先将RDF预处理为图数据库支持的数据格式（如属性图模型），再进行后续管理操作。"}
{"text": "目前，还没有一种数据库系统被公认为是具有主导地位的知识图谱数据库。"}
{"text": "但可以预见，随着三元组库和图数据库的相互融合发展，知识图谱的存储和数据管理手段将愈加丰富和强大。"}
{"text": "1.6.2知识图谱与智能问答基于知识图谱的问答（Knowledge-based_Question_Answering,KBQA，下称“知识问答”）是智能问答系统的核心功能，是一种人机交互的自然方式。"}
{"text": "知识问答依托一个大型知识库（知识图谱、结构化数据库等），将用户的自然语言问题转化成结构化查询语句（如SPARQL、SQL等），直接从知识库中导出用户所需的答案。"}
{"text": "近几年，知识问答聚焦于解决事实型问答，问题的答案是一个实义词或实义短语。"}
{"text": "如“中国的首都是哪个城市？北京”或“菠菜是什么颜色的？绿色”。"}
{"text": "事实型问题按问题类型可分为单知识点问题（Single-hop_Questions）和多知识点问题（Multi-hop_Questions）；按问题的领域可分为垂直领域问题和通用领域问题。"}
{"text": "相对于通用领域或开放领域，垂直领域下的知识图谱规模更小、精度更高，知识问答的质量更容易提升。"}
{"text": "知识问答技术的成熟与落地不仅能提高人们检索信息的精度和效率，还能提升用户的产品体验。"}
{"text": "无论依托的知识库的规模如何，用户总能像“跟人打交道一样”使用自然语言向机器提问并得到反馈，便利性与实用性共存。"}
{"text": "攻克知识问答的关键在于理解并解析用户提出的自然语言问句。"}
{"text": "这涉及自然语言处理、信息检索和推理（Reasoning）等多个领域的不同技术。"}
{"text": "相关研究工作在近五年来受到越来越多国内外学者的关注，研究方法主要可分为三大类：基于语义解析（Semantic_Parsing）的方法、基于信息检索（Information_Retrieval）的方法和基于概率模型（Probabilistic_Models）的方法。"}
{"text": "大部分先进的知识问答方法是基于语义解析的，目的是将自然语言问句解析成结构化查询语句，进而在知识库上执行查询得到答案。"}
{"text": "通常，自然语言问句经过语义解析后，所得的语义结构能解释答案的产生。"}
{"text": "在实际工程应用中，这一点优势不仅能帮助用户理解答案的产生，还能在产生错误答案时帮助开发者定位错误的可能来源。"}
{"text": "微软在利用语义解析技术解决单知识点问答（Single-hop_Question_Answering）中有突出贡献。"}
{"text": "2014年，叶等人[98]指出，解决单知识点问答的关键在于将原任务分解为两个子任务——话题词识别和关系检测。"}
{"text": "如回答“姚明的妻子是谁？”，可先通过计算语义相似性将问句解析成形如“（姚明，妻子，?）”的查询。"}
{"text": "其中，话题词是“姚明”，问题中包含的关系为“妻子”（或“配偶”），再在知识库中执行查询，得到答案。"}
{"text": "2015年，叶等人[99]强调，直接从大型知识库中寻找与问句含义匹配的关系是比较困难的。"}
{"text": "论文中首先采用实体链接（Entity_Linking）定位话题词，再从与话题词相关的关系子集中寻找与问句含义匹配的关系，从而将问句解析成一个结构化的查询。"}
{"text": "2016年，叶等人[100]继承了斯坦福自然语言处理组开源的WebQuestions数据集，并在此基础上标注了问题的语义解析结果（SPARQL查询），贡献了WebQuestionsSP数据集。"}
{"text": "在基于语义解析的方法训练过程中，问答模型隐式地学习了标注数据中蕴涵的语法解析规律。"}
{"text": "这使得模型能具有更好的可解释性。"}
{"text": "但是，数据标注需要花费大量的人力和财力，是不切实际的。"}
{"text": "而基于信息检索的方法回避了这个问题。"}
{"text": "基于信息检索的知识问答大致可分为两步：①通过粗粒度信息检索，在知识库中直接筛选出候选答案；②根据问句中抽取出的特征，对候选答案进行排序。"}
{"text": "这就要求模型对问句的语义有充分的理解。"}
{"text": "而在自然语言中，词语同义替换等语言现象提升了理解问题的难度。"}
{"text": "[102]为了实现有效的信息检索式知识问答，学者们聚焦于如何让机器理解用户的问题，以及掌握问题与知识库间的匹配规律。"}
{"text": "可行的方法包括：●集成额外的文本信息[101]，如Wikipedia或搜索引擎结果；●提出更多、更复杂的网络结构，如多列卷积神经网络[102]（Multi-ColumnConvolutional_Neural_Networks,MCCNN）、深度残差双向长短时记忆网络[6]（DeepResidual_Bidirectional_Long_Short-term_Memory_Network）和注意力最大池化层[103]（Attentive_Max_Pooling_Layer）；●联合训练[104]实体链接和关系检测两个模块。"}
{"text": "除上述两大流派外，有部分学者将知识问答问题看作是一个条件概率问题[105,106]，即是要求给定问句Q时，答案为α的概率P（A=α|Q），进而引入概率分解[9]或变分推理[107]的技巧，将目标概率分而治之。"}
{"text": "大部分已有的知识问答解决方案都停留在回答单知识点事实型问题上。"}
{"text": "在这类问题中，基于语义解析的方法和基于信息检索的方法并不呈完全割裂、对立的关系[1]。"}
{"text": "二者几乎都把知识问答看作是话题词识别和关系检测两个子任务串行。"}
{"text": "在一些论文中，学者们声称单知识点问答已接近人类水平[108]。"}
{"text": "未来，学者们必然将更多的精力投入解决复杂的多知识点事实型问答上。"}
{"text": "这类问题涉及的自然语言现象更丰富，如关系词的词汇组合性[109]（Sub-Lexical_Compositionality）、多关系词间语序等。"}
{"text": "另外一种思路是：研究如何将多知识点问题转化为单知识点问题。"}
{"text": "因此，先进的单知识点问答模型直接被复用。"}
{"text": "除此之外，在理解问题、回答问题的过程中，模型应具备更强的推理能力和更好的可解释性。"}
{"text": "更强的推理能力能满足用户的复杂提问需求。"}
{"text": "更好的可解释性使用户在“知其然”的同时“知其所以然”。"}
{"text": "1.6.3知识图谱与机器推理推理是指基于已知的事实或知识推断得出未知的事实或知识的过程。"}
{"text": "典型的推理包括演绎推理（Deductive_Reasoning）、溯因推理（Inductive_Reasoning）、归纳推理（Abductive_Reasoning）、类比推理（Analogical_Reasoning）等。"}
{"text": "在知识图谱中，推理主要用于对知识图谱进行补全（Knowledge_Base_Completion,KBC）和知识图谱质量的校验。"}
{"text": "知识图谱中的知识可分为概念层和实体层。"}
{"text": "知识图谱推理的任务是根据知识图谱中已有的知识推理出新的知识或识别出错误的知识。"}
{"text": "其中，概念层的推理主要包括概念之间的包含关系推理，实体层的推理主要包括链接预测与冲突检测，实体层与概念层之间的推理主要包括实例检测。"}
{"text": "推理的方法主要包含基于规则的推理、基于分布式表示学习的推理、基于神经网络的推理以及混合推理。"}
{"text": "1.基于规则的推理基于规则的推理通过定义或学习知识中存在的规则进行推理。"}
{"text": "根据规则的真值类型，可分为硬逻辑规则和软逻辑规则。"}
{"text": "硬逻辑规则中的每条规则的真值都为1，即绝对正确，人工编写的规则多为硬逻辑规则。"}
{"text": "软逻辑规则即每条规则的真值为区间在0到1之间的概率，规则挖掘系统的结果多为软逻辑规则，其学习过程一般是基于规则中结论与条件的共现特征，典型方法有AMIE[110]等。"}
{"text": "软逻辑规则可通过真值重写转化为硬逻辑规则。"}
{"text": "硬逻辑规则可写成知识图谱本体中的SWRL规则，然后通过如Pellet、Hermit等本体推理机进行推理。"}
{"text": "规则推理在大型知识图谱上的效率受限于它的离散性，Cohen提出了一个可微的规则推理机TensorLog[111]。"}
{"text": "基于规则的推理方法最主要的优点是在通常情况下规则比较接近人思考问题时的推理过程，其推理结论可解释，所以对人比较友好。"}
{"text": "在知识图谱中已经沉淀的规则具有较好的演绎能力。"}
{"text": "2.基于分布式表示学习的推理分布式表示学习的核心是将知识图谱映射到连续的向量空间中，并为知识图谱中的元素学习分布式表示为低维稠密的向量或矩阵。"}
{"text": "分布式表示学习通过各元素的分布式表示之间的计算完成隐式的推理。"}
{"text": "多数表示学习方法以单步关系即单个三元组为输入和学习目标，不同的分布式表示学习方法对三元组的建模基于不同的空间假设。"}
{"text": "例如，以TransE[112]为代表的Trans系列模型基于的是关系向量表示在空间中的平移不变性，故将关系向量看作是头实体向量到尾实体向量的翻译并采用向量加法模拟；以DistMult[113]为代表的线性转换模型将关系表示为矩阵，头实体的向量可经过关系矩阵的线性变换转换为尾实体；以RESCAL[114]为代表的模型将知识图谱表示为高维稀疏的三维张量，通过张量分解得到实体和关系的表示。"}
{"text": "考虑到知识图谱中的多步推理的表示学习方法有PTransE[115]和CVSM[116]。"}
{"text": "3.基于神经网络的推理基于神经网络的推理通过神经网络的设计模拟知识图谱推理，其中NTN[117]用一个双线性张量层判断头实体和尾实体的关系，ConvE[118]等在实体和关系的表示向量排布出的二维矩阵上采用卷机神经网络进行链接预测，R-GCN[119]通过图卷积网络捕捉实体的相邻实体信息，IRN[120]采用记忆矩阵以及以递归神经网络为结构的控制单元模拟多步推理的过程。"}
{"text": "基于神经网络的知识图谱推理表达能力强，在链接预测等任务上取得了不错的效果。"}
{"text": "网络结构的设计多样，能够满足不同的推理需求。"}
{"text": "4.混合推理混合推理一般结合了规则、表示学习和神经网络。"}
{"text": "例如，NeuralLP[121]是一种可微的知识图谱推理方法，融合了关系的表示学习、规则学习以及循环神经网络，由LSTM生成多步推理中的隐变量，并通过隐变量生成在多步推理过程中对每种关系的注意力。"}
{"text": "DeepPath[122]和MINERVA[123]用强化学习方法学习知识图谱多步推理过程中的路径选择策略。"}
{"text": "RUGE[124]将已有的推理规则输入知识图谱表示学习过程中，约束和影响表示学习结果并取得更好的推理效果。"}
{"text": "文献[125]使用了对抗生成网络（GAN）提升知识图谱表示学习过程中的负样本生成效率。"}
{"text": "混合推理能够结合规则推理、表示学习推理以及神经网络推理的能力并实现优势互补，能够同时提升推理结果的精确性和可解释性。"}
{"text": "基于规则的知识图谱推理研究主要分为两部分：一是自动规则挖掘系统，二是基于规则的推理系统。"}
{"text": "目前，二者的主要发展趋势是提升规则挖掘的效率和准确度，用神经网络结构的设计代替在知识图谱上的离散搜索和随机游走是比较值得关注的方向。"}
{"text": "基于表示学习的知识图谱推理研究的主要研究趋势是，一方面提高表示学习结果对知识图谱中含有的语义信息的捕捉能力，目前的研究多集中在链接预测任务上，其他推理任务有待跟进研究；另一方面是利用分布式表示作为桥梁，将知识图谱与文本、图像等异质信息结合，实现信息互补以及更多样化的综合推理。"}
{"text": "基于神经网络的知识表示推理的主要发展趋势是设计更加有效和有意义的神经网络结构，来实现更加高效且精确的推理，通过对神经网络中间结果的解析实现对推理结果的部分解释是比较值得关注的方向。"}
{"text": "1.6.4知识图谱与推荐系统随着互联网技术的飞速发展，各种信息在互联网上汇集，信息呈指数级增长，人们面临着信息过载的问题，推荐系统的提出是解决这一问题的有力途径。"}
{"text": "但是，推荐系统在启动阶段往往效果不佳，存在冷启动问题，而且用户历史记录数据往往较为稀疏，使得推荐算法的性能很难让用户满意。"}
{"text": "知识图谱作为先验知识，可以为推荐算法提供语义特征，引入它们可以有效地缓解数据稀疏问题，提高模型的性能。"}
{"text": "基于知识图谱的推荐模型大部分是以现有的推荐模型为基础的，如基于协同过滤和基于内容的推荐模型，将知识图谱中关于商品、用户等实体的结构化知识加入推荐模型中，通过引入额外的知识改善早期推荐模型中数据稀疏的问题。"}
{"text": "文献[126]提出了利用DBpedia知识图谱中的层次类别信息应用于推荐任务中，他们通过传播激活算法在知识图谱中寻找推荐实体。"}
{"text": "文献[127]通过计算知识图谱中蕴涵的语义距离建立音乐推荐模型。"}
{"text": "下面分别介绍三类利用知识图谱的推荐模型，分别为：基于知识图谱中元路径的推荐模型、基于概率逻辑程序的推荐模型、基于知识图谱表示学习技术的推荐模型。"}
{"text": "考虑到知识图谱是一个表示不同实体之间关系的图，研究人员利用图上路径的连通信息计算物品之间的相似度[128]。"}
{"text": "研究人员通过元路径的概念利用图的信息[129,130]，元路径是图中不同类型实体和关系构成的路径。"}
{"text": "文献[131]利用元路径在图上传播用户偏好，并结合传统的协同过滤模型，最终实现了个性化的推荐模型。"}
{"text": "其具体方法如下：首先，沿着不同元路径利用路径相似度计算用户对不同物品的偏好，最终学得在元路径P下的偏好矩阵。"}
{"text": "针对每条元路径学得偏好矩阵，通过潜在因子模型对每个偏好矩阵进行分解，最终可获得每条路径下用户和物品的潜在因子矩阵，最终通过对每条路径下推荐结果的求和获得最终的全局推荐模型。"}
{"text": "其工作有效地利用了知识图谱中不同类型实体间路径的语义信息传递用户的偏好，但是路径需要人工选择。"}
{"text": "文献[132]提出了基于概率逻辑程序的推荐模型，文献作者[133]将推荐问题形式化为逻辑程序，该逻辑程序对目标用户按查询得分高低输出推荐物品的结果，最终寻找到目标用户的推荐物品。"}
{"text": "文献作者提出了三种不同的推荐方法，分别为EntitySim、TypeSim和GraphLF，性能超过了以前的最佳方法[134]。"}
{"text": "这三种方法都是基于通用目的的概率逻辑系统ProPPR。"}
{"text": "其中，EntitySim方法只使用图上的连接信息；TypeSim方法使用了实体的type信息，GraphLF提出了一个结合概率逻辑程序和用户物品潜在因子模型的方法。"}
{"text": "他们的基本思路类似于文献[134]的工作，通过规则在知识图谱中传递用户的偏好，解决了路径人工选择的问题。"}
{"text": "但是，他们将推荐的流程分为寻找用户偏好实体和通过偏好实体寻找物品两个步骤，导致无法有效地利用物品与物品之间的关系和用户与用户之间的关系。"}
{"text": "例如，在电影推荐的例子中，电影《谍影重重4》是《谍影重重3》的续集，但是《谍影重重4》更换了主演，而如果通过他们方法中的规则，用户无法通过《谍影重重3》的主演马特·达蒙寻找到《谍影重重4》。"}
{"text": "通过知识图谱表示学习技术，可以获得知识图谱中实体和关系的低维稠密向量，其可以在低维的向量空间中计算实体间的关联性，与传统的基于符号逻辑在图上查询和推理的方法相比，大大降低了计算的复杂度。"}
{"text": "文献[134]提出使用知识图谱表示学习技术提取知识图谱中的特征，以该特征向量使用K近邻的方法寻找用户最相近的物品，但是该模型与推荐模型结合较为松散，仅使用知识图谱表示学习作为特征提取的一种方法。"}
{"text": "文献[135]在王灏等人[136]工作的基础上进行扩展，通过表示学习的方法将知识图谱中的信息加入推荐模型中，提出了协同知识图谱表示学习的推荐模型（CollaborativeKnowledge_Base_Embedding_Recommender_System），他们方法的具体思路如下：首先，通过知识表示学习获得知识图谱中和推荐物品相关的结构化信息，通过去噪编码器网络从物品相关的文本中学习编码层的文本表示向量，并通过和文本建模相似的去噪编码器网络从图像中学习视觉表示向量，并将这些表示向量引入物品的潜在因子向量中，结合矩阵分解算法完成推荐。"}
{"text": "该工作通过贝叶斯理论的角度解释并联合了不同算法的优化目标。"}
{"text": "但是，在推荐领域的知识图谱中，实体之间的关系非常稠密，且关系类型较少。"}
{"text": "以TransE为代表的模型不适合处理一对多、多对多的关系，尽管TransR针对该问题进行了一定的改进，但当应对相同类型关系的一对多、多对一和多对多关系时，算法实际退化为TransE。"}
{"text": "因此，本书在协同过滤算法上引入一类新的知识图谱表示学习的技术[137,138]提取知识图谱中的结构化信息，最终提出了一个基于知识图谱表示学习的协同过滤推荐系统。"}
{"text": "1.6.5区块链与去中心化的知识图谱语义网的早期理念实际上包含三个方面：知识的互联、去中心化的架构和知识的可信。"}
{"text": "知识图谱在一定程度上实现了“知识互联”的理念，然而在去中心化的架构和知识可信两个方面都仍然没有出现较好的解决方案。"}
{"text": "对于去中心化，相比起现有的多为集中存储的知识图谱，语义网强调知识以分散的方式互联和相互链接，知识的发布者拥有完整的控制权。"}
{"text": "近年来，国内外已经有研究机构和ID管企业开始探索通过区块链技术实现去中心化的知识互联。"}
{"text": "这包括去中心化的实体理、基于分布式账本的术语及实体命名管理、基于分布式账本的知识溯源、知识签名和权限管理等。"}
{"text": "知识的可信与鉴真也是当前很多知识图谱项目面临的挑战和问题。"}
{"text": "由于很多知识图谱数据来源广泛，且知识的可信度量需要作用到实体和事实级别，怎样有效地对知识图谱中的海量事实进行管理、追踪和鉴真，也成为区块链技术在知识图谱领域的一个重要应用方向。"}
{"text": "此外，将知识图谱引入智能合约（Smart_Contract）中，可以帮助解决目前智能合约内生知识不足的问题。"}
{"text": "例如，PCHAIN[139]引入知识图谱Oracle机制，解决传统智能合约数据不闭环的问题。"}
{"text": "1.7本章小结知识图谱本身可以看作是一种新型的信息系统基础设施。"}
{"text": "从数据维度上看，知识图谱要求用更加规范的语义提升企业数据的质量，用链接数据的思想提升企业数据之间的关联度，终极目标是将非结构、无显示关联的粗糙数据逐步提炼为结构化、高度关联的高质量知识。"}
{"text": "每个企业都应该将知识图谱作为一种面向数据的信息系统基础设施进行持续性建设。"}
{"text": "从技术维度上看，知识图谱的构建涉及知识表示、关系抽取、图数据存储、数据融合、推理补全等多方面的技术，而知识图谱的利用涉及语义搜索、知识问答、自动推理、知识驱动的语言及视觉理解、描述性数据分析等多个方面。"}
{"text": "要构建并利用好知识图谱，也要求系统性地综合利用来自知识表示、自然语言处理、机器学习、图数据库、多媒体处理等多个相关领域的技术，而非单个领域的单一技术。"}
{"text": "因此，知识图谱的构建和利用都应注重系统思维是未来的一种发展趋势。"}
{"text": "互联网促成了大数据的集聚，大数据进而促进了人工智能算法的进步。"}
{"text": "新数据和新算法为规模化知识图谱构建提供了新的技术基础和发展条件，使得知识图谱构建的来源、方法和技术手段都发生了极大的变化。"}
{"text": "知识图谱作为知识的一种形式，已经在语义搜索、智能问答、数据分析、自然语言理解、视觉理解、物联网设备互联等多个方面发挥出越来越大的价值。"}
{"text": "AI浪潮愈演愈烈，而作为底层支撑的知识图谱赛道也从鲜有问津到缓慢升温，虽然还谈不上拥挤，但作为通往未来的必经之路，注定会走上风口。"}
{"text": "第2章知识图谱表示与建模漆桂林东南大学，潘志霖阿伯丁大学，陈华钧浙江大学知识图谱表示（Knowledge_Graph_Representation）指的是用什么语言对知识图谱进行建模，从而可以方便知识计算。"}
{"text": "从图的角度来看，知识图谱是一个语义网络，即一种用互联的节点和弧表示知识的一个结构[1]。"}
{"text": "语义网络中的节点可以代表一个概念（concept）、一个属性（attribute）、一个事件（event）或者一个实体（entity）；而弧表示节点之间的关系，弧的标签指明了关系的类型。"}
{"text": "语义网络中的语义主要体现在图中边的含义。"}
{"text": "为了给这些边赋予语义，研究人员提出了术语语言（Terminological_Language），并最终提出了描述逻辑（Description_Logic），描述逻辑是一阶谓词逻辑的一个子集，推理复杂度是可判定的。"}
{"text": "W3C采用了以描述逻辑为逻辑基础的本体语言OWL作为定义Web术语的标准语言。"}
{"text": "W3C还推出了另外一种用于表示Web本体的语言RDF_Schema（简称RDFS）。"}
{"text": "目前基于向量的知识表示开始流行，这类表示将知识图谱三元组中的主谓宾表示成数值向量，通过向量的知识表示，可以采用统计或者神经网络的方法进行推理，对知识图谱中的实体直接的关系进行预测。"}
{"text": "本章将对知识表示的常见方法进行介绍，并且讨论如何用这些知识表示方法对知识进行建模。"}
{"text": "2.1什么是知识表示20世纪90年代，MIT_AI实验室的R.Davis定义了知识表示的五大用途或特点：●客观事物的机器标示（A_KR_is_a_Surrogate），即知识表示首先需要定义客观实体的机器指代或指称。"}
{"text": "●一组本体约定和概念模型（A_KR_is_a_Set_of_Ontological_Commitments），即知识表示还需要定义用于描述客观事物的概念和类别体系。"}
{"text": "●支持推理的表示基础（A_KR_is_a_Theory_of_Intelligent_Reasoning），即知识表示还需要提供机器推理的模型与方法。"}
{"text": "●用于高效计算的数据结构（A_KR_is_a_medium_for_Efficient_Computation），即知识表示也是一种用于高效计算的数据结构。"}
{"text": "●人可理解的机器语言（A_KR_is_a_Medium_of_Human_Expression），即知识表示还必须接近于人的认知，是人可理解的机器语言。"}
{"text": "有关知识表示的研究可以追溯到人工智能的早期研究。"}
{"text": "例如，认知科学家M.RossQuillian和Allan_M.Collins提出了语义网络的知识表示方法[2-3]，以网络的方式描述概念之间的语义关系。"}
{"text": "典型的语义网络如WordNet属于词典类的知识库，主要定义名词、动词、形容词和副词之间的语义关系。"}
{"text": "20世纪70年代，随着专家系统的提出和商业化发展，知识库构建和知识表示更加得到重视。"}
{"text": "传统的专家系统通常包含知识库和推理引擎（InferenceEngine）两个核心模块。"}
{"text": "无论是语义网络，还是框架语言和产生式规则，都缺少严格的语义理论模型和形式化的语义定义。"}
{"text": "为了解决这一问题，人们开始研究具有较好的理论模型基础和算法复杂度的知识表示框架。"}
{"text": "比较有代表性的是描述逻辑语言（Description_Logic）[4]。"}
{"text": "描述逻辑是目前大多数本体语言（如OWL）的理论基础。"}
{"text": "第一个描述逻辑语言是1985年由RonaldJ.Brachman等提出的KL-ONE[5]。"}
{"text": "描述逻辑主要用于刻画概念（Concepts）、属性（Roles）、个体（Individual）、关系（Relationships）、元语（Axioms，即逻辑描述Logic_Statement）等知识表达要素。"}
{"text": "与传统专家系统的知识表示语言不同，描述逻辑家族更关心知识表示能力和推理计算复杂性之间的关系，并深入研究了各种表达构件的组合带来的查询、分类、一致性检测等推理计算的计算复杂度问题。"}
{"text": "语义网的基础数据模型RDF受到了元数据模型、框架系统和面向对象语言等多方面的影响，其最初是为人们在Web上发布结构化数据提供一个标准的数据描述框架。"}
{"text": "与此同时，语义网进一步吸收描述逻辑的研究成果，发展出了用OWL系列标准化本体语言。"}
{"text": "现代知识图谱如DBpedia、Yago、Freebase、Schema.ORG、Wikidata等大多以语义网的表达模型为基础进行扩展或删减。"}
{"text": "无论是早期专家系统时代的知识表示方法，还是语义网时代的知识表示模型，都属于以符号逻辑为基础的知识表示方法。"}
{"text": "符号知识表示的特点是易于刻画显式、离散的知识，因而具有内生的可解释性。"}
{"text": "但由于人类知识还包含大量不易于符号化的隐性知识，完全基于符号逻辑的知识表示通常由于知识的不完备而失去鲁棒性，特别是推理很难达到实用。"}
{"text": "由此催生了采用连续向量的方式来表示知识的研究。"}
{"text": "基于向量的方式表示知识的研究由来已有。"}
{"text": "随着表示学习的发展，以及自然语言处理领域词向量等嵌入（Embedding）技术手段的出现，启发了人们用类似于词向量的低维稠密向量的方式表示知识。"}
{"text": "通过嵌入将知识图谱中的实体和关系投射到一个低维的连续向量空间，可以为每一个实体和关系学习出一个低维度的向量表示。"}
{"text": "这种基于连续向量的知识表示可以实现通过数值运算来发现新事实和新关系，并能更有效发现更多的隐式知识和潜在假设，这些隐式知识通常是人的主观不易于观察和总结出来的。"}
{"text": "更为重要的是，知识图谱嵌入也通常作为一种类型的先验知识辅助输入很多深度神经网络模型中，用来约束和监督神经网络的训练过程。"}
{"text": "如图2-1所示为基于离散符号的知识表示与基于连续向量的知识表示对比。"}
{"text": "图2-1基于离散符号的知识表示与基于连续向量的知识表示对比综上所述，与传统人工智能相比，知识图谱时代的知识表示方法已经发生了很大的变化。"}
{"text": "一方面，现代知识图谱受到规模化扩展的影响，通常采用以三元组为基础的较为简单实用的知识表示方法，并弱化了对强逻辑表示的要求；另一方面，由于知识图谱是很多搜索、问答和大数据分析系统的重要数据基础，基于向量的知识图谱表示使得这些数据更易于和深度学习模型集成，使得基于向量的知识图谱表示越来越受到重视。"}
{"text": "由于知识表示涉及大量传统人工智能的内容，并有其明确、严格的内涵及外延定义，为避免混淆，在本书中主要侧重于知识图谱的表示方法的介绍，因此用“知识表示”和“知识图谱的表示方法”加以了区分。"}
{"text": "2.2人工智能早期的知识表示方法知识是智能的基础。"}
{"text": "人类智能往往依赖有意或无意运用已知的知识。"}
{"text": "与此类似，人工智能系统需要获取并运用知识。"}
{"text": "这里有两个核心问题：怎么表示知识？怎样在计算机中高效地存储与处理知识？本章主要阐述第一个核心问题。"}
{"text": "2.2.1一阶谓词逻辑一阶谓词逻辑（或简称一阶逻辑）（First_Order_Logic）是公理系统的标准形式逻辑。"}
{"text": "不同于命题逻辑（Propositional_Logic），一阶逻辑支持量词（Quantifier）和谓词（Predicate）。"}
{"text": "例如，在命题逻辑里，以下两个句子是不相关的命题：“John_MaCarthy是图灵奖得主”（p）、“Tim_Berners-Lee是图灵奖得主”（q）。"}
{"text": "但是，在一阶逻辑里，可以用谓词和变量表示知识，例如，图灵奖得主（x）表示x是图灵奖得主。"}
{"text": "这里，图灵奖得主是一元谓词（Predicate）,x是变量（Variable），图灵奖得主（x）是一个原子公式（Atomic_Formula）。"}
{"text": "Ø图灵奖得主（x）是一个否定公式（Negated_Formula）。"}
{"text": "在上面的例子中，若x为John_MaCarthy，图灵奖得主（x）为第一个命题p。"}
{"text": "若x为Tim_Berners-Lee，图灵奖得主（x）为第二个命题q。"}
{"text": "1.一阶谓词逻辑优点●结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "●严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "●可实现性。"}
{"text": "可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.一阶谓词逻辑缺点●有限的可用性。"}
{"text": "一阶逻辑的逻辑归结只是半可判定性的。"}
{"text": "●无法表示不确定性知识。"}
{"text": "2.2.2霍恩子句和霍恩逻辑霍恩子句（Horn_Clause）得名于逻辑学家Alfred_Horn[6]。"}
{"text": "一个子句是文字的析取。"}
{"text": "霍恩子句是带有最多一个肯定（positive）文字的子句，肯定文字指的是没有否定符号的文字。"}
{"text": "例如，Øp1∨…∨Øpn∨_q是一个霍恩子句，它可以被等价地写为（p1∧…∧pn）→q。"}
{"text": "Alfred_Horn于1951年撰文指出这种子句的重要性。"}
{"text": "霍恩逻辑（Horn_Logic）是一阶逻辑的子集。"}
{"text": "基于霍恩逻辑的知识库是一个霍恩规则的集合。"}
{"text": "一个霍恩规则由原子公式构成：B1∧…∧Bn→H，其中H是头原子公式，B1,…,Bn是体原子公式。"}
{"text": "事实是霍恩规则的特例，它们是没有体原子公式且没有变量的霍恩Berners-Lee）是一个事实，可以简写为图灵奖得主规则。"}
{"text": "例如，→图灵奖得主（Tim（Tim_Berners-Lee）。"}
{"text": "1.霍恩逻辑的优点●结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "●严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "●易实现性。"}
{"text": "可判定，可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.霍恩逻辑的缺点●有限的表达能力。"}
{"text": "不能定义类表达式，不能够任意使用量化。"}
{"text": "●无法表示不确定性知识。"}
{"text": "2.2.3语义网络语义网络是由Quillian等人提出用于表达人类的语义知识并且支持推理[3]。"}
{"text": "语义网络又称联想网络，它在形式上是一个带标识的有向图。"}
{"text": "图中“节点”用以表示各种事物、概念、情况、状态等。"}
{"text": "每个节点可以带有若干属性。"}
{"text": "节点与节点间的“连接弧”（称为联想弧）用以表示各种语义联系、动作。"}
{"text": "语义网络的单元是三元组：（节点1，联想弧，节点2）。"}
{"text": "例如（Tim_Berners-Lee，类型，图灵奖得主）和（Tim_Berners-Lee，发明，互联网）是三元组。"}
{"text": "由于所有的节点均通过联想弧彼此相连，语义网络可以通过图上的操作进行知识推理。"}
{"text": "1.语义网络的优点1）联想性。"}
{"text": "它最初是作为人类联想记忆模型提出来的。"}
{"text": "2）易用性。"}
{"text": "直观地把事物的属性及其语义联系表示出来，便于理解，自然语言与语义网络的转换比较容易实现，故语义网络表示法在自然语言理解系统中的应用最为广泛。"}
{"text": "3）结构性。"}
{"text": "语义网络是一种结构化的知识表示方法，对数据子图特别有效。"}
{"text": "它能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2.语义网络的缺点1）无形式化语法。"}
{"text": "语义网络表示知识的手段多种多样，虽然灵活性很高，但同时也由于表示形式的不一致提高了对其处理的复杂性。"}
{"text": "例如，“每个学生都读过一本书”可以表示为多种不同的语义网络，例如图2-2和图2-3中的语义网络。"}
{"text": "在图2-2中，GS表示一个概念节点，指的是具有全称量化的一般事件，g是一个实例节点，代表GS中的一个具体例子，而s是一个全称变量，是学生这个概念的一个个体，r和b都是存在变量，其中r是读这个概念的一个个体，b是书这个概念的一个个体，F指g覆盖的子空间及其具体形式，而∀代表全称量词。"}
{"text": "而图2-3则把“每个学生都读过一本书”表示成：任何一个学生s1都是属于读过一本书这个概念的元素。"}
{"text": "图2-3表示“每个学生都读过一本书”的语义网络2）无形式化语义。"}
{"text": "与一阶谓词逻辑相比，语义网络没有公认的形式表示体系。"}
{"text": "一个给定的语义网络表达的含义完全依赖处理程序如何对它进行解释。"}
{"text": "通过推理网络而实现的推理不能保证其正确性。"}
{"text": "此外，目前采用量词（包括全称量词和存在量词）的语义网络表示法在逻辑上是不充分的，不能保证不存在二义性。"}
{"text": "2.2.4框架框架（Frame）最早由Marvin_Minsky在1975年提出[7]，目标是更好地理解视觉推理和自然语言处理。"}
{"text": "其理论的基本思想是：认为人们对现实世界中各种事物的认识都以一种类似于框架的结构存储在记忆中。"}
{"text": "当面临一个新事物时，就从记忆中找出一个合适的框架，并根据实际情况对其细节加以修改、补充，从而形成对当前事物的认识。"}
{"text": "框架是一种描述对象（事物、事件或概念等）属性的数据结构。"}
{"text": "在框架理论中，类是知识表示的基本单位。"}
{"text": "每个类有一些槽，每个槽又可分为若干“侧面”。"}
{"text": "一个槽用于表示描述对象的一个属性，而一个侧面用语表示槽属性的一个方面，槽和侧面都可以有属性值，分别称为槽值和侧面值。"}
{"text": "除此之外，框架还允许给属性设默认值，以及设立触发器以维护框架。"}
{"text": "1）下面是框架的基本组成的一个示例：2）表2-1给出一个带变量框架实例。"}
{"text": "如果把框架“tx未遂杀人案”的变量赋值，可以得到下面的一个框架实例，如表2-2所示。"}
{"text": "表2-1带变量框架实例表2-2变量赋值框架实例1.框架的优点1）结构性：能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2）框架对于知识的描述比较全面，支持默认值以及触发器。"}
{"text": "2.框架的缺点1）框架的构建成本非常高，对知识库的质量要求非常高。"}
{"text": "2）默认值会增大推理的复杂度。"}
{"text": "3）无法表示不确定性知识。"}
{"text": "2.2.5描述逻辑描述逻辑是一阶逻辑的一个可判定子集。"}
{"text": "最初由Ronald_J.Brachman在1985年提出。"}
{"text": "描述逻辑可以被看成是利用一阶逻辑对语义网络和框架进行形式化后的产物。"}
{"text": "描述逻辑一般支持一元谓词和二元谓词。"}
{"text": "一元谓词称为类，二元谓词称为关系。"}
{"text": "描述逻辑的重要特征是同时具有很强的表达能力和可判定性。"}
{"text": "描述逻辑近年来受到广泛关注，被选为W3C互联网本体语言（OWL）的理论基础。"}
{"text": "1.描述逻辑的优点1）结构性。"}
{"text": "能把事物的属性以及事物间的各种语义联想显式地表示出来。"}
{"text": "2）严密性。"}
{"text": "有形式化的语法和语义，以及相关的推理规则。"}
{"text": "3）多样性。"}
{"text": "具有大量可判定的扩展，以满足不同应用场景的需求。"}
{"text": "4）易实现性。"}
{"text": "可判定，可以转换为计算机内部形式，以便用算法实现。"}
{"text": "2.描述逻辑的缺点1）有限的表达能力。"}
{"text": "不支持显式使用变量，不能够任意使用量化。"}
{"text": "2）无法表示不确定性知识。"}
{"text": "2.3互联网时代的语义网知识表示框架随着语义网的提出，知识表示迎来了新的契机和挑战，契机在于语义网为知识表示提供了一个很好的应用场景，挑战在于面向语义网的知识表示需要提供一套标准语言可以用来描述Web的各种信息。"}
{"text": "早期Web的标准语言HTML和XML无法适应语义网对知识表示的要求，所以W3C提出了新的标准语言RDF、RDFS和OWL。"}
{"text": "这两种语言的语法可以跟XML兼容。"}
{"text": "下面详细介绍这几种语言。"}
{"text": "2.3.1RDF和RDFSRDF是W3C的RDF工作组制定的关于知识图谱的国际标准。"}
{"text": "RDF是W3C一系列语义网标准的核心，如图2-4所示。"}
{"text": "●表示组（Representation）包括URI/IRI、XML和RDF。"}
{"text": "前两者主要是为RDF提供语法基础。"}
{"text": "●推理组（Reasoning）包括RDF-S、本体OWL、规则RIF和统一逻辑。"}
{"text": "统一逻辑目前还没有定论。"}
{"text": "●信任组和用户互动组。"}
{"text": "图2-4对W3C的语义网标准栈做了分组。"}
{"text": "目前，跟知识图谱最相关的有：图2-4W3C的语义网标准栈及其分组2006年，人们开始用RDF发布和链接数据，从而生成知识图谱，比较知名的有DBpedia、Yago和Freebase。"}
{"text": "2009年，Tim_Berners-Lee为进一步推动语义网开放数据的发展，进一步提出了开放链接数据的五星级原则，如表2-3所示。"}
{"text": "表2-3开放链接数据的五星级原则Tim_Berners-Lee提出了实现五星级原则的四个步骤：●使用URIs对事物命名；●使用HTTP_URIs，以方便搜索；●使用RDF描述事物并提供SPARQL端点，以方便对RDF图谱查询；●链接不同的图谱（例如通过owl:sameAs），以方便数据重用。"}
{"text": "2007年，不少开放图谱实现与DBpedia链接。"}
{"text": "如图2-5为开放链接数据早期的发展。"}
{"text": "图2-5开放链接数据早期的发展1.RDF简介在RDF中，知识总是以三元组的形式出现。"}
{"text": "每一份知识可以被分解为如下形式：(subject,predicate,object)。"}
{"text": "例如，“IBM邀请Jeff_Pan作为讲者，演讲主题是知识图谱”可以写成以下RDF三元组：（IBM-Talk,speaker,Jeff）,（IBM-Talk,theme,KG）。"}
{"text": "RDF中的主语是一个个体（Individual），个体是类的实例。"}
{"text": "RDF中的谓语是一个属性。"}
{"text": "属性可以连接两个个体，或者连接一个个体和一个数据类型的实例。"}
{"text": "换言之，RDF中的宾语可以是一个个体，例如（IBM-Talk,speaker,Jeff）也可以是一个数据类型的实例，例如（IBM-Talk,talkDate,“05-10-2012”^xsd:date）。"}
{"text": "如果把三元组的主语和宾语看成图的节点，三元组的谓语看成边，那么一个RDF知识库则可以被看成一个图或一个知识图谱，如图2-6所示。"}
{"text": "三元组则是图的单元。"}
{"text": "在RDF中，三元组中的主谓宾都有一个全局标识URI，包括以上例子中的Jeff、IBM_Talk_和KG，如图2-7所示。"}
{"text": "图2-6一个RDF知识库可以被看成一个图图2-7三元组的全局标识URI全局标识URI可以被简化成前缀URI，如图2-8所示。"}
{"text": "RDF允许没有全局标识的空白节点（Blank_Node）。"}
{"text": "空白节点的前缀为“_”。"}
{"text": "例如，Jeff是某一次关于KG讲座的讲者，如图2-9所示。"}
{"text": "图2-8前缀URI图2-9没有全局标识的空白节点RDF是抽象的数据模型，支持不同的序列化格式，例如RDF/XML、Turtle和N-Triple，如图2-10所示。"}
{"text": "图2-10不同的序列化格式2.开放世界假设不同于经典数据库采用封闭世界假设，RDF采用的是开放世界假设。"}
{"text": "也就是说，RDF的开放性特点和要求。"}
{"text": "（IBM-图谱里的知识有可能是不完备的，这符合Web讲座只有一位讲者。"}
{"text": "换一个角度，（IBM-Talk,speaker,Jeff）并不意味着Talk,speaker,Jeff）意味着IBM讲座至少有一位讲者。"}
{"text": "采用开放世界假设意味着RDF图谱可以被分布式储存，如图2-11所示。"}
{"text": "IBM图2-11RDF图谱可以被分布式储存同时，分布式定义的知识可以自动合并，如图2-12所示。"}
{"text": "图2-12分布式定义的知识可以自动合并3.RDFS简介RDF用到了类以及属性描述个体之间的关系。"}
{"text": "这些类和属性由模式（schema）定义。"}
{"text": "RDF_Schema（RDF模式，简称RDFS）提供了对类和属性的简单描述，从而给RDF数据提供词汇建模的语言。"}
{"text": "更丰富的定义则需要用到OWL本体描述语言。"}
{"text": "RDFS提供了最基本的对类和属性的描述元语：●rdf:type：用于指定个体的类；●rdfs:subClassOf：用于指定类的父类；●rdfs:subPropertyOf：用于指定属性的父属性；●rdfs:domain：用于指定属性的定义域；●rdfs:range：用于指定属性的值域。"}
{"text": "举例来说，下面的三元组表示用户自定义的元数据Author是Dublin_Core的元数据Creator的子类，如图2-13所示。"}
{"text": "RDF_Schema通过这样的方式描述不同词汇集的元数据之间的关系，从而为网络上统一格式的元数据交换打下基础。"}
{"text": "下面用图2-14说明RDFS，为了简便，边的标签省略了RDF或者RDFS。"}
{"text": "知识被分为两类，一类是数据层面的知识，例如haofen_type_Person（haofen是Person类的一个实例），另外一类是模式层面的知识，例如speaker_domainPerson（speaker属性的定义域是Person类）。"}
{"text": "图2-13Author是Creator的子类图2-14RDFS示例2.3.2OWL和OWL2Fragments前面介绍了RDF和RDFS，通过RDF（S）可以表示一些简单的语义，但在更复杂的场景下，RDF（S）语义的表达能力显得太弱，还缺少常用的特征：（1）对于局部值域的属性定义。"}
{"text": "RDF（S）中通过rdfs:range定义了属性的值域，该值域是全局性的，无法说明该属性应用于某些具体的类时具有的特殊值域限制，如无法声明父母至少有一个孩子。"}
{"text": "（2）类、属性、个体的等价性。"}
{"text": "RDF（S）中无法声明两个类或多个类、属性和个体是等价还是不等价，如无法声明Tim-Berns_Lee和T.B.Lee是同一个人。"}
{"text": "（3）不相交类的定义。"}
{"text": "在RDF（S）中只能声明子类关系，如男人和女人都是人的子类，但无法声明这两个类是不相交的。"}
{"text": "（4）基数约束。"}
{"text": "即对某属性值可能或必需的取值范围进行约束，如说明一个人有双亲（包括两个人），一门课至少有一名教师等。"}
{"text": "（5）关于属性特性的描述。"}
{"text": "即声明属性的某些特性，如传递性、函数性、对称性，以及声明一个属性是另一个属性的逆属性等，如大于关系的逆关系是小于关系。"}
{"text": "为了得到一个表达能力更强的本体语言，W3C提出了OWL语言扩展RDF（S），作为在语义网上表示本体的推荐语言。"}
{"text": "W3C于2002年7月31日发布了OWL_Web_本体语言（OWL_Web_Ontology_Language）工作草案的细节，是为了更好地开发语义网。"}
{"text": "1.OWL的语言特征如图2-15所示，OWL1.0有OWL_Lite、OWL_DL、OWL_Full三个子语言，三个子语言的特征和使用限制举例如表2-4所示。"}
{"text": "图2-15OWL_1.0的主要子语言表2-4三个子语言的特征和使用限制举例可以采用以下原则选择这些语言：●选择OWL_Lite还是OWL_DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性；●选择OWL_DL还是OWL_Full主要取决于用户在多大程度上需要RDF的元模型机制，如定义类型的类型以及为类型赋予属性；●当使用OWL_Full而不是OWL_DL时，推理的支持可能不能工作，因为目前还没有完全支持OWL_Full的系统实现。"}
{"text": "OWL的子语言与RDF有以下关系。"}
{"text": "首先，OWL_Full可以看成是RDF的扩展；其次，OWL_Lite和OWL_Full可以看成是一个约束化的RDF的扩展；再次，所有的OWL文Full文档；最档（Lite、DL、Full）都是一个RDF文档，所有的RDF文档都是一个OWL后，只有一些RDF文档是一个合法的OWL_Lite和OWL_DL文档。"}
{"text": "2.OWL的重要词汇（1）等价性声明。"}
{"text": "声明两个类、属性和实例是等价的。"}
{"text": "如：exp：运动员owl:equivalentClass_exp：体育选手exp：获得_owl:equivalentProperty_exp：取得exp：运动员A_owl:sameIndividualAs_exp：小明以上三个三元组分别声明了两个类、两个属性以及两个个体是等价的，exp_是命名空间_http://www.example.org_的别称，命名空间是唯一识别的一套名字，用来避免名字冲突，在OWL中可以是一个URL。"}
{"text": "（2）属性传递性声明。"}
{"text": "声明一个属性是传递关系。"}
{"text": "例如，exp:ancestor_rdf:typeowl:TransitiveProperty指的是exp:ancestor_是一个传递关系。"}
{"text": "如果一个属性被声明为传递，则由a_exp:ancestor_b和b_exp:ancestor_c可以推出a_exp:ancestor_c。"}
{"text": "例如exp：小明exp:ancestor_exp：小林；exp：小林_exp:ancestor_exp：小志，根据上述声明，可以推出exp：小明exp:ancestor_exp：小志。"}
{"text": "（3）属性互逆声明。"}
{"text": "声明两个属性有互逆的关系。"}
{"text": "例如，exp:ancestor_owl:inverseOfexp:descendant指的是exp:ancestor和exp:descendant是互逆的。"}
{"text": "如果exp：小明exp:ancestor_exp：小林，根据上述声明，可以推出exp：小林_exp:descendant_exp：小明。"}
{"text": "（4）属性的函数性声明。"}
{"text": "声明一个属性是函数。"}
{"text": "例如，exp:hasMother_rdf:typeowl:FunctionalProperty指的是exp:hasMother是一个函数，即一个生物只能有一个母亲。"}
{"text": "（5）属性的对称性声明。"}
{"text": "声明一个属性是对称的。"}
{"text": "例如rdf:typeowl:SymmetricProperty指的是exp:friend是一个具有对称性的属性；如果exp：小明exp:friendexp：小林，根据上述声明，有exp：小林_exp:friend_exp：小明。"}
{"text": "exp:friend（6）属性的全称限定声明。"}
{"text": "声明一个属性是全称限定。"}
{"text": "如：exp:Person_owl:allValuesFrom_exp:Womenexp:Person_owl:onProperty_exp:hasMother这个说明exp:hasMother_在主语属于exp:Person类的条件下，宾语的取值只能来自exp:Women类。"}
{"text": "（7）属性的存在限定声明。"}
{"text": "声明一个属性是存在限定。"}
{"text": "如：exp:SemanticWebPaper_owl:someValuesFrom_exp:AAAIexp:SemanticWebPaper_owl:onProperty_exp:publishedIn这个说明exp:publishedIn在主语属于exp:SemanticWebPaper类的条件下，宾语的取值部分来自exp:AAAI类。"}
{"text": "上面的三元组相当于：关于语义网的论文部分发表在AAAI上。"}
{"text": "（8）属性的基数限定声明。"}
{"text": "声明一个属性的基数。"}
{"text": "如：exp:Person_owl:cardinality“1”^^xsd:integerexp:Person_owl:onProperty_exp:hasMother指的是exp:hasMother在主语属于exp:Person类的条件下，宾语的取值只能有一个，“1”的数据类型被声明为xsd:integer，这是基数约束，本质上属于属性的局部约束。"}
{"text": "（9）相交的类声明。"}
{"text": "声明一个类是等价于两个类相交。"}
{"text": "如：exp:Mother_owl:intersectionOf_tmp_tmp_rdf:type_rdfs:Collection_tmp_rdfs:member_exp:Person_tmp_rdfs:member_exp:HasChildren指tmp是临时资源，它是exp:Person和exp:HasChildren两个类的交集。"}
{"text": "exp:HasChildren。"}
{"text": "上述三元组说明rdfs:Collection类型，是一个容器，它的两个成员是exp:Person和exp:Mother是此外，OWL还有如表2-5所示词汇扩展。"}
{"text": "表2-5OWL词汇扩展3.OWL版本目前，OWL2是OWL的最新版本，老的OWL版本也被称为OWL1。"}
{"text": "OWL2定义了一些OWL的子语言，通过限制语法使用，使得这些子语言能够更方便地实现，以及服务不同的应用。"}
{"text": "OWL2的三大子语言是OWL_2_RL、OWL_2_QL和OWL_2_EL。"}
{"text": "OWL_2_QL是OWL2子语言中最为简单的，QL代表Query_Language，所以OWL_2_QL是专为基于本体的查询设计的。"}
{"text": "它的查询复杂度是AC0，非常适合大规模处理。"}
{"text": "它是基于描述逻辑DL-Lite定义的。"}
{"text": "表2-6给出了OWL_2_QL词汇总结。"}
{"text": "表2-6OWL_2_QL词汇总结另外一个能够提供多项式推理的OWL是OWL_2_EL。"}
{"text": "与OWL_2_QL不同，OWL_2_EL专为概念术语描述、本体的分类推理而设计，广泛应用在生物医疗领域，如临床医疗术语本体SNOMED_CT。"}
{"text": "OWL_2_EL的分类复杂度是Ptime-Complete，它是基于描述逻辑语言EL++定义的。"}
{"text": "表2-7给出了OWL_2_QL词汇总结。"}
{"text": "表2-7OWL_2_QL词汇总结例如，OWL_2_EL允许表达如下复杂的概念：Female⊓∃likes.Movie⊓∃hasSon.(Student⊓∃attends.CSCourse)指的是所有喜欢电影、儿子是学生且参加计算机课程的女性。"}
{"text": "下面给出一个例子。"}
{"text": "假设有一个本体，包含以下公理：公理1.Apple⊑∃beInvestedBy.(Fidelity⊓BlackStone)：苹果由富达和黑石投资。"}
{"text": "公理2.∃beFundedBy.Fidelity⊑InnovativeCompanies：借助富达融资的公司都是创新企业。"}
{"text": "公理3.∃beFundedBy.BlackStone⊑InnovativeCompanies：借助黑石融资的公司都是创新企业。"}
{"text": "公理4.beInvestedBy⊑beFundedBy：投资即是帮助融资。"}
{"text": "由公理1可以推出公理5:Apple⊑∃beInvestedBy.Fidelity；由公理5和公理4可以推出公⊑⊑∃beFundedBy.Fidelity；最后，由公理6和公理2可以推出公理7:Apple理6:Apple_InnovativeCompanies。"}
{"text": "还有一个推理复杂度是多项式时间的OWL2子语言叫OWL_2_RL。"}
{"text": "OWL_2_RL扩展了RDFS的表达能力，在RDFS的基础上引入属性的特殊特性（函数性、互反性和对称性），允许声明等价性，允许属性的局部约束。"}
{"text": "OWL_2_RL_的推理是一种前向链推理，即将推理规则应用到OWL_2_RL本体，得到新的知识，即OWL_2_RL推理是针对实例数据的推理。"}
{"text": "下面给出两个OWL_2_RL上的推理规则：p_rdfs:domain_x,spo⇒s_rdf:type_xp_rdfs:range_x,spo⇒o_rdf:type_x其中，s、p、o、x为变量。"}
{"text": "第一条规则表示如果属性p的定义域是类x，而且实例s和o有关系p（这里把属性与关系看成是一样的），那么实例s是类x的一个元素。"}
{"text": "第二条规则表示如果属性p的值域是类x，而且实例s和o有关系p，那么实例o是类x的一个元素。"}
{"text": "例如exp:hasChild_rdfs:domain_exp:Person,exp:Helen_exp:hasChild_exp:Jack，由第一条规则可以推出_exp:Helen_rdf:type_exp:Person。"}
{"text": "OWL_2_RL允许的核心词汇有：●rdfs:subClassOf；●rdfs:subPropertyOf；●rdfs:domain；●rdfs:range；●owl:TransitiveProperty；●owl:FunctionalProperty；●owl:sameAs；●owl:equivalentClass；●owl:equivalentProperty；●owl:someValuesFrom；●owl:allValuesFrom。"}
{"text": "OWL_2_RL的前向链推理复杂度是PTIME完备的，PTIME复杂度是针对实例数据推理得到的结果。"}
{"text": "2.3.3知识图谱查询语言的表示RDF支持类似数据库的查询语言，叫作SPARQL[1]，它提供了查询RDF数据的标准语法、处理SPARQL查询的规则以及结果返回形式。"}
{"text": "1.SPARQL知识图谱查询基本构成●变量，RDF中的资源，以“?”或者“$”指示；●三元组模板，在WHERE子句中列出关联的三元组模板，之所以称为模板，因为三元组中允许存在变量；●SELECT子句中指示要查询的目标变量。"}
{"text": "下面是一个简单的SPARQL查询例子：这个SPARQL查询指的是查询所有选修CS328课程的学生，PREFIX部分进行命名空间的声明，使得下面查询的书写更为简洁。"}
{"text": "2.常见的SPARQL查询算子（1）OPTIONAL。"}
{"text": "可选算子，指的是在这个算子覆盖范围的查询语句是可选的。"}
{"text": "例如：指的是查询所有选修CS328课程的学生姓名，以及他们的邮箱。"}
{"text": "OPTIONAL关键字指示如果没有邮箱，则依然返回学生姓名，邮箱处空缺。"}
{"text": "（2）FILTER。"}
{"text": "过滤算子，指的是这个算子覆盖范围的查询语句可以用来过滤查询结果。"}
{"text": "例如：指的是查询学生姓名、选修课程以及他们的年龄；如果有年龄，则年龄必须大于25岁。"}
{"text": "（3）UNION。"}
{"text": "并算子，指的是将两个查询的结果合并起来。"}
{"text": "例如：指的是查询选修课程CS328或CS909的学生姓名以及邮件。"}
{"text": "注意，这里的邮件是必须返回的，如果没有邮件值，则不返回这条记录。"}
{"text": "需要注意UNION和OPTIONAL的区别。"}
{"text": "下面给出一个SPARQL查询的例子。"}
{"text": "给定一个RDF数据集：以及一个SPARQL查询：这个SPARQL查询期望查询所有的收购关系，可以得到查询结果如表2-8所示。"}
{"text": "表2-8查询结果给定论文一个SPARQL查询：这个查询期望查询所有具备关联交易的公司。"}
{"text": "假设有下面两条规则：hold_share（X,Y）:-control（X,Y）conn_trans（Y,Z）:-hold_share（X,Y）,hold_share（X,Z）第一条规则指的是如果X控制了Y，那么X控股Y；第二条规则指的是如果X同时控股Y和Z，那么Y和Z具备关联交易。"}
{"text": "通过查询重写技术，可以得到下面的SPARQL查询：但是这个查询比较复杂，可以通过下面的SPARQL查询简化：在这个查询中，SPARQL允许嵌套查询，即WHERE子句中包含SELECT子句。"}
{"text": "2.3.4语义Markup表示语言语义网进一步定义了在网页中嵌入语义Markup的方法和表示语言。"}
{"text": "被谷歌知识图谱以及Schema.Org采用的语义Markup语言主要包括JSON-LD、RDFa和HTML5MicroData。"}
{"text": "1.JSON-LDJSON-LD（JavaScript_Object_Notation_for_Linked_Data）是一种基于JSON表示和传输链接数据的方法。"}
{"text": "JSON-LD描述了如何通过JSON表示有向图，以及如何在一个文档中混合表示链接数据及非链接数据。"}
{"text": "JSON-LD的语法和JSON兼容。"}
{"text": "JSON-LD处理算法和API（JSON-LD_Processing_Algorithms_and_API）描述了处理JSON-LD数据所需的算法及编程接口，通过这些接口可以在JavaScript、Python及Ruby等编程环境中直接对JSON-LD文档进行转换和处理。"}
{"text": "下面是一个简单的JSON例子：JSON文档表示一个人。"}
{"text": "人们很容易推断这里的含义：“name”是人的名字，“homepage”是其主页，“image”是其某种照片。"}
{"text": "当然，机器不理解“name”和“image”这样的术语。"}
{"text": "JSON-LD通过引入规范的术语表示，例如统一化表示“name”、“homepage”和“image”的URI，使得数据交换和机器理解成为基础。"}
{"text": "如下所示：可以看出，JSON-LD呈现出语义网技术的风格，它们有着类似的目标：围绕某类知识提供共享的术语。"}
{"text": "例如，每个数据集不应该围绕“name”重复发明概念。"}
{"text": "但是，JSON-LD的实现没有选择大部分语义网技术栈（TURTLE/SPARQL/Quad单、不复杂以及面向一般开发人员的方式推进。"}
{"text": "Stores），而是以简2.RDFaRDFa（Resource_Description_Framework_in_attributes）是一种早期网页语义标记语言。"}
{"text": "RDFa也是W3C推荐标准。"}
{"text": "它扩充了XHTML的几个属性，网页制作者可以利用这些属性在网页中添加可供机器读取的资源。"}
{"text": "与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中，它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组。"}
{"text": "RDFa通过引入名字空间的方法，在已有的标签中加入RDFa相应的属性，以便解析支持RDFa技术的浏览器或者搜索引擎，从而达到优化的目的。"}
{"text": "上面的代码示例中用到了RDFa属性中的about属性和property属性。"}
{"text": "这段代码示例说明了一篇文章，然后描述了和这篇文章相关的信息，例如标题、创建者和创建日期，就可以让支持RDFa的机器识别这些属性。"}
{"text": "RDFa可以从机器可理解的层面优化搜索，提升访问体验以及网页数据的关联。"}
{"text": "3.HTML5_MicrodataMicrodata（微数据）是在网页标记语言中嵌入机器可读的属性数据。"}
{"text": "微数据使用自定义词汇表、带作用域的键值对给DOM做标记，用户可以自定义微数据词汇表，在自己的网页中嵌入自定义的属性。"}
{"text": "微数据是给那些已经在页面上可见的数据施加额外的语义，当HTML的词汇不够用时，使用微数据可以取得较好的效果。"}
{"text": "下面是一个HTML5Microdata的示例。"}
{"text": "这个例子给出了Person类下一个叫Andy的人的照片和URL地址。"}
{"text": "通过HTML5Microdata，浏览器可以很方便地从网页上提取微数据实体、属性及属性值。"}
{"text": "2.4常见开放域知识图谱的知识表示方法不同的知识图谱项目都会根据实际的需要选择不同的知识表示框架。"}
{"text": "这些框架有不同的描述术语、表达能力、数据格式等方面的考虑，但本质上有相似之处。"}
{"text": "这里以三个最典型的开放域知识图谱（Freebase、Wikidata、ConceptNet）为例，尝试比较不同的知识图谱项目选用的知识表示框架，并总结影响知识表示框架选择的主要因素。"}
{"text": "为便于比较分析，以RDF、OWL的描述术语和表达能力为主要比较对象。"}
{"text": "2.4.1FreebaseFreebase的知识表示框架主要包含如下几个要素：对象-Object、事实-Facts、类型-ID，称为MIDTypes和属性-Properties。"}
{"text": "“Object”代表实体。"}
{"text": "每一个“Object”有唯一的（Machine_ID）。"}
{"text": "一个“Object”可以有一个或多个“Types”。"}
{"text": "“Properties”用来描述“Facts”。"}
{"text": "例如，“Barack_Obama”是一个Object，并拥有一个唯一的MID:“/m/02mjmr”。"}
{"text": "这个Object是“/government/us_president”，并有一个称的一个为“/government/us_president/presidency_number”的Property，其数值是“44”。"}
{"text": "Freebase使用复合值类型（Compound_Value_Types,CVT）处理多元关系。"}
{"text": "type如图2-16所示，示例的CVT描述了关于Obama的任职期限的多元关系“government_position_held”。"}
{"text": "这个多元关系包含多个子二元关系：“office_holder”“office_position”“from”“to”等。"}
{"text": "一个CVT就是有唯一MID的Object，也可以有多个Types。"}
{"text": "为了以示区别，Freebase把所有非CVT的Object也称为“Topic”。"}
{"text": "图2-16Freebase的知识表示结构示例2.4.2WikidataWikidata的知识表示框架主要包含如下要素：页面-Pages、实体-Entities、条目-Items、属性-Properties、陈述-Statements、修饰-Qualifiers、引用-Reference等。"}
{"text": "Wikidata起源于Wikipedia，因此与Wikipedia一样，以页面“Page”为基本的组织单元。"}
{"text": "Entities类似于OWL:Things，代指最顶层的对象。"}
{"text": "每一个Entity都有一个独立的维基页面。"}
{"text": "Entities主要有两类：Items和Properties。"}
{"text": "Items类似于RDF中的Instance，代指实例对象。"}
{"text": "Properties和Statements分别等价于RDF中的Property和Statement。"}
{"text": "通常一个Item的页面还包含多个别名-aliases和多个指向Wikipedia的外部链接-Sitelinks。"}
{"text": "每个Entities有多个Statements。"}
{"text": "一个Statement包含一个Property、一个或多个Values、一个或多个Qualifiers、一个或多个References、一个标识重要性程度的Rank。"}
{"text": "修饰-Qualifiers用于处理复杂的多元表示。"}
{"text": "如一个陈述“spouse:Jane_Belson”描述了一个二元关系。"}
{"text": "可以使用Qualifiers给这个陈述增加多个附加信息来刻画多元关系，如“startdate:25_November_1991”and“end_date:11_May_2011”等。"}
{"text": "引用-References用于标识每个陈述的来源或出处，如来源于某个维基百科页面等。"}
{"text": "引用也是一种Qualifiers，通常添加到Statements的附加信息中。"}
{"text": "Wikidata支持多种数值类型，包括其自有的Item类型、RDF_Literal、URL、媒体类型Commons_Media，以及Time、Globe_coordinates和Quantity三种复杂类型。"}
{"text": "Wikidata允许给每个Statement增加三种权重：normal（缺省）、preferred和deprecated。"}
{"text": "Wikidata定义了三种Snacks作为Statement的具体描述结构：PropertyValueSnack、PropertyNoValueSnack、PropertySomeValueSnack。"}
{"text": "PropertyNoValueSnack类似于OWL中的Negation，表示类似于“Elizabeth_spouse”的知识。"}
{"text": "PropertySomeValueSnack类似于OWL中的存在量词someValuesFrom，表示类似于“PopeLinus_had_a_date_of_birth,but_it_is_unknown_to_us”这样的知识。"}
{"text": "of_England_had_no_I_Wikidata的URI机制遵循了Linked_Open_Data的URI原则，采用统一的URI机制：Item，如Q49，或者一个http://www.wikidata.org/entity/<id>。"}
{"text": "其中，<id>可以是一个Property，如P234。"}
{"text": "2.4.3ConceptNet5ConceptNet5的知识表示框架主要包含如下要素：概念-Concepts、词-Words、短语-Phrases、断言-Assertions、关系-Relations、边-Edges。"}
{"text": "Concepts由Words或Phrases组成，构成了图谱中的节点。"}
{"text": "与其他知识图谱的节点不同，这些Concepts通常是从自然语言文本中提取出来的，更接近自然语言描述，而不是形式化的命名。"}
{"text": "Assertions描述了Concepts之间的关系，类似于RDF中的Statements。"}
{"text": "Edges类似于RDF中的Property。"}
{"text": "一个Concepts包含多条边，而一条边可能有多个产生来源。"}
{"text": "例如，一个“化妆Cause漂亮”的断言可能来源于文本抽取，也可能来源于用户的手工输入。"}
{"text": "来源越多，该断言就越可靠。"}
{"text": "ConceptNet5根据来源的多少和可靠程度计算每个断言的置信度。"}
{"text": "ConceptNet5示例如图2-17所示。"}
{"text": "ConceptNet5中的关系包含21个预定义的、多语言通用的关系，如IsA、UsedFor等，以及从自然语言文本中抽取的更加接近自然语言描述的非形式化的关系，如of,caused_by等。"}
{"text": "on_top图2-17ConceptNet5示例ConceptNet5对URI进行了精心的设计。"}
{"text": "URI同时考虑了类型（如是概念还是关系）、语言、正则化后的概念名称、词性、歧义等因素。"}
{"text": "其中，n代指这是一个名词，basement用于区分歧义。"}
{"text": "在处理表示“x_is_the_first_argument_of_y”这类多元关系的问题上，ConceptNet5把所有关于某条边的附加信息增加为边的属性，如图2-18所示。"}
{"text": "图2-18ConceptNet5的知识表示结构2.5知识图谱的向量表示方法与前面所述的表示方法不同的是，本节要描述的方法是把知识图谱中的实体和关系映射到低维连续的向量空间，而不是使用基于离散符号的表达方式。"}
{"text": "2.5.1知识图谱表示的挑战在前面提到的一些知识图谱的表示方法中，其基础大多是以三元组的方法对知识进行组织。"}
{"text": "在具体的知识库网络中，节点对应着三元组的头实体和尾实体，边对应着三元组的关系。"}
{"text": "虽然这种离散的符号化的表达方式可以非常有效地将数据结构化，但是在当前的大规模应用上也面临着巨大的挑战。"}
{"text": "知识以基于离散符号的方法进行表达，但这些符号并不能在计算机中表达相应语义层面的信息，也不能进行语义计算，对下游的一些应用并不友好。"}
{"text": "在基于网络结构的知识图谱上进行相关应用时，因为图结构的特殊性，应用算法的使用与图算法有关，相关算法具有较高的复杂度，面对大规模的知识库很难扩展。"}
{"text": "数据具有一定的稀疏性，现实中的知识图谱无论是实体还是关系都有长尾分布的情况，也就是某一个实体或关系具有极少的实例样本，这种现象会影响某些应用的准确率。"}
{"text": "从上面的问题可以看出，对于当前的数据量较大的知识图谱、变化各异的应用来说，需要改进传统的表示方法。"}
{"text": "2.5.2词的向量表示方法在介绍有关知识图谱的向量表示方法之前，在此先介绍词的表示方法。"}
{"text": "在自然语言处理领域中，因为离散符号化的词语并不能蕴涵语义信息，所以将词映射到向量空间，这不仅有利于进行相应的计算，在映射的过程中也能使相关的向量蕴涵一定的语义。"}
{"text": "知识图谱中的向量表示方法也在此次有所借鉴。"}
{"text": "1.独热编码传统的独热编码（One-Hot_Encoding）方法是将一个词表示成一个很长的向量，该向量的维度是整个词表的大小。"}
{"text": "对于某一个具体的词，在其独热表示的向量中，除了表示该词编号的维度为1，其余都为0。"}
{"text": "如图2-19所示，假如词Rome的编号为1，则在其独热编码中，仅有维度1是1，其余都是0。"}
{"text": "这种表示方法虽然简单，但是可以看出其并没有编码语义层面的信息，稀疏性非常强，当整个词典非常大时，编码出向量的维度也会很大。"}
{"text": "2.词袋模型词袋模型（Bag-of-Words,BoW）是一种对文本中词的表示方法。"}
{"text": "该方法将文本想象成一个装词的袋子，不考虑词之间的上下文关系，不关心词在袋子中存放的顺序，仅记录每个词在该文本（词袋）中出现的次数。"}
{"text": "具体的方法是先收集所有文本的可见词汇并组成一个词典，再对所有词进行编号，对于每个文本，可以使用一个表示每个词出现次数的向量来表示，该向量的每一个维度的数字表示该维度所指代的词在该文本中出现的次数。"}
{"text": "如图2-20所示，在文本doc1中，Rome出现32次，Paris出现14次，France出现0次。"}
{"text": "图2-19独热编码示例1图2-20独热编码示例23.词向量上面对词的表示方法并没有考虑语义层面的信息，为了更多地表示词与词之间的语义相似程度，提出词的分布式表示，也就是基于上下文的稠密向量表示法，通常称为词向量或词嵌入（Word_Embedding）。"}
{"text": "产生词向量的手段主要有三种：●Count-based。"}
{"text": "基于计数的方法，简单说就是记录文本中词的出现次数。"}
{"text": "●Predictive。"}
{"text": "基于预测的方法，既可以通过上下文预测中心词，也可以通过中心词预测上下文。"}
{"text": "●Task-based。"}
{"text": "基于任务的，也就是通过任务驱动的方法。"}
{"text": "通过对词向量在具体任务上的表现效果对词向量进行学习。"}
{"text": "对词向量的产生方法到现在为止有较多的研究，在本章中并不展开讨论，下面简单介绍经典的开源工具word2vec[8]中包含的CBoW和Skip-gram两个模型。"}
{"text": "CBoW也就是连续词袋模型（Continuous_Bag-of-Words），和之前提到的BoW相似之处在于该模型也不用考虑词序的信息。"}
{"text": "其主要思想是，用上下文预测中心词，从而训练出的词向量包含了一定的上下文信息。"}
{"text": "如图2-21（a）所示，其中wn是中心词，wn−2,wn−1,wn+1,wn+2为该中心词的上下文的词。"}
{"text": "将上下文词的独热表示与词向量矩阵E相乘，提取相应的词向量并求和得到投影层，然后再经过一个Softmax层最终得到输出，输出的每一维表达的就是词表中每个词作为该上下文的中心词的概率。"}
{"text": "整个模型在训练的过程就像是一个窗口在训练语料上进行滑动，所以被称为连续词袋模型。"}
{"text": "Skip-gram的思想与CBoW恰恰相反，其考虑用中心词来预测上下文词。"}
{"text": "如图2-21（b）所示，先通过中心词的独热表示从词向量矩阵中得到中心词的词向量得到投影层，然后经过一层Softmax得到输出，输出的每一维中代表某个词作为输入中心词的上下文出现的概率。"}
{"text": "图2-21CBoW模型在训练好的词向量中可以发现一些词的词向量在连续空间中的一些关系，如图2-22所示。"}
{"text": "vec（Rome）−vec（Italy）≈vec（Paris）−vec（France）可以看出，Roma和Italy之间有is-capital-of的关系，而这种关系恰好也在Paris和France之间出现。"}
{"text": "通过两对在语义上关系相同的词向量相减可以得出相近的结果，可以猜想出Roma和Italy的词向量通过简单的相减运算，得到了一种类似is-capital-of关系的连续向量，而这种关系的向量可以近似地平移到其他具有类似关系的两个词向量之间。"}
{"text": "这也说明了经过训练带有一定语义层面信息的词向量具有一定的空间平移性。"}
{"text": "图2-22词向量在连续空间中的关系上面所说的两个词之间的关系，恰好可以简单地理解成知识图谱中的关系（relation）、（Rome,is-capital-of,Italy）和（Paris,is-capital-of,France），可以看作是知识图谱中的三元组（triple），这对知识图谱的向量表示产生了一定的启发。"}
{"text": "2.5.3知识图谱嵌入的概念为了解决前面提到的知识图谱表示的挑战，在词向量的启发下，研究者考虑如何将知识图谱中的实体和关系映射到连续的向量空间，并包含一些语义层面的信息，可以使得在下游任务中更加方便地操作知识图谱，例如问答任务[9]、关系抽取[10]等。"}
{"text": "对于计算机来说，连续向量的表达可以蕴涵更多的语义，更容易被计算机理解和操作。"}
{"text": "把这种将知识图谱中包括实体和关系的内容映射到连续向量空间方法的研究领域称为知识图谱嵌入（Knowledge_Graph（Representation_Learning）、知识表示学习。"}
{"text": "Embedding）、知识图谱的向量表示、知识图谱的表示学习类似于词向量，知识图谱嵌入也是通过机器学习的方法对模型进行学习，与独热编码、词袋模型的最大区别在于，知识图谱嵌入方法的训练需要基于监督学习。"}
{"text": "在训练的过程中，可以学习一定的语义层信息，词向量具有的空间平移性也简单地说明了这点。"}
{"text": "类似于词向量，经典的知识图谱嵌入模型TransE的设计思想就是，如果一个三元组（h,r,t）成立，那么它们需要符合h+r≈t关系，例如：vec（Rome）+vec（is−capital−of）≈vec（Italy）所以，在知识图谱嵌入的学习过程中，不同的模型从不同的角度把相应的语义信息嵌入知识图谱的向量表示中，如图2-23所示。"}
{"text": "图2-23语义信息嵌入知识图谱的向量表示中2.5.4知识图谱嵌入的优点研究者将目光从传统的知识图谱表示方法转移到知识图谱的嵌入方法，是因为与之前的方法相比，用向量表达实体和关系的知识图谱嵌入方法有很多优点。"}
{"text": "使用向量的表达方式可以提高应用时的计算效率，当把知识图谱的内容映射到向量空间时，相应的算法可以使用数值计算，所以计算的效率也会同时提高。"}
{"text": "用向量表示后，知识图谱将更加适用于当前流行的机器学习算法，例如神经网络等方法。"}
{"text": "因为下游应用输入的并不再是符号，所以可以考虑的方法也不会仅局限于图算法。"}
{"text": "将知识图谱嵌入作为下游应用的预训练向量输入，使得输入的信息不再是孤立的不包含语义信息的符号，而是已经经过一次训练，并且包含一定信息的向量。"}
{"text": "如上所述，知识图谱的嵌入方法可以提高计算的效率，增加下游应用的多样性，并可以作为预训练，为下游模型提供语义支持，所以对其展开的研究具有很大的应用价值和前景。"}
{"text": "2.5.5知识图谱嵌入的主要方法多数知识图谱嵌入模型主要依靠知识图谱中可以直接观察到的信息对模型进行训练，也就是说，根据知识图谱中所有已知的三元组训练模型。"}
{"text": "对于这类方法，常常只需训练出来的实体表示和矩阵表示满足被用来训练的三元组即可，但是这样的结果往往并不能完全满足所有的下游任务。"}
{"text": "所以，当前也有很多的研究者开始关注怎么利用一些除知识图谱之外的额外信息训练知识图谱嵌入。"}
{"text": "这些额外的信息包括实体类型（Entity_Types）、关系路径（Relation_Paths）等。"}
{"text": "根据有关知识图谱嵌入的综述[11]，将知识图谱嵌入的方法分类介绍如下。"}
{"text": "1.转移距离模型转移距离模型（Translational_Distance_Model）的主要思想是将衡量向量化后的知识图谱中三元组的合理性问题，转化成衡量头实体和尾实体的距离问题。"}
{"text": "这一方法的重点是如何设计得分函数，得分函数常常被设计成利用关系把头实体转移到尾实体的合理性的函数。"}
{"text": "受词向量的启发，由词与词在向量空间的语义层面关系，可以拓展到知识图谱中头实体和尾实体在向量空间的关系。"}
{"text": "也就是说，同样可以考虑把知识图谱中的头实体和尾实体映射到向量空间中，且它们之间的联系也可以考虑成三元组中的关系。"}
{"text": "TransE[12]便是受到了词向量中平移不变性的启发，在TransE中，把实体和关系都表示为向量，对于某一个具体的关系（head,relation,tail），把关系的向量表示解释成头实体的向量到尾实体的向量的转移向量（Translation_vector）。"}
{"text": "也就是说，如果在一个知识图谱中，某一个三元组成立，则它的实体和关系需要满足关系head+relation≈tail。"}
{"text": "2.语义匹配模型相比于转移距离模型，语义匹配模型（Semantic_Matching_Models），更注重挖掘向量化后的实体和关系的潜在语义。"}
{"text": "该方向的模型主要是RESCAL[13]以及它的延伸模型。"}
{"text": "RESCAL模型的核心思想是将整个知识图谱编码为一个三维张量，由这个张量分解出一个核心张量和一个因子矩阵，核心张量中每个二维矩阵切片代表一种关系，因子矩阵中每一行代表一个实体。"}
{"text": "由核心张量和因子矩阵还原的结果被看作对应三元组成立的概率，如果概率大于某个阈值，则对应三元组正确；否则不正确。"}
{"text": "其得分函数可以写成DistMul[14]通过限制Mr为对角矩阵简化RESCAL模型，也就是说其限制Mr=diag（r）。"}
{"text": "但因为是对角矩阵，所以存在h⊺diag（r）t=t⊺diag（r）h，也就是说这种简化的模型只天然地假设所有关系是对称的，显然这是不合理的。"}
{"text": "ComplEx[15]模型考虑到复数的乘法不满足交换律，所以在该模型中实体和关系的向量表示不再依赖实数而是放在了复数域，从而其得分函数不具有对称性。"}
{"text": "也就是说，对于非对称的关系，将三元组中的头实体和尾实体调换位置后可以得到不同的分数。"}
{"text": "3.考虑附加信息的模型除了仅仅依靠知识库中的三元组构造知识图谱嵌入的模型，还有一些模型考虑额外的附加信息进行提升。"}
{"text": "实体类型是一种容易考虑的额外信息。"}
{"text": "在知识库中，一般会给每个实体设定一定的类别，例如Rome具有city的属性、Italy具有country的属性。"}
{"text": "最简单的考虑实体类型的方法是在知识图谱中设立类似于IsA这样的可以表示实体属性的关系，例如（Rome,IsA,city）（Italy,IsA,Country）这样的三元组。"}
{"text": "当训练知识图谱嵌入的时候，考虑这样的三元组就可以将属性信息考虑到向量表示中。"}
{"text": "也有一些方法[16]考虑相同类型的实体需要在向量表示上更加接近。"}
{"text": "关系路径也可以称为实体之间的多跳关系（Multi-hop_Relationships），一般就是指可以连接两个实体的关系链，例如（Rome,is−capital−of,Italy）（Italy,is−country−of,Europe）.从Rome到Europe的关系路径就是一条is−capital−of→is−country−of关系链。"}
{"text": "当前很多方法也尝试考虑关系路径来提升嵌入模型，这里的关键问题是考虑如何用相同的向量表达方式来表达路径。"}
{"text": "在基于路径的TransE，也就是PTransE[17]中，考虑了相加、相乘和RNN三种用关系表达关系路径的方法：p=r1+r2+⋯+rlp=r1∙r2∙⋯∙rlci=f（W[ci−1;ri]）.在基于RNN的方法中，令c1=r1并且一直遍历路径中的关系，直到最终p=cn。"}
{"text": "对于某一个知识库中存在的三元组，其两个实体间的关系路径p需要和原本两个实体间关系的向量表示相接近。"}
{"text": "文本描述（Textual_Descriptions）指的是在一些知识图谱中，对实体有一些简要的文本描述，如图2-24所示，这些描述本身具有一定的语义信息，对提高嵌入的质量有一定的提升。"}
{"text": "除了某些知识库本身具有的文本描述，也可以使用外部的文本信息和语料库。"}
{"text": "Wang[18]提出了一种在知识图谱嵌入的过程中使用文本信息的联合模型，该模型分三个部分：知识模型、文本模型和对齐模型。"}
{"text": "其中，知识模型对知识图谱中的实体和关系做嵌入，这是一个TransE的变种；文本模型对语料库中词语进行向量化，这是一个Skip-gram模型的变种；对齐模型用来保证知识图谱中的实体和关系与单词的嵌入在同一个空间中。"}
{"text": "联合模型在训练时降低来自三个子模型的损失之和。"}
{"text": "图2-24文本描述示例逻辑规则（Logical_Rules）也是常被用来考虑的附加信息，这里讨论的重点主要是霍恩子句，例如简单规则∀x,y:IsDirectorOf（x,y）⇒BeDirectedBy（y,x）说明了两个不同的关系之间的关系。"}
{"text": "Guo[19]提出了一种以规则为指导的知识图谱嵌入方法，其中提出的软规则（Soft_rule）指的是使用AMIE+规则学习方法在知识图谱中挖掘的带有置信度的规则，该方法的整体框架是一个迭代的过程，其中包含两个部分，称为软标签预测阶段（Soft_Label_Prediction）和嵌入修正阶段（Embedding_Rectification）。"}
{"text": "简单来说，就是讲规则学习和知识图谱嵌入学习互相迭代，最后使得知识图谱嵌入可以融入一定的规则信息。"}
{"text": "2.5.6知识图谱嵌入的应用在知识图谱嵌入的发展中，也有很多的相关应用一起发展起来，它们和知识图谱嵌入之间有着相辅相成的关系。"}
{"text": "本小节将简单介绍一些典型的应用。"}
{"text": "1.链接预测链接预测（Link_Prediction）指通过一个已知的实体和关系预测另一个实体，或者通过两个实体预测关系。"}
{"text": "简单来说，也就是（h,r,?）,（?,r,t）,（h,?,t）三种知识图谱的补全任务，被称为链接预测。"}
{"text": "当知识图谱的嵌入被学习完成后，知识图谱嵌入就可以通过排序完成。"}
{"text": "例如需要链接预测(Roma,is-capital-of,?)，可以将知识图谱中的每个实体都放在尾实体的位置上，并且放入相应的知识图谱嵌入模型的得分函数中，计算不同实体作为该三元组的尾实体的得分，也就是该三元组的合理性，得分最高的实体会被作为链接预测的结果。"}
{"text": "链接预测也常被用于评测知识图谱嵌入。"}
{"text": "一般来说，会用链接预测的正确答案的排序评估某种嵌入模型在链接预测上的能力，比较常见的参数有平均等级（Mean_Rank）、平均倒数等级（Mean_Reciprocal_Rank）和命中前n（Hist@n）。"}
{"text": "2.三元组分类三元组分类（Triple_Classification）指的是给定一个完整的三元组，判断三元组的真假。"}
{"text": "这对于训练过的知识图谱向量来说非常简单，只需要把三元组各个部分的向量表达带入相应的知识图谱嵌入的得分函数，三元组的得分越高，其合理性和真实性越高。"}
{"text": "3.实体对齐实体对齐（Entity_Resolution）也称为实体解析，任务是验证两个实体是否指代或者引用的是同一个事物或对象。"}
{"text": "该任务可以删除同一个知识库中冗余的实体，也可以在知识库融合的时候从异构的数据源中找到相同的实体。"}
{"text": "一种方法是，如果需要确定x、y两个实体指代同一个对象有多大可能，则使用知识图谱嵌入的得分函数对三元组(x,EqualTo,y)打分，但这种方法的前提是需要在知识库中存在EqualTo关系。"}
{"text": "也有研究者提出完全根据实体的向量表示判断，例如设计一些实体之间的相似度函数来判断两个实体的相似程度，再进行对齐。"}
{"text": "4.问答系统利用知识图谱完成问答系统是该任务的一个研究方向，该任务的重心是对某一个具体的通过自然语言表达的问题，使用知识图谱中的三元组对其进行回答，如下：A:Where_is_the_capital_of_Italy？Q:Rome（Rome,is-capital-of,Italy）A:Who_is_the_president_of_USA？Q:Donald_Trump（Donald_Trump,is-president-of,USA）文献[9]介绍了一种借助知识图谱嵌入完成该问题的方法。"}
{"text": "简单来说就是设计一种得分函数，使问题的向量表示和其正确答案的向量表示得分较高。"}
{"text": "S（q,a）是被设计出来的得分函数S（q,a）=（Wφ（q））⊺（Wψ（a））.式中，W为包含词语、实体和关系的向量表示的矩阵；φ（q）为词语出现的稀疏向量；ψ（a）为实体和关系出现的稀疏向量。"}
{"text": "简单来说，Wφ（q）和Wψ（a）可以分别表示问题和答案的向量表示。"}
{"text": "当a是q的正确答案时，得分函数S（q,a）被期望得到一个较高的分数，反之亦然。"}
{"text": "5.推荐系统推荐系统的本质是对用户推荐其没有接触过的、但有可能会感兴趣或者购买的服务或产品，包括电影、书籍、音乐、商品等。"}
{"text": "协同过滤算法（Collaborative_Filtering）对用户和物品项目之间的交互进行建模并作为潜在表示取得了很好的效果。"}
{"text": "在知识图谱嵌入的发展下，推荐系统也尝试借助知识图谱的信息提高推荐系统的能力。"}
{"text": "例如，Zhang[20]尝试知识图谱中的三元组、文本信息和图像信息对物品项目进行包含一定语义的编码得到相应的向量表示，然后使用协同过滤算法对用户进行向量表示，对两个向量表示相乘得到分数，得分越高说明该用户越喜好该商品。"}
{"text": "2.7本章小结本章比较全面地介绍了知识图谱的表示与建模方法。"}
{"text": "目前大部分开放知识图谱的表示语言基于RDF、RDFS和OWL，这几个语言是W3C推荐的标准本体语言。"}
{"text": "除了这些标准语言，本章还介绍了知识图谱的查询语言SPARQL和语义Markup语言。"}
{"text": "最后，介绍了知识图谱的嵌入式方法。"}
{"text": "第3章知识存储王鑫天津大学随着知识图谱规模的日益增长，数据管理愈加重要。"}
{"text": "一方面，以文件形式保存的知识图谱显然无法满足用户的查询、检索、推理、分析及各种应用需求；另一方面，传统数据库的关系模型与知识图谱的图模型之间存在显著差异，关系数据库无法有效地管理大规模知识图谱数据。"}
{"text": "为了更好地进行三元组数据的存储，语义万维网领域发展出专门存储RDF数据的三元组库；数据库领域发展出用于管理属性图的图数据库。"}
{"text": "虽然目前没有一种数据库系统被公认为具有主导地位的知识图谱数据库，但可以预见，随着三元组库和图数据库的相互融合发展，知识图谱的存储和数据管理手段将愈加丰富和强大。"}
{"text": "本章首先介绍图数据模型和图查询语言等基本知识；以演示操作的方式讲解各种主流知识图谱数据库，包括基于关系数据库的存储方案、面向RDF的三元组数据库和原生图数据库；以图数据库Neo4j为例介绍图模型数据的底层存储细节，同时梳理图数据索引和查询处理等关键技术；最后，以ApacheJena为例，针对知识图谱数据库开源工具进行实践。"}
{"text": "3.1知识图谱数据库基本知识本节首先介绍目前表示知识图谱的两种主要图数据模型：RDF图和属性图。"}
{"text": "3.1.1知识图谱数据模型从数据模型角度来看，知识图谱本质上是一种图数据。"}
{"text": "不同领域的知识图谱均须遵循相应的数据模型。"}
{"text": "往往一个数据模型的生命力要看其数学基础的强弱，关系模型长盛不衰的一个重要原因是其数学基础为关系代数。"}
{"text": "知识图谱数据模型的数学基础源于有着近300年历史的数学分支——图论。"}
{"text": "在图论中，图是二元组G=（V,E），其中V是节点集合，E是边集合。"}
{"text": "知识图谱数据模型基于图论中图的定义，用节点集合表示实体，用边集合表示实体间的联系，这种一般和通用的数据表示恰好能够自然地刻画现实世界中事物的广泛联系。"}
{"text": "1.RDF图RDF是W3C制定的在语义万维网上表示和交换机器可理解信息的标准数据模型[1]。"}
{"text": "在RDF三元组集合中，每个Web资源具有一个HTTPURI作为其唯一的id；一个RDF图定义为三元组(s,p,o)的有限集合；每个三元组代表一个陈述句，其中s是主语，p是谓语，o是宾语；(s,p,o)表示资源s与资源o之间具有联系p，或表示资源s具有属性p且其取值为o。"}
{"text": "实际上，RDF三元组集合即为图中的有向边集合。"}
{"text": "如图3-1所示，是一个虚构的软件开发公司的社会网络图，其中有张三、李四、王五和赵六4名程序员，有“图数据库”和“RDF三元组库”2个项目；张三认识李四和王五；张三、王五和赵六参加“图数据库”的开发，该项目使用Java语言；王五参加“RDF三元组库”的开发，该项目使用C++语言。"}
{"text": "图3-1RDF图示例值得注意的是，RDF图对于节点和边上的属性没有内置的支持。"}
{"text": "节点属性可用三元组表示，这类三元组的宾语称为字面量，即图中的矩形。"}
{"text": "边上的属性表示起来稍显烦琐，最常见的是利用RDF中一种叫作“具体化”（reification）的技术[2]，需要引入额外的点表示整个三元组，将边属性表示为以该节点为主语的三元组。"}
{"text": "例如在图3-2中，引入节点ex:participate代表三元组(ex:zhangsan，参加，ex:graphdb)，该节点通过RDF内置属性rdf:subject、rdf:predicate和rdf:object分别与代表的三元组的主语、谓语和宾语建立起联系，这样三元组(ex:participate，权重，0.4)就实现了为原三元组增加边属性的效果。"}
{"text": "图3-2RDF图中边属性的表示2.属性图属性图可以说是目前被图数据库业界采纳最广的一种图数据模型[3]。"}
{"text": "属性图由节点集和边集组成，且满足如下性质：（1）每个节点具有唯一的id；（2）每个节点具有若干条出边；（3）每个节点具有若干条入边；（4）每个节点具有一组属性，每个属性是一个键值对；（5）每条边具有唯一的id；（6）每条边具有一个头节点；（7）每条边具有一个尾节点；（8）每条边具有一个标签，表示联系；（9）每条边具有一组属性，每个属性是一个键值对。"}
{"text": "图3-3给出的属性图不仅表达了RDF图的全部数据，而且还增加了边上的“权重”属性。"}
{"text": "图3-3属性图示例图3-3的每个节点和每条边均有id。"}
{"text": "遵照属性图的要素，节点4的出边集合为{边10,边11}，入边集合为{边8}，属性集合为{姓名=\"王五\"，年龄=32}；边11的头节点是节点3，尾节点是节点4，标签是“参加”，属性集合为{权重=0.4}。"}
{"text": "3.1.2知识图谱查询语言在知识图谱数据模型上，需要借助知识图谱查询语言进行查询操作。"}
{"text": "目前，RDF图上的查询语言是SPARQL；属性图上的查询语言常用的是Cypher和Gremlin。"}
{"text": "1.SPARQLSPARQL是W3C制定的RDF图数据的标准查询语言[4]。"}
{"text": "SPARQL从语法上借鉴了SQL，同样属于声明式查询语言。"}
{"text": "最新的SPARQL1.1版本为有效查询RDF图专门设计了三元组模式、子图模式、属性路径等多种查询机制。"}
{"text": "几乎全部的RDF三元组数据库都实现了SPARQL语言。"}
{"text": "下面通过几个例子介绍SPARQL语言的基本功能。"}
{"text": "查询使用的是RDF图数据。"}
{"text": "（1）查询程序员张三认识的其他程序员输出：说明：PREFIX关键字将ex定义为URI“http://www.example.com/”的前缀缩写，WHERE关键字指明了查询的三元组模式（Triple_Pattern）,SELECT关键字列出了要返回的结果变量。"}
{"text": "三元组模式查询是最基本的SPARQL查询。"}
{"text": "（2）查询程序员张三认识的其他程序员参加的项目输出：说明：这是由两个三元组模式组成的一个基本图模式（Basic_Graph_Pattern）查询，简称为BGP查询。"}
{"text": "实际上，这两个三元组模式之间通过公共变量？p连接为一个链式查询。"}
{"text": "（3）查询节点ex:zhangsan认识的30岁以上的程序员参加的项目名称输出：说明：关键字FILTER用于指明过滤条件，对变量匹配结果进行按条件筛选。"}
{"text": "这里既有？p和？pr分别作为两个三元组模式的宾语和主语连接起来的链式模式，也有？p作为两个三元组模式的主语连接起来的星形结构，该查询是一个更加一般的BGP查询。"}
{"text": "实际上，BGP查询相当于一个带有变量的查询图，查询过程是在数据图中寻找与查询图映射Isomorphism）或子图同态匹配的所有子图，等价于图论中的子图同构（Subgraph（Subgraph_Homomorphism）问题[5]，所以也将BGP查询称为子图匹配查询。"}
{"text": "（4）查询年龄为29的参加了项目ex:graphdb的程序员参加的其他项目及其直接或间接认识的程序员参加的项目输出：说明：这里使用了Path）机制，ex:knows*/ex:participate类似于正则表达式，其表示经过0条、1条或多条ex:knows边，再经过一条ex:participate边。"}
{"text": "1.1引入的属性路径（Property_SPARQL_SPARQL实际上是一整套知识服务标准体系。"}
{"text": "SPARQL1.1语言的语法和语义的完整定义请参见W3C的推荐标准“SPARQL1.1查询语言”[4]，该标准连同其他10个推荐标准共同组成了SPARQL知识平台，包括查询[4]、更新[6]、服务描述[7]、联邦查询[8]、查询结果格式[9]、蕴涵推理[10]和接口协议[11]等。"}
{"text": "开放的SPARQL学习教程有WikiBooks_SPARQL教程[12]、WikidataSPARQL教程[13]和Apache_Jena_SPARQL教程[14]等。"}
{"text": "本章3.4节将以Apache_Jena作为实践工具，讲解如何使用SPARQL进行知识图谱的查询和更新。"}
{"text": "2.CypherCypher最初是图数据库Neo4j中实现的属性图数据查询语言[15]。"}
{"text": "与SPARQL一样，Cypher也是一种声明式语言，即用户只需要声明“查什么”，而无须关心“怎么查”，这就好比乘坐出租车到一个目的地，只需要告诉司机要到哪里，具体的行车路线可由司机安排，乘客并不需要关心。"}
{"text": "这类语言的优点是便于用户学习掌握，同时给予数据库进行查询优化的空间，缺点是不能满足高级用户导航式查询的要求，数据库规划的查询执行计划有可能并不是最优方案。"}
{"text": "2015年，Neo4j公司发起开源项目openCypher[16]，旨在对Cypher进行标准化工作，为其他实现者提供语法和语义的参考标准。"}
{"text": "虽然Cypher的发展目前仍由Neo4j主导，但包括SAP_HANA_Graph[17]、Redis_Graph[18]、AgensGraph[19]和Memgraph[20]等在内的图数据库产品已经实现了Cypher。"}
{"text": "下面通过例子了解Cypher语言的基本功能。"}
{"text": "使用的知识图谱是图3-3中的属性图。"}
{"text": "（1）查询图中的所有程序员节点输出：说明：MATCH关键字指明需要匹配的模式，这里将节点分为了程序员和项目两类，p作为查询变量会依次绑定到每个类型为Programmer的节点，RETURN关键字返回变量p的值作为查询结果。"}
{"text": "（2）查询程序员与“图数据库”项目之间的边输出：说明：此查询返回边及其属性，程序员类型节点与图数据库项目节点之前存在3条标签为参加的边。"}
{"text": "（3）查询从节点1出发的标签为“认识”的边输出：说明：从节点1出发沿“认识”边到达节点2和节点4。"}
{"text": "（4）查询节点1认识的30岁以上的程序员参加的项目名称输出：说明：该查询MATCH子句等价于SPARQLBGP查询的链式查询。"}
{"text": "（5）查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目输出：说明：“：认识*0..”表示由一个节点到达另一个节点的路径包括0个、1个或多个“认识”边。"}
{"text": "对比该查询的SPARQL版本。"}
{"text": "3.GremlinGremlin是Apache_TinkerPop图计算框架[21]提供的属性图查询语言[22]。"}
{"text": "ApacheTinkerPop被设计为访问图数据库的通用API接口，其作用类似于关系数据库上的JDBC接口。"}
{"text": "Gremlin的定位是图遍历语言，其执行机制好比是一个人置身于图中沿着有向边，从一个节点到另一个节点进行导航式的游走。"}
{"text": "这种执行方式决定了用户使用Gremlin需要指明具体的导航步骤，这和自己驾驶汽车到一个目的地需要知道行车路线是一个道理，所以将Gremlin归为过程式语言，即需要明确“怎么做”。"}
{"text": "这类语言的优点是可以时刻知道自己在图中所处的位置，以及是如何到达该位置的；缺点是用户需要“认识路”！与受到SQL影响的声明式语言SPARQL和Cypher不同，Gremlin更像一种函数式的编程语言接口。"}
{"text": "下面通过几个例子认识Gremlin语言，假设用g代表图3-3中的属性图。"}
{"text": "（1）列出图中所有节点的属性输出：说明：V表示节点集合。"}
{"text": "（2）列出图中所有的边输出：说明：E表示边集合。"}
{"text": "（3）查询从节点1出发的标签为“认识”的边输出：说明：v(1)选取id为1的节点；outE表示节点的出边集合，outE(’认识’)是标签为“认识”的出边集合。"}
{"text": "（4）查询节点1认识的30岁以上的程序员参加的项目名称输出：说明：out(’认识’)选取标签为“认识”的出边指向的邻接节点集合；filter为过滤器，filter{it.年龄>30}的意思是后面只处理年龄大于30的节点。"}
{"text": "（5）查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目输出：说明：in(’参加’)选取标签为“参加”的入边连接的邻接节点集合；has(’年龄’,29)的作用是只选取具有属性“年龄=29”的节点；as('x')将当前的导航步骤命名为x;loop('x'){it.loops>=0}为从x开始到当前的步骤循环0次、1次或多次。"}
{"text": "对比该查询的SPARQL和Cypher版本。"}
{"text": "3.2常见知识图谱存储方法本节介绍三类知识图谱数据库：基于关系数据库的存储方案、面向RDF的三元组数据库和原生图数据库，多数系统给出了演示操作步骤。"}
{"text": "3.2.1基于关系数据库的存储方案关系数据库拥有40多年的发展历史，从理论到实践有着一整套成熟体系。"}
{"text": "在历史上，关系数据库曾经取代了层次数据库和网状数据库；成功吸收容纳了面向对象数据库和XML数据库，成为现今数据管理的主流数据库产品。"}
{"text": "商业数据库包括Oracle、DB2和SQL_Server等，开源数据库包括PostgreSQL和MySQL等。"}
{"text": "因此基于历史上的成功经验，人们容易想到使用关系数据库存储知识图谱。"}
{"text": "基于关系数据库的存储方案是目前知识图谱采用的一种主要存储方法。"}
{"text": "本小节将按照时间发展顺序简要介绍各种基于关系表的知识图谱存储结构，包括三元组表、水平表、属性表、垂直划分、六重索引和DB2RDF。"}
{"text": "如图3-4所示，下面以摘自DBpedia数据集[23]的RDF数据作为知识图谱进行讲解和举例。"}
{"text": "该知识图谱描述了IBM公司及其创始人Charles_Flint和Google公司及其创始人LarryPage的一些属性和联系。"}
{"text": "对于其他格式的知识图谱，这些存储方案同样适用。"}
{"text": "图3-4摘自DBpedia数据集的RDF知识图谱1.三元组表三元组表是将知识图谱存储到关系数据库的最简单、最直接的办法，就是在关系数据库中建立一张具有3列的表，该表的模式为：三元组表(主语，谓语，宾语)将知识图谱中的每条三元组存储为三元组表中的一行记录。"}
{"text": "表3-1是图3-4中知识图谱对应的三元组表，由于一共有21行，限于篇幅仅列出了前5行。"}
{"text": "表3-1三元组表三元组表存储方案虽然简单明了，但三元组表的行数与知识图谱的边数一样，其最大问题在于将知识图谱查询翻译为SQL查询后的三元组表自连接。"}
{"text": "例如，如图3-5所示的SPARQL查询是查找1850年出生且1934年逝世的创办了某公司的人，翻译为等价的SQL查询后如图3-6所示，这里三元组表的表名为t。"}
{"text": "一般自连接的数量与SPARQL中三元组模式数量相当。"}
{"text": "当三元组表规模较大时，多个自连接操作会使SQL查询性能低下。"}
{"text": "采用三元组表存储方案的代表是RDF数据库系统3store[24]。"}
{"text": "图3-5一个星形SPARQL查询图3-6三元组表方案中SPARQL查询转换为等价的SQL查询2.水平表水平表存储方案同样非常简单，与三元组表不同，其每行记录存储一个知识图谱中一个主语的所有谓语和宾语。"}
{"text": "实际上，水平表就相当于知识图谱的邻接表。"}
{"text": "表3-2是图3-4中知识图谱对应的水平表，共有5行、13列，限于篇幅省略了若干列。"}
{"text": "不难看出，水平表的列数是知识图谱中不同谓语的数量，行数是知识图谱中不同主语的数量。"}
{"text": "表3-2水平表在水平表存储方案中，图3-5所示的SPARQL查询可以等价地翻译为图3-7中的SQL查询。"}
{"text": "这里水平表的表名为t。"}
{"text": "可见，与三元组表相比，水平表的查询大为简化，仅需单表查询即可完成该任务，不用进行连接操作。"}
{"text": "图3-7水平表方案中SPARQL查询转换为等价的SQL查询但是水平表的缺点在于：所需列的数目等于知识图谱中不同谓语数量，在真实知识图谱数据集中，不同谓语数量可能为几千个到上万个，很可能超出关系数据库允许的表中列数目的上限；对于一行来说，仅在极少数列上具有值，表中存在大量空值，空值过多会影响表的存储、索引和查询性能；在知识图谱中，同一主语和谓语可能具有多个不同宾语，即一对多联系或多值属性，而水平表的一行一列上只能存储一个值，无法应对这种情况（可以将多个值用分隔符连接存储为一个值，但这违反关系数据库设计的第一范式）；知识图谱的更新往往会引起谓语的增加、修改或删除，即水平表中列的增加、修改或删除，这是对于表结构的改变，成本很高。"}
{"text": "采用水平表存储方案的代表是早期的RDF数据库系统DLDB[25]。"}
{"text": "3.属性表属性表（Property_Table）存储方案是对水平表的细化，将同类主语分到一个表中，不同类主语分到不同表中。"}
{"text": "这样就解决了表中列的数目过多的问题。"}
{"text": "对于图3-5中的SPARQL查询，在属性表存储方案上等价的SQL查询如图3-9所示；该查询与图3-7中水平表上查询的唯一区别是将表名由t变为了person。"}
{"text": "图3-8属性表图3-9属性表方案中SPARQL查询转换为等价的SQL查询属性表既克服了三元组表的自连接问题，又解决了水平表中列数目过多的问题。"}
{"text": "实际上，水平表方案是属性表存储方案的一种极端情况，即水平表是将所有主语划归为一类，因此属性表中的空值问题与水平表相比会大为缓解。"}
{"text": "但属性表方案仍有缺点：对于规模稍大的真实知识图谱数据，主语的类别可能有几千个到上万个，按照属性表方案，需要建立几千个到上万个表，这往往超过了关系数据库的限制；对于知识图谱上稍复杂的查询，属性表方案仍然会进行多个表之间的连接操作，从而影响查询效率；即使在同一类型中，不同主语具有的谓语集合也可能存在较大差异，这样会造成与水平表中类似的空值问题；水平表方案中存在的一对多联系或多值属性存储问题仍然存在。"}
{"text": "采用属性表存储方案的代表是RDF三元组库Jena[26]。"}
{"text": "4.垂直划分垂直划分（Vertical_Partitioning）存储方案是由美国麻省理工学院的Abadi等人在2007年提出的RDF数据存储方法[27]。"}
{"text": "该方法以三元组的谓语作为划分维度，将RDF知识图谱划分为若干张只包含(主语，宾语)两列的表，表的总数量即知识图谱中不同谓语的数量；也就是说，为每种谓语建立一张表，表中存放知识图谱中由该谓语连接的主语和宾语值。"}
{"text": "对于图3-5中的SPARQL查询，在垂直划分存储方案中等价的SQL查询如图3-11所示；该查询涉及3张谓语表born、died和founder的连接操作。"}
{"text": "由于谓语表中的行都是按照主语列进行排序的，可以快速执行这种以“主语-主语”作为连接条件的查询操作，而这种连接操作又是常用的。"}
{"text": "与之前基于关系数据库的知识图谱存储方案相比，垂直划分有一些突出的优点：谓语表仅存储出现在知识图谱中的三元组，解决了空值问题；一个主语的一对多联系或多值属性存储在谓语表的多行中，解决了多值问题；每个谓语表都按主语列的值进行排序，能够使用归并排序连接（Merge-sort_Join）快速执行不同谓语表的连接查询操作。"}
{"text": "与之前基于关系数据库的知识图谱存储方案相比，垂直划分有一些突出的优点：谓语表仅存储出现在知识图谱中的三元组，解决了空值问题；一个主语的一对多联系或多值属性存储在谓语表的多行中，解决了多值问题；每个谓语表都按主语列的值进行排序，能够使用归并排序连接（Merge-sort_Join）快速执行不同谓语表的连接查询操作。"}
{"text": "图3-10垂直划分存储方案图3-11垂直划分方案中等价的SQL查询不过，垂直划分存储方案依然存在几个缺点：需要创建的表的数目与知识图谱中不同谓语数目相等，而大规模的真实知识图谱（如DBpedia、YAGO、Wikidata等）中谓语数目可能超过几千个，在关系数据库中维护如此规模的表需要很大的开销；越是复杂的知识图谱查询操作，需要执行的表连接操作数量越多，而对于未指定谓语的三元组查询，将发生需要连接全部谓语表进行查询的极端情况；谓语表的数量越多，数据更新维护代价越大，对于一个主语的更新将涉及多张表，产生很高的更新时I/O开销。"}
{"text": "采用垂直划分存储方案的代表数据库是SW-Store[28]。"}
{"text": "5.六重索引六重索引（Sextuple_Indexing）存储方案是对三元组表的扩展，是一种典型的“空间换时间”策略，其将三元组全部6种排列对应地建立为6张表，即spo(主语，谓语，宾语)、pos(谓语，宾语，主语)、osp(宾语，主语，谓语)、sop(主语，宾语，谓语)、pso(谓语，主语，宾语)和ops(宾语，谓语，主语)。"}
{"text": "不难看出，其中spo表就是原来的三元组表。"}
{"text": "六重索引通过6张表的连接操作不仅缓解了三元组表的单表自连接问题，而且加速了某些典型知识图谱查询的效率。"}
{"text": "使用六重索引方法的典型系统有RDF-3X[28]和Hexastore[29]。"}
{"text": "具体来说，六重索引方案的优点有：知识图谱查询中的每种三元组模式查询都可以直接使用相应的索引表进行快速的前缀范围查找，表3-3给出了全部8种三元组模式查询能够使用的索引表；可以通过不同索引表之间的连接操作直接加速知识图谱上的连接查询，如图3-12所示的链式SPARQL查询“查找生于1850年的人创立的公司的营业领域”，可以通过spo和pso表的连接快速执行三元组模式“?person_founder?company”与“?company_industry?ind”的连接操作，避免了单表的自连接。"}
{"text": "表3-3三元组模式查询能够使用的索引表图3-12一个链式SPARQL查询六重索引存储方案存在的问题包括：虽然部分缓解了三元组表的单表自连接问题，但需要花费6倍的存储空间开销、索引维护代价和数据更新时的一致性维护代价，随着知识图谱规模的增大，该问题会愈加突出；当知识图谱查询变得复杂时，会产生大量的连接索引表查询操作，索引表的自连接依然不可避免。"}
{"text": "6.DB2RDFDB2RDF是由IBM研究中心于2013年提出的一种面向实体的RDF知识图谱存储方案[30]，该方案是以往RDF关系存储方案的一种权衡折中，既具备了三元组表、属性表和垂直划分方案的部分优点，又克服了这些方案的部分缺点。"}
{"text": "三元组表的优势在于“行维度”上的灵活性，即存储模式不会随行的增加而变化；DB2RDF方案将这种灵活性扩展到“列维度”上，即将表的列作为谓语和宾语的存储位置，而不将列与谓语进行绑定。"}
{"text": "当插入数据时，将谓语动态地映射存储到某列；方案能够确保将相同的谓语映射到同一组列上。"}
{"text": "DB2RDF存储方案由4张表组成，即dph表、rph表、ds表和rs表；图3-13给出了图3-4中知识图谱对应的DB2RDF存储方案。"}
{"text": "dph（direct_primary_hash）是存储方案的主表，该表中一行存储一个主语（主语列）及其全部谓语（predi列）和宾语（vali列）,0≤i≤k,k为图着色结果值或某个给定值。"}
{"text": "如果一个主语的谓语数量大于k，则一行不足以容纳下一个实体，将在下一行存储第k+1到2k个谓语和宾语，以此类推，这种情况叫作溢出。"}
{"text": "spill列是溢出标志，即对于一行能存储下的实体，该行spill列为0，对于溢出的实体，该实体所有行的spill列为1。"}
{"text": "例如，在图3-13的dph表中，除实体Android溢出外，其余实体均存储为一行。"}
{"text": "对于多值谓语的处理，引入ds（direct_secondary_hash）表。"}
{"text": "当dph表中遇到一个多值谓语时，则在相应的宾语处生成一个唯一的id值；将该id值和每个对应的宾语存储为ds表的一行。"}
{"text": "例如，在图3-13的dph表中，主语Google的谓语industry（pred1列）是多值谓语，则在其宾语列（val1）存储id值lid:1；在ds表中存储lid:1关联的两个宾语Software和Internet。"}
{"text": "实际上，dph表实现了列的共享：一方面，不同实体的相同谓语总是会被分配到相同的列上；另一方面，同一列中可以存储多个不同的谓语。"}
{"text": "例如，主语Charles_Flint和Larry_Page的谓语founder都被分配到pred3列，该列也存储了主语Android的谓语kernel和graphics。"}
{"text": "正是由于DB2RDF方案具备“列共享”机制，才使得在关系表中最大列数目上限的情况下可以存储远超出该上限的谓语数目，也能够有效地解决水平表方案中存在的谓语稀疏性空值问题。"}
{"text": "在真实的知识图谱中，不同主语往往具有不同的谓语集合，例如，谓语born只有人才具有，谓语employees只有公司才具有，这也是能够实现列共享的原因所在。"}
{"text": "图3-13DB2RDF方案从图数据模型的角度来看，dph表和ds表实际上存储了实体节点（主语）的出边信息（从主语经谓语到宾语）；为了提高查询处理效率，还需要存储实体节点的入边信息（从宾语经谓语到主语）。"}
{"text": "为此，DB2RDF方案提供了rph（reverse_primary_hash）表和rs（reverse_secondary_hash）表，如图3-13所示。"}
{"text": "DB2RDF方案中SPARQL查询转换为等价的SQL查询如图3-14所示。"}
{"text": "从中可以看出，对于知识图谱的星型查询，DB2RDF存储方案只需要查询dph表即可完成，无须进行连接操作。"}
{"text": "图3-14DB2RDF方案中SPARQL查询转换为等价的SQL查询在DB2RDF方案中，谓语到列的映射是需要重点考虑的问题。"}
{"text": "因为关系表中最大列的数目是固定的，该映射的两个优化目标是：使用的列的数目不要超过某个值m；尽量减少将同一主语的两个不同谓语分配到同一列的情况，从而减少溢出现象，因为溢出会导致查询时发生自连接。"}
{"text": "谓语到列映射的一种方法是使用一组散列函数，将谓语映射到一组列编号，并将谓语及其宾语存储到这组列中的第一个空列上；在一个主语对应的一行中，如果存储某谓语（及其宾语）时，散列函数计算得出的这组列中的所有列都被之前存储的该主语的谓语占用了，则产生溢出，到下一行存储该谓语。"}
{"text": "例如，表3-4给出了谓语到列映射的散列函数表，其中包括h2两个散列函数，映射了5个谓语到列编号组。"}
{"text": "现在开始存储以h1和Android作为主语的三元组：当存储(Android,developer,Google)时，在dph表中为主语Android插入一个新行，根据h1的值将谓语developer存入列pred1；当存储(Android,version,8.1)时，根据h1的值将谓语version存储列pred2；当存储(Android,kernel,Linux)时，谓语kernel被h1映射到列pred1，但该列已被占用，因而接着被h2映射到列pred3；当存储(Android,preceded,8.0)时，谓语preceded被h1映射到列predk；当存储(Android,graphics,OpenGL)时，谓语graphics被h1映射到列pred3，被h2映射到列pred2，但这两列都已被占用，这时产生溢出，将谓语graphics溢出到下一行的列pred3中存储，如图3-13的dph表所示。"}
{"text": "表3-4谓语到列映射的散列函数表如果可以事先获取知识图谱的一个子集，则可以利用知识图谱的内在结构优化谓语到列的映射。"}
{"text": "方法是将谓语到列的映射转化为图着色（Graph_Coloring）问题[31]。"}
{"text": "将一个主语上出现的不同谓语称为共现谓语（Co-occurrence_Predicates），目标是让共现谓语着上不同颜色（映射到不同列中），非共现谓语可以着上相同颜色（映射到同一列中）。"}
{"text": "为此，构建图着色算法的冲突图（Interference_Graph）：图中节点为知识图谱中的所有谓语；每对共现谓语节点之间由一条边相连。"}
{"text": "图着色问题的要求是为冲突图中的节点着上颜色，使得每个节点的颜色不同于其任一邻接节点的颜色，并使所用颜色数最少；对应到谓语映射问题，即为冲突图中的谓语节点分配列，使得每个谓语映射到的列不同于其任一共现谓语映射到的列，并使所用的列数目最少。"}
{"text": "可见，对于13个谓语，仅使用了5种颜色，即只需使用5列。"}
{"text": "需要指出的是，图着色是经典的NP难问题，对于规模较大的冲突图可用贪心算法（如Welsh-Powell算法）[32]求得近似解。"}
{"text": "图3-15冲突图如果在大规模真实知识图谱（如DBpedia）中，图着色所需颜色数量超过了关系数据表的列数上限m，则根据某种策略（如最频繁使用的前k个谓语）选取一个谓语子集，使得该谓语子集到列的映射满足图着色要求；对于不在该子集中的谓语，再使用前面提到的散列函数组策略进行映射。"}
{"text": "3.2.2面向RDF的三元组数据库由于RDF是W3C推荐的表示语义网上关联数据（Linked_Data）的标准格式，RDF也是表示和发布Web上知识图谱的最主要数据格式之一。"}
{"text": "面向RDF的三元组数据库是专门为存储大规模RDF数据而开发的知识图谱数据库，其支持RDF的标准查询语言SPARQL。"}
{"text": "本节将分别介绍几种主要的开源和商业RDF三元组数据库。"}
{"text": "主要的开源RDF三元组数据库包括：Apache旗下的Jena、Eclipse旗下的RDF4J以及源自学术界的RDF-3X和gStore；主要的商业RDF三元组数据库包括：Virtuoso、AllegroGraph、GraphDB和BlazeGraph。"}
{"text": "ApacheJena将以实践形式进行详细介绍；下面分别介绍RDF4J、RDF-3X、gStore、Virtuoso、AllegroGraph、GraphDB和BlazeGraph。"}
{"text": "1.开源RDF三元组数据库RDF4JRDF4J目前是Eclipse基金会旗下的开源孵化项目，其前身是荷兰软件公司Aduna开发的Sesame框架。"}
{"text": "Sesame框架的历史可以追溯到1999年，当时作为Aduna公司的一个语义Web项目进行开发，后来发展成为语义Web领域一个非常有名的管理和处理RDF的开源Java框架，功能包括RDF数据的解析、存储、推理和查询等。"}
{"text": "2016年5月，Sesame框架改名为RDF4J，并迁移为Eclipse开源项目继续开发。"}
{"text": "RDF4J本身提供内存和磁盘两种RDF存储机制，支持全部的SPARQL1.1查询和更新语言，可以使用与访问本地RDF库相同的API访问远程RDF库，支持所有主流RDF数据格式，包括RDF/XML、Turtle、N-Triples、N-Quads、JSON-LD、TriG和TriX。"}
{"text": "RDF4J框架的重要特点是其模块化的软件架构设计。"}
{"text": "图3-16RDF4J的高层架构图（1）底层的RDF模型定义了URI、空节点（Blank_Node）、字面值（Literal）和语句（Statement）等RDF基本元素。"}
{"text": "（2）Rio代表“RDF_I/O”，即RDF输入/输出，包括各种RDF文件格式的解析器（Parser）和编写器（Writer），解析器负责将RDF文件解析为RDF模型中的三元组语句，编写器负责将三元组语句写为RDF文件。"}
{"text": "（3）Sail_API代表“存储和推理层API”（Storage_And_Inference_Layer_API），是实现RDF存储和推理的底层系统（System）API（即SPI），其作用是将RDF存储和推理功能从底层实现细节中抽象出来，使得底层存储和推理实现模块可以透明地被替换；Sail_API是SAIL底层存储开发者需要实现的API，普通用户无须关心；RDF4J自带了两种SailAPI实现，即基于内存的MemoryStore和基于磁盘的NativeStore。"}
{"text": "（4）存储库API（Repository_API）是用户使用的RDF管理和处理高层API，提供RDF的存储、查询和推理等服务，面向终端用户，简单易用；存储库API的一种实现是基于本地SAIL实现的SailRepository，另一种是基于远程HTTP服务器实现的HttpRepository。"}
{"text": "（5）架构图的顶层是用户开发的应用程序和HTTP服务器，用户应用程序直接调用存储库API;HTTP服务器实现了通过HTTP访问存储库API的Web服务，可通过HttpClient库与HTTP服务器进行远程通信，从而访问远程RDF4J存储库。"}
{"text": "正是由于RDF4J规范的模块化设计，使其成为很多其他RDF三元组数据库（如GraphDB）的上层标准框架，这些三元组库只需要实现各自的SAIL_API，依赖于RDF4J存储库API的应用程序而无须修改，便可以在不同的三元组库之间实现透明切换。"}
{"text": "图3-17使用RDF4J工作台执行SPARQL查询2.开源RDF三元组数据库RDF-3XRDF-3X是由德国马克斯·普朗克计算机科学研究所研发的RDF三元组数据库系统，其最初成果发表于2008年的数据库国际会议VLDB[28]，后经功能扩展和完善，最新版本是GH-RDF3X，源代码可以从GitHub上下载。"}
{"text": "目前，RDF-3X只支持Linux系统。"}
{"text": "RDF-3X的最大特点在于其为RDF数据精心打造的压缩物理存储方案、查询处理和查询优化技术。"}
{"text": "在逻辑存储上，虽然以简单的三元组表为基础，但首次提出全索引方案：建立6种三元组索引spo、sop、osp、ops、pso和pos；建立6种二元聚合索引sp、ps、so、os、po和op；建立3种一元聚合索引s、p、o。"}
{"text": "在物理存储上，采用基于B+树的压缩方案：使用字典快速查找表建立RDF字符串到整数id的映射；使用面向字节的增量编码B+树页面内部，不会跨越不同页压缩技术，实现三元组的压缩存放；三元组压缩限于面，避免了不必要的解压缩操作，能够提高查询效率。"}
{"text": "借助巧妙设计的三元组压缩技术，全索引方案的空间开销是可以接受的，全索引为查询处理和优化带来了巨大便利。"}
{"text": "对于利用全索引方案的查找，仅以spo索引为例进行举例。"}
{"text": "如图3-18所示，利用spo索引查找三元组模式(Albert_Einstein,invented,?x),spo索引中存储的是已经进行字典编码之后的由整数id值组成的(s,p,o)三元组，并且已按照s、p、o值由小到大的顺序进行了排序。"}
{"text": "图3-18使用spo索引进行三元组模式查找RDF-3X的查询处理器首先对SPARQL查询进行转化，生成若干查询执行计划；对于仅包含一个三元组模式的查询，可以通过一次相应索引查找操作完成；对于由多个三元组模式组成的查询，需要对多个连接的顺序进行优化。"}
{"text": "RDF-3X采用的是一种自底向上的动态规划优化算法，其优化过程充分考虑了SPARQL查询的特点，并且最大限度地保持了有利于用全索引方案进行归并连接的连接顺序。"}
{"text": "同时，RDF-3X还开发了基于代价模型的选择度评估（Selectivity_Estimates）机制，采用选择度直方图和频繁连接路径相结合的方法进行查询执行计划的选择度评估。"}
{"text": "RDF-3X是命令行程序，使用RDF-3X装载RDF文件music_1000_triples.nt的命令如图3-19所示，其中的rdf3xload是命令名称，testds是数据库名称；进行SPARQL查询的命令如图3-20所示，rdf3query是命令名称，sparql.rq是SPARQL查询文件名称。"}
{"text": "图3-19使用RDF-3X装载RDF文件图3-20使用RDF-3X进行SPARQL查询3.开源RDF三元组数据库gStoregStore是基于图的RDF三元组数据库。"}
{"text": "gStore将RDF图G中的每个实体节点及其邻居属性和属性值编码成一个二进制位串，由这些位串作为节点组成一张与RDF图G对应的标签图G*。"}
{"text": "在执行SPARQL查询时，将查询图Q也转化为一张查询的标签图Q*。"}
{"text": "gStore的研究工作已经证明了Q*在G*上的匹配是Q在G上匹配的超集。"}
{"text": "为了支持在G*上快速地查找到Q*的匹配位置，gStore系统提出建立“VS树”索引，其基本思想实际上是为标签图G*建立不同详细程度的摘要图（summary_graph）；利用“VS”树索引提供的摘要图，gStore系统提出可以大幅削减SPARQL查询的搜索空间，加快查询速度。"}
{"text": "目前，gStore已经作为开源项目发布，源代码和文档可以从其GitHub项目网站下载。"}
{"text": "与RDF-3X一样，gStore只能在Linux系统上运行。"}
{"text": "关于gStore内部实现的详细信息可参见文献[33]。"}
{"text": "4.商业RDF三元组数据库VirtuosoVirtuoso虽然是可以支持多种数据模型的混合数据库管理系统，但其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。"}
{"text": "Virtuoso同时发布了商业版本VirtuosoUniversalServer（Virtuoso统一服务器）和开源版本OpenLinkVirtuoso。"}
{"text": "图3-21使用Virtuoso进行SPARQL查询5.商业RDF三元组数据库AllegroGraphAllegroGraph是Franz公司开发的RDF三元组数据库。"}
{"text": "由于Franz公司有着深厚的人工智能背景，早期一直开发Common_Lisp和Prolog语言的实现工具，这使得AllegroGraph对语义推理功能具有较为完善的支持。"}
{"text": "AllegroGraph除了三元组数据库的基本功能外，还支持动态物化的RDFS++推理机、OWL2_RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析库、可视化RDF图浏览器等。"}
{"text": "同时，AllegroGraph支持Java、Python、C#、Ruby、Clojure/Scala、Lisp等多种语言的编程访问接口。"}
{"text": "6.商业RDF三元组数据库GraphDBGraphDB是RDF三元组数据库，其前身OWLIM一直是支持W3C语义Web标准的主流产品。"}
{"text": "GraphDB目前有社区免费版、标准版和企业版，其中企业版支持多台机器的集群分布式部署。"}
{"text": "GraphDB的高层架构如图3-26所示。"}
{"text": "图3-26GraphDB的高层架构对于GraphDB的各部分组件自顶向下进行介绍：（1）Workbench是GraphDB的Web管理工具；（2）Engine是查询处理和推理引擎，由查询优化器（Query_Optimiser）、推理机（Reasoner）、存储层（Storage）和插件管理器（Plugin_Manager）组成；●查询优化器能够在多种查询执行计划中挑选出较高效的一种，查询经过解析后会交由查询优化器进行优化；●推理机执行基于RDF规则的前向链推理，由显式三元组推导出全部导出三元组，导出三元组会随显式三元组的更新而同步更新；●存储层使用pos和pso两种三元组索引、psco和pocs两种带有上下文信息的四元组索引以及字面值（Literal）索引存储RDF数据；实体池（Entity_Pool）是GraphDB存储层的核心部件，起到将RDF实体（URI、空节点和字面值）映射到内部整数ID的字典编码器的作用，同时还实现了对事务管理的支持机制。"}
{"text": "（3）Connectors是GraphDB连接外部工具的桥梁，包括用于建立快速关键字查找功能的Lucene和用于建立搜索引擎的Solr和Elasticsearch。"}
{"text": "（4）插件管理器在Engine内起到插件管理作用，既包括GraphDB内部实现的插件，也包括各种外部工具连接器。"}
{"text": "7.商业RDF三元组数据库BlazegraphBlazegraph在1.5版本之前叫作Bigdata，但众所周知的“大数据”的兴起使得这个不温不火的RDF三元组库软件被淹没其中。"}
{"text": "但这个软件在“大数据”兴起前很多年就叫Bigdata，迫不得已改名叫Blazegraph之后，其开发理念也有所调整。"}
{"text": "原来仅仅是支持RDF三元组存储和SPARQL，现在已经定位为全面支持Blueprints标准的图数据库。"}
{"text": "不过，其内部实现技术仍是面向RDF三元组和SPARQL的，因而可以理解为是“基于RDF三元组库的图数据库”。"}
{"text": "从2006年发布至今，Blazegraph一直由SYSTAP公司开发，虽然它既不是最知名的RDF三元组库，也不是最流行的图数据库，但开发进展稳扎稳打，积累了相对全面的功能。"}
{"text": "Blazegraph可以通过其官方网站下载。"}
{"text": "既可以将Blazegraph作为War包部署为Web程序，也可以将其配置为单机或分布式数据库服务器。"}
{"text": "图3-27Blazegraph的Web用户界面8.商业RDF三元组数据库StardogStardog是由美国Stardog_Union公司开发的RDF三元组数据库，其首个公开发布版本是2012年2月发布的Stardog_0.9。"}
{"text": "Stardog支持RDF图数据模型、SPARQL查询语言、属性图模型、Gremlin图遍历语言、OWL2标准、用户自定义的推理与数据分析规则、虚拟图、地理空间查询以及多种编程语言与网络接口支持。"}
{"text": "虽然Stardog发布较晚，但其对OWL2推理机制具有良好的支持，同时具备全文搜索、GraphQL查询、路径查询、融合机器学习任务等功能，能够支持多种不同编程语言和Web访问接口，使得Stardog成为一个知识图谱数据存储和查询平台。"}
{"text": "Stardog分为企业版和社区版，社区版可以免费用于非商业用途。"}
{"text": "3.2.3原生图数据库1.最流行的图数据库Neo4jNeo4j的1.0版本发布于2010年。"}
{"text": "Neo4j基于属性图模型，其存储管理层为属性图结构中的节点、节点属性、边、边属性等设计了专门的存储方案。"}
{"text": "这使得Neo4j在存储层对于图数据的存取效率天生就优于关系数据库。"}
{"text": "同时，Neo4j还具备OLTP数据库必需的ACID事务处理功能。"}
{"text": "Neo4j的不足之处在于其社区版是单机系统，虽然Neo4j企业版支持高可用性（HighAvailability）集群，但其与分布式图存储系统的最大区别在于每个节点上存储图数据库的完整副本（类似于关系数据库镜像的副本集群），不是将图数据划分为子图进行分布式存储，并非真正意义上的分布式数据库系统。"}
{"text": "如果图数据超过一定规模，系统性能就会因为磁盘、内存等限制而大幅降低。"}
{"text": "开发者注册信息后可以免费下载Neo4j桌面打包安装版（Neo4j_Desktop），其中包括Neo4j企业版的全部功能，即Neo4j服务器、客户端及全部组件。"}
{"text": "Neo4j浏览器是功能完善的Neo4j可视化交互式客户端工具，可以用于执行Cypher语言。"}
{"text": "使用Neo4j内置的Movie图数据库执行Cypher查询，返回“TomHanks”所出演的全部电影，如图3-31所示。"}
{"text": "此外，成功启动Neo4j服务器之后，会在7474和7473端口分别开启HTTP和HTTPS服务。"}
{"text": "例如，使用浏览器访问http://localhost:7474/进入Web界面，执行Cypher查询，其功能与Neo4j浏览器是一致的。"}
{"text": "图3-31Neo4j浏览器界面2.分布式图数据库JanusGraphJanusGraph借助第三方分布式索引库Elasticsearch、Solr和Lucene实现各种类型数据的快速检索功能，包括地理信息数据、数值数据和全文搜索。"}
{"text": "JanusGraph的前身Titan是由Aurelius公司开发的，而该公司的创始人Rodriguez博士恰恰就是Blueprints标准及Gremlin语言的主要开发者，Titan对于Blueprints标准和Gremlin语言的全面支持便不难理解，JanusGraph基本上继承了Titan的这一特性。"}
{"text": "同时，JanusGraph也是OLTP图数据库，其支持多用户并发访问和实时图遍历查询。"}
{"text": "另一方面，JanusGraph还具备基于Hadoop_MapReduce的图分析引擎，其可以将Gremlin导航查询自动转化为MapReduce任务。"}
{"text": "从这个角度看，JanusGraph也可作为图计算引擎使用。"}
{"text": "3.图数据库OrientDBOrientDB对于数据模式的支持也相对灵活，可以管理无模式数据（Schema-less），也可以像关系数据库那样定义完整的模式（Schema-full），还可以适应介于两者之间的混合模式（Schema-mixed）数据。"}
{"text": "在查询语言方面，OrientDB支持扩展的SQL和Gremlin用于图上的导航式查询；值得注意的是，在2.2版本引入的MATCH语句实现了声明式的模式匹配，这类似于Cypher语言查询模式。"}
{"text": "从数据管理角度来看，OrientDB是一个功能上相对全面的数据库管理系统，除对图数据基本的存储和查询外，还支持完整的事务处理ACID特性、基于多主机复制模式（Multi-Master_Replication）的分布式部署、对于多种操作系统的支持（由于使用Java开发）和数据库安全性支持等。"}
{"text": "根据2018年2月DB-Engines的排名，OrientDB排在最流行图数据库的第3位。"}
{"text": "4.图数据库CayleyCayley使用Go语言开发，可以作为Go类库使用；对外提供RESTAPI；具有内置的查询编辑器和可视化界面；支持多种查询语言，包括基于Gremlin的Gizmo、GraphQL和MQL；支持多种存储后端，包括键值数据库Bolt、LevelDB,NoSQL数据库MongoDB、CouchDB、PouchDB、ElasticSearch，关系数据库PostgreSQL、MySQL等；具有良好的模块化设计，易于扩展，对新语言和存储后端有良好的支持。"}
{"text": "需要指出的是，Cayley虽然可以存储N-Quads格式的RDF文件，但目前尚不支持SPARQL查询。"}
{"text": "图3-35Cayley查询结果的可视化3.2.4知识图谱数据库比较下面对常用的知识图谱数据库进行比较，如表3-5所示。"}
{"text": "总体来讲，基于关系的存储系统继承了关系数据库的优势，成熟度较高，在硬件性能和存储容量满足的前提下，通常能够适应千万到十亿级三元组规模的管理。"}
{"text": "官方测评显示，关系数据库Oracle_12c配上空间和图数据扩展组件（Spatial_and_Graph）可以管理的三元组数量高达1.08万亿条[34]！当然，这样的性能效果是在Oracle专用硬件上获得的，所需软硬件成本投入很大。"}
{"text": "对于一般在百万到上亿级三元组的管理，使用稍高配置的单机系统和主流RDF三元组数据库（如Jena、RDF4J、Virtuoso等）完全可以胜任。"}
{"text": "如果需要管理几亿到十几亿以上大规模的RDF三元组，则可尝试部署具备分布式存储与查询能力的数据库系统（如商业版的GraphDB和BlazeGraph、开源的JanusGraph等）。"}
{"text": "近年来，以Neo4j为代表的图数据库系统发展迅猛，使用图数据库管理RDF三元组也是一种很好的选择；但目前大部分图数据库还不能直接支持RDF三元组存储，对于这种情况，可采用数据转换方式，先将RDF预处理为图数据库支持的数据格式（如属性图模型），再进行后续管理操作。"}
{"text": "表3-5主要知识图谱数据库的比较续表3.3知识存储关键技术为了适应大规模知识图谱数据的存储管理与查询处理，知识图谱数据库内部针对图数据模型设计了专门的存储方案和查询处理机制。"}
{"text": "本节首先以图数据库Neo4j为例介绍其内部存储方案，然后简要描述知识图谱数据库的两类索引技术。"}
{"text": "3.3.1知识图谱数据库的存储：以Neo4j为例这一节将深入Neo4j图数据库底层，探究其原生的图存储方案。"}
{"text": "对于遵循属性图的图数据库，存储管理层的任务是将属性图编码表示为在磁盘上存储的数据格式。"}
{"text": "虽然不同图数据库的具体存储方案各有差异，但一般认为具有“无索引邻接”特性（Index-FreeAdjacency）的图数据库才称为原生图数据库[35]。"}
{"text": "在实现了“无索引邻接”的图数据库中，每个节点维护着指向其邻接节点的直接引用，这相当于每个节点都可看作是其邻接节点的一个“局部索引”，用其查找邻接节点比使用“全局索引”更能节省时间。"}
{"text": "这就意味着图导航操作代价与图大小无关，仅与图的遍历范围成正比。"}
{"text": "作为对比，来看看在非原生图数据库中使用全局索引关联邻接节点的情形。"}
{"text": "如果觉得这样的查找代价还是可以接受的话，那么换一个问题，“谁认识张三”的查找代价是多少？显然，对于这个查询，需要通过全局索引检查每个节点，看其认识的人中有没有张三，总代价为O(nlogn)，这样的复杂度对于大图数据的遍历操作是不可接受的。"}
{"text": "有人说，可为“被认识”关系再建一个同样的全局索引，但那样索引的维护开销就会翻倍，而且仍然不能做到图遍历操作代价与图规模无关。"}
{"text": "只有将图数据的边表示的关系当作数据库的“一等公民”（即数据库中最基本、最核心的概念，如关系数据库中的“关系”），才能实现真正的“无索引邻接”特性。"}
{"text": "图3-36邻接关系的全局索引示例图3-37将关系作为“一等公民”在Neo4j数据库中，属性图的不同部分是被分开存储在不同文件中的。"}
{"text": "正是这种将图结构与图上属性分开存储的策略，使得Neo4j具有高效率的图遍历操作。"}
{"text": "首先，来看在Neo4j中是如何存储图节点和边的。"}
{"text": "节点记录存储在文件neostore.nodestore.db中。"}
{"text": "节点记录的第0字节inUse是记录使用标志字节的，告诉数据库该记录是否在使用中，还是已经删除并可回收用来装载新的记录；第1～4字节nextRelId是与节点相连的第1条边的id；第5～8字节nextPropId是节点的第1个属性的id。"}
{"text": "边记录存储在文件neostore.relationshipstore.db中。"}
{"text": "边记录第0字节inUse含义与节点记录相同，表示是否正被数据库使用的标志；第1～4字节secondNode分别是该边的起始节点id和终止节点id；第9～12字节relType是指向该边的关系类型的指针；第13～16字节firstPrevRelId和第17～20字节firstNextRelId分别为指向起始节点上前一个和后一个边记录的指针；第21～24字节secPrevRelId和第25～28字节secNextRelId分别为指向终止节点上前一个和后一个边记录的指针；指向前后边记录的4个指针形成了两个“关系双向链”；第29～32字节nextPropId是边上的第1个属性的id。"}
{"text": "和第5～8字节firstNode图3-38Neo4j中节点和边记录的物理存储结构Neo4j实现节点和边快速定位的关键是“定长记录”的存储方案，将具有定长记录的图结构与具有变长记录的属性数据分开存储。"}
{"text": "例如，一个节点记录长度是9字节，如果要查找id为99的节点记录所在位置（id从0开始），则可直接到节点存储文件第891个字节处访问（存储文件从第0个字节开始）。"}
{"text": "边记录也是“定长记录”，长度为33字节。"}
{"text": "这样，数据库已知记录id可以O(1)的代价直接计算其存储地址，而避免了全局索引中O(nlogn)的查找代价。"}
{"text": "图3-39展示了Neo4j中各种存储文件之间是如何交互的。"}
{"text": "存储在节点文件中的节点1和节点4均有指针指向存储在属性文件中各自的第1个属性记录；也有指针指向存储在边文件中各自的第1条边，分别为边7和边8。"}
{"text": "如要查找节点属性，可由节点找到其第1个属性记录，再沿着属性记录的单向链表进行查找；如要查找一个节点上的边，可由节点找到其第1条边，再沿着边记录的双向链表进行查找；当找到了所需的边记录后，可由该边进一步找到边上的属性；还可由边记录出发访问该边连接的两个节点记录（图3-39中的虚线箭头）。"}
{"text": "需要注意的是，每个边记录实际上维护着两个双向链表，一个是起始节点上的边，一个是终止节点上的边，可以将边记录想象为被起始节点和终止节点共同拥有，双向链表的优势在于不仅可在查找节点上的边时进行双向扫描，而且支持在两个节点间高效率地添加和删除边。"}
{"text": "图3-39Neo4j中图的物理存储例如，由节点1导航到节点4的过程为：（1）由节点1知道其第1条边为边7；（2）在边文件中通过定长记录计算出边7的存储地址；（3）由边7通过双向链表找到边8；（4）由边8获得其中的终止节点id（secondNode），即节点4；（5）在节点文件中通过定长记录计算出节点4的存储地址。"}
{"text": "这些操作除了记录字段的读取，就是定长记录地址的计算，均是O(1)时间的高效率操作。"}
{"text": "可见，正是由于将边作为“一等公民”，将图结构实现为定长记录的存储方案，赋予了Neo4j作为原生图数据库的“无索引邻接”特性。"}
{"text": "3.3.2知识图谱数据库的索引图数据上的索引一种是对节点或边上属性数据的索引，一种是对图结构的索引；前者可应用关系数据库中已有的B+树索引技术直接实现，而后者仍是业界没有达成共识的、开放的研究问题。"}
{"text": "1.属性数据索引Neo4j数据库在前述存储方案的基础上还支持用户对属性数据建立索引，目的是加速针对某属性的查询处理性能。"}
{"text": "Neo4j索引的定义通过Cypher语句完成，目前支持对于同一个类型节点的某个属性构建索引。"}
{"text": "例如，对所有程序员节点的姓名属性构建索引。"}
{"text": "在一般情况下，在查询中没有必要指定需要使用的索引，查询优化器会自动选择要用到的索引。"}
{"text": "例如，下面的查询查找姓名为张三的程序员，显然会用到刚刚建立的索引。"}
{"text": "应用该索引无疑会根据姓名属性的值快速定位到姓名是“张三”的节点，而无须扫描程序员节点的全部属性。"}
{"text": "删除索引的语句为：不难发现，为图节点或边的属性建立索引与为关系表的某一列建立索引在本质上并无不同之处，完全可以通过B+树或散列表实现。"}
{"text": "这种索引并不涉及图数据上的任何图结构信息。"}
{"text": "2.图结构索引图结构索引是为图数据中的点边结构信息建立索引的方法。"}
{"text": "利用图结构索引可以对图查询中的结构信息进行快速匹配，从而大幅削减查询搜索空间。"}
{"text": "大体上，图结构索引分为“基于路径的”和“基于子图的”两种。"}
{"text": "（1）基于路径的图索引。"}
{"text": "一种典型的基于路径的图索引叫作GraphGrep[36]。"}
{"text": "这种索引将图中长度小于或等于一个固定长度的全部路径构建为索引结构。"}
{"text": "索引的关键字可以是组成路径的节点或边上属性值或标签的序列。"}
{"text": "图3-40是在图3-3的属性图上构建的GraphGrep索引。"}
{"text": "这里构建的是长度小于或等于2的路径索引，关键字为路径上的边标签序列，值为路径经过的节点id序列。"}
{"text": "例如，索引将关键字“认识.参加”映射到节点id序列(1,4,3)和(1,4,5)。"}
{"text": "利用该路径索引，类似前面出现过的“查询年龄为29的参加了项目3的程序员参加的其他项目及其直接或间接认识的程序员参加的项目”的查询处理效率会大幅提高，因为由节点1出发，根据关键字“认识.参加”，可以快速找到满足条件的节点3和节点5。"}
{"text": "（2）基于子图的索引。"}
{"text": "基于子图的索引可以看作是基于路径索引的一般化形式，是将图数据中的某些子图结构信息作为关键字，将该子图的实例数据作为值而构建的索引结构。"}
{"text": "图3-41是在图3-3的属性图上构建的一种子图索引。"}
{"text": "满足第1个关键字子图的节点序列为(1,2,4)，满足第2个关键字子图的节点序列为(1,4,3)。"}
{"text": "如果查询中包含某些作为关键字的子图结构，则可以利用该子图索引，快速找到与这些子图结构匹配的节点序列，这样可大幅度减小查询操作的搜索空间。"}
{"text": "图3-40基于路径的图索引示例图3-41基于子图的图索引示例不过，一个图数据的子图有指数个，将哪些子图作为关键字建立索引尚未得到很好的解决。"}
{"text": "一种叫作gIndex[37]的索引方法，首先利用数据挖掘方法，在图数据中发现出现次数超过一定阈值的频繁子图，再将去掉冗余之后的频繁子图作为关键字建立子图索引。"}
{"text": "但gIndex建立索引的过程是相当耗时的，而且用户查询中还有可能没有包含任何一个频繁子图，这样就无法利用该子图索引。"}
{"text": "一种更合理的方法是从用户的查询日志中挖掘频繁使用的子图模式，并以此作为关键字建立索引。"}
{"text": "3.4开源工具实践3.4.1三元组数据库Apache_Jena1.开源工具简介Apache_Jena是Apache顶级项目，其前身为惠普实验室开发的Jena工具包。"}
{"text": "Jena是语义Web领域主要的开源框架和RDF三元组库，较好地遵循W3C标准，其功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理等。"}
{"text": "Jena具备一套原生存储引擎，可对RDF三元组进行基于磁盘或内存的存储管理；同时具有一套基于规则的推理引擎，用于执行RDFS和OWL本体推理任务。"}
{"text": "本实践相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "2.开源工具的技术架构ApacheJena框架如图3-42所示。"}
{"text": "自底向上看，Jena的存储API为上层提供基本三元组存储和本体存储功能，支持的底层存储类型包括：基于内存的存储、基于关系数据库的SDB存储、基于原生三元组的TDB存储和用户定制的存储。"}
{"text": "推理API为上层提供本体推理服务，可以使用Jena内置基于规则的推理机进行RDFS和OWL本体上的推理任务，或者选择通过接口调用第三方外部推理机。"}
{"text": "Jena对外界应用程序的API包括实现基本三元组管理功能的RDFAPI、实现RDFS和OWL本体推理功能的本体API和实现查询处理功能的SPARQL_API。"}
{"text": "Java应用程序代码可以通过导入类库的形式直接调用这些API。"}
{"text": "Jena还提供了支持各种RDF三元组格式的解析器和编写器，支持的三元组格式包括：RDF/XML、Turtle、N-Triple和RDFa。"}
{"text": "图3-42Apache_Jena框架实质上，Jena是一个Java框架类库。"}
{"text": "在一般情况下，上述功能需要在Java程序中进行调用。"}
{"text": "Jena为了用户使用方便，提供了一个名为Fuseki的独立RDF数据库Web应用程序。"}
{"text": "本实践将使用Fuseki作为认识知识图谱数据库的入门工具。"}
{"text": "Fuseki是基于Jena的SPARQL服务器，可以作为独立的服务由命令行启动，也可以作为操作系统服务或JavaWeb应用程序。"}
{"text": "Fuseki底层存储基于TDB，具有SPARQL查询处理的Web用户界面，同时提供服务器监控和管理功能界面。"}
{"text": "Fuseki支持最新的SPARQL1.1版本，同时支持SPARQL图存储HTTP协议。"}
{"text": "访问OpenKG可以获取使用实例和整体配置细节。"}
{"text": "3.其他类似工具RDF4J是Eclipse基金会旗下的开源孵化项目，其前身是荷兰软件公司Aduna开发的Sesame框架，其功能包括：RDF数据的解析、存储、推理和查询等。"}
{"text": "RDF4J提供内存和磁盘两种RDF存储机制，支持SPARQL1.1查询和更新语言。"}
{"text": "gStore是由北京大学开发的基于图的RDF三元组数据库。"}
{"text": "AllegroGraph是Franz公司开发的RDF三元组数据库。"}
{"text": "AllegroGraph对语义推理功能具有较为完善的支持。"}
{"text": "除了三元组数据库的基本功能，AllegroGraph_RDFS++推理机、OWL2RL推理机、Prolog规则推理系统、时空推理机制、社会网络分析还支持动态物化的库、可视化RDF图浏览器等。"}
{"text": "GraphDB是由Ontotext软件公司开发的RDF三元组数据库。"}
{"text": "GraphDB实现了RDF4J框架的SAIL层，可以使用RDF4J的RDF模型、解析器和查询引擎直接访问GraphDB。"}
{"text": "GraphDB的特色是对于RDF推理功能的良好支持。"}
{"text": "3.4.2面向RDF的三元组数据库gStore1.开源工具简介gStore是由北京大学计算机科学技术研究所数据管理实验室自2011年开始研发的面向RDF知识图谱的开源图数据库系统，遵循Apache开源协议。"}
{"text": "不同于传统基于关系数据库的RDF数据管理方法，gStore原生基于图数据模型，在存储RDF数据时维持并根据其图结构构建了基于二进制位图索引的新型索引结构——VS树。"}
{"text": "本实践相关工具、实验数据及操作说明由OpenKG提供，下载链接为http://openkg.cn/tool/gstore。"}
{"text": "2.开源工具的技术架构如图3-43所示为gStore的整体处理流程，gStore的RDF数据管理可分为两部分：离线数据存储和在线查询处理。"}
{"text": "图3-43gStore的整体处理流程在离线数据存储阶段，gStore将RDF数据解析成图格式并以邻接表的方式存储在键值数据库上。"}
{"text": "同时，gStore将RDF数据上的所有点和边通过二进制编码的方式编码成若干位图索引，并将这些位图索引组织成VS树。"}
{"text": "在在线查询处理阶段，gStore也将SPARQL查询解析成查询图。"}
{"text": "然后，gStore按照对RDF数据图的编码方式，将SPARQL查询图进行编码以形成一个标签图，并在VS树和RDF数据图的邻接表上进行检索以得到每个查询变量的候选匹配。"}
{"text": "最后，gStore将所有查询变量的候选匹配连接成最终匹配。"}
{"text": "目前，gStore只能在Linux系统上通过Shell命令编译、安装与运行。"}
{"text": "同时，gStore官网还提供了gStore_Workbench，方便用户操作RDF数据库。"}
{"text": "具体包括：（1）环境配置。"}
{"text": "Linux中编译、安装与运行gStore需要预安装一些C++库，包括readline、curl和boost等。"}
{"text": "可以从OpenKG网站或gStore官网上下载gStore源代码，然后通过make来编译得到gStore运行程序。"}
{"text": "同时，通过OpenKG网站或gStore官网可以下载gStore_Workbench，进行编译安装后可以得到gStore_Workbench。"}
{"text": "（2）数据导入。"}
{"text": "gStore目前支持NT格式的RDF数据，利用gStore安装路径下bin目录中gbuild或者gStore_Workbench中的数据库管理页面导入数据。"}
{"text": "gStore_Workbench中的数据库管理页面还记录目前gStore包括的数据库统计信息。"}
{"text": "（3）查询处理。"}
{"text": "gStore目前完全支持SPARQL1.0查询语法，利用gStore安装路径下bin目录中gquery或者gStoreWorkbench中的图数据库查询页面，就可以输入查询然后得到结果。"}
{"text": "gStore同时还提供HTTP接口，可以利用gStore安装路径下bin目录中ghttp启动HTTP服务，进而接收其他机器远程通过HTTP发来的SPARQL查询请求。"}
{"text": "访问OpenKG网站可以获取使用实例和整体配置细节。"}
{"text": "3.其他类似工具Jena的前身是惠普实验室（HP_Labs）2000年开发的工具包。"}
{"text": "Jena从发布起就一直是语义Web领域最为流行的开源Java框架和RDF数据库之一，并始终遵循W3C标准，其提供的API功能包括：RDF数据管理、RDFS和OWL本体管理、SPARQL查询处理。"}
{"text": "针对RDF数据，Jena维护了一张大的三元组表和三种属性表，包括单值属性表、多值属性表和属性类表。"}
{"text": "Virtuoso是OpenLink公司开发的知识图谱管理系统，有免费的社区版和收费的商业版。"}
{"text": "Virtuoso是可以支持包括RDF在内的多种数据模型的混合数据库管理系统。"}
{"text": "其基础源自开发了多年的传统关系数据库管理系统，因此具备较为完善的事务管理、并发控制和完整性机制。"}
{"text": "第4章知识抽取与知识挖掘王志春北京师范大学，陈华钧浙江大学，王昊奋上海乐言信息科技有限公司知识抽取是构建大规模知识图谱的重要环节，而知识挖掘则是在已有知识图谱的基础上发现其隐藏的知识。"}
{"text": "知识抽取和知识挖掘对于知识图谱的构建及应用具有重要的意义。"}
{"text": "本章将首先介绍知识抽取的技术和方法，然后介绍知识内容挖掘和知识结构挖掘。"}
{"text": "4.1知识抽取任务及相关竞赛4.1.1知识抽取任务定义知识抽取是实现自动化构建大规模知识图谱的重要技术，其目的在于从不同来源、不同结构的数据中进行知识提取并存入知识图谱中。"}
{"text": "知识抽取的数据源可以是结构化数据（如链接数据、数据库）、半结构化数据（如网页中的表格、列表）或者非结构化数据（即纯文本数据）。"}
{"text": "面向不同类型的数据源，知识抽取涉及的关键技术和需要解决的技术难点有所不同。"}
{"text": "知识抽取的概念最早在20世纪70年代后期出现于NLP研究领域，是指自动化地从文本中发现和抽取相关信息，并将多个文本碎片中的信息进行合并，将非结构化数据转换为结构化数据，包括某一特定领域的模式、实体关系或RDF三元组。"}
{"text": "给定一段关于苹果公司的文字描述，知识抽取方法可以自动获取关于苹果公司的结构化信息，包括其总部地址、创始人以及创立时间。"}
{"text": "图4-1知识抽取的典型例子具体地，知识抽取包括以下子任务：1.命名实体识别从文本中检测出命名实体，并将其分类到预定义的类别中，例如人物、组织、地点、时间等。"}
{"text": "2.关系抽取从文本中识别抽取实体及实体之间的关系。"}
{"text": "例如，从句子“[王思聪]是万达集团董事长[王健林]的独子”中识别出实体“[王健林]”和“[王思聪]”之间具有“父子”关系。"}
{"text": "3.事件抽取识别文本中关于事件的信息，并以结构化的形式呈现。"}
{"text": "例如，从恐怖袭击事件的新闻报道中识别袭击发生的地点、时间、袭击目标和受害人等信息。"}
{"text": "4.1.2知识抽取相关竞赛一些重要的竞赛对知识抽取技术的发展起到了巨大的推动作用。"}
{"text": "这些竞赛一般与学术会议同时举办，在明确定义知识抽取相关任务的基础上，提供标准评测数据和评测指标，吸引了大量的参与者。"}
{"text": "本节将介绍知识抽取相关的重要竞赛。"}
{"text": "1.消息理解会议（Message_Understanding_Conference,MUC）MUC由美国国防部高级研究计划局（DARPA）启动并资助，目的是鼓励和开发更好的信息抽取方法。"}
{"text": "1987—1998年，MUC会议共举办了七届。"}
{"text": "MUC不仅仅是学术会议，其更重要的是在于对信息抽取系统的评测。"}
{"text": "在每届MUC会议前，组织者向参加者提供消息文本的样例和信息抽取任务的说明；参加者开发参赛系统并提交系统的输出结果。"}
{"text": "各个系统的结果与标准结果比对后得到最终的评测结果，参与者最后在会议上交流技术和感受。"}
{"text": "在MUC的评测中，召回率（Recall）和精确率（Precision）是评价信息抽取系统性能的两个重要评价指标。"}
{"text": "召回率是系统抽取的正确结果占标准结果的比例；精确率是系统抽取的正确结果占其抽取的所有结果的比例。"}
{"text": "为了综合两个方面的因素考量系统的性能，通常基于召回率和准确率计算F1值。"}
{"text": "MUC会议积极推动了命名实体识别和共指消解等技术的进步与发展。"}
{"text": "在MUC会议中，出现了一些F1值高达90%左右的系统，接近于人工标注的质量。"}
{"text": "MUC定义的一系列规范以及确立的评价体系也已经成为知识抽取领域的标准。"}
{"text": "2.自动内容抽取（Automatic_Content_Extraction,ACE）ACE是一项由美国国家标准技术研究所（NIST）组织的评测会议，该会议从1999年至2008年共举办了八次评测。"}
{"text": "ACE与MUC解决的问题类似，但是ACE对MUC定义的任务进行了融合、分类和细化。"}
{"text": "ACE评测涉及英语、阿拉伯语和汉语三种语言，主要包括以下任务：（1）实体检测和跟踪。"}
{"text": "这是ACE最基础和核心的任务，该任务要求识别文本中的实体，实体类型包括人物（Person,PER）、组织（Organization,ORG）、设施（Facility,FAC）、地缘政治实体（Geographical_Political_Entity,GPE）和位置（Location,LOC）等。"}
{"text": "（2）关系检测与表征。"}
{"text": "该任务要求识别和表征实体间的关系，关系被分为五大类，包括角色（role）关系、部分整体（part-whole）关系、位于（at）关系、邻近（near）关系和社会（social）关系，每个大类关系又被进一步细分，总共有24种类型。"}
{"text": "（3）事件检测与表征。"}
{"text": "该任务要求识别实体参与的五类事件，包括交互（interaction）、移动（movement）、转移（transfer）、创建（creation）和销毁（destruction）事件。"}
{"text": "任务要求自动标注每个事件的文本提及或锚点，并按类型和子类型对其进行分类；最后，还需要根据类型特定的模板进一步确定事件参数和属性。"}
{"text": "3.知识库填充（Knowledge_Base_Population,KBP）KBP评测由文本分析会议（Text_Analysis_Conference,TAC）主办，其目标是开发和评估从非结构化文本中获取知识填充知识库的技术。"}
{"text": "KBP评测从2009年开始，每年举办一次，截至2017年，已经举办了九届。"}
{"text": "KBP评测覆盖了知识库填充的独立子任务以及被称为“冷启动”的端到端知识库构建任务。"}
{"text": "独立子任务主要包括以下四个方面：（1）实体发现与链接（Entity_Discovery_and_Linking,EDL）。"}
{"text": "主要的EDL任务是在评估文档集合中提取特定个人（PER）、组织（ORG）、设施（FAC）、地缘政治实体（GPE）和位置（LOC）实体的名称和提及，并将每个提及链接到其对应的KB节点。"}
{"text": "（2）槽填充（Slot_Filling,SF）。"}
{"text": "插槽填充任务是搜索文档集合以填充特定实体的特定属性（“插槽”）值。"}
{"text": "（3）事件跟踪（Event_Track）。"}
{"text": "事件跟踪旨在从非结构化文本中提取关于事件的信息，使其作为结构化知识库的输入。"}
{"text": "该任务具体包括事件块（Event_Nugget）任务（检测和链接事件块）和事件参数（Event_Argument）任务（提取属于同一事件的事件参数和链接属于同一事件的参数）。"}
{"text": "（4）信念和情感（Belief_and_Sentiment,BeSt）。"}
{"text": "信仰和情感跟踪检测实体对另一个实体、关系或事件的信念和情绪。"}
{"text": "端到端冷启动知识库构建任务基于给定的知识库模式（KB_schema）从文本中获取以下信息：实体，在实体发现与链接任务中定义的实体和实体提及；槽关系，在槽填充中涉及的实体属性（“槽”）；事件，在事件跟踪任务中的事件和事件块；事件参数，在事件跟踪任务中的事件参数；情绪，信念和情感任务中源实体向目标实体的情绪。"}
{"text": "4.语义评测（Semantic_Evaluation,SemEval）SemEval是由ACL-SIGLEX组织的国际权威的词义消歧评测，目标是增进人们对词SenseEval，于1998年举办第一届。"}
{"text": "截至2017义与多义现象的理解。"}
{"text": "该评测前期被称为年，已经成功举办了十一届。"}
{"text": "早期评测比较关注词义消歧问题，后来出现了更多文本语义理解的任务，包括语义角色标注、情感分析、跨语言语义分析等。"}
{"text": "4.2面向非结构化数据的知识抽取大量的数据以非结构化数据（即自由文本）的形式存在，如新闻报道、科技文献和政府文件等，面向文本数据的知识抽取一直是广受关注的问题。"}
{"text": "在前文介绍的知识抽取领域的评测竞赛中，评测数据大多属于非结构化文本数据。"}
{"text": "本节将对这一类知识抽取技术和方法进行概要介绍，具体包括面向文本数据的实体抽取、关系抽取和事件抽取。"}
{"text": "4.2.1实体抽取实体抽取又称命名实体识别，其目的是从文本中抽取实体信息元素，包括人名、组织机构名、地理位置、时间、日期、字符值和金额值等。"}
{"text": "实体抽取是解决很多自然语言处理问题的基础，也是知识抽取中最基本的任务。"}
{"text": "想要从文本中进行实体抽取，首先需要从文本中识别和定位实体，然后再将识别的实体分类到预定义的类别中去。"}
{"text": "例如，给定一段新闻报道中的句子“北京时间10月25日，骑士后来居上，在主场以119∶112击退公牛”。"}
{"text": "实体抽取旨在获取如图4-2所示的结果。"}
{"text": "例句中的“北京”“10月25日”分别为地点和时间类型的实体，而“骑士”和“公牛”均为组织实体。"}
{"text": "实体抽取问题的研究开展得比较早，该领域也积累了大量的方法。"}
{"text": "总体上，可以将已有的方法分为基于规则的方法、基于统计模型的方法和基于深度学习的方法。"}
{"text": "图4-2实体抽取举例1.基于规则的方法早期的命名实体识别方法主要采用人工编写规则的方式进行实体抽取。"}
{"text": "这类方法首先构建大量的实体抽取规则，一般由具有一定领域知识的专家手工构建。"}
{"text": "然后，将规则与文本字符串进行匹配，识别命名实体。"}
{"text": "这种实体抽取方式在小数据集上可以达到很高的准确率和召回率，但随着数据集的增大，规则集的构建周期变长，并且移植性较差。"}
{"text": "2.基于统计模型的方法基于统计模型的方法利用完全标注或部分标注的语料进行模型训练，主要采用的模型包括隐马尔可夫模型（Hidden_Markov_Model）、条件马尔可夫模型（Conditional_MarkovModel）、最大熵模型（Maximum_Entropy_Model）以及条件随机场模型（ConditionalRandom_Fields）。"}
{"text": "该类方法将命名实体识别作为序列标注问题处理。"}
{"text": "与普通的分类问题相比，序列标注问题中当前标签的预测不仅与当前的输入特征相关，还与之前的预测标签相关，即预测标签序列是有强相互依赖关系的。"}
{"text": "从自然文本中识别实体是一个典型的序列标注问题。"}
{"text": "基于统计模型构建命名实体识别方法主要涉及训练语料标注、特征定义和模型训练三个方面。"}
{"text": "（1）训练语料标注。"}
{"text": "为了构建统计模型的训练语料，人们一般采用Inside–Outside–Beginning（IOB）或Inside–Outside（IO）标注体系对文本进行人工标注。"}
{"text": "在IOB标注体系中，文本中的每个词被标记为实体名称的起始词（B）、实体名称的后续词（I）或实体名称的外部词（D）。"}
{"text": "而在IO标注体系中，文本中的词被标记为实体名称内部词（I）或实体名称外部词（D）。"}
{"text": "表4-1以句子“苹果公司是一家美国的跨国公司”为例，给出了IOB和IO实体标注示例。"}
{"text": "表4-1IOB和IO实体标注示例（2）特征定义。"}
{"text": "在训练模型之前，统计模型需要计算每个词的一组特征作为模型的输入。"}
{"text": "这些特征具体包括单词级别特征、词典特征和文档级特征等。"}
{"text": "单词级别特征包括是否首字母大写、是否以句点结尾、是否包含数字、词性、词的n-gram等。"}
{"text": "词典特征依赖外部词典定义，例如预定义的词表、地名列表等。"}
{"text": "文档级特征基于整个语料文档集计算，例如文档集中的词频、同现词等。"}
{"text": "斯坦福大学的NER[1]是一个被广泛使用的命名实体识别工具，具有较高的准确率。"}
{"text": "Stanford_NER模型中定义的特征包括当前词、当前词的前一个词、当前词的后一个词、当前词的字符n-gram、当前词的词性、当前词上下文词性序列、当前词的词形、当前词上下文词形序列、当前词左侧窗口中的词（窗口大小为4）、当前词右侧窗口中的词（窗口大小为4）。"}
{"text": "定义何种特征对于命名实体识别结果有较大的影响，因此不同命名实体识别算法使用的特征有所不同。"}
{"text": "（3）模型训练。"}
{"text": "隐马尔可夫模型（Hidden_Markov_Model,HMM）和条件随机场（Conditional_Random_Field,CRF）是两个常用于标注问题的统计学习模型，也被广泛应用于实体抽取问题。"}
{"text": "HMM是一种有向图概率模型，模型中包含了隐藏的状态序列和可观察的观测序列。"}
{"text": "每个状态代表了一个可观察的事件，观察到的事件是状态的随机函数。"}
{"text": "HMM模型结构如图4-3所示，每个圆圈代表一个随机变量，随机变量xt是t时刻的隐藏状态；随机变量yt是t时刻的观测值，图中的箭头表示条件依赖关系。"}
{"text": "HMM模型有两个基本假设：●在任意t时刻的状态只依赖于其前一时刻的状态，与其他观测及状态无关，即P（xt|xt−1,xt−2,...,x1,yt−1,yt−2,...,y1）=P（xt|xt−1）；●任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关，即P（yt|xt,xt−1,xt−2,...,x1,yt−1,yt−2,...,y1）=P（yt|xt）。"}
{"text": "图4-3HMM模型结构在应用于命名实体识别问题时，HMM模型中的状态对应词的标记，标注问题可以看作是对给定的观测序列进行序列标注。"}
{"text": "基于HMM的有代表性的命名实体识别方法可参考文献[2,3]。"}
{"text": "CRF是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型。"}
{"text": "在序列标注问题中，线性链CRF是常用的模型，其结构如图4-4所示。"}
{"text": "在序列标注问题中，状态序列变量x对应标记序列，y表示待标注的观测序列。"}
{"text": "图4-4线性链CRF模型结构给定训练数据集，模型可以通过极大似然估计得到条件概率模型；当标注新数据时，给定输入序列y，模型输出使条件概率P（x|y）最大化的x*。"}
{"text": "美国斯坦福大学开发的命名实体识别工具Stanford_NER是基于CRF的代表性系统[1]。"}
{"text": "3.基于深度学习的方法随着深度学习方法在自然语言处理领域的广泛应用，深度神经网络也被成功应用于命名实体识别问题，并取得了很好的效果。"}
{"text": "与传统统计模型相比，基于深度学习的方法直接以文本中词的向量为输入，通过神经网络实现端到端的命名实体识别，不再依赖人工定义的特征。"}
{"text": "目前，用于命名实体识别的神经网络主要有卷积神经网络（Convolutional_NeuralNetwork,CNN）、循环神经网络（Recurrent_Neural_Network,RNN）以及引入注意力机制（Attention_Mechanism）的神经网络。"}
{"text": "一般地，不同的神经网络结构在命名实体识别过程中扮演编码器的角色，它们基于初始输入以及词的上下文信息，得到每个词的新向量表示；最后再通过CRF模型输出对每个词的标注结果。"}
{"text": "（1）LSTM-CRF模型。"}
{"text": "该模型使用了长短时记忆神经网络（Long_Shot-Term_Memory_Neural_Network,LSTM）与CRF相结合进行命名实体识别。"}
{"text": "该模型自底向上分别是Embedding层、双向LSTM层和CRF层。"}
{"text": "Embedding层是句子中词的向量表示，作为双向LSTM的输入，通过词向量学习模型获得。"}
{"text": "双向LSTM层通过一个正向LSTM和一个反向LSTM，分别计算每个词考虑左侧和右侧词时对应的向量，然后将每个词的两个向量进行连接，形成词的向量输出；最后，CRF层以双向LSTM输出的向量作为输入，对句子中的命名实体进行序列标注。"}
{"text": "经过实验对比发现，双向LSTM与CRF组合的模型在英文测试数据上取得了与传统统计方法最好结果相近的结果，而传统方法中使用了大量的人工定义的特征以及外部资源；在德语测试数据上，深度学习模型取得了比统计学习方法更优的结果。"}
{"text": "图4-5LSTM-CRF命名实体识别模型[4]（2）LSTM-CNNs-CRF模型。"}
{"text": "MA_Xuezhe等人发表于ACL2016的论文提出了将双向LSTM、CNN和CRF相结合的序列标注模型[5]，并成功地应用于命名实体识别问题中。"}
{"text": "该模型与LSTM-CRF模型十分相似，不同之处是在Embedding层中加入了每个词的字符级向量表示。"}
{"text": "模型Embedding层中每个词的向量输入由预训练获得的词向量和CNN获得的字符级向量连接而成，通过双向LSTM和CRF层获得词的标注结果。"}
{"text": "LSTM-CNNs-CRF序列标注模型框架如图4-7所示。"}
{"text": "在CoNLL-2003命名实体识别数据集上，该模型获得了91.2%的F1值。"}
{"text": "图4-6获取词语字符级向量表示的CNN模型[5]图4-7LSTM-CNNs-CRF序列标注模型框架[5]（3）基于注意力机制的神经网络模型。"}
{"text": "在自然语言处理领域，基于注意力机制的神经网络模型最早应用于解决机器翻译问题，注意力机制可以帮助扩展基本的编码器-解码器模型结构，让模型能够获取输入序列中与下一个目标词相关的信息。"}
{"text": "在命名实体识别问题方面，Marek_Rei等人在COLING2016的论文中提出了基于注意力机制的词向量和字符级向量组合方法[6]。"}
{"text": "该方法认为除了将词作为句子基本元素学习得到的特征向量，命名实体识别还需要词中的字符级信息。"}
{"text": "因此，该方法除了使用双向LSTM得到词的特征向量，还基于双向LSTM计算词的字符级特征向量。"}
{"text": "假设输入词为“big”，该方法将词中的字符看作一个序列，然后通过正、反向的LSTM计算字符序列的最终状态和，两者相连得到词“big”的字符级向量h∗。"}
{"text": "h∗通过一个非线性层得到m之后，与“big”的词向量x进行加权相加，而两者相加的权重z是通过一个两层的神经网络计算获得的。"}
{"text": "在得到句子中每个词的新向量之后，模型使用CRF对句子中的命名实体进行序列标注。"}
{"text": "注意力机制的引入使得模型可以动态地确定每个词的词向量和字符级向量在最终特征中的重要性，有效地提升了命名识别的效果。"}
{"text": "与基于词向量和字符级向量拼接的方法相比，基于注意力机制的方法在八个数据集上都获得了最好的实验结果。"}
{"text": "图4-8基于注意力机制的词向量和字符级向量组合方法[6]4.2.2关系抽取关系抽取是知识抽取的重要子任务之一，面向非结构化文本数据，关系抽取是从文本中抽取出两个或者多个实体之间的语义关系。"}
{"text": "关系抽取与实体抽取密切相关，一般在识别出文本中的实体后，再抽取实体之间可能存在的关系。"}
{"text": "目前，关系抽取方法可以分为基于模板的关系抽取方法、基于监督学习的关系抽取方法和基于弱监督学习的关系抽取方法。"}
{"text": "1.基于模板的关系抽取方法早期的实体关系抽取方法大多基于模板匹配实现。"}
{"text": "该类方法基于语言学知识，结合语料的特点，由领域专家手工编写模板，从文本中匹配具有特定关系的实体。"}
{"text": "在小规模、限定领域的实体关系抽取问题上，基于模板的方法能够取得较好的效果。"}
{"text": "假设想从文本中自动抽取具有“夫妻”关系的实体，并且观察到包含“夫妻”关系的例句。"}
{"text": "板：●例句1:[姚明]与妻子[叶莉]还有女儿姚沁蕾并排坐在景区的游览车上，画面十分温馨●例句2:[徐峥]老婆[陶虹]晒新写真可以简单地将上述句子中的实体替换为变量，从而得到如下能够获取“夫妻”关系的模●模板1:[X]与妻子[Y]……●模板2:[X]老婆[Y]……利用上述模板在文本中进行匹配，可以获得新的具有“夫妻”关系的实体。"}
{"text": "为了进一步提高模板匹配的准确率，还可以将句法分析的结果加入模板中。"}
{"text": "基于模板的关系抽取方法的优点是模板构建简单，可以比较快地在小规模数据集上实现关系抽取系统。"}
{"text": "但是，当数据规模较大时，手工构建模板需要耗费领域专家大量的时间。"}
{"text": "此外，基于模板的关系抽取系统可移植性较差，当面临另一个领域的关系抽取问题时，需要重新构建模板。"}
{"text": "最后，由于手工构建的模板数量有限，模板覆盖的范围不够，基于模板的关系抽取系统召回率普遍不高。"}
{"text": "2.基于监督学习的关系抽取方法基于监督学习的关系抽取方法将关系抽取转化为分类问题，在大量标注数据的基础上，训练有监督学习模型进行关系抽取。"}
{"text": "利用监督学习方法进行关系抽取的一般步骤包括：预定义关系的类型；人工标注数据；设计关系识别所需的特征，一般根据实体所在句子的上下文计算获得；选择分类模型（如支持向量机、神经网络和朴素贝叶斯等），基于标注数据训练模型；对训练的模型进行评估。"}
{"text": "在上述步骤中，关系抽取特征的定义对于抽取的结果具有较大的影响，因此大量的研究工作围绕关系抽取特征的设计展开。"}
{"text": "根据计算特征的复杂性，可以将常用的特征分为轻量级、中等量级和重量级三大类。"}
{"text": "轻量级特征主要是基于实体和词的特征，例如句子中实体前后的词、实体的类型以及实体之间的距离等。"}
{"text": "中等量级特征主要是基于句子中语块序列的特征。"}
{"text": "重量级特征一般包括实体间的依存关系路径、实体间依存树结构的距离以及其他特定的结构信息。"}
{"text": "例如，对于句子“Forward_[motion]_of_the_vehicle_through_the_air_caused_a_[suction]_on_thetube”，轻量级的特征可以是实体[motion]和[suction]、实体间的词road{of,the,vehicle,through,the,air,caused,a}等；重量级的特征可以包括依存树中的路径“caused→nsubj→实体1”“caused→dobj→实体2”等。"}
{"text": "draft传统的基于监督学习的关系抽取是一种依赖特征工程的方法，近年来有多个基于深度学习的关系抽取模型被研究者们提出。"}
{"text": "深度学习的方法不需要人工构建各种特征，其输入一般只包括句子中的词及其位置的向量表示。"}
{"text": "目前，已有的基于深度学习的关系抽取方法主要包括流水线方法和联合抽取方法两大类。"}
{"text": "流水线方法将识别实体和关系抽取作为两个分离的过程进行处理，两者不会相互影响；关系抽取在实体抽取结果的基础上进行，因此关系抽取的结果也依赖于实体抽取的结果。"}
{"text": "联合抽取方法将实体抽取和关系抽取相结合，在统一的模型中共同优化；联合抽取方法可以避免流水线方法存在的错误积累问题。"}
{"text": "（1）基于深度学习的流水线关系抽取方法●CR-CNN模型[7]。"}
{"text": "给定输入的句子，CR-CNN模型首先将句子中的词映射到长度为dw的低维向量，每个词的向量包含了词向量和位置向量两部分。"}
{"text": "然后，模型对固定大小滑动窗口中的词的向量进行卷积操作，为每个窗口生成新的长度为dc的特征向量；对所有的窗口特征向量求最大值，模型最终得到整个句子的向量表示dx。"}
{"text": "在进行关系分类时，CR-CNN模型计算句子向量和每个关系类型向量的点积，得到实体具有每种预定义关系的分值。"}
{"text": "CR-CNN模型在SemEval-2010_Task_8数据集上获得了84.1%的F1值，这个结果优于当时最好的非深度学习方法。"}
{"text": "图4-9CR-CNN模型[7]●Attention_CNNs模型[8]。"}
{"text": "Wang等人提出的多层注意力卷积神经网络（Multi-levelAttention_CNN），将注意力机制引入到神经网络中，对反映实体关系更重要的词语赋予更大的权重，借助改进后的目标函数提高关系提取的效果。"}
{"text": "其模型的结构如图4-10所示，在输入层，模型引入了词与实体相关的注意力，同时还在池化和混合层引入了针对目标关系类别的注意力。"}
{"text": "在SemEval-2010_Task_8数据集上，该模型获得了88%的F1值。"}
{"text": "●Attention_BLSTM模型[9]。"}
{"text": "Attention_BLSTM模型如图4-11所示，它包含两个LSTM网络，从正向和反向处理输入的句子，从而得到每个词考虑左边和右边序列背景的状态向量；词的两个状态向量通过元素级求和产生词的向量表示。"}
{"text": "在双向LSTM产生的词向量基础上，该模型通过注意力层组合词的向量产生句子向量，进而基于句子向量将关系分类。"}
{"text": "注意力层首先计算每个状态向量的权重，然后计算所有状态向量的加权和得到句子的向量表示。"}
{"text": "实验结果表明，增加注意力层可以有效地提升关系分类的结果。"}
{"text": "图4-10Attention_CNNs模型的结构[8]图4-11Attention_BLSTM模型[9]在关系抽取问题方面，还有许多其他属于流水线方法的深度学习模型。"}
{"text": "图4-12关系抽取模型在SemEval-2010_Task_8数据集F1值对比（%）（2）基于深度学习的联合关系抽取方法。"}
{"text": "在流水线关系抽取方法中，实体抽取和关系抽取两个过程是分离的。"}
{"text": "联合关系抽取方法则是将实体抽取和关系抽取相结合，图4-13展示的是一个实体抽取和关系抽取的联合模型[13]。"}
{"text": "该模型主要由三个表示层组成：词嵌入层（嵌入层）、基于单词序列的LSTM-RNN层（序列层）以及基于依赖性子树的LSTM-RNN层（依存关系层）。"}
{"text": "在解码过程中，模型在序列层上构建从左到右的实体识别，并实现依存关系层上的关系分类，其中每个基于子树的LSTM-RNN对应于两个被识别实体之间的候选关系。"}
{"text": "在对整个模型结构进行解码之后，模型参数通过基于时间的反向传播进行更新。"}
{"text": "在依存关系层堆叠在序列层上，因此嵌入层和序列层被实体识别和关系分类任务共享，共享参数受实体和关系标签的共同影响。"}
{"text": "该联合模型在SemEval-2010_Task8数据集上获得了84.4%的F1值；将WordNet作为外部知识后，该模型可以获得85.6%的F1值。"}
{"text": "图4-13实体抽取和关系抽取的联合模型[13]3.基于弱监督学习的关系抽取方法基于监督学习的关系抽取方法需要大量的训练语料，特别是基于深度学习的方法，模型的优化更依赖大量的训练数据。"}
{"text": "当训练语料不足时，弱监督学习方法可以只利用少量的标注数据进行模型学习。"}
{"text": "基于弱监督学习的关系抽取方法主要包括远程监督方法和Bootstrapping方法。"}
{"text": "（1）远程监督方法。"}
{"text": "远程监督方法通过将知识图谱与非结构化文本对齐的方式自动构建大量的训练数据，减少模型对人工标注数据的依赖，增强模型的跨领域适应能力。"}
{"text": "远程监督方法的基本假设是如果两个实体在知识图谱中存在某种关系，则包含两个实体的句子均表达了这种关系。"}
{"text": "例如，在某知识图谱中存在实体关系创始人（乔布斯，苹果公司），则包含实体乔布斯和苹果公司的句子“乔布斯是苹果公司的联合创始人和CEO”则可被用作关系创始人的训练正例。"}
{"text": "因此，远程监督关系抽取方法的一般步骤为：●从知识图谱中抽取存在目标关系的实体对；●从非结构化文本中抽取含有实体对的句子作为训练样例；●训练监督学习模型进行关系抽取。"}
{"text": "远程监督关系抽取方法可以利用丰富的知识图谱信息获取训练数据，有效地减少了人工标注的工作量。"}
{"text": "但是，基于远程监督的假设，大量噪声会被引入到训练数据中，从而引发语义漂移的现象。"}
{"text": "为了改进远程监督实体关系抽取方法，一些研究围绕如何克服训练数据中的噪声问题展开。"}
{"text": "最近，多示例学习、采用注意力机制的深度学习模型以及强化学习等模型被用来解决样例错误标注的问题，取得了较好的效果。"}
{"text": "下面介绍两个具有代表性的模型。"}
{"text": "Guoliang_Ji等人在发表于AAAI2017的论文中提出了基于句子级注意力和实体描述的神经网络关系抽取模型APCNNs[14]。"}
{"text": "模型结构如图4-14所示，图4-14（a）是PCNNs（Piecewise_Convolutional_Neural_Networks）模型，用于提取单一句子的特征向量；其输入是词向量和位置向量，通过卷积和池化操作，得到句子的向量表示。"}
{"text": "关系的分类是基于包特征上的Softmax分类器实现的。"}
{"text": "APCNNs模型实际采用了多示例学习的策略，将同一关系的样例句子组成样例包，关系分类是基于样例包的特征进行的。"}
{"text": "实验结果表明，该模型可以有效地提高远程监督关系抽取的准确率。"}
{"text": "图4-14APCNNs模型[14]在采用多示例学习策略时，有可能出现整个样例包都包含大量噪声的情况。"}
{"text": "针对这一问题，Jun_Feng等人提出了基于强化学习的关系分类模型CNN-RL[15]。"}
{"text": "CNN-RL模型框架如图4-15所示，模型有两个重要模块：样例选择器和关系分类器。"}
{"text": "样例选择器负责从样例包中选择高质量的句子，然后由关系分类器从句子级特征对关系进行分类。"}
{"text": "整个模型采用强化学习的方式，样例选择器基于一个随机策略，在考虑当前句子的选择状态情况下选择样例句子；关系分类器利用卷积神经网络对句子中的实体关系进行分类，并向样例选择器反馈，帮助其改进样例选择策略。"}
{"text": "在实验对比中，该模型获得了比句子级卷积神经网络和样例包级关系分类模型更好的结果。"}
{"text": "图4-15CNN-RL模型[15]（2）Bootstrapping方法。"}
{"text": "Bootstrapping方法利用少量的实例作为初始种子集合，然后在种子集合上学习获得关系抽取的模板，再利用模板抽取更多的实例，加入种子集合中。"}
{"text": "通过不断地迭代，Bootstrapping方法可以从文本中抽取关系的大量实例。"}
{"text": "有很多实体关系抽取系统都采用了Bootstrapping方法。"}
{"text": "Brin等人[16]构建的DIPER利用少量实体对作为种子，从Web上大量非结构化文本中抽取新的实例，同时学习新的抽取模板，迭代地获取实体关系，是较早使用Bootstrapping方法的系统。"}
{"text": "Agichtein等人[17]设计实现了Snowball关系抽取系统，该系统在DIPER系统基础上提出了模板生成和关系抽取的新策略。"}
{"text": "在关系抽取过程中，Snowball可以自动评价新实例的可信度，并保留最可靠的实例加入种子集合。"}
{"text": "Etzioni等人[18]构建了KnowItAll抽取系统，从Web文本中抽取非特定领域的事实信息，该系统关系抽取的准确率能达到90%。"}
{"text": "此后，一些基于Bootstrapping的系统加入了更合理的模板描述、限制条件和评分策略，进一步提高了关系抽取的准确率。"}
{"text": "例如NELL系统[19]，它以初始本体和少量种子作为输入，从大规模的Web文本中学习，并对学习到的内容进行打分来提升系统性能。"}
{"text": "Bootstrapping方法的优点是关系抽取系统构建成本低，适合大规模的关系抽取任务，并且具备发现新关系的能力。"}
{"text": "但是，Bootstrapping方法也存在不足之处，包括对初始种子较为敏感、存在语义漂移问题、结果准确率较低等。"}
{"text": "4.2.3事件抽取事件是指发生的事情，通常具有时间、地点、参与者等属性。"}
{"text": "事件的发生可能是因为一个动作的产生或者系统状态的改变。"}
{"text": "事件抽取是指从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式呈现出来，例如事件发生的时间、地点、发生原因、参与者等。"}
{"text": "基于一段苹果公司举办产品发布会的新闻报道，可以通过事件抽取方法自动获取报道事件的结构化信息，包括事件类型、涉及公司、发生时间及地点、所发布的产品。"}
{"text": "一般地，事件抽取任务包含的子任务有：●识别事件触发词及事件类型；●抽取事件元素的同时判断其角色；●抽出描述事件的词组或句子；●事件属性标注；●事件共指消解。"}
{"text": "图4-16事件抽取示例已有的事件抽取方法可以分为流水线方法和联合抽取方法两大类。"}
{"text": "1.事件抽取的流水线方法流水线方法将事件抽取任务分解为一系列基于分类的子任务，包括事件识别、元素抽取、属性分类和可报告性判别；每一个子任务由一个机器学习分类器负责实施。"}
{"text": "一个基本的事件抽取流水线需要的分类器包括：（1）事件触发词分类器。"}
{"text": "判断词汇是否为事件触发词，并基于触发词信息对事件类别进行分类。"}
{"text": "（2）元素分类器。"}
{"text": "判断词组是否为事件的元素。"}
{"text": "（3）元素角色分类器。"}
{"text": "判定事件元素的角色类别。"}
{"text": "（4）属性分类器。"}
{"text": "判定事件的属性。"}
{"text": "（5）可报告性分类器。"}
{"text": "判定是否存在值得报告的事件实例。"}
{"text": "表4-2列出了在事件抽取过程中，触发词分类和元素分类常用的分类特征。"}
{"text": "各个阶段的分类器可以采用机器学习算法中的不同分类器，例如最大熵模型、支持向量机等。"}
{"text": "表4-2触发词分类和元素分类常用的分类特征2.事件的联合抽取方法事件抽取的流水线方法在每个子任务阶段都有可能存在误差，这种误差会从前面的环节逐步传播到后面的环节，从而导致误差不断累积，使得事件抽取的性能急剧衰减。"}
{"text": "为了解决这一问题，一些研究工作提出了事件的联合抽取方法。"}
{"text": "在联合抽取方法中，事件的所有相关信息会通过一个模型同时抽取出来。"}
{"text": "一般地，联合事件抽取方法可以采用联合推断或联合建模的方法，如图4-17所示。"}
{"text": "联合推断方法首先建立事件抽取子任务的模型，然后将各个模型的目标函数进行组合，形成联合推断的目标函数；通过对联合目标函数进行优化，获得事件抽取各个子任务的结果。"}
{"text": "联合建模的方法在充分分析子任务间的关系后，基于概率图模型进行联合建模，获得事件抽取的总体结果。"}
{"text": "具有代表性的联合建模方法是Qi_Li等人在ACL2013论文中提出的联合事件抽取模型[20]。"}
{"text": "该模型将事件触发词、元素抽取的局部特征和捕获任务之间关联的结构特征结合进行事件抽取。"}
{"text": "在图4-18所示的事件触发词和事件元素示例中，“fired”是袭击（Attack）事件的触发词，但是由于该词本身具有歧义性，流水线方法中的局部分类器很容易将其错误分类；但是，如果考虑到“tank”很可能是袭击事件的工具（Instrument）元素，那么就比较容易判断“fired”触发的是袭击事件。"}
{"text": "此外，在流水线方法中，局部的分类器也不能捕获“fired”和“died”之间的依赖关系。"}
{"text": "为了克服局部分类器的不足，新的联合抽取模型在使用大量局部特征的基础上，增加了若干全局特征。"}
{"text": "例如，在图4-18的句子中，事件死亡（Die）和事件（Attack）的提及“died”和“fired”共享了三个参数；基于这种情况，可以定义形如图4-19所示的事件抽取全局特征。"}
{"text": "这类全局特征可以从整体的结构中学习得到，从而使用全局的信息来提升局部的预测。"}
{"text": "联合抽取模型将事件抽取问题转换成结构预测问题，并使用集束搜索方法进行求解。"}
{"text": "图4-17联合事件抽取方法图4-18事件触发词和事件元素示例图4-19事件抽取全局特征在事件抽取任务上，同样有一些基于深度学习的方法被提出。"}
{"text": "传统的事件抽取方法通常需要借助外部的自然语言处理工具和大量的人工设计的特征；与之相比，深度学习方法具有以下优势：●减少了对外部工具的依赖，甚至不依赖外部工具，可以构建端到端的系统；●使用词向量作为输入，词向量蕴涵了丰富的语义信息；●神经网络具有自动提取句子特征的能力，避免了人工设计特征的烦琐工作。"}
{"text": "图4-20展示了一个基于动态多池化卷积神经网络的事件抽取模型。"}
{"text": "该模型由YuboChen等人于2015年发表在ACL会议上[21]。"}
{"text": "模型总体包含词向量学习、词汇级特征抽取、句子级特征抽取和分类器输出四个部分。"}
{"text": "其中，词向量学习通过无监督方式学习词的向量表示；词汇级特征抽取基于词的向量表示获取事件抽取相关的词汇线索；句子级特征抽取通过动态多池化卷积神经网络获取句子的语义组合特征；分类器输出产生事件元素的角色类别。"}
{"text": "在CNN方法的结果。"}
{"text": "ACE2005英文数据集上的实验表明，该模型获得了优于传统方法和其他图4-20基于动态多池化卷积神经网络的事件抽取模型4.3面向结构化数据的知识抽取垂直领域的知识往往来源于支撑企业业务系统的关系数据库，因此，从数据库这种结构化数据中抽取知识也是一类重要的知识抽取方法。"}
{"text": "在该领域，已经有一些标准和工具支持将数据库数据转化为RDF数据、OWL本体等。"}
{"text": "W3C的RDB2RDF工作组于2012年发布了两个推荐的RDB2RDF映射语言：DM（Direct_Mapping，直接映射）和R2RML。"}
{"text": "DM和R2ML映射语言用于定义关系数据库中的数据如何转换为RDF数据的各种规则，具体包括URI的生成、RDF类和属性的定义、空节点的处理、数据间关联关系的表达等。"}
{"text": "4.3.1直接映射直接映射规范定义了一个从关系数据库到RDF图数据的简单转换，为定义和比较更复杂的转换提供了基础。"}
{"text": "它也可用于实现RDF图或定义虚拟图，可以通过SPARQL查询或通过RDF图API访问。"}
{"text": "直接映射将关系数据库表结构和数据直接转换为RDF图，关系数据库的数据结构直接反映在RDF图中。"}
{"text": "直接映射的基本规则包括：●数据库中的表映射为RDF类；●数据库中表的列映射为RDF属性；●数据库表中每一行映射为一个资源或实体，创建IRI；●数据库表中每个单元格的值映射为一个文字值（Literal_Value）；如果单元格的值对应一个外键，则将其替换为外键值指向的资源或实体的IRI。"}
{"text": "下面给出一个简单的例子，解释直接映射的基本思路。"}
{"text": "首先，假设通过SQL语句创建图4-21中的两个数据库表。"}
{"text": "创建数据库表的SQL语句如下：基于直接映射标准，上述两个表可以输出如下的RDF数据：图4-21数据库表在直接映射过程中，数据库表中的每一行（例如People表中的<7,“Bob”,18>）产生了一组具有共同主语（subject）的三元组。"}
{"text": "主语是由IRI前缀和表名（People）、主键列名（ID）、主键值（7）串联而成的IRI。"}
{"text": "每列的谓词是由IRI前缀和表名、列名连接形成的IRI。"}
{"text": "这些值是从列值的词汇形式形成的RDF文字。"}
{"text": "每个外键都会生成一个三元组，其谓词由外键列名、引用表和引用的列名组成。"}
{"text": "这些三元组的宾语是被引用三元组的行标识符（例如<Addresses/ID=18>）。"}
{"text": "直接映射不会为NULL值生成三元组。"}
{"text": "4.3.2R2RMLR2RML映射语言是一种用于表示从关系数据库到RDF数据集的自定义映射的语言。"}
{"text": "这种映射提供了在RDF数据模型下查看现有关系型数据的能力，并且可以基于用户自定义的结构和目标词汇表示原有的关系型数据。"}
{"text": "在数据库的直接映射中，生成的RDF图的结构直接反映了数据库的结构，目标RDF词汇直接反映数据库模式元素的名称，结构和目标词汇都不能改变。"}
{"text": "然而，通过使用R2RML，用户可以在关系数据上灵活定制视图。"}
{"text": "每个R2RML映射都针对特定的数据库模式和目标词汇量身定制。"}
{"text": "R2RML映射的输入是符合该模式的关系数据库，输出是采用目标词汇表中谓词和类型描述的RDF数据集。"}
{"text": "R2RML映射是通过逻辑表（Logic_Tables）从数据库中检索数据的。"}
{"text": "一个逻辑表可以是数据库中的一个表、视图或有效的SQL语句查询。"}
{"text": "每个逻辑表通过三元组映射（Triples_Map）映射至RDF数据，而三元组映射是可以将逻辑表中每一行映射为若干RDF三元组的规则。"}
{"text": "“逻辑表”突破了关系数据库表的物理结构的限制，为不改变数据库原有的结构而灵活地按需生成RDF数据奠定了基础。"}
{"text": "三元组映射的规则主要包括两个部分，一个主语映射和多个谓词-宾语映射。"}
{"text": "主语映射从逻辑表生成所有RDF三元组中的主语，通常使用基于数据库表中的主键生成的IRI表示。"}
{"text": "谓词-宾语映射则包含了谓词映射和宾语映射，其过程与主语映射相似。"}
{"text": "图4-22中给出了一个示例数据库，其包含两个表，分别是雇用表和部门表。"}
{"text": "将上述数据库映射为RDF数据，期望的输出结果如下：图4-22示例数据库为了生成期望的输出结果，可以基于R2RML定义如下所示的映射文档：在上述例子中，为了将图4-22中的DEPT表中数据转换为RDF数据，可以基于SQL语句查询定义一个R2RML视图，然后基于该视图定义R2RML映射文档。"}
{"text": "用于创建R2RML视图的SQL语句如下所示。"}
{"text": "用于DEPT表数据转换的R2RML映射文档如下所示。"}
{"text": "此外，为了生成谓词ex:department的三元组，需要将EMP和DEPT表进行连接，可以通过定义下面的映射实现。"}
{"text": "4.3.3相关工具目前，有许多工具支持以访问知识图谱的形式直接访问关系数据库，可以直接使用语句查询数据库中的信息；这类工具也常被称为基于本体的数据库访问SPARQL（Ontology_Based_Database_Access,OBDA）系统。"}
{"text": "这里介绍几种重要的OBDA系统，表4-3列出了这些系统的主要特性。"}
{"text": "表4-3OBDA系统的主要特性对比（1）D2RQ[22]。"}
{"text": "D2RQ是较早开发和发布的OBDA系统，它可以将关系数据库以RDF形式发布，其平台框架如图4-23所示。"}
{"text": "其中，D2R_Server是一个HTTP_Server，主要功能提供对RDF数据的查询访问接口，供上层的RDF浏览器、SPARQL查询客户端以及HTML浏览器调用。"}
{"text": "D2R_Server使用了一种可定制的D2RQ映射文件将关系数据库内容映射为RDF格式，与本章前面介绍的映射语言十分相似。"}
{"text": "基于D2RQ映射，Web端的请求被重写为SQL查询，这种即时转换允许从大型实时数据库发布RDF，而无须将数据复制到专用的RDF三元组存储中。"}
{"text": "此外，D2RQ系统还部分支持R2RML映射。"}
{"text": "（2）Mastro[23]。"}
{"text": "Mastro是一个基于Java语言开发的OBDA系统，系统中的本体使用属于DL-Lite轻量级描述逻辑系列的语言定义，通过数据库和本体元素之间的映射，用户可以通过SPARQL查询数据库。"}
{"text": "Mastro数据源管理器支持与最流行的商业和非商业DBMS的交互。"}
{"text": "除此之外，还为Oracle、DB2、SQLServer、MySQL和PostgreSQL提供支持。"}
{"text": "图4-23D2RQ平台框架[22]图4-24Mastro系统结构[23]（3）Ultrawrap[24]。"}
{"text": "Ultrawrap是一个商业化系统，其系统结构如图4-25所示，主要包含编译器和服务器两部分。"}
{"text": "其中，编译器负责建立数据库到RDF和OWL的映射；服务器负责在数据库上执行SPARQL查询。"}
{"text": "Ultrawrap在执行SPARQL查询时可以获得与SQL语句查询相同的速度，它支持R2RML和D2RQ映射，并为用户提供图形界面个性化定制映射。"}
{"text": "图4-25Ultrawrap系统结构（4）Morph-RDB[25]。"}
{"text": "Morph-RDB是由马德里理工大学本体工程组开发的RDB2RDF引擎，遵循R2RML规范。"}
{"text": "Morph-RDB支持两种操作模式：数据升级（从关系数据库中的数据生成RDF实例）和查询转换（SPARQL到SQL）。"}
{"text": "Morph-RDB采用各种优化技术来生成高效的SQL查询，例如自连接消除和子查询消除。"}
{"text": "目前，Morph-RDB支持MySQL、PostgreSQL、H2、CSV文件和MonetDB等数据源。"}
{"text": "（5）Ontop[26]。"}
{"text": "Ontop是一个将关系数据库作为虚拟的RDF图进行SPARQL查询的工具。"}
{"text": "Ontop由Bozen-Bolzano自由大学开发，是基于Apache许可证的开源工具。"}
{"text": "通过将本体中的词汇（类和属性）通过映射链接到数据源，Ontop系统将关系数据库转换为虚拟的RDF图。"}
{"text": "Ontop支持R2RML映射，它可以将SPARQL查询翻译为关系数据库中的SQL查询，从而实现在数据库上的SPARQL查询。"}
{"text": "图4-26Ontop的系统结构[26]4.4面向半结构化数据的知识抽取半结构化数据是一种特殊的结构化数据形式，该形式的数据不符合关系数据库或其他形式的数据表形式结构，但又包含标签或其他标记来分离语义元素并保持记录和数据字段的层次结构。"}
{"text": "自万维网出现以来，半结构化数据越来越丰富，全文文档和数据库不再是唯一的数据形式，因此半结构化数据也成为知识获取的重要来源。"}
{"text": "目前，百科类数据、网页数据是可被用于知识获取的重要半结构化数据，本节将介绍面向此类数据的知识抽取方法。"}
{"text": "4.4.1面向百科类数据的知识抽取以维基百科为代表的百科类数据是典型的半结构化数据。"}
{"text": "在维基百科中，词条页面结构如图4-27所示，包含了词条标题、词条摘要、跨语言链接、分类、信息框等要素，这些都是关于描述对象的半结构化数据。"}
{"text": "图4-27维基百科词条页面结构因为词条包含丰富的半结构化数据，并且其中的信息具有较高的准确度，维基百科已经成为构建大规模知识图谱的重要数据来源。"}
{"text": "目前，基于维基百科已经构建起多个知识图谱，包括DBpedia[27]和Yago[28]等。"}
{"text": "随着中文百科站点的发展，如百度百科、互动百科，一些大规模的中文知识图谱也陆续基于百科数据被构建出来，包括Zhishi.me[29]、XLore[30]和CN-DBpedia[31]等。"}
{"text": "在基于百科数据构建知识图谱的过程中，关键问题是如何准确地从百科数据中抽取结构化语义信息。"}
{"text": "在基于百科数据构建的知识图谱中，DBpedia是较早发布、具有代表性的知识图谱，下面对它的构建方法进行介绍。"}
{"text": "DBpedia是一个大规模的多语言百科知识图谱，是维基百科的机构化版本。"}
{"text": "DBpedia采用固定模式对维基百科中的实体信息进行抽取，在Linking_Open_Data原则的指导下，将其以关联数据的形式在Web上发布与共享。"}
{"text": "得益于维基百科的数据规模，DBpedia是目前最大的跨领域知识图谱之一。"}
{"text": "截至2019年2月，DBpedia英文版描述了458万个实体，其中有422万个实体被准确地在一个本体中进行分类，其中包括144.5万个人物、73.5万个地点、41.1万件作品、24.1万个组织、25.1万个物种和6000种疾病。"}
{"text": "此外，DBpedia还提供DBpedia数据集包含超过了125种语言的本地化版本，共包含了3830万个事物。"}
{"text": "完整的3800万个来自125种不同语言的标签和摘要，2520万个图片链接和2980万个外部网页链接。"}
{"text": "DBpedia通过大约5000万个RDF链接与其他链接数据集连接，使其成为LOD数据集的重要核心。"}
{"text": "总体上，DBpedia包含约30亿条RDF三元组，其中5.8亿条是从维基百科的英文版中提取的，24.6亿条是从其他语言版本中提取的。"}
{"text": "根据抽样评测，DBpedia中RDF三元组的正确率达88%。"}
{"text": "图4-28所示为DBpedia知识抽取的总体框架。"}
{"text": "框架的主要组成部分是：页面集合，包含本地及远程的维基百科文章数据；目标数据，存储或序列化提取的RDF三元组；将特定类型的维基标记转换为三元组的提取器；支持提取器的解析器，其作用是确定数据类型，在不同单元之间转换值并将标记分解成列表；提取作业，负责将页面集合、提取器和目标数据分组到一个工作流程中；知识提取管理器，负责管理将维基百科文章传递给提取器并将其输出传递到目标数据的过程。"}
{"text": "图4-28DBpedia知识抽取的总体框架[27]DBpedia使用了多种知识提取器从维基百科中获取结构化数据，具体包括：●标签（Labels）：抽取维基百科词条的标题，并将其定义为实体的标签；●摘要（Abstracts）：抽取维基百科词条页面的第一段文字，将其定义为实体的短摘要；抽取词条目录前最长500字的长摘要。"}
{"text": "●跨语言链接（Inter-language_Links）：抽取词条页面指向其他语言版本的跨语言链接；联；●图片（Images）：提取指向图片的链接；●重定向（Redirects）：抽取维基百科词条的重定向链接，建立其与同义词条的关●消歧（Disambiguation）：从维基百科消歧页面抽取有歧义的词条链接；●外部链接（External_Links）：抽取词条正文指向维基百科外部的链接；●页面链接（Pagelinks）：抽取词条正文指向维基百科内部的链接；●主页（Homepages）：抽取诸如公司、机构等实体的主页链接；●分类（Categories）：抽取词条所属的分类；●地理坐标（Geo-Coordinates）：抽取词条页面中存在的地理位置的经纬度坐标。"}
{"text": "●信息框（infobox）：从词条页面的信息框中抽取实体的结构化信息。"}
{"text": "在上述抽取器中，信息框抽取从维基百科中取获得大量的实体属性和实体关系，是DBpedia中最有价值的信息之一。"}
{"text": "信息框抽取有两种形式，一种为一般抽取，另一种为基于映射的抽取。"}
{"text": "信息框的一般抽取直接将信息框中的信息转换为RDF三元组。"}
{"text": "三元组的主语由DBpedia的URI前缀和词条名称相连组成，谓语由信息框属性URI前缀和属性名相连组成，宾语则基于属性值创建，可以是实体的URI或者数据类型的值。"}
{"text": "然而，这种抽取方式对于维基百科信息框中存在的属性名和信息框模板同义异名问题不作处理，因此抽取出的三元组存在数据不一致的问题。"}
{"text": "为了处理该类问题，DBpedia使用了基于映射的信息框抽取方法；该方法首先将信息框的模板、属性映射到人工定义的本体中的类型和属性，然后采用本体中的词汇描述抽取出的结构化信息，获得的三元组数据质量更高。"}
{"text": "图4-29信息框示例[27]4.4.2面向Web网页的知识抽取互联网中的网页含有丰富的数据，与普通文本数据相比，网页也具有一定的结构，因此也被视为是一种半结构化的数据。"}
{"text": "从页面的HTML代码中可以看到，产品的名称、价格等具体信息可以通过HTML中的标记区分获取到。"}
{"text": "图4-30某电商网站产品搜索结果页面及其HTML代码从网页中获取结构化信息一般通过包装器实现，图4-31展示了基于包装器抽取网页信息的框架。"}
{"text": "包装器是能够将数据从HTML网页中抽取出来，并将它们还原为结构化数据的软件程序。"}
{"text": "包装器的生成方法有三大类：手工方法、包装器归纳方法和自动抽取方法。"}
{"text": "图4-31基于包装器抽取网页信息的框架1.手工方法手工方法是通过人工分析构建包装器信息抽取的规则。"}
{"text": "手工方法需要查看网页结构和代码，在人工分析的基础上，手工编写出适合当前网站的抽取表达式；表达式的形式一般可以是XPath表达式、CSS选择器的表达式等。"}
{"text": "XPath即为XML路径语言，它是一种用来确定XML（标准通用标记语言的子集）文档中某部分位置的语言。"}
{"text": "借助它可以获取网页中元素的位置，从而获取需要的信息。"}
{"text": "在图4-30的例子中，如果要获取产品价格信息，则可以定义如下XPath进行抽取：CSS选择器是通过CSS元素实现对网页中元素的定位，并获取元素信息的。"}
{"text": "分析图4-30中的搜索结果页面，价格信息的CSS选择器表达式为：2.包装器归纳方法包装器归纳方法是基于有监督学习方法从已标注的训练样例集合中学习信息抽取的规则，然后对相同模板的其他网页进行数据抽取的方法。"}
{"text": "典型的包装器归纳流程包括以下步骤：网页清洗、网页标注、包装器空间生成、包装器评估。"}
{"text": "（1）网页清洗。"}
{"text": "纠正和清理网页不规范的HTML、XML标记，可采用TIDY类工具。"}
{"text": "（2）网页标注。"}
{"text": "在网页上标注需要抽取的数据，标注过程一般是给网页中的某个位置打上特殊的标签，表明此处是需要抽取的数据。"}
{"text": "例如，在图4-30的例子中，如果需要抽取页面上“华为P10”产品的信息和价格，则可以在产品信息和价格所在的标签里打上一个特殊的标记作为标注。"}
{"text": "（3）包装器空间生成。"}
{"text": "基于标注的数据生成XPath集合空间，对生成的集合进行归纳，从而形成若干个子集。"}
{"text": "归纳的目标是使子集中的XPath能够覆盖尽可能多的已标注数据项，使其具有一定的泛化能力。"}
{"text": "（4）包装器评估。"}
{"text": "包装器可以通过准确率和召回率进行评估。"}
{"text": "使用待评估包装器对训练数据中的网页进行标注，将包装器输出的与人工标注的相同项的数量表示为N；准确率是N除以包装器输出标注的总数量，而召回率是N除以人工标注数据项的总数量。"}
{"text": "准确率和召回率越高，表示包装器的质量越好。"}
{"text": "3.自动抽取方法包装器归纳方法需要大量的人工标注工作，因而不适用对大量站点进行数据的抽取。"}
{"text": "此外，包装器维护的工作量也很大，一旦网站改版，需要重新标注数据，归纳新的包装器。"}
{"text": "自动抽取方法不需要任何的先验知识和人工标注的数据，可以很好地克服上述问题。"}
{"text": "在自动抽取方法中，相似的网页首先通过聚类被分成若干组，通过挖掘同一组中相似网页的重复模式，可以生成适用于该组网页的包装器。"}
{"text": "在应用包装器进行数据抽取时，首先将需要抽取的页面划分到先前生成的网页组，然后应用该组对应的包装器进行数据抽取。"}
{"text": "上述三种Web页面的信息抽取方法各有优点和缺点，表4-5对它们进行了对比。"}
{"text": "表4-5Web页面的信息抽取方法对比4.5知识挖掘知识挖掘是从已有的实体及实体关系出发挖掘新的知识，具体包括知识内容挖掘和知识结构挖掘。"}
{"text": "4.5.1知识内容挖掘：实体链接实体链接是指将文本中的实体指称（Mention）链向其在给定知识库中目标实体的过程。"}
{"text": "实体链接可以将文本数据转化为有实体标注的形式，建立文本与知识库的联系，可以为进一步文本分析和处理提供基础。"}
{"text": "通过实体链接，文本中的实体指称与其在知识库中对应的实体建立了链接。"}
{"text": "实体链接的基本流程如图4-33所示，包括实体指称识别、候选实体生成和候选实体消歧三个步骤，每个步骤都可以采用不同的技术和方法。"}
{"text": "图4-32实体链接示例图4-33实体链接的基本流程1.实体指称识别实体链接的第一步是要识别出文本中的实体指称，例如从图4-32给出的文本中识别[乔丹]、[美国]、[NBA]等。"}
{"text": "该步骤主要通过命名实体识别技术或者词典匹配技术实现。"}
{"text": "命名实体识别技术在本章前面已经介绍过；词典匹配技术需要首先构建问题领域的实体指称词典，通过直接与文本的匹配识别指称。"}
{"text": "2.候选实体生成候选实体生成是确定文本中的实体指称可能指向的实体集合。"}
{"text": "例如，上述例子中实体指称[乔丹]可以指代知识库中的多个实体，如[篮球运动员迈克尔乔丹]、[足球运动员迈克尔乔丹]、[运动品牌飞人乔丹]等。"}
{"text": "生成实体指称的候选实体有以下三种方法：（1）表层名字扩展。"}
{"text": "某些实体提及是缩略词或其全名的一部分，因此可以通过表层名字扩展技术，从实体提及出现的相关文档中识别其他可能的扩展变体（例如全名）。"}
{"text": "然后，可以利用这些扩展形式形成实体提及的候选实体集合。"}
{"text": "表层名字扩展可以采用启发式的模式匹配方法实现。"}
{"text": "例如，常用的模式是提取实体提及邻近括号中的缩写作为扩展结果；例如“University_of_Illinois_at_Urbana-Champaign（UIUC）”“Hewlett-Packard（HP）”等。"}
{"text": "除了使用模式匹配的方法，也有一些方法通过有监督学习的技术从文本中抽取复杂的实体名称缩写。"}
{"text": "（2）基于搜索引擎的方法。"}
{"text": "将实体提及和上下文文字提交至搜索引擎，可以根据搜索引擎返回的检索结果生成候选实体。"}
{"text": "例如，可以将实体指称作为搜索关键词提交至谷歌搜索引擎，并将其返回结果中的维基百科页面作为候选实体。"}
{"text": "此外，维基百科自有的搜索功能也可以用于生成候选实体。"}
{"text": "（3）构建查询实体引用表。"}
{"text": "很多实体链接系统都基于维基百科数据构建查询实体引用表，建立实体提及与候选实体的对应关系。"}
{"text": "实体引用表示例如表4-5所示，它可以看作是一个<键-值>映射；一个键可以对应一个或多个值。"}
{"text": "在完成引用表构建后，可以通过实体提及直接从表中获得其候选实体。"}
{"text": "为了构建查询实体引用表，常用的方法是基于维基百科中的词条页面、重定向页面、消歧页面、词条正文超链接等抽取实体提及与实体的对应关系。"}
{"text": "维基百科词条页面描述的对象通常被当作知识库中的实体，词条页面的标题即为实体提及；重定向页面的标题可以作为其所指向词条实体的提及；消歧页面标题可作为实体提及，其对应的实体是页面中列出的词条实体。"}
{"text": "维基百科页面中的链接是以[[实体|实体提及]]的格式标记的，因此处理所有的链接可以提取实体和实体提及的对应关系。"}
{"text": "表4-5实体引用表示例3.候选实体消歧在确定文本中的实体指称和它们的候选实体后，实体链接系统需要为每一个实体指称确定其指向的实体，这一步骤被称为候选实体消歧。"}
{"text": "一般地，候选实体消歧被作为排序问题进行求解；即给定实体提及，对它的候选实体按照链接可能性由大到小进行排序。"}
{"text": "总体上，候选实体消歧方法包括基于图的方法、基于概率生成模型的方法、基于主题模型的方法和基于深度学习的方法等。"}
{"text": "下面介绍每类方法中具有代表性的工作。"}
{"text": "[32]（1）基于图的方法。"}
{"text": "基于图的方法将实体指称、实体以及它们之间的关系通过图的形式表示出来，然后在图上对实体指称之间、候选实体之间、实体指称与候选实体之间的关联关系进行协同推理。"}
{"text": "该类方法比较具有代表性的是Han等人较早提出的基于参照图（Referent_Graph）协同实体链接方法[33]。"}
{"text": "Han等人提出在候选实体消歧时，首先建立如图4-34所示的参照图，图中对实体、提及-实体、实体-实体的关系进行了表示；图中实体提及和实体间的加权边表示了它们的局部依赖性；实体和实体间的加权边代表实体间的语义相关度，为进行全局协同的实体消歧提供了基础。"}
{"text": "在计算了实体提及的初始重要性度量等人的方法将其作为实体消歧的初始依据并在参照图上进行传递，该过程与后，Han_PageRank算法中节点rank值的传递与更新方式类似。"}
{"text": "最后，基于实体消歧依据的传递结果，计算一个结合局部相容度和全局依赖性的实体消歧目标函数，为每个实体提及确定能使目标函数最大化的目标实体，从而得到实体消歧结果。"}
{"text": "采用基于图的方法进行候选实体消歧的实体链接系统还有文献[34]、文献[35]等。"}
{"text": "图4-34参照图[33]（2）基于概率生成模型的方法。"}
{"text": "基于概率生成模型对实体提及和实体的联合概率进行建模，可以通过模型的推理求解实体消歧问题。"}
{"text": "在Han等人[36]提出的实体-提及概率生成模型中，实体提及被作为生成样本进行建模，其生成过程如图4-35所示。"}
{"text": "图4-35实体提及生成过程示例[36]首先，模型依据实体的概率分布P（e）选择实体提及对应的实体，如例子中的[Michael_Jeffrey_Jordan]和[Michael_I.Jordan]；然后，模型依据给定实体e实体名称的条件概率P（s|e）选择实体提及的名称，如例子中的[Jordan]和[Michael_Jordan]；最后，模型依据给定实体e上下文的条件概率P（c|e）输出实体提及的上下文。"}
{"text": "根据上述实体提及的生成过程，实体和提及的联合概率可以定义为P（m,e）=P（s,c,e）=P（e）P（s|e）P（c|e）在该方法中，P（e）对应了实体的流行度，P（s|e）对应了实体名称知识，P（c|e）对应了上下文知识。"}
{"text": "当给定实体提及m时，候选实体消歧通过以下式子实现（3）基于主题模型的方法。"}
{"text": "Han等人认为，在同一个文本中出现的实体应该与文本表述的主题相关。"}
{"text": "基于该思想，他们提出了实体-主题模型，可以对实体在文本中的相容度、实体与话题的一致性进行联合建模，从而提升实体链接的结果。"}
{"text": "实体-主题模型如图4-36所示，给定主题数量T、实体数量E、实体名称数量K和词的数量V，实体-主题模型通过如下过程生成关于主题、实体名称和实体上下文的全局知识。"}
{"text": "首先，基于E维狄利克雷分布抽样得到每个主题z中实体的分布φz；然后，基于K维狄利克雷分布抽样得到每个实体e名称的分布ψe；最后，基于V维狄利克雷分布抽样得到实体e上下文词的分布ξe。"}
{"text": "通过吉布斯抽样算法，可以基于实体-主题模型推断获得实体消歧所需的决策信息。"}
{"text": "图4-36实体-主题模型[37]（4）基于深度学习的方法。"}
{"text": "在候选实体消歧过程中，准确计算实体的相关度十分重要。"}
{"text": "因为在利用上下文中信息或进行协同实体消歧时，都需要评价实体与实体的相关度。"}
{"text": "Huang等人[38]提出了一个基于深度神经网络的实体语义相关度计算模型，如图4-37所示。"}
{"text": "在输入层，每个实体对应的输入信息包括实体E、实体拥有的关系R、实体类型ET和实体描述D。"}
{"text": "基于词袋和独热表示的输入经过词散列层进行降维，然后经过多层神经网络的非线性变换，得到语义层上实体的表示；两个实体的相关度被定义为它们语义层表示向量的余弦相似度。"}
{"text": "图4-37实体提及生成过程示例[38]4.5.2知识结构挖掘：规则挖掘1.归纳逻辑程序设计归纳逻辑程序设计（Inductive_Logic_Programming,ILP）是以一阶逻辑归纳为理论基础，并以一阶逻辑为表达语言的符号规则学习算法[39]。"}
{"text": "知识图谱中的实体关系可看作是二元谓词描述的事实，因此也可通过ILP方法从知识图谱中学习一阶逻辑规则。"}
{"text": "给定背景知识和目标谓词（知识图谱中即为关系）,ILP系统可以学习获得描述目标谓词的逻辑规则集合。"}
{"text": "FOIL[40]是早期具有代表性的ILP系统，它采用顺序覆盖的策略逐条学习逻辑规则，在学习每条规则时，FOIL采用了基于信息熵的评价函数引导搜索过程，归纳学习一阶规则。"}
{"text": "下面通过一个例子介绍FOIL的规则学习过程。"}
{"text": "设有规则学习问题如表4-6所示。"}
{"text": "背景知识描述了某一家庭的成员关系，规则学习的目标谓词为daughter，该目标谓词有若干正例和反例事实。"}
{"text": "FOIL在规则学习过程中，从空规则daughter（X,Y）←开始，逐一将可用谓词加入规则体进行考察，按照预定标准评估规则的优劣并选取最优规则；持续谓词的添加直至规则只覆盖正例而不覆盖任何反例。"}
{"text": "表4-7列出了FOIL学习单个规则的过程。"}
{"text": "当获得一个满足上述要求的规则后，FOIL将被该规则覆盖的正例移除，然后基于剩余的正例和反例再重复上述过程获得新的规则，直至所有正例都被移除。"}
{"text": "表4-6规则学习问题表4-7FOIL学习单个规则的过程注：和分别为被规则ri覆盖正例和反例的数量。"}
{"text": "在扩展规则体的每一步，FOIL选择使得规则FOIL_Gain达到最大的谓词加入规则体。"}
{"text": "FOIL_Gain的定义为：式中，Ri为当前待扩展的规则；Li+1为由候选谓词构成的新文字；和分别为被规则Ri覆盖正例和反例的数量；和分别为被新规则Ri+1覆盖正例和反例的数量；为同时被规则Ri和Ri+1覆盖的正例数量。"}
{"text": "基于FOIL_Gain评价函数，FOIL在构建规则的每一阶段倾向于选择覆盖较多正例和较少反例的规则。"}
{"text": "在早期的ILP系统中，还有以Progol[41]为代表的基于逆语义蕴涵的学习方法。"}
{"text": "文献[39,42]对大量ILP方法进行了综述。"}
{"text": "多数ILP系统仅适用于小规模的数据集，在较大规模的数据集上运行效率不高。"}
{"text": "因此，近年来也有大量研究致力于提高ILP系统的可扩展性，这些工作包括FOIL-D[43]、PILP[44]、QuickFOIL[45]和分布式并行的ILP系统[46]等。"}
{"text": "最近，针对大规模知识图谱的特点，Galarraga等人研究并提出了AMIE系统[47];AMIE采用关联规则挖掘的方法，并定义了新的支持度和覆盖度度量对搜索空间进行剪枝，并可以在知识图谱不完备的条件下评价规则，在规则质量和学习效率方面都比传统ILP方法有很大的提升。"}
{"text": "在对AMIE多个计算过程进行优化后，Galarraga等人又发布了其升级系统AMIE+[48]，新系统具有更高的计算效率。"}
{"text": "2.路径排序算法（PathRankingAlgorithm,PRA）PRA[49,50]是一种将关系路径作为特征的知识图谱链接预测算法，因为其获取的关系路径实际上对应一种霍恩子句，PRA计算的路径特征可以转换为逻辑规则，便于人们发现和理解知识图谱中隐藏的知识。"}
{"text": "PRA的基本思想是通过发现连接两个实体的一组关系路径来预测实体间可能存在的某种特定关系。"}
{"text": "如图4-38所示，若要预测球员和赛事联盟之间的AlthletePlaysForLeague关系，连接实体HinesWard和NFL的关系路径<AlthletePlaysForTeam,TeamPlaysInLeague>可以作为预测模型的一个重要特征。"}
{"text": "实际上，该关系路径对应着一个常识知识，可以用图4-39中的霍恩子句表示。"}
{"text": "在链接预测过程中，PRA会自动发现有用的关系路径来构建预测模型；PRA具体的工作流程分为三个重要的步骤：特征选择、特征计算和关系分类。"}
{"text": "图4-38示例知识图谱子图[50]图4-39霍恩子句（1）特征选择。"}
{"text": "因为知识图谱中连接特定实体对的关系路径数量可能会很多，特别是当允许的关系路径长度较长时，关系路径的数量将快速增长。"}
{"text": "PRA并不使用连接实体对的所有关系路径作为模型的特征，所以第一步会对关系路径进行选择，仅保留对于预测目标关系潜在有用的关系路径。"}
{"text": "为了保证特征选择的效率，PRA使用了基于随机游走的特征选择方法；对于某个关系路径π,PRA基于随机游走计算该路径的准确度（precision）和覆盖度（coverage）。"}
{"text": "式中，P（si→Gi;π）是以实体si为起点，沿着关系路径π进行随机游走能够抵达目标实体的概率。"}
{"text": "PRA对于准确度和覆盖度都分别设定阈值，只有当两个度量值不小于阈值的关系路径时，才被作为特征保留。"}
{"text": "（2）特征计算。"}
{"text": "在选择了有用的关系路径作为特征之后，PRA将为每个实体对计算其特征值。"}
{"text": "给定实体对(h,t)和某一特征路径π,PRA将从实体s为起点沿着关系路径π进行随机游走抵达实体t的概率作为该实体对在关系路径π特征的值。"}
{"text": "通过计算实体对在每个特征关系路径上的可达概率，就可以得到该实体对所有特征的值。"}
{"text": "（3）关系分类。"}
{"text": "基于训练样例（目标关系的正例实体对和反例实体对）和它们的特征，PRA为每个目标关系训练一个分类模型。"}
{"text": "利用训练完的模型，可以预测知识图谱中任意两个实体间是否存在某特定关系。"}
{"text": "关系分类可以使用任何一种分类模型，PRA中使用了逻辑回归分类模型，并取得了较好的效果。"}
{"text": "PRA在训练逻辑回归模型的过程中，可以获得关系路径的权重，从而可以对路径的重要性进行排序；而且关系路径具有很好的可解释性。"}
{"text": "图4-40PRA在NELL数据集上进行链接预测时获得的重要关系路径和相应解释[50]4.6开源工具实践：基于DeepDive的关系抽取实践本实践介绍了一个公司实体间的股权交易关系的实例，该案例是基于斯坦福大学DeepDive开源关系抽取框架实现的。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "该框架遵循Apache开源协议。"}
{"text": "4.6.1开源工具的技术架构如图4-41所示为DeepDive的整体处理流程，主要分为数据准备和因子图模型构建两个部分，CNdeepdive在此基础上添加了神经网络模型和增量操作。"}
{"text": "在具体应用中，可以选择使用因子图模型或神经网络模型。"}
{"text": "图4-41DeepDive的整体处理流程图中浅色字体部分是股权交易关系抽取实例在框架中对应的文件名、命令或需要配置的脚本文件。"}
{"text": "第5章知识图谱融合汪鹏东南大学5.1什么是知识图谱融合知识图谱包含描述抽象知识的本体层和描述具体事实的实例层。"}
{"text": "本体层用于描述特定领域中的抽象概念、属性、公理；实例层用于描述具体的实体对象、实体间的关系，包含大量的事实和数据。"}
{"text": "一方面，本体虽然能解决特定应用中的知识共享问题，但事实上不可能构建出一个覆盖万事万物的统一本体，这不仅是因为世界知识的无限性决定构建这样的本体在工程上难以实施，更重要的是由于本体构建所具有的主观性和分布性特点决定了这种统一本体的构建无法得到一致的认可；此外，过于庞大的本体也往往难以维护和使用。"}
{"text": "在实际应用中，不同的用户和团体根据不同的应用需求和应用领域来构建或选择合适的本体。"}
{"text": "这样一来，即使在同一个领域内也往往存在着大量的本体。"}
{"text": "这些本体描述的内容在语义上往往重叠或关联，但使用的本体在表示语言和表示模型上却具有差异，这便造成了本体异构。"}
{"text": "在知识图谱应用中，为了获取其他应用所拥有的信息，或者联合多个应用以实现更强大的功能，不同应用系统之间的信息交互非常的普遍和频繁。"}
{"text": "然而，如果不同的系统采用的本体是异构的，它们之间的信息交互便无法正常进行。"}
{"text": "在实际的知识图谱应用中，本体异构造成了大量的信息交互问题。"}
{"text": "因此，解决本体异构、消除应用系统间的互操作障碍是很多知识图谱应用面临的关键问题之一。"}
{"text": "另一方面，知识图谱中的大量实例也存在异构问题，同名实例可能指代不同的实体，不同名实例可能指代同一个实体，大量的共指问题会给知识图谱的应用造成负面影响。"}
{"text": "因此，知识图谱应用还需要解决实例层的异构问题。"}
{"text": "知识融合是解决知识图谱异构问题的有效途径。"}
{"text": "知识融合建立异构本体或异构实例之间的联系，从而使异构的知识图谱能相互沟通，实现它们之间的互操作。"}
{"text": "为了解决知识融合问题，首先需要分析造成本体异构和实例异构的原因，这是解决知识融合问题的基础。"}
{"text": "其次，还需要明确融合针对的具体对象，建立何种功能的映射，以及映射的复杂程度，这对于选择合适的融合方法非常重要。"}
{"text": "知识融合的核心问题在于映射的生成。"}
{"text": "目前的各种本体匹配和实例匹配使用的技术基本可归结为基于自然语言处理进行术语比较、基于本体结构进行匹配，以及基于实例的机器学习等几类；不同的技术在效果、效率以及适应的范围方面都有不同，综合使用多种方法或技术往往能提高映射的结果质量。"}
{"text": "5.2知识图谱中的异构问题在解决局部领域中信息共享问题的同时，知识图谱的使用也引入了新的问题。"}
{"text": "首先，由于同一领域中不同组织建立的知识图谱往往是异构的，基于不同知识图谱的系统间的互操作依然困难；其次，交叉领域中的知识通常是异构的，相互之间的信息交互问题依然没有解决；最后，由于人类本身知识体系的复杂性和对世界的不同主观看法，建立一个包罗万象的统一知识图谱并不现实。"}
{"text": "因此，随着知识图谱的广泛应用，知识图谱异构带来的信息互操作困难将普遍存在。"}
{"text": "在基于知识图谱的应用中，由于获取数据或者为了实现特定的功能，不同系统间常常要进行信息交互，同一系统也往往要处理来自多个领域的信息。"}
{"text": "这些具体应用都涉及知识图谱异构，处理知识图谱间的异构问题成为大量系统实现互操作的关键。"}
{"text": "实际上，针对模型之间的异构问题的研究早在面向对象建模和数据库建模领域中就已经开展了[1]。"}
{"text": "模型间的不匹配是导致异构的根本原因。"}
{"text": "与这些模型相似，知识图谱之间的不匹配正是造成知识图谱异构的直接原因。"}
{"text": "然而，知识图谱中的本体远比面向对象模型或数据库模式更为复杂，造成本体异构的不匹配因素更多；知识图谱中的实例规模通常较大，其异构形式也具有多样性。"}
{"text": "尽管知识图谱的异构形式多种多样，但总的来说，这些异构的情形都可被划分为两个层次[2]：第一个层次是语言层不匹配，是指用来描述知识的元语言是不匹配的，其中既包括描述知识语言的语法和所使用的语言原语上的不匹配，还包括定义类、关系和公理等知识成分机制上的不匹配；第二个层次是模型层不匹配，是指由于本体建模方式不同所造成的不匹配，包括不同的建模者对事物的概念化抽象不匹配、对相同概念或关系的划分方式不匹配，以及对本体成分解释的不匹配。"}
{"text": "明确这些不匹配的因素是解决知识图谱异构问题的基础。"}
{"text": "下面分别阐述这两种层次上的异构。"}
{"text": "5.2.1语言层不匹配在知识工程发展的过程中出现了多种知识表示语言。"}
{"text": "不同的时期都存在着几种流行的语言，如早期有Ontolingua和Loom等本体语言，近年则有DAML+OIL、RDF(S)、OWL和OWL2等。"}
{"text": "这些本体语言之间往往并非完全兼容。"}
{"text": "当不同时期构建的知识或同一时期采用不同语言表示的知识进行交互时，首先面临着由于知识表示语言之间的不匹配所造成的异构问题[3]。"}
{"text": "这类语言层次上不匹配的情形分为语法不匹配、逻辑表示不匹配、原语的语义不匹配和语言表达能力不匹配四类。"}
{"text": "1.语法不匹配不同的知识描述语言常采用不同的语法。"}
{"text": "近年来的本体语言基本采用XML的书写格式，而早期的本体语言则没有固定的格式可言。"}
{"text": "以如何定义一个概念为例：在RDFSchema中，定义一个概念可采用<rdfs:Class_rdf:ID=\"CLASSNAME\"/>的形式；在Loom中，可采用(defconcept_CLASSNAME)定义一个类；而在Ontolingua中，定义一个类则采用(define-class_COMPONENT（?x）…)的形式。"}
{"text": "这种语法上的差异是本体之间最简单的不匹配之一。"}
{"text": "一般来说，如果表示的成分在两种语言中都是存在的，则采用一个简单的重写机制就足以解决这类问题。"}
{"text": "但是，语法上的不匹配通常不会单独出现，而是与其他语言层上的差异同时出现。"}
{"text": "因此，尽量将不同的语言转化为同样的语法格式能方便解决其他本体不匹配问题。"}
{"text": "2.逻辑表示不匹配不同语言的逻辑表示也可能存在着不匹配。"}
{"text": "例如，为了表示两个类是不相交的，一些语言可能采用明确的声明，如在rdf:ID=\"A\"><owl:disjointWith_rdf:resource=\"#B\"/></owl:Class>，而另一些语言则必须借助子类和非算子来完成同样的声明，即采用A_subclass-of(NOT_B)、B_subclass-of(NOT_A)来表示同样的结果。"}
{"text": "这就是说，不同的语言可能采用不同的形式来表示逻辑意义上的等价结果。"}
{"text": "这一类中可表示为：<owl:Class_OWL的不匹配与本体语言所采用的逻辑表示有关。"}
{"text": "相对而言，这类不匹配也容易解决，例如，通过定义从语言L1逻辑表示到语言L2的逻辑表示的转换规则。"}
{"text": "3.原语的语义不匹配在语言层的另一个不匹配是语言原语的语义。"}
{"text": "尽管有时不同的语言使用同样名称的原语来进行本体构建，但它们的语义是有差异的。"}
{"text": "例如，在OWL_Lite和OWL_DL语言中，原语“Class”声明的对象只能作为本体中的概念，而在OWL_Full和RDF(S)中，“Class”声明的对象既可以作为一个类，也可以作为一个实例。"}
{"text": "有时，即使两个本体看起来使用同样的语法，但它们的语义是有差别的。"}
{"text": "例如，在OIL和RDF_Schema中，当定义一个关系时往往都需要声明关系的定义域，即<rdfs:domain>，但是OIL将<rdfs:domain>的声明解释为其中参数的交，而RDF_Schema则将它解释为这些参数的并。"}
{"text": "因此，当采用不同语言的本体交互时，需要注意它们的原语表达的意义的差异。"}
{"text": "4.语言表达能力不匹配最后一种语言层的不匹配是指不同本体语言表达能力上的差异。"}
{"text": "这种不匹配体现在一些本体语言能够表达的事情在另一些语言中不能表达出来。"}
{"text": "一些语言支持对资源的列表、集合以及属性上的默认值等功能，而一些语言则没有；一些语言已经具有表达概念间非、并和交，以及关系间的包含、传递、对称和互逆等功能，而一些语言则不具有这样的表达能力；一些语言具有表示概念空集和概念全集的概念，如OWL中的owl:Thing和owl:Nothing。"}
{"text": "这一类的不匹配对本体的互操作影响很大[4]。"}
{"text": "一般来说，当本体语言的表达能力不同时，为了方便解决本体之间的异构，需要将表达能力弱的语言向表达能力强的语言转换；但是，如果表达能力强的语言并不完全兼容表达能力弱的语言，这样的转换可能会造成信息的损失。"}
{"text": "5.2.2模型层不匹配当不同的本体描述相交或相关领域时，在本体的模型层次上也存在着不匹配。"}
{"text": "模型层次上的不匹配与使用的本体语言无关，它们既可以发生在以同一种语言表示的本体之间，也可以发生在使用不同语言的本体之间。"}
{"text": "Visser_P_R_S等人将本体模型层上的不匹配区分为概念化不匹配和解释不匹配两种情况[3]。"}
{"text": "概念化不匹配是由于对同样的建模领域进行抽象的方式不同造成的；解释不匹配则是由于对概念化说明的方式不同造成的，这包括概念定义和使用术语上的不匹配。"}
{"text": "1.概念化不匹配概念化不匹配又可分为概念范围的不匹配和模型覆盖的不匹配两类。"}
{"text": "（1）概念范围的不匹配。"}
{"text": "同样名称的概念在不同的领域内表示的含义往往有差异；同时，不同的建模者出于对领域需求或主观认识上的不同，在建模过程中对概念的划分往往也有差异，这些都统称为概念范围的不匹配。"}
{"text": "有时，不同本体中的两个概念从表面上看似乎表示同样的概念（如具有同样的名称），而且它们之间对应的实例可能有相交，但却不可能拥有完全一样的实例集合。"}
{"text": "以一个概念“Hero”为例，对于在文化和认识上差异较大的两个团体来说，各自本体中的概念“Hero”往往难以有一致的实例集合。"}
{"text": "此外，在本体建模过程中需要从现实事物抽象出概念，并根据概念抽象层次的不同进行划分。"}
{"text": "当不同的建模者对不同的概念进行划分时，可能会对一个概念的划分持有不同的观点。"}
{"text": "例如，在考虑对动物相关的知识进行本体建模时，一些建模者将概念“动物”划分为“哺乳动物”和“鸟”两个子类，而另一些人则是把“动物”划分为“食肉动物”和“食草动物”。"}
{"text": "最后，还存在将同一个概念定义在不同抽象层次上的不匹配。"}
{"text": "例如，本体O1将人概念化为“Persons”，而本体O2没有“Persons”这样的概念，它用“Males”和“Females”来表示人。"}
{"text": "（2）模型覆盖的不匹配。"}
{"text": "不同本体对于描述的领域往往在覆盖的知识范围上有差异，而且对于所覆盖的范围，它们之间描述的详细程度也有差异，这就是模型覆盖的不匹配。"}
{"text": "一般来说，有三种不同维度的模型覆盖。"}
{"text": "①模型的广度，即本体模型描述的领域范围，也就是哪些领域内的事物是包含在本体内的，哪些领域内的事物不是当前本体所关心的。"}
{"text": "②模型的粒度，即本体对所建模的领域进行描述的详细程度，如有的本体仅仅列出概念，有的本体则进一步列出概念的属性，甚至概念之间所具有的各种关系等。"}
{"text": "③本体建模的观点，这决定了本体从什么认识角度来描述领域内的知识。"}
{"text": "从上述不同的维度进行本体建模所得到的结果都是有差异的。"}
{"text": "例如，关于公共交通的本体可能包括也可能不包括有关“出租车”的知识（广度上的不匹配），可能区分不同类型的火车（如客车和货车），也可能不进行这样的区分（粒度上的不匹配），还可能从技术角度描述或从功能角度描述（观点的不匹配）。"}
{"text": "由于本体的建模反映了建模者的主观性，这一类的不匹配情况在实际应用中很普遍。"}
{"text": "2.解释不匹配本体模型层上的另一类不匹配现象是解释不匹配，它又包含了模型风格的不匹配和建模术语上的不匹配。"}
{"text": "（1）模型风格的不匹配①范例不匹配。"}
{"text": "不同的范例可用来表示相同的概念，这也就出现了不匹配。"}
{"text": "例如，对时间的表示可以采用基于时间间隔的方式，也可以使用基于时间点的方式[5]。"}
{"text": "此外，在建模过程中使用不同的上层本体也往往会造成这一类的不匹配，因为不同上层本体往往对时间、行为、计划、因果和态度等概念有着不同的划分风格。"}
{"text": "②概念描述不匹配。"}
{"text": "在本体建模中，对同一个概念的建模可以有几种选择。"}
{"text": "例如，为了区别两个类，既可以使用一个合适的属性，也可以引入一个独立的新类。"}
{"text": "描述概念时，不同抽象层次的概念是以Is-a的关系建立的：概念抽象的区别可以通过层次的高层或低层体现出来。"}
{"text": "然而，有的本体从高层到低层描述这种概念层次，有的则是从低层到高层来描述，这便造成了概念描述的不匹配。"}
{"text": "（2）建模术语上的不匹配①同义术语。"}
{"text": "不同本体中含义上相同的概念常常由于建模者的习惯而被使用不同的名字表示。"}
{"text": "例如，为了表示“汽车”，一个本体中使用词汇“Car”，而另一个词汇中使用词汇“Automobile”。"}
{"text": "这类的不匹配问题称为同义术语。"}
{"text": "同义术语引起的问题经常和其他的语义问题共同存在，如果没有人工或其他技术的帮助，机器是无法识别这些术语是否是同义的。"}
{"text": "②同形异义术语。"}
{"text": "另一类重要的建模术语不匹配是术语之间的同形异义现象。"}
{"text": "例如，术语“Conductor”在音乐领域和电子工程领域的意义分别是“指挥家”和“半导体”。"}
{"text": "这种本体不匹配问题更加难以处理，往往需要考虑术语所处的上下文并借助人类的知识来解决。"}
{"text": "③编码格式。"}
{"text": "最后的一种不匹配是由于本体表示中采用不同的编码格式造成的。"}
{"text": "例如，日期可被表示为“dd/mm/yyyy”或“mm-dd-yy”，距离可以用“Mile”描述，也可以用“Kilometer”描述，人的姓名可以用全名“FullName”形式，也可以用“FirstName+LastName”的形式。"}
{"text": "这样的不匹配种类很多，没有通用的自动识别和发现算法。"}
{"text": "但是，如果能发现这种不匹配，对它的处理则是很容易的，一般只需要做一个转换就能消除。"}
{"text": "不同本体间的不匹配是造成本体异构的直接原因，明确这些异构便于选择合理的方法去处理实际中的问题。"}
{"text": "例如，如果异构是语言层不匹配造成的，则进行语言之间的转换即可；如果是模型层上不匹配造成的，可以根据匹配类型的不同选择正确的算法。"}
{"text": "5.3本体概念层的融合方法与技术5.3.1本体映射与本体集成解决本体异构的通用方法是本体集成与本体映射[6-9]。"}
{"text": "本体集成直接将多个本体合并为一个大本体，本体映射则寻找本体间的映射规则，这两种方法最终都是为了消除本体异构，达到异构本体间的互操作。"}
{"text": "如图5-1所示的本体映射和本体集成的示意图，图中不同的异构本体分别对应着不同的信息源。"}
{"text": "为了实现基于异构本体的系统间的信息交互，本体映射的方法在本体之间建立映射规则，信息借助这些规则在不同的本体间传递；而本体集成的方法则将多个本体合并为一个统一的本体，各个异构系统使用这个统一的本体，这样一来，它们之间的交互可以直接进行，从而解决了本体异构问题。"}
{"text": "图5-1本体映射和本体集成的示意图既然不同系统间的互操作问题是本体异构造成的，因此，将这些异构本体集成为一个统一的本体是解决此类问题的一种自然想法。"}
{"text": "对于本体集成，根据实施过程的不同，又可以将其分为单本体的集成和全局本体-局部本体的集成两种形式。"}
{"text": "1.基于单本体的集成这种本体集成方法是直接将多个异构本体集成为一个统一的本体，该本体提供统一的语义规范和共享词汇。"}
{"text": "不同的系统都使用这个本体，这样便消除了由本体异构导致的互操作问题。"}
{"text": "显然，在本体集成的过程中产生了新的本体，因此也有人将本体集成看作一种生成新本体的过程。"}
{"text": "此外，集成过程通常利用了多个现有本体，因此这还是一种本体的重用[10]。"}
{"text": "Pinto_H_S等人将本体集成划分成一系列的活动[11]，主要包括：决定本体集成的方式，即需要判断消除异构的单本体是应该从头建立，还是应该利用现有的本体来集成，这需要评估两种方法的代价和效率来进行取舍；识别本体的模块，即明确集成后的本体应该包含哪些模块，以便于在集成过程中对于不同的模块选择相关的本体；识别每个模块中应该被表示的知识，即需要明确不同模块中需要哪些概念、属性、关系和公理等；识别候选本体，即从可能的本体中选择可用于集成的候选本体；执行集成过程，基于上面的基础，根据一定的集成步骤完成本体集成。"}
{"text": "这样的集成方法虽然看起来很有效，但在实际应用中往往存在明显的缺点。"}
{"text": "首先，使用这些异构本体的系统往往有着不同的功能和侧重点，这些系统之间通常不是等价或可相互替代的，某些系统能处理一些特定和深入的问题，某些系统则可能处理全面和基础的问题。"}
{"text": "这样，集成后的本体对于其中的一些系统来说可能过于庞大，况且它们往往只使用该集成本体的一部分。"}
{"text": "因此，这样的本体不方便系统使用，而且在涉及本体操作（如推理和查询）时会降低系统的效率。"}
{"text": "其次，单个本体的方法容易受到其中某个系统变化的影响[6]，当某个系统要求改变本体以适应它的新需求时，集成的本体需要重新进行修改，这种修改往往并不简单，因为它很可能会影响到与之进行交互的其他系统，还需要与其他系统进行反复协商。"}
{"text": "所以，从这些方面能看出单本体的集成缺乏灵活性。"}
{"text": "2.基于全局本体-局部本体的集成为了克服单本体的本体集成方法的缺陷，另一种途径是采用全局本体-局部本体来达到本体集成。"}
{"text": "这种方法首先抽取异构本体之间的共同知识，根据它建立一个全局本体。"}
{"text": "全局本体描述了不同系统之间一致认可的知识。"}
{"text": "同时，各个系统可以拥有自己的本体，称为局部本体。"}
{"text": "局部本体既可以在全局本体的基础上根据自己的需要进行扩充，也可以直接建立自己特有的本体，但无论哪种方式，都需要建立局部本体与全局本体之间的映射[12,13]。"}
{"text": "这样，局部本体侧重于特定的知识，而全局本体则保证不同系统间异构的部分能进行交互。"}
{"text": "这种方法既避免了局部本体存在过多的冗余，本体规模不会过于庞大，同时也达到了解决本体间异构的目的。"}
{"text": "每个局部本体可以独立开发，对它们进行修改不会影响其他的系统，只要保证与全局本体一致就可以。"}
{"text": "但是全局本体—局部本体的本体集成方法也并不完美。"}
{"text": "除了需要维护全局本体和各个系统中的局部本体，为了保证全局本体和局部本体始终一致，还需要建立和维护它们之间的映射。"}
{"text": "但总的来说，全局本体—局部本体的集成方法较单本体的集成方法灵活。"}
{"text": "本体映射和集成都是为了解决本体间的异构问题，虽然它们的事实过程存在着差别，但相互之间也存在着联系。"}
{"text": "一方面，在很多本体集成过程中，映射可看作集成的子过程。"}
{"text": "在单本体的本体集成中，需要分析不同本体之间的映射，才能够将它们集成为一个新的本体；在基于全局本体—局部本体的集成过程中，需要在局部本体和全局本体之间建立映射。"}
{"text": "另一方面，通过本体映射在异构本体间建立联系规则后，本体就能根据映射规则进行交互，因此，建立映射后的多本体又可视为一种虚拟的集成。"}
{"text": "然而，集成本体的工作耗时费力，而且缺乏自动方法支持；随着多本体的变化，集成过程需要不断地重复进行，代价过高。"}
{"text": "此外，集成的本体对于不同的应用不具有通用性，缺乏灵活性。"}
{"text": "因此，本体集成不适合解决语义Web中分布和动态的多本体应用问题。"}
{"text": "实际上，大多应用只需要实现本体间的互操作就可以满足需求，完全的集成是没有必要的。"}
{"text": "本体映射通过建立本体间的映射规则达到本体互操作，其形式比较灵活，更能适应分布动态的环境。"}
{"text": "5.3.2本体映射分类明确本体映射的分类是建立异构本体间映射的基础。"}
{"text": "虽然本体间的不匹配揭示了本体异构的原因，但通常的本体映射并不直接以各种不匹配准则来划分，因为那样的映射分类过于抽象和宽泛，不方便实现。"}
{"text": "尽管很多研究者在本体映射上做了大量的相关工作[9]，但对于本体映射的分类这个基本问题却缺少系统的总结、分析和论述。"}
{"text": "这里在总结前人研究的基础上，从三个角度来探讨本体映射的分类问题，即映射的对象、映射的功能以及映射的复杂程度。"}
{"text": "1.映射的对象角度通过这个角度的分类，明确映射应该建立在异构本体的哪些成分之间。"}
{"text": "本体间的不匹配是造成本体异构的根本原因，这种不匹配可分为语言层和模型层两个层次。"}
{"text": "从语言层来说，目前大多数的本体采用几种流行的本体语言表示，如OWL或RDF(S)，很多本体工具都具有在这些语言之间进行相互转换的功能。"}
{"text": "由于不同本体语言之间表达能力上的差异，这种转换有时会造成本体信息的损失。"}
{"text": "因此，语言间的转换应该尽可能指向表达能力强的语言，以减少信息的损失。"}
{"text": "而实际上，通常的本体映射很少考虑语言层次上的异构。"}
{"text": "将不同语言表示的本体转换为相同的表示形式能方便映射处理。"}
{"text": "通常，这种转换带来的信息损失不应该对映射结果造成明显的影响。"}
{"text": "而从模型层来说，虽然模型层的不匹配划分能方便对本体映射进行统一处理，但对实际应用来说，依据模型层的不匹配来划分本体映射过于抽象。"}
{"text": "实际上，大多映射研究直接从组成本体的成分出发，即由于本体主要由概念、关系、实例和公理组成，本体间的映射应建立在这些基本成分之上。"}
{"text": "建立异构本体的概念之间的映射是最基本的映射，因为概念是本体中最基本的成分，没有概念，其他的本体成分无从谈起。"}
{"text": "所以，概念间的映射是最基本的和必需的。"}
{"text": "对于本体中的关系来说，由于它可表示不同概念之间的关系或描述某个对象的赋值，对于很多应用来说（如查询），往往需要借助这些关系之间的映射进行信息交互。"}
{"text": "因此，关系之间的映射也很重要。"}
{"text": "需要注意的是，由于有些关系连接两个对象，而有些关系连接对象和它的赋值（即概念的属性），这两类关系的映射处理方法可能会有所不同。"}
{"text": "不同本体之间的实例也会出现异构，例如不同的实例名实际上表示同一个对象。"}
{"text": "由于语义Web包含大量的实例，在有些情况下往往需要考虑实例的异构，并需要建立异构实例之间的映射。"}
{"text": "为了检查实例之间是否等价，目前的方法基于属性匹配或逻辑推理[14]。"}
{"text": "但是，逻辑推理的方法通常很耗时，而属性匹配的方法又很可能得到不确定的答案。"}
{"text": "XuBaowen等人提出了一种检查实例等价的框架[15]，这种方法同时使用了属性匹配和逻辑推理两种方法，并利用一种基于不相交集合并的算法来加速推理过程。"}
{"text": "但总的来说，由于实例之间的映射情况比其他对象的映射简单，但是实例的数目太多，处理起来非常耗时，因此很多映射工作并不着重考虑实例上的映射。"}
{"text": "公理是本体中的一个重要成分，它是对其他本体成分的约束和限制。"}
{"text": "通常，一个公理由一些操作符和本体成分组合而成。"}
{"text": "因此，如果两个本体使用的表示语言都支持同样的操作符，那么公理之间的映射便可以转换为其他成分之间的映射。"}
{"text": "因此，通常并不需要考虑公理之间的映射。"}
{"text": "综上所述，从映射的对象来看，可将本体映射分为概念之间的映射和关系之间的映射两类，其中概念之间的映射是最基本的映射。"}
{"text": "除非有特殊的要求，一般不考虑针对实例或公理之间的映射。"}
{"text": "2.映射的功能角度通过这个角度的分类，进一步明确应该建立具有何种功能的本体映射。"}
{"text": "确定在本体的何种成分之间建立映射并不足够，还需要进一步明确这样的映射具有什么功能。"}
{"text": "例如，一些映射声明不同本体间的两个概念是相等的，而一些则声明不同本体间的两个关系是互逆的。"}
{"text": "现有大多数本体映射研究的问题在于只考虑几种最基本和常见的映射功能，如概念间的等价和包含，以及关系间的等价等，而没有充分考虑异构本体间各种有用的映射功能。"}
{"text": "实际上，本体的概念或关系之间可能存在的映射功能种类很多，WangPeng等人以概念间的映射和关系间的映射为基础，从功能上归纳出11种主要的本体映射，并称这些映射为异构本体间的桥[16]：表示概念间映射的桥包括等价（Equal）、同形异义（Different）、上义（Is-a）、下义（Include）、重叠（Overlap）、部分（Part-of）、对立（Opposed）和连接（Connect）共8种；表示关系间映射的桥等价（Equal）、包含（Subsume）和逆（Inverse）3种。"}
{"text": "这11种桥基本能描述异构本体间具有的映射功能。"}
{"text": "最基本的映射功能是等价映射，是为了建立不同本体的成分之间的等价关系。"}
{"text": "等价映射声明了概念之间和关系之间的对应，异构本体的等价成分之间在互操作过程中可以直接相互替代。"}
{"text": "同形异义的映射能够指出表示名称相同的本体成分实际上含义是不同的。"}
{"text": "上义和下义映射则说明了概念之间和属性之间的继承关系，关系间的包含映射对于关系来说也具有同样的功能。"}
{"text": "重叠映射表示概念之间的相似性。"}
{"text": "对立映射表示概念之间的对立。"}
{"text": "同样，逆映射表示关系之间的互逆。"}
{"text": "概念上的部分映射则表示了来自不同概念间的个体具有整体—部分关系。"}
{"text": "此外，通过一些特殊的连接映射，还能将不同的本体概念相互联系起来。"}
{"text": "从功能上归纳和区分上述映射具有重要的意义。"}
{"text": "首先，不同功能的映射，其发现的方法和建立的难度都具有差别，即使是同一成分之间的映射，不同的映射功能都会影响着寻找映射的方法和过程；有的映射功能同时适用于概念和关系，在不同成分上发现这样的映射所使用的方法可能有相似性；有的映射功能则只针对特定的成分，发现这样的映射可能需要借助特殊的方法。"}
{"text": "其次，区分具体的映射功能对于实际应用来说非常重要，不同功能的映射在处理本体互操作中扮演的角色会有不同，有的映射仅仅为了建立本体之间的数据转换的规则，有的映射还能用于进行跨本体的推理和查询应用。"}
{"text": "3.映射的复杂程度角度通过这个角度的分类，明确什么形式的映射是简单的，什么形式的映射是复杂的。"}
{"text": "本体间的映射还具有复杂和简单之分，这需要同时考虑映射涉及的对象和映射具有的功能。"}
{"text": "实际上，复杂映射和简单映射的界限很难界定。"}
{"text": "通常，将那些基本的、必要的、组成简单的和发现过程相对容易的映射称作简单映射；将那些不直观的、组成复杂并且发现过程相对困难的映射称为复杂映射。"}
{"text": "这里的复杂映射同时考虑映射对象和映射功能。"}
{"text": "从映射对象上，将那些包含复杂概念的映射看作是复杂映射，这里的复杂概念指通过概念的并、交和非等算子构成的复合概念，涉及这一类复杂概念的映射寻找方法相对单个的原子概念来说较为困难。"}
{"text": "而由于关系的映射发现方法通常都不容易，因此无论是原子关系还是复杂关系上的映射均看作复杂映射。"}
{"text": "从功能上看，除概念和关系上的等价映射以及概念上的上义和下义外，其余的映射功能都属于复杂映射。"}
{"text": "基于这种思想，本体映射的分类如表5-1所示，其中“+”表示这种映射存在，“×”表示这种映射不存在，背景为深色表示这种映射是复杂映射。"}
{"text": "从表中可以看出，存在的本体映射中大部分都属于复杂映射。"}
{"text": "然而，目前的研究表明，大多数的本体映射工作都是针对简单映射的，针对复杂映射的探讨并不多。"}
{"text": "表5-1本体映射的分类Noy_N_F将基于本体的语义集成研究划分为三个层次[17]:①发现映射，即给定两个本体，怎样寻找它们之间的映射；②表示映射，即对于找到的映射，应该能够进行合理表示，这种表示要方便推理和查询；③使用映射，即一旦映射被发现和表示后，需要将它使用起来，如进行异构本体间的推理和查询等。"}
{"text": "接下来从这些层次入手，逐步阐述映射的发现、表示和应用问题。"}
{"text": "5.3.3本体映射方法和工具在确定本体映射的分类后，最重要也是最困难的任务在于如何发现异构本体间的映射。"}
{"text": "尽管本体间的映射可以通过手工建立，但非常耗时，而且很容易出错[18]。"}
{"text": "因此，目前的研究侧重于开发合理的映射发现方法和工具，采用自动或半自动的方式来构建。"}
{"text": "尽管不同的本体映射方法使用的技术不同，但过程基本是相似的。"}
{"text": "总的来说，本体映射的过程可分为三步：图5-2本体映射生成的过程①导入待映射的本体。"}
{"text": "待映射的本体不一定都要转换为统一的本体语言格式，但是要保证本体中需要进行映射的成分能够被方便获取。"}
{"text": "②发现映射。"}
{"text": "利用一定的算法，如计算概念间的相似度等，寻找异构本体间的联系，然后根据这些联系建立异构本体间的映射规则。"}
{"text": "当然，如果映射比较简单或者难以找到合适的映射发现算法，也可以通过人工来发现本体间的映射。"}
{"text": "③表示映射。"}
{"text": "当本体之间的映射被找到后，需要将这些映射合理地表示起来。"}
{"text": "映射的表示格式是事先手工制定的。"}
{"text": "在发现映射后，需要根据映射的类型，借助工具将发现的映射合理表示和组织。"}
{"text": "这三个步骤是一个粗略但却通用的本体映射过程，实际应用中的很多映射算法对于每一个阶段都有更详细的描述。"}
{"text": "为了建立本体映射，不同的研究者从不同角度出发，采用不同的映射发现方法来寻找本体间的映射。"}
{"text": "同时，不同的映射发现方法能处理的映射类型和具体过程都有很大差别[17]。"}
{"text": "从已有的映射方法以及相关的工具来看，发现本体映射的方法可分为四种[19,20]:①基于术语的方法，即借助自然语言处理技术，比较映射对象之间的相似度，以发现异构本体间的联系；②基于结构的方法，即分析异构本体之间结构上的相似，寻找可能的映射规则；③基于实例的方法，即借助本体中的实例，利用机器学习等技术寻找本体间的映射；④综合方法，即在一个映射发现系统中同时采用多种寻找本体映射的方法，一方面能弥补不同方法的不足，另一方面还能提高映射结果的质量。"}
{"text": "根据使用技术的不同，下面分别介绍一些典型的本体映射工作。"}
{"text": "很多映射工作可能同时采用了多种映射发现技术，如果其中的某一种技术较为突出，则将这个工作划分到这一种技术的分类下；如果几种技术的重要程度比较均衡，则将这样的工作划分为综合方法。"}
{"text": "此外，实际的研究和应用表明，仅仅是用基于术语的方法很难取得满意的映射结果，为此，很多方法进一步考虑了本体结构上的相似性来提高映射质量，所以将基于术语和基于结构的映射发现方法放在一处进行讨论。"}
{"text": "1.基于术语和结构的本体映射从本体中术语和结构的相似性来寻找本体映射是比较直观和基础的方法。"}
{"text": "这里先介绍这种方法的思想，然后探讨一些典型和相关的工作。"}
{"text": "（1）技术综述1）基于术语的本体映射技术。"}
{"text": "这类本体映射方法从本体的术语出发，比较与本体成分相关的名称、标签或注释，寻找异构本体间的相似性。"}
{"text": "比较本体间的术语的方法又可分为基于字符串的方法和基于语言的方法。"}
{"text": "①基于字符串的方法。"}
{"text": "基于字符串的方法直接比较表示本体成分的术语的字符串结构。"}
{"text": "字符串比较的方法有很多，Cohen_W等人系统地分析和比较了各种字符串比较技术[21]。"}
{"text": "主要的字符串比较技术如下。"}
{"text": "（a）规范化。"}
{"text": "在进行严格字符串比较之前，需要对字符串进行规范化，这能提高后续比较的结果。"}
{"text": "规范化操作主要包括：大小写规范化，即将字符串中的每个符号转换为大写字母或小写字母的形式；消除变音符，即将字符串中的变音符号替换为它的常见形式，如Montréal替换为Montreal；空白正规化，即将所有的空白字符（如空格、制表符和回车等）转换为单个的空格符号；连接符正规化，包括正规化单词的换行连接符等；消除标点，在不考虑句子的情况下要去除标点符号；消除无用词，去除一些无用的词汇，如“to”和“a”等。"}
{"text": "这些规范化操作主要针对拉丁语系，对于其他的语言来说，规范化过程会有所不同。"}
{"text": "（b）相似度量方法。"}
{"text": "在规范字符串的基础上，能进一步度量不同字符串间的相似程度。"}
{"text": "常用的字符串度量方法有：汉明距离、子串相似度、编辑距离和路径距离等。"}
{"text": "如果两个字符串完全相同，它们间的相似度为1；如果字符串间不存在任何相似，则相似度为0；如果字符串间存在部分相似，则相似度为区间(0,1)中的某个值。"}
{"text": "一种常用来比较两个字符串的直接方法是汉明距离，它计算两个字符中字符出现位置的不同。"}
{"text": "定义5.1对于给定的任意两个字符串s和t，它们的汉明距离相似度定义为：相似的字符串间往往具有相同的子串，子串检测就是从发现子串来计算字符串间的相似度，它的定义如下。"}
{"text": "定义5.2任意两字符串s和t，如果存在两个字符串p和q，且s=p+t+q或t=p+s+q，那么称t是s的子串或s是t的子串。"}
{"text": "还可进一步精确度量两字符串包含共同部分的比例，即子串相似度。"}
{"text": "定义5.3子串相似度度量任意两个字符串s和t间的相似度δ，令x为s和t的最大共同子串，则它们的子串相似度为：字符串间的相似度还能通过编辑距离来度量。"}
{"text": "两字符串之间的编辑距离是指修改其中一个使之与另一个相同所需要的最小操作代价。"}
{"text": "这些编辑操作包括插入、删除和替代字符。"}
{"text": "定义5.4给定一个字符串操作集合op和一个代价函数w，对于任意一对字符串s和t，存在将s转换为t的操作序列集合，两字符串间的编辑距离δ(s,t)是将s转换为t的最小操作序列的代价和：注意，这里给出的编辑距离没有正规化，即δ的值可能不在区间[0,1]。"}
{"text": "显然，编辑距离越大，表示两字符串的相似程度越小。"}
{"text": "编辑距离是最基本的判断字符串间相似度的指标，以它为基础，能构造出很多更复杂的相似度度量公式，这里不一一介绍。"}
{"text": "除了直接比较单个术语的字符串相似，还可以在比较时考虑与之相关的一系列的字符串。"}
{"text": "路径比较便是这类方法中的一种。"}
{"text": "例如，比较两个概念的相似度时，可以将它们的所有父概念集中起来，并在相似度计算中考虑这些路径上的概念。"}
{"text": "定义5.5给定两个字符串序列和，它们之间的路径距离计算如下：有式中，δ’是某种字符串度量函数，并且λ∈[0,1]；当比较的两条路径出现空路径时，。"}
{"text": "②基于语言的方法。"}
{"text": "基于语言的方法依靠自然语言处理技术寻找概念或关系之间的联系。"}
{"text": "这类方法又可分为内部方法和外部方法，前者使用语言的内部属性，如形态和语法特点，后者则利用外部的资源，如词典等。"}
{"text": "内部方法在寻找术语间的映射时利用词语形态和语法分析来保证术语的规范化。"}
{"text": "它寻找同一字符串的不同语言形态，如Apple和Apples等。"}
{"text": "寻找词形变化的算法很多，最著名的是Porter_M_F提出的Stemming算法[22]。"}
{"text": "外部方法利用词典等外部资源来寻找映射。"}
{"text": "基于词典的方法使用外部词典匹配语义相关的术语。"}
{"text": "例如，使用WordNet能判断两个术语是否有同义或上下义关系。"}
{"text": "尽管基于术语的相似度度量方法很多，但是根据它很难得到比较好的映射结果，一般仅能判断概念或关系之间等价的可能程度，而对于发现其他功能的映射来说，基于术语的方法难以达到满意的效果。"}
{"text": "2）基于结构的本体映射技术。"}
{"text": "在寻找映射的过程中，同时考虑本体的结构能弥补只进行术语比较的不足，提高映射结果的精度。"}
{"text": "基于结构的方法又可分为内部结构和外部结构，前者考虑本体的概念或关系的属性和属性值的数据类型等，后者则考虑与其他成分间的联系。"}
{"text": "①内部结构。"}
{"text": "基于内部结构的方法利用诸如属性或关系的定义域、它们的基数、传递性或对称性来计算本体成分之间的相似度。"}
{"text": "通常，具有相同属性或者属性的数据类型相同的概念之间的相似度可能性较大。"}
{"text": "②外部结构。"}
{"text": "比较两本体的成分之间的相似也可以考虑与它们相关的外部结构，例如，如果两个概念相似，它们的邻居也很可能是相似的。"}
{"text": "从本体外部结构上判断本体成分的相似主要借助人们在本体使用过程中所获得的一些经验。"}
{"text": "有一些常用来判断本体成分相似的准则，这些准则包括：(C1)直接超类或所有的超类相似；(C2)兄弟相似；(C3)直接子类或所有的子类相似；(C4)所有或大部分后继（不一定是子类，可能通过其他关系连接）相似；(C5)所有或大部分的叶子成分相似；(C6)从根节点到当前节点的路径上的实体都相似。"}
{"text": "对于通过Part-of关系或Is-a关系构成的本体，本体成分之间的关系比较特殊和常见，可以利用一些特定的方法来判断结构上的相似[23]。"}
{"text": "计算概念之间的相似也可以考虑它们之间的关系。"}
{"text": "如果概念A和B通过关系R建立联系，并且概念A’和B’间具有关系R'，如果已知B和B’以及R和R’分别相似，则可以推出概念A和A’也相似[24]。"}
{"text": "然而，这种方法的问题在于如何判断关系的相似性。"}
{"text": "关系的相似性计算一直是一个很困难的问题。"}
{"text": "外部结构的方法无法解决由于本体建模的观点不同而造成的异构，如对于同一个概念“Human”，本体O1将它特化为两个子类“Man”和“Woman”，而本体O2却将它划分为“Adult”和“Young_Person”。"}
{"text": "基于结构的方法难以解决这种不同划分下的子类之间的相似度问题。"}
{"text": "（2）方法和工具1）AnchorPROMPT。"}
{"text": "PROMPT是Stanford大学开发的一套本体工具集[25]，其中包括：①一个交互式本体集成工具iPROMPT，它帮助用户进行本体集成操作，能够提供什么成分能被合并的建议，能识别集成操作中造成的不一致问题和其他潜在的错误，并建议iPROMPT不能识别的本体间的相似；③一个本体版本工具可能的策略来解决这些问题，为了达到集成本体的目的，iPROMPT需要发现本体间的映射；②一个寻找本体间相似映射的工具AnchorPROMPT，它扩展了iPROMPT发现映射的性能，能发现更多PROMPTDiff，它比较本体的两个版本，识别它们之间结构上的不同；④一个从大本体抽取语义完全的子本体工具PROMPTFactor，它从现有本体创建一个新本体，并能保证结果子本体是良构的。"}
{"text": "除AnchorPROMPT直接处理映射外，其他工具都并非为了发现本体映射，但本体映射在每个工具中具有重要作用。"}
{"text": "PROMPT的各个工具之间并非孤立存在，而是相互联系的，它们共享数据结构，并在需要时能相互借用算法。"}
{"text": "目前，PROMPT的这些工具已集成到Protégé系统中。"}
{"text": "本体映射是解决很多多本体问题的基础。"}
{"text": "为了发现本体间的映射，Noy_N_F等人于1999年就开发了SMART算法[26,27]，该方法通过比较概念名的相似性，识别异构本体间的等价概念。"}
{"text": "AnchorPROMPT算法正是以SAMRT为基础，通过扩展SMART而得到的[28]；它采用有向图表示本体，图中包括本体中的概念继承和关系继承等信息；算法输入两个本体和它们的相关术语对集合，然后利用本体的结构和用户反馈来判断这些术语对之间的映射。"}
{"text": "①AnchorPROMPT的思想。"}
{"text": "AnchorPROMPT的目标是在术语比较的基础上利用本体结构进一步判断和发现可能相似的本体成分。"}
{"text": "AnchorPROMPT的输入是一个相关术语对的集合，其中每对术语分别来自两个不同本体，这样的术语对称为“锚”。"}
{"text": "术语对可以利用iPROMPT工具中的术语比较算法自动生成，也可以由用户提供。"}
{"text": "AnchorPROMPT算法的目标是根据所提供的初始术语对集合，进一步分析异构本体的结构，产生新的语义相关术语对。"}
{"text": "AnchorPROMPT将每个本体O视为一个带边有向图G。"}
{"text": "O中的每个概念C表示图中的节点，每个关系S是连接相关概念A和B之间的边。"}
{"text": "图中通过一条边连接的两节点称为相邻节点。"}
{"text": "如果从节点A出发，经过一系列边能到达节点B，那么A和B之间就存在一条路径。"}
{"text": "路径的长度是边的数目。"}
{"text": "为发现新的语义相关术语对，AnchorPROMPT遍历异构本体中由“锚”限定的对应路径。"}
{"text": "AnchorPROMPT沿着这些路径进行比较，以寻找两个本体间更多的语义相关术语。"}
{"text": "例如，假设现有两对相关术语对：概念对(A,B)和概念对(G,H)。"}
{"text": "它表示本体O1中的概念A和本体O2中的概念B相似；同样，O1中的G和O2中的H也相似，如图5-3所示。"}
{"text": "图中显示了本体O1中概念A到G之间存在一条路径以及本体O2中概念B到H之间存在一条路径；两本体间的实线箭头表示初始的“锚”，虚线箭头表示路径上可能相关的术语对。"}
{"text": "AnchorPROMPT算法并行遍历两条路径，对于在同样的步骤下到达的概念对，算法同时增加它们之间的相似度分数。"}
{"text": "例如，当遍历图5-3中的路径后，算法会增加概念对(C,D)之间和(E,F)之间的相似度分数。"}
{"text": "对所有起始节点和终止节点间的全部路径，算法重复这个过程，并累计概念对上的相似度分数。"}
{"text": "可见，AnchorPROMPT算法基于这样的直觉：如果两对术语相似，并且存在着连接它们的路径，那么这些路径中的节点成员通常也是相似的。"}
{"text": "因此，根据最初给定的相关术语对的小集合，AnchorPROMPT算法能够产生本体间大量可能的语义相似术语对。"}
{"text": "②AnchorPROMPT算法。"}
{"text": "为说明AnchorPROMPT的工作原理，这里以两个描述病人就诊的异构本体为例，如图5-4所示。"}
{"text": "对于这样的两个本体，假设输入的初始相关术语对是(TRIAL,Trial)和(PERSON,Person)。"}
{"text": "这样的术语对利用基本的术语比较技术能很容易识别出来。"}
{"text": "根据输入的相关术语对，算法能寻找到相关术语对之间的路径集合。"}
{"text": "对于上面的两对相关术语，在本体O1中存在一条“TRIAL”和“PERSON”之间的路径，在本体O2中也存在二条从“Trial”到“Person”之间的路径。"}
{"text": "在实际应用中，这样的路径数目可能有很多，为了减少大量的比较操作，可以通过预先定义路径长度来限制路径的总数，如规定只考虑长度小于5的路径等。"}
{"text": "图5-3遍历术语对间的路径图5-4两个描述病人就诊的异构本体这里考虑O1中的路径Path1:TRIAL→PROTOCOL→STUDY-SITE→PERSON和O2中的路径Path2:Trial→Design→Blinding→Person。"}
{"text": "当AnchorPROMPT遍历这两条路径时，它增加路径中同一位置的一对术语的相似度分数。"}
{"text": "在这个例子中，算法增加这两对概念的相似度分数，即概念对(PROTOCOL,Design)和(STUDY-SITE,Blinding)。"}
{"text": "AnchorPROMPT算法重复以上过程，直到并行遍历完相关术语对之间的这种路径，每次遍历都累加符合条件的概念对的相似度分数。"}
{"text": "结果，经常出现在相同位置的术语对间的相似度分数往往最高。"}
{"text": "（a）等价组。"}
{"text": "在遍历本体图中的路径时，AnchorPROMPT区别对待连接概念间的继关系和普通关系同样看待，承关系与其他普通关系，因为如把概念间的AnchorPROMPT的方法不能很好地利用这种继承关系。"}
{"text": "与普通关系不同，Is-a关系连接着已经相似的概念，如图5-5中的“PROTOCOL”和“EXECUTED-PROTOCOL”，事实上它们Is-a描述了概念之间的包含。"}
{"text": "AnchorPROMPT算法将这种通过Is-a关系连接的概念作为一个等价组看待。"}
{"text": "考虑图5-5中从的路径，其中将“PROTOCOL”和“EXECUTED-PROTOCOL”作为一个等价组，并用括号来做区别，这样的一条路径写为Path:Trial→POPULATION→CROSSOVER。"}
{"text": "[EXECUTED-PROTOCOL,PROTOCOL]→TREATMENT-CROSSOVER_TRIAL到这样，AnchorPROMPT将等价组看作路径上的单个节点。"}
{"text": "等价组节点的入边是其中每个成员的入边的并；相似地，它的出边是每个成员的出边的并。"}
{"text": "显然图5-5中等价组节点有两条入边和一条出边。"}
{"text": "等价组的大小是节点中包括的概念总数，但对于AnchorPROMPT算法来说，它将这些概念视为一个节点。"}
{"text": "图5-5路径中的等价组（b）相似度分数。"}
{"text": "给定两个术语：来自本体O1中的概念C1和本体O2中的概念C2，计算它们之间相似度分数S(C1,C2)的过程如下：步骤1：生成长度小于给定参数L的全部路径集合，这些路径连接着输入的两本体中的锚。"}
{"text": "步骤2：从步骤1生成的路径集合中，生成所有可能的等长路径对的集合，每一对路径中的一条来自O1，另一条来自O2。"}
{"text": "步骤3：在步骤2生成的路径对基础上，对于路径中处于相同位置的节点对N1和N2，为节点中的所有概念对之间的相似度分加上一个常数X。"}
{"text": "如果概念C1和C2出现在上述路径中，则它们之间的相似度分数S(C1,C2)反映了C1和C2出现在路径中的相同位置的频繁程度。"}
{"text": "当进行比较的节点包含等价组时，增加相似度分数的情况有所不同。"}
{"text": "例如，对于处于同一位置的一对节点(A1,[B2,C2])，需要分析如何对(A1,B2)以及(A1,C2)打分。"}
{"text": "这个问题在接下来的部分进行分析。"}
{"text": "根据上述算法，AnchorPROMPT算法生成很多可能的相似术语对，将这些术语对的相似分数进行排序，去除一些相似分数较低的术语对，就得到语义相关的术语对。"}
{"text": "③AnchorPROMPT评估。"}
{"text": "Noy_N_F等人对AnchorPROMPT进行了一系列的评估试验，得到了一些有用的经验。"}
{"text": "（a）等价组大小。"}
{"text": "试验表明，当等价组大小最大值为0（0是一个特殊的标记，表示算法不区分概念间的继承关系和普通关系）或1（节点只包含单个概念，但区分概念间的继承关系和普通关系）时，87%的试验没有任何结果，不生成任何映射。"}
{"text": "当等价组的最大尺寸为2时，只有12%的试验没有结果。"}
{"text": "因此，在随后的试验中设定等价组的最大尺寸大小为2。"}
{"text": "（b）等价组成员的相似度分数。"}
{"text": "为评价等价组成员如何打分合理而做了两类试验。"}
{"text": "第一类试验中对节点中的所有成员都加X分；而在第二类试验中为等价组中的成员只加X/3或X/2的分数不等。"}
{"text": "试验结果表明，对等价组成员打分不同能将结果的准确率提高14%。"}
{"text": "（c）锚的数目和路径最大长度。"}
{"text": "在大量的试验中表明，并非输入的锚数量越多和规定的最大路径长度越大能得到越好的映射结果，算法执行结果的正确率总体提高不明显，但运行时间明显增长[29]。"}
{"text": "试验表明，当最大长度路径设为2时，能获得最好的正确率。"}
{"text": "当限制路径最大长度为3时，平均正确率为61%；当最大长度提高到4时，正确率只有少量的提升，达到65%。"}
{"text": "④AnchorPROMPT的讨论。"}
{"text": "当AnchorPROMPT算法考虑路径长度为1时，如果概念A和A’相似以及B和B’相似，则认为连接A和B的关系S和连接A’和B’的关系S’相似。"}
{"text": "以此类推，可以得到路径上更多的关系对也是相似的。"}
{"text": "实际上，AnchorPROMPT算法正是基于这样的假设：本体中相似的术语通常也通过相似的关系连接。"}
{"text": "在实际应用中，随着路径的过长，这个假设的可行性就越小，因此生成结果的精度反而会降低。"}
{"text": "而路径长度过短又可能使得路径上不包含任何的术语对，例如路径长度为1时，算法生成的结果和只使用术语比较技术的iPROMPT是一样的。"}
{"text": "AnchorPROMPT其他方面的讨论如下。"}
{"text": "（a）减少负面结果的影响。"}
{"text": "概念间的相似度分数是一个累加值。"}
{"text": "两个不相关的术语可能出现在某一对路径的相同位置，但对于所有的路径来说，这两个不相关的术语总出现在不同路径对的同一位置上的概率很小。"}
{"text": "AnchorPROMPT累加遍历所有路径过程中对应概念对的相似度分数，这能够消除这类负面结果的影响。"}
{"text": "试验中可以设定一个相似度分数的阈值，便于去掉相似度分数小于阈值的术语对。"}
{"text": "试验表明，AnchorPROMPT的确可以去除大多数的这类术语对。"}
{"text": "（b）执行本体映射。"}
{"text": "AnchorPROMPT建立了术语之间的映射，它的结果可以提供给本体合并工具（如iPROMPT）或其他的本体应用直接使用。"}
{"text": "（c）局限性。"}
{"text": "AnchorPROMPT的映射发现方法并非适用于所有的本体。"}
{"text": "当两个本体间的结构差别很大时，该方法处理的效果并不好。"}
{"text": "此外，当一个本体对领域描述得比较深入时，而另一个本体描述同样的领域比较肤浅时，AnchorPROMPT算法获得的结果也不令人满意。"}
{"text": "⑤AnchorPROMPT的总结。"}
{"text": "AnchorPROMPT是基于结构的本体映射发现技术中的一项典型工作，它以基于术语技术得到的本体映射结果为基础，进一步分析本体图的结构相似性，从而发现更多的本体映射。"}
{"text": "由AnchorPROMPT算法的过程可以看出，该算法只能发现异构本体原子概念间的等价映射，以及少量原子关系间的等价映射。"}
{"text": "对于复杂概念或复杂关系间的本体映射，AnchorPROMPT是无法处理的。"}
{"text": "从技术上说，AnchorPROMPT算法是基于一种直观的经验，缺乏严格的理论依据。"}
{"text": "2）iPROMPT。"}
{"text": "PROMPT工具中的iPROMPT利用术语技术发现不同本体间的映射，并根据映射结果给出一系列本体合并建议，用于指导用户进行本体合并。"}
{"text": "iPROMPT从语言角度判断本体间概念或关系的相似。"}
{"text": "然后以这些初始的术语相似为基础，执行合并算法完成本体合并的任务。"}
{"text": "在合并本体时要与用户进行交互，iPROMPT的本体合并过程如图5-6所示，步骤和算法如下。"}
{"text": "图5-6iPROMPT的本体合并过程步骤1：基于概念名或关系名相似，识别出潜在的合并候选术语，然后为用户生成一个可能的合并操作建议列表。"}
{"text": "iPROMPT中的操作包括合并概念、合并关系、合并实例、拷贝单个的概念和拷贝一系列的概念等。"}
{"text": "步骤2：从合并建议列表中选择一条建议（也可以由用户直接定义一条合并操作），系统执行建议的合并操作，并自动发现由于这样的操作对整个合并建议列表产生的变化，即实现建议列表的更新，然后系统自动判断新的本体合并建议列表中的冲突和潜在的其他问题，并寻找可能的解决方案，经过这些处理，系统生成新的且无冲突的建议列表。"}
{"text": "当执行合并操作后，iPROMPT检查合并后本体中的不一致性和潜在问题，主要包括：①名字冲突。"}
{"text": "合并后的本体中的每个术语名字必须是唯一的，例如一个拷贝本体O1中的概念“Location”到本体O2时，可能O2中存在一个同名的关系，这便出现了名字冲突。"}
{"text": "这样的冲突可以通过重命名来解决。"}
{"text": "②当在本体间拷贝属性时，如果被拷贝属性的值域和定义域中包含概念，且这些概念并不在本体中存在时，便出现了不一致问题。"}
{"text": "在这种情况下可以考虑删除这些概念或为本体增加这些概念来解决。"}
{"text": "③概念继承冗余，本体合并可能造成一些概念继承连接出现冗余，即有些概念继承路径是不必要的。"}
{"text": "对于这种问题，iPROMPT建议用户删除一些多余的概念来避免冗余。"}
{"text": "Noy_N_F等人从准确率和召回率来评估iPROMPT算法的效果。"}
{"text": "这里的准确率是指用户遵循iPROMPT给出的建议占所有建议的比例；召回率是指用户实际执行的合并操作占工具给出的建议的比例。"}
{"text": "试验表明，iPROMPT算法的平均准确率是96.9%，平均召回率是88.6%。"}
{"text": "总的来说，在发现本体映射的过程中，iPROMPT主要利用术语相关性计算方法寻找本体间概念或概念的相关属性的映射，因此，它只能发现有限的概念间或属性间的等价映射。"}
{"text": "3）MAFRA。"}
{"text": "MAFRA是处理语义Web上分布式本体间映射的一个框架[30-32]，该框架是为了处理、表示并应用异构本体间的映射。"}
{"text": "MAFRA引入了语义桥和以服务为中心的思想。"}
{"text": "语义桥提供异构本体间数据（主要是实例和属性值）转换的机制，并利用映射提供基于分布式本体的服务。"}
{"text": "MAFRA体系结构如图5-7所示，其结构由水平方向和垂直方向的两个模块组成。"}
{"text": "水平方向的五个模块具体包括：①正规化。"}
{"text": "要求各个本体必须表示为一个统一形式（如RDF、OWL等），以消除不同源本体之间语法和语言上的差异。"}
{"text": "MAFRA的正规化过程还包括一些词语方面的处理，如消除常见词和扩展缩写等。"}
{"text": "②相似度。"}
{"text": "MAFRA利用多种基本的术语或结构相似度方法来获取本体成分之间的关系。"}
{"text": "在计算概念间关系的过程中还考虑了概念的属性。"}
{"text": "③语义桥。"}
{"text": "根据本体成分间的相似度，利用语义桥来表示本体映射。"}
{"text": "这些语义桥包括表示概念桥和属性桥，前者能实现实例间转换，后者表示属性间转换的规则。"}
{"text": "还能利用推理建立一些隐含的语义桥。"}
{"text": "④执行。"}
{"text": "在获得本体间交互的请求时，利用语义桥中的映射规则完成实例转换或属性转换。"}
{"text": "⑤后处理。"}
{"text": "映射执行产生的转换结果需要进一步处理，以提高转换结果的质量，例如，需要识别转换结果中表示同一对象的两个实例等。"}
{"text": "垂直方向四个模块具体包括：①演化。"}
{"text": "当本体发生变化时，对生成的“语义桥”进行维护，即同步更新语义桥。"}
{"text": "②协同创建。"}
{"text": "对于某些本体成分可能存在多个不同的映射建议，此时一般通过多个用户协商，选择一致的映射方案。"}
{"text": "③领域限制和背景知识。"}
{"text": "给出一些领域限制能避免生成不必要的映射；提供一些特定领域的背景知识，如同义词典能提高映射结果的质量。"}
{"text": "④用户界面交互。"}
{"text": "给出图形化的操作界面能让本体建立的过程更容易。"}
{"text": "图5-7MAFRA体系结构MAFRA主要给出一套本体映射方法学，用来表示映射，将映射划分为概念桥和属性桥两类，并利用映射实现异构本体间的数据转换。"}
{"text": "尽管MAFRA支持通过手工建立一些复杂的映射，但它缺乏自己特有的映射发现技术。"}
{"text": "因此，MAFRA更多只是一个处理异构本体映射的框架。"}
{"text": "4）ONION。"}
{"text": "ONION是Mitra_P等人设计的一个解决本体互操作的系统[33-34]。"}
{"text": "该系统采用半自动算法生成本体互操作的映射规则，解决本体之间的异构。"}
{"text": "为了使异构本体具有统一格式，ONION采用图的形式表示本体，具体保存时采用的格式。"}
{"text": "本体图中包含了有五种明确定义的语义关系：{SubClassOf;RDF_PartOf;AttributeOf;InstanceOf;ValueOf}。"}
{"text": "本体映射的生成是半自动的，生成算法将可能的映射结果提供给专家，专家可以通过设定相似度阈值或直接选择的形式来接受、修改或改变建议。"}
{"text": "专家还可以添加新的映射，以补充算法无法生成的映射规则。"}
{"text": "ONION的映射生成过程同时使用了术语匹配和本体图匹配。"}
{"text": "对于每一种术语匹配算法，专家为其分配一定的置信度，最终的术语匹配结果是几个算法结果的综合[35]。"}
{"text": "在计算两个本体的映射过程中，很多算法都需要比较两个本体之间所有可能的术语对，对于大本体而言，这样的计算过程非常耗时。"}
{"text": "为避免这种问题，ONION在计算本体映射时提出一个“窗口算法”，即算法首先将每个本体划分为几个“窗口”，一个“窗口”包括本体中的一个连通子图。"}
{"text": "在发现映射的过程中，并不对所有可能的“窗口”对都进行比较，比较只在那些可能会有映射的窗口对之间进行。"}
{"text": "“窗口算法”虽然降低了比较过程的时间复杂度，但同时也可能造成映射的遗漏。"}
{"text": "ONION的映射发现算法分为非迭代算法和迭代算法两种。"}
{"text": "①非迭代算法，利用几种语言匹配器来发现本体术语间的关系，最后将各个匹配器发现的相似度进行综合，并将结果提供给本体专家进一步确认。"}
{"text": "在这个过程中，专家可以事先设定一些阈值，使算法自动去除一些不可能的相似度结果。"}
{"text": "同时，非迭代算法还借助词典（如WordNet），利用字典中的同义词集来提高映射发现的映射质量。"}
{"text": "②迭代算法，迭代寻找本体子图间结构上的同态以得到相似的概念，每一次迭代都利用上一次生成的映射结果。"}
{"text": "Nexus和ONION的试验表明，如果映射发现过程只使用子图比较技术的话，得到的结果往往不令人满意。"}
{"text": "因此，迭代算法一般以基本匹配器生成的结果为基础，再进行子图匹配。"}
{"text": "ONION算法的试验结果表明，采用这种方法得到的映射精度在56%～73%之间，映射结果的召回率为50%～90%。"}
{"text": "试验还表明，在映射发现过程中采用多种策略能提高精度。"}
{"text": "ONION中寻找的映射是原子概念之间的等价关系，属于本体间的简单映射。"}
{"text": "5）Wang_Peng和Xu_Baowen的方法。"}
{"text": "Wang_Peng和Xu_Baowen等人也探讨了建立本体映射规则的方法[36]。"}
{"text": "该方法借助各种本体概念相似度的度量[37]，寻找异构本体概念间的关系。"}
{"text": "该方法认为概念间的语义关系可以通过概念名、概念属性和概念在本体中的上下文得到。"}
{"text": "这种方法认为不同本体间概念的相似度包括三个部分：①概念的同义词集相似度。"}
{"text": "同义词集是语义相同或相近词的分组[38]。"}
{"text": "基于同名或同义词集的概念在多数情况下具有相同或是相近的含义，因此，这里将概念的名称作为相似度首要考虑的要素。"}
{"text": "②概念特征上的相似度。"}
{"text": "概念的特征包含概念的属性、概念附带的关系以及属性和关系取值的限制，是从概念的内部组成上比较它们之间的相似度。"}
{"text": "③概念上下文上的相似度。"}
{"text": "以上的两种相似度都是基于概念自身的，上下文的相似度是由当前概念的语义邻居结构的相似度决定的。"}
{"text": "以下定义概念的语义邻居概念集。"}
{"text": "定义5.6概念Co的语义邻居概念集N(Co,r)={Ci|∀i,d(Co,Ci)≤r}。"}
{"text": "式中，d表示概念间的距离，其数值为联系两概念的最短的关系数目。"}
{"text": "这里的关系包含直接继承关系。"}
{"text": "d≤r表明与当前的概念在语义距离上小于某一定常数。"}
{"text": "在以上分析的基础上，给出了本体间概念相似度的计算公式：S(Cp,Cq)=Ww×Sw(Cp,Cq)+Wu×Su(Cp,Cq)+Wn×Sn(Cp,Cq)式中，Ww、Wu和Wn是权重；Sw、Su和Sn分别代表概念名称、特征以及上下文三方面的相似性度量。"}
{"text": "计算采用Tverski_A定义的非对称的相似度度量[39]：式中，a、b是待度量概念元素；Ai和Bi,i∈{w,u,n}分别对应概念的同义词集、特征集或语义邻居集；||表示取集合的势；表示两集合的并集；/表示两集合的差集；α(a,b)由a、b所在类结构层次决定.式中，depth()是当前概念在层次结构中的深度，定义为从当前概念到顶层概念的最短路径长度。"}
{"text": "该方法利用概念间的相似度辅助本体映射的生成。"}
{"text": "①如果两个概念有相同名称、相同特征和相同上下文，则它们必然是相同的，即Sw(a,b)=Su(a,b)=Sn(a,b)=1事实上，①中的条件过于苛刻，两概念满足三种相似度都为1的情况极少。"}
{"text": "通常，如果两概念在三种相似度或总相似度中具有较高的值，它们相同的可能就很大。"}
{"text": "②更值得关注的结论是，在同一本体中，父概念与子概念的相似度通常小于子概念与父概念的相似度[38]，该结论可推广到不同本体中概念间存在父子关联的判别中。"}
{"text": "根据上面的相似度量方法和分析，该方法得到生成概念上的等价关系和上/下义关系两种映射。"}
{"text": "生成规则如下。"}
{"text": "定义5.7如果不同本体中两概念的互相相似度都大于定常数，那么这两概念是等价的，表示为(Oa:Ci,Ob:Cj))。"}
{"text": "式中，AddBridge表示添加一个映射的操作，BCequal表示两个概念等价。"}
{"text": "定义5.8如果在不同本体中，某一概念Ci对于另一概念Cj的相似度大于某一常数，同时该相似度比Cj对于Ci的相似度大于定常数，那么将由这两概念构成上/下义关系，表示为：∀Oa:Ci,Ob:Cj,S(Oa:Ci,Ob:Cj)≥βandS(Oa:Ci,Ob:Cj)S(Ob:Cj,Oa:Ci)≥γ⇒AddBridge(isa(Oa:Ci,Ob:Cj))。"}
{"text": "式中，isa表示两概念具有上义和下义关系。"}
{"text": "从上面的论述可以看出，这种方法从多个角度综合考虑概念的映射，并能抽取简单概念之间的等价和继承关系，但这些映射仍然属于简单映射。"}
{"text": "6）S-Match。"}
{"text": "S-Match是一个本体匹配系统，能发现异构本体间的映射[40]。"}
{"text": "它输入两个本体的图结构，返回图节点之间的语义关系；其中可能的语义关系有等价（=）、泛化（）、特化（）、不匹配（⊥）和相交（）。"}
{"text": "S-Match基于本体抽象层的概念继承结构树，不考虑本体中的实例。"}
{"text": "S-Match的核心是计算异构本体间的语义关系。"}
{"text": "输入的本体树结构以标准的XML格式编码，这种编码能以手工编辑的文件格式调入，或者能通过相应的转换器产生。"}
{"text": "该方法首先以一种自顶向下的方式计算树中的每个标签的含义，这需要提供必要的先验词汇和领域知识，在目前的版本中，S-Match利用WordNet。"}
{"text": "执行结果的输出是一个被丰富的树。"}
{"text": "然后，用户协调两本体的匹配过程，这种方法使用三个外部库。"}
{"text": "第一个库是包含弱语义的元素匹配器，它们执行字符串操作（如前缀、编辑距离和数据类型等），并猜测编码相似的词之间的语义关系。"}
{"text": "目前的_S-Match包含13个弱语义的元素层次匹配器，分成三类：①基于字符串的匹配器，它利用字符串比较技术产生语义关系；②基于含义的匹配器，它利用WordNet的继承结构特点产生语义关系；③基于注释的匹配器，它利用注释在WordNet中的含义产生语义关系。"}
{"text": "第二个库由强语义的元素层次匹配器组成，当前使用的是WordNet。"}
{"text": "第三个库是由结构层次的强语义匹配器组成的。"}
{"text": "输入给定的两个带标签的本体树T1和T2,S-Match算法分为4步：步骤1：对所有在T1和T2中的标签，计算标签的含义。"}
{"text": "其中的思想是将自然语言表示的节点标签转换为一种内部的形式化形式，以此为基础计算每个标签的含义。"}
{"text": "其中的预处理包括：分词，即标签被解析为词，如Wine_and_Cheese⇔_Cheese>；词形分析，即将词的形态转换为基本形式，如Images⇔Image；建立原子概念，即利用WordNet提取前面分词后节点的含义；建立复杂概念，根据介词和连词，由原子概念构成复杂概念。"}
{"text": "<Wine,and,步骤2：对所有T1和T2中的节点，计算节点上概念的含义。"}
{"text": "扩展节点标签的含义，通过捕获树结构中的知识，定义节点中概念的上下文。"}
{"text": "步骤3：对所有T1和T2中的标签对，计算标签间的关系。"}
{"text": "利用先验知识，如词汇、领域知识，借助元素层次语义匹配器建立概念间的关系。"}
{"text": "步骤4：对所有T1和T2中的节点对，计算节点上的概念间的关系。"}
{"text": "将概念间的匹配问题转换为验证问题，并利用第3步计算得到的关系作为公理，通过推理获得概念间的关系。"}
{"text": "与一些基于术语和结构的本体映射系统比较，S-Match在查准率和查全率方面都比较好，但是试验发现该方法的执行时间要长于其他方法。"}
{"text": "7）Cupid。"}
{"text": "Cupid系统实现了一个通用的模式匹配算法[41]，它综合使用了语言和结构的匹配技术，并在预定义词典的帮助下，计算相似度获得映射结果。"}
{"text": "该方法输入图格式的模式，图节点表示模式中的元素。"}
{"text": "与其他的混合方法比较[42],Cupid得到更好的映射结果。"}
{"text": "发现模式匹配的算法包含三个阶段。"}
{"text": "①语言匹配，计算模式元素的语言相似度，基于词法正规化、分类、字符串比较技术和查词典等方法；②结构匹配，计算结构相似度，度量元素出现的上下文；结构匹配算法的主要思想是利用一些启发式规则，例如两个非叶节点相似，如果它们在术语上相似，并且以两元素为根的子树相似；③映射生成，计算带权重相似度和生成最后的映射，这些映射的权重相似度应该高于预先设定的阈值。"}
{"text": "Cupid针对数据库模式（通常作为一种简单的本体），它只支持模式间元素的简单映射，但给出的方法也适用于处理本体映射。"}
{"text": "8）其他方法。"}
{"text": "Chimaera是一个合并和测试大本体的环境[43]。"}
{"text": "寻找本体映射是进行合并操作的一个主要任务。"}
{"text": "Chimaera将匹配的术语对作为候选的合并对象，术语对匹配考虑术语名、术语定义、可能的缩写与展开形式以及后缀等因素。"}
{"text": "Chimaera能识别术语间是否包含或不相关等简单的映射关系。"}
{"text": "BUSTER是德国不来梅大学开发的改善信息检索的语义转换中间件[44]，是为了方便获取异构和分布信息源中的数据。"}
{"text": "BUSTER通过解决结构、语法和语义上的异构来完成异构信息源的集成。"}
{"text": "它认为不同系统的用户如果在一些基本词汇上达成一致，便能确保不同源本体间的信息查询相互兼容。"}
{"text": "因此，BUSTER建立局部本体和基本词汇集之间的映射，通过这种映射来达到异构信息源查询。"}
{"text": "COMA是一个模式匹配系统[45]，它是一种综合的通用匹配器。"}
{"text": "COMA提供一个可扩展的匹配算法库、一个合并匹配结果的框架，以及一个评估不同匹配器的有效性平台。"}
{"text": "它的匹配库是可扩展的，目前该系统包含6个单独的匹配器、5个混合匹配器和1个面向重用的匹配器，它们大多数的实现基于字符串技术。"}
{"text": "面向重用的匹配器则力图重用其他匹配器得到的结果来得到更好的映射。"}
{"text": "模式被编码为有向无环图。"}
{"text": "COMA支持在匹配过程中与用户进行交互，提高匹配结果的准确率。"}
{"text": "ASCO原型依靠识别不同本体间相关元素对的算法[46]来发现映射，这些元素对可以是概念对，也可以是关系对。"}
{"text": "ASCO使用本体中包含的可用信息来处理映射，这些信息包括标识、标签、概念和标签的注释、关系和它的定义域和值域，概念和关系的结构，以及本体的实例和公理。"}
{"text": "该方法的匹配过程分为几个阶段：语言阶段应用语言处理技术和字符串比较度量元素间关系，并利用词汇数据库来计算概念或关系间的相似度；结构阶段利用概念和关系的结构计算概念或关系间的相似度。"}
{"text": "（3）基于术语和结构的本体映射总结。"}
{"text": "尽管基于术语和结构的本体映射探索不少，但是总的来说取得的映射结果都不够让人满意，大多数的工作只能发现简单概念间的等价和包含映射，以及原子关系之间的等价。"}
{"text": "这一类方法大部分基于一些直观的思想，缺乏理论的依据和支持，因此适用范围窄，取得的映射结果质量低。"}
{"text": "2.基于实例的本体映射基于实例的本体映射发现方法通过比较概念的外延，即本体的实例，发现异构本体之间的语义关联。"}
{"text": "（1）技术综述。"}
{"text": "基于实例的本体映射技术可分为两种情况：本体概念间存在共享实例和概念之间没有共享实例。"}
{"text": "①共享实例的方法。"}
{"text": "当来自不同本体的两概念A和B有共享实例时，寻找它们之间关系最简单的方法是测试实例集合的交。"}
{"text": "当两概念等价时，显然有AB=A=B。"}
{"text": "然而，当两概念相似，即它们存在部分共享实例时，直接求交集的方法不合适，为此采用如下定义的对称差分来比较两概念。"}
{"text": "定义5.9对称差分表示两集合的相似度，如果x和y是两个概念对应的实例集合，则它们的对称差分相似度为可见，对称差分值越大，概念间的差异越大。"}
{"text": "此外，还可以根据实例集合的概率解释来计算相似度，在随后的方法中将详细介绍。"}
{"text": "②无共享实例的方法。"}
{"text": "当两概念没有共享实例时，基于共享实例的方法无能为力。"}
{"text": "事实上，很多异构本体间都不存在共享实例，除非特意人工构建共享实例集合。"}
{"text": "在这种情况下，可以根据连接聚合等数据分析方法获得实例集之间的关系。"}
{"text": "常用的连接聚合度量包括单连接、全连接、平均连接和Haussdorf距离。"}
{"text": "其中，Haussdorf距离度量两个集合之间的最大距离。"}
{"text": "而ValtchevP提出的匹配相似度则通过建立实体间的对应关系来进一步计算集合之间的相似度[47]。"}
{"text": "基于实例的映射发现方法很多采用机器学习技术来发现异构本体间映射。"}
{"text": "通过训练，有监督的学习方法可以让算法了解什么样的映射是好的（正向结果），什么样的映射不正确（负向结果）。"}
{"text": "训练完成后，训练结果用于发现异构本体间的映射。"}
{"text": "大量的本体实例包含了实例间具有的关系以及实例属于哪个概念等信息，学习算法利用这些信息能学习概念之间或关系之间的语义关系。"}
{"text": "常用的机器学习算法包括形式化概念分析[48]、贝叶斯学习[49]和神经网络[50]等。"}
{"text": "（2）方法和工具1）GLUE。"}
{"text": "GLUE是著名的本体映射生成系统之一，它应用机器学习技术，用半自动的方法发现异构本体间的映射[51,8,52]。"}
{"text": "GLUE是对半自动模式发现系统LSD的一个改进[53]。"}
{"text": "GLUE认为概念分类是本体中最重要的部分，它着重寻找分类本体概念之间的1∶1映射。"}
{"text": "该方法还能扩充为发现关系之间的映射以及处理更复杂的映射形式（如1∶n或n∶1）[54]。"}
{"text": "①GLUE的思想。"}
{"text": "GLUE的目的是根据分类本体寻找本体间1∶1的映射。"}
{"text": "其中的主要思想包括：（a）相似度定义。"}
{"text": "GLUE有自己特有的相似度定义，它基于概念的联合概率分布，利用概率分布度量并判断概念之间的相似度。"}
{"text": "GLUE定义了4种概念的联合概率分布。"}
{"text": "（b）计算相似度。"}
{"text": "由于本体之间的实例是独立的，为了计算本体O1中概念A和本体O2中概念B之间的相似度，GLUE采用了机器学习技术。"}
{"text": "它利用A的实例训练一个匹配器，然后用该匹配器去判断B的实例。"}
{"text": "（c）多策略学习。"}
{"text": "使用机器学习技术存在的一个问题是：一个特定的学习算法通常只适合解决一类特定问题。"}
{"text": "然而，本体中的信息类型多种多样，单个学习器无法有效利用各种类型的信息。"}
{"text": "为此，GLUE采用多策略学习技术，即利用多个学习器进行学习，并通过一个元学习器综合各学习器的结果。"}
{"text": "（d）利用领域约束。"}
{"text": "GLUE利用领域约束条件和通用启发式规则来提高映射结果的精度。"}
{"text": "一个领域约束的例子是“如果概念X匹配Professor以及概念Y是X的祖先，那么Y不可能匹配概念Assistant-Professor”；一个启发式规则如“两个概念的邻居都是匹配的，那么这两个概念很可能也匹配”。"}
{"text": "（e）处理复杂映射。"}
{"text": "为了能发现本体间的复杂映射，如1∶n类型的概念映射，GLUE被扩展为CGLUE系统，以寻找复杂的映射。"}
{"text": "以下给出GLUE方法的详细介绍。"}
{"text": "②相似度度量。"}
{"text": "很多本体相似度定义过于依赖概念本身和它的语法表示，与这些方法不同，GLUE定义了更精确的相似度表示。"}
{"text": "GLUE将概念视为实例的集合，并认为该实例集合是无限大的全体实例集中的一个子集。"}
{"text": "在此基础上，GLUE定义不同概念间的联合)和P(概率分布。"}
{"text": "概念A和B之间的联合概率分布包括4种：P(A,B)、P(,B)、P(A,)。"}
{"text": "以P(A,)为例，它表示从全体实例集中随机选择一个实例，该实例属于A但不属于B的概率，概率的值为属于A但不属于B的实例占全体实例集的比例。"}
{"text": "GLUE的相似度度量正是基于这4种概念的联合分布，它给出了两个相似度度量函数。"}
{"text": "第一个相似度度量函数是基于Jaccard系数[55]：当A与B不相关时，该相似度取得最小值0；当A和B是等价概念时，该相似度取得最大值1。"}
{"text": "另一个相似度度量函数为“最特化双亲”，它定义为其中，概率P(A|B)和P(B|A)能用4种联合概率来表示。"}
{"text": "这个定义表明，如果B包含A，则B越特化，P(A|B)越大，那样MSP(A,B)的值越大。"}
{"text": "这符合这样的直觉：A最特化的双亲是包含A的最小集；或者说在A的所有父概念中，它与直接父概念的相似度最大。"}
{"text": "类似于“最特化双亲”，还可以定义“最泛化孩子”的相似度度量。"}
{"text": "③GLUE体系结构。"}
{"text": "GLUE主要由三个模块组成：分布估计、相似度估计和放松标记，如图5-8所示。"}
{"text": "图5-8GLUE体系结构分布估计输入两个分类本体O1和O2以及它们的实例。"}
{"text": "然后利用机器学习技术计算每对概念的联合概率分布。"}
{"text": "由于联合概率分布包含4种，这样一共需要计算4|O1||O2|个概率，其中|Oi|是本体Oi中概念的数目。"}
{"text": "分布评估使用一组基本学习器和一个元学习器。"}
{"text": "相似度估计利用输入的联合概率分布，并借助相似度函数，计算概念对之间的相似度，输出两个分类本体之间的概念相似度矩阵。"}
{"text": "放松标记模块利用相似度矩阵以及领域特定的约束和启发式知识，寻找满足领域约束和常识知识的映射，输出最终的映射结果。"}
{"text": "④分布估计。"}
{"text": "考虑计算P(A,B)的值，其中A∈O1且B∈O2，这个联合概率分布是同时属于A和B的实例数与全体实例总数的比值。"}
{"text": "通常这个比值是无法计算的，因为不可能知道全体实例。"}
{"text": "因此，必须基于现有的数据来估计P(A,B)，即利用两个本体的输入实例。"}
{"text": "注意，两个本体的实例可以重叠，但没有必要必须那样。"}
{"text": "Ui表示本体Oi的实例集合，它是全体实例中的本体Oi对应部分的抽样。"}
{"text": "N(Ui)是Ui中实例的数目，公式来估计：是同时属于A和B的实例数目。"}
{"text": "这样，P(A,B)能用如下的这样将P(A,B)的计算转化为计算和。"}
{"text": "例如，为了计算的数值，需要知道U2中的每个实例s是否同时属于A和B；由于B是O2的概念，属于B的那部分实例是很容易得到的，因为这已在本体中明确说明；而A并不在本体O2中，因此只需要判断O2中的实例s是否属于A。"}
{"text": "为了达到这个目的，GLUE使用了机器学习方法。"}
{"text": "特别地，将O1的实例集合U1划分为属于A的实例集和不属于A的实例集。"}
{"text": "然后，将这两个集合作为正例和反例，分别训练关于A的实例分类器。"}
{"text": "最后，使用该分类器预测O2中的实例s是否属于A。"}
{"text": "通常，分类器返回的结果并非是明确的“是”或“否”，而是一个[0,1]之间的置信度值。"}
{"text": "这个值反映了分类的不确定性。"}
{"text": "这里规定置信度大于0.5就表示“是”。"}
{"text": "常用的分类学习器很多，GLUE使用的分类学习器将在随后部分介绍。"}
{"text": "基于上述思想，通过学习的方法得到和等参数，就能估计A和B的联合概率分布。"}
{"text": "具体的过程如图5-9所示。"}
{"text": "●划分本体O1的实例集合U1为和，分别表示属于A和不属于A的实例集合，如图5-9（a）和图5-9（b）所示。"}
{"text": "●使用和作为正例和反例分别训练学习器L，如图5-9（c）。"}
{"text": "●划分本体O2的实例集合U2为和，分别表示属于B和不属于B的实例集合，如图5-9（d）和图5-9（e）所示。"}
{"text": "●对中的每个实例使用学习器L进行分类。"}
{"text": "将划分为两个集合和。"}
{"text": "相似地，对应用学习器L，得到两个集合和，如图5-9（f）所示。"}
{"text": "●重复（a）～（d），得到集合和。"}
{"text": "●使用公式计算P(A,B)。"}
{"text": "类似地，可以计算出其他3种联合概率分布。"}
{"text": "图5-9估计概念A和B的概率分布⑤多策略学习。"}
{"text": "训练实例分类器的过程可根据不同类型的信息，如可以利用词语出现的频率、实例名和实例属性的赋值格式等。"}
{"text": "基本的分类学习器有很多，但不同学习器通常只适合针对特定信息类型进行分类，分类的效果不一定让人满意。"}
{"text": "为了在学习过程中充分考虑信息类型，提高分类的精度，GLUE采用多策略的学习方法。"}
{"text": "在分布估计阶段，系统会训练多个基本学习器L1,…,Lk。"}
{"text": "每种学习器利用来自实例数据中某种类型的信息进行分类学习训练。"}
{"text": "训练完成后，当使用这些基本学习器进行实例分类时，借助一个元学习器合并各个学习器的预测结果。"}
{"text": "与采用单个学习器的方法相比，多策略的学习方法能得到较高的分类准确率，并可以得到较好的联合分布近似值。"}
{"text": "目前实现的GLUE系统中有2个基本分类学习器：内容学习器和名字学习器。"}
{"text": "此外，还有1个元学习器将基本学习器的结果进行线性合并。"}
{"text": "内容学习器和名字学习器的细节如下：（a）内容学习器。"}
{"text": "利用实例文本内容中的词频来进行分类预测。"}
{"text": "一个实例通常由名将这些信息都作为实例的文本内容。"}
{"text": "例如，实字、属性集合以及属性值组成。"}
{"text": "GLUE例“Professor_Cook”的文本内容是“R.Cook,Ph.D.,University_of_Sydney,Australia”。"}
{"text": "内容学习器采用贝叶斯学习技术[56]，这是最流行和有效的分类法之一。"}
{"text": "它采用分词和抽取词干技术将每个输入实例的文本内容表示为一组标记，即输入实例的内容表示为d={w1,…,wk}，其中的wj是标记。"}
{"text": "内容学习器的目的是计算输入的一个实例（用它的内容d表示）属于概念A的概率，即P(A|d)。"}
{"text": "根据贝叶斯原理，P(A|d)可被重写为P(d|A)P(A)/P(d)。"}
{"text": "其中，P(d)是一个常量，而P(d|A)和P(A)能通过训练实例来估计。"}
{"text": "特别地，P(A)被估计为属于A的实例占全部训练实例的比例。"}
{"text": "因此，只需要计算P(d|A)就可以得到P(A|d)。"}
{"text": "为计算P(d|A)，假设实例的内容d中的标记wj是独立的，这样便有：P(d|A)=P(w1|A)P(w2|A)···P(wk|A)式中，P(wj|A)可用n(wj,A)/n(A)来估计，n(A)表示在属于A的训练实例中，所有标记出现的总次数，n(wj,A)则表示标记wj出现在属于A的训练实例中的次数。"}
{"text": "注意，尽管标记独立假设在很多时候并不成立，但贝叶斯学习技术往往在很多领域都取得了不错的效果，这种现象的相关解释见文献[60]。"}
{"text": "P(|d)可通过相似的方法来计算。"}
{"text": "（b）名字学习器。"}
{"text": "相似于内容学习器，但名字学习器利用实例的全名而不是实例的内容来进行分类预测。"}
{"text": "这里的实例全名是指从根节点直到实例所在位置的路径上所有概念名的连接。"}
{"text": "例如，图5-9（d）中s4的全名为“GBJs4”。"}
{"text": "（c）元学习器。"}
{"text": "基本学习器的预测结果通过元学习器来合并。"}
{"text": "元学习器分配给每个基本学习器一个权重，表示基本学习器的重要程度，然后合并全部基本学习器的预测值。"}
{"text": "例如，假设内容学习器和名字学习器的权重分别是0.6和0.4；对于本体O2中的实例s4，如果内容学习器预测它属于A的概率为0.8，属于的概率为0.2，名字学习器预测它属于A的概率为0.3，属于的概率为0.7，则元学习器预测s4属于A的概率为0.8×0.6+0.3×0.4=0.6，属于的概率为0.4。"}
{"text": "这种基本学习器的权重往往由人工给定，但也可以使用机器学习的方法自动设置[57]。"}
{"text": "⑥利用领域约束和启发式知识。"}
{"text": "经过相似估计，得到了概念之间的相似度矩阵，进一步利用给定的领域约束和启发式知识，能获得最佳的正确映射。"}
{"text": "放松标记是一种解决图中节点的标签分配问题的有效技术。"}
{"text": "该方法的思想是节点的标签通常受其邻居的特征影响。"}
{"text": "基于这种观察，放松标记技术将节点邻居对其标签的影响用公式量化。"}
{"text": "放松标记技术已成功用于计算机视觉和自然语言处理等领域中的相似匹配。"}
{"text": "GLUE将放松标记技术用于解决本体映射问题，它根据两本体的特征和领域知识寻找本体节点间的对应关系。"}
{"text": "考虑约束能提高映射的精度。"}
{"text": "约束又可分为领域独立约束和领域依赖约束两种。"}
{"text": "领域独立约束表示相关节点间交互的通用知识，其中最常用的两种约束是邻居约束和并集约束。"}
{"text": "邻居约束是指“两节点的邻居匹配，则两节点也匹配”；并集约束指“如果节点X的全部孩子匹配Y，那么节点X也匹配Y”；该约束适用于分类本体，它基于这样的事实，即X是它的所有孩子的并集。"}
{"text": "领域依赖约束表示特定节点间交互的用户知识，在GLUE系统中，它可分为包含、频率和邻近三种。"}
{"text": "以一个大学组织结构的本体为例，包含约束如“如果节点Y不是节点X的后继，并且Y匹配PROFESSOR，则X不可能匹配FACULTY”；频率约束如“至多只有一个节点和DEPARTMENT-CHAIR匹配”；邻近约束如“如果X邻居中的节点匹配ASSOCIATE-PROFESSOR，则X匹配PROFESSOR的机会增加”。"}
{"text": "GLUE利用这些限制进一步寻找正确的映射或去除不太可能的映射。"}
{"text": "⑦实验评估。"}
{"text": "GLUE系统的实验结果表明，对于1∶1的映射，正确率为66%～97%。"}
{"text": "在基本学习器中，内容学习器的正确率为52%～83%，而名字学习器的正确率很低，只有12%～15%。"}
{"text": "在半数的实验中，元学习器只少量提高正确率，在另一半的实验中，正确率提高了6%～15%。"}
{"text": "放松标记能进一步提高3%～18%的正确率，只有一个实验例外。"}
{"text": "由实验可见，对于适量的数据，GLUE能取得较好的概念间1∶1形式的映射结果。"}
{"text": "尽管GLUE取得了不错的映射结果，但几个因素阻碍它取得更高的映射正确率。"}
{"text": "首先，一些概念不能被匹配是因为缺少足够的训练数据。"}
{"text": "其次，利用放松标签进行优化的时候可能没有考虑全局的知识，因此优化的映射结果对整个本体来说并不是最佳的。"}
{"text": "第三，在实现中使用的两个基本学习器是通用的文本分类器，使用适合待映射本体的特定学习器可以得到更好的正确率。"}
{"text": "最后，有些节点的描述过于含糊，机器很难判断与之相关的映射。"}
{"text": "⑧扩充GLUE发现复杂映射。"}
{"text": "GLUE寻找给定分类本体概念之间1∶1的简单映射，但是实际应用中的复杂映射很普遍。"}
{"text": "为此，GLUE被扩充为CGLUE，用于发现异构本体O1中的概间的复杂映射。"}
{"text": "目前的CGLUE系统主要针对概念间的复杂映射，如念“Course”等价于O2中的“Undergrad-Courses”“Grad-Course”。"}
{"text": "CGLUE中的复杂映射形式如A=X1op1X2op2…opn-1Xn，其中A是O1中的概念，Xi是O2中的概念，opi是算子。"}
{"text": "这种1∶n的映射可扩展为m∶n的形式，如A1op1A2=X1op1X2op2X3。"}
{"text": "由于将概念看作实例的集合，因此opi可以是并、差和补等集合运算符。"}
{"text": "CGLUE将形如X1op1X2op2···opn-1Xn的复合概念称作映射对象。"}
{"text": "CGLUE还进一步假设概念D的孩子C1,C2,…,Ck要满足条件,1≤i,j≤k,i≠j，且。"}
{"text": "这样的假设对实际本体的质量提出了很高的要求。"}
{"text": "CGLUE将复合概念都可以重写为概念并的形式，便于统一处理。"}
{"text": "对于O1中的概念A,CGLUE枚举O2中的所有概念并的组合，并比较它与A的相似度。"}
{"text": "比较的方法与GLUE中的相似。"}
{"text": "最后返回相似度最高的映射结果。"}
{"text": "由于概念并组合的数目是指数级的，上面的“暴力”方法是不实用的。"}
{"text": "因此需要考虑从巨量的候选复合概念中搜索A的近似。"}
{"text": "为提高搜索的效率，CGLUE采用人工智能中的定向搜索技术，其基本思想是在搜索过程中的每一阶段，只集中关注最可能的k个候选对象。"}
{"text": "定向搜索算法寻找概念A的最佳映射的步骤如下：步骤1。"}
{"text": "令初始候选集合S为O2的全部原子概念集合。"}
{"text": "设highest_sim=0。"}
{"text": "步骤2。"}
{"text": "循环：（a）计算A和S中每个候选对象的相似度分数。"}
{"text": "（b）令new_highest_sim为S中对象的最高相似度分数。"}
{"text": "（c）如果|new_highest_sim-highest_sim|≤ε，则停止，返回S中拥有最高相似度分数的候选对象；其中ε是预定的。"}
{"text": "（d）否则，选择C中有最高分的k个候选对象。"}
{"text": "扩展这些候选创建新的候选对象。"}
{"text": "添加新候选对象到S。"}
{"text": "设置highest_sim=new_highest_sim。"}
{"text": "算法的步骤2（a）采用GLUE中的学习方法计算概念A和候选概念间的相似度分数。"}
{"text": "在步骤2（c）中，ε最初设置为0。"}
{"text": "在步骤2（d）中，对于选择的k个候选对象，算法将它们与O2中的节点分别进行并操作，这样一共产生k|O2|个新候的选对象；接着，去除前面使用的候选对象。"}
{"text": "因为每个候选对象只是O2概念的并，去除过程很快。"}
{"text": "CGLUE的实验结果表明，该算法发现了GLUE不能发现的1∶n类型的概念映射。"}
{"text": "试验还表明，对于一部分实验，CGLUE取得50%～57%的正确率，对另外一部分实验只获得16%～27%的正确率。"}
{"text": "实验还表明，CGLUE能帮助用户确定52%～84%的正确1∶1映射。"}
{"text": "CGLUE的开发者认为，如果进一步利用领域约束等知识，能取得更好的映射结果。"}
{"text": "⑨GLUE的总结。"}
{"text": "GLUE是早期经典的本体映射工作之一，该方法取得的结果较早期大多的映射发现技术更好。"}
{"text": "GLUE的语义相似基础建立在概念的联合概率分布上，它利用机器学习的方法，特别是采用了多策略的学习来计算概念相似度；GLUE利用放松标记技术，利用启发式知识和特定领域约束来进一步提高匹配的正确率。"}
{"text": "试验表明，对于概念之间1∶1的简单映射，GLUE能得到很不错的结果。"}
{"text": "扩展后的CGLUE系统还能进一步发现概念间1∶n类型的映射。"}
{"text": "尽管GLUE取得了很多不错的映射结果，但该方法还存在一些不足。"}
{"text": "首先，GLUE和CGLUE的映射正确率并不是很高，即使应用相关的领域约束，对各种情况的映射仍然难以得到高精度的映射结果；这主要是由于GLUE建立在机器学习技术上，机器学习技术的特性决定了很难取得接近100%的正确率；对不同本体之间的映射，都需要进行学习训练，使用起来很麻烦；学习器的类型有限，难以处理本体中各种类型的信息。"}
{"text": "其次，对于复杂概念间的映射，CGLUE提出的算法并不能让人满意，这种算法寻找到的复杂概念映射不是完备的，很多正确的映射可能会被漏掉。"}
{"text": "最后，GLUE无法处理关于异构本体的关系之间的映射。"}
{"text": "2）概念近似的方法。"}
{"text": "在基于异构本体的信息检索中，为了得到正确和完备的查询结果，往往需要将原查询重写为近似的查询。"}
{"text": "本体间概念的近似技术是近似查询研究的重点，它不仅用于解决异构本体的近似查询，而且还提供了一类表示和发现概念间映射的方法。"}
{"text": "①方法的思想。"}
{"text": "在本体查询系统中，信息源和查询都是针对特定本体的。"}
{"text": "不同的信息系统可能使用不同的本体，一个查询用某个本体中的词汇表达，但系统可能使用另一个本体，因而无法回答这个查询。"}
{"text": "一般地，如果S是基于本体O的信息源，则S只能回答关于O的查询。"}
{"text": "因此，如果用户（查询提出者）和系统（查询回答者）使用不同的本体，便带来了查询异构问题。"}
{"text": "当不存在一个全局本体时，异构查询问题通常需要在这两个本体之间解决。"}
{"text": "令用户本体为O1，系统本体为O2，则必须把用户提出的关于O1的查询重写为关于O2的查询，系统才能够回答。"}
{"text": "查询重写的理想目标是把关于O1的查询重写为关于O2的解释相同的查询，这样系统才能准确地给出查询结果。"}
{"text": "但是对于O1中的很多查询，可能不存在关于O2的解释相同的查询，或者找到这样的查询所需的时间是不可接受的，因此常常需要重写为解释近似于原查询的查询。"}
{"text": "令Q为关于O1的查询，R是重写Q得到的关于O2的近似查询，称R是Q在O2中的近似；令O2中全部概念的集合为T，则也称R是Q在T中的近似。"}
{"text": "R作为Q在T中的近似，它在信息源S中的查全率和查准率可定义为：查全率和查准率决定了近似的质量，较好的近似有较高的查全率和查准率。"}
{"text": "如果在所有S中都有recall(Q,R)=1，则近似查询结果包括了所有原查询的结果，称R是完备的；如果在所有S中都有precision(Q,R)=1，则所有近似查询结果都是原查询的结果，称R是正确的。"}
{"text": "查询间的蕴涵关系可用来寻找完备或正确的近似，如果QR，那么R一定是完备的，称R是Q在T中的一个上近似；反之，如果RQ，那么R一定是正确的，称R是Q在T中的一个下近似。"}
{"text": "本体间的概念近似技术正是基于上述思想，研究如何通过概念近似来重写查询表达式中的概念，以获得较高查全率和查准率的结果。"}
{"text": "这种方法虽然最终是为了处理查询，但它的核心过程是表示和寻找异构本体概念间的近似；寻找概念近似的过程通常是基于实例进行的，因此是一种重要的本体映射发现方法。"}
{"text": "②Stuckenschmidt_H的概念近似。"}
{"text": "寻找O1中概念C在O2中的近似是近似查询中的关键问题，其质量决定了近似查询的质量。"}
{"text": "Stuckenschmidt_H提出了利用概念的最小上界和最大下界计算概念近似的方法[57]。"}
{"text": "该方法首先定义了概念的最小上界和最大下界，并以此作为概念的上近似和下近似。"}
{"text": "从概念的蕴涵关系层次上看，概念的最小上界包括了概念在另一本体中所有的直接父类，概念的最大下界包括了概念在另一本体中所有的直接子类，如图5-10所示。"}
{"text": "C为O1中概念，概念C的最小上界lub(C,T)包含A1,A2,…,Am，是C在O2中的直接父类；概念C的最大下界glb(C,T)包含B1,B2,…,Bn，是C在O2中的直接父类。"}
{"text": "图5-10最小上界和最大下界定义5.10令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最小上界lub(C,T)是T中概念的集合，满足：1.对于任何D∈lub(C,T)，有CD；2.对于任何A∈T且CA，存在B∈lub(C,T)满足BA。"}
{"text": "找到C在T中的最小上界后，定义其中元素的合取为C在T中的一个上近似，记为下式：由于C被最小上界中的概念蕴涵，可知Cua(C,T)，所以ua(C,T)确实是C在T中的上近似。"}
{"text": "定义5.11令C为O1中概念，T为O2中全部概念的集合。"}
{"text": "定义C在T中的最大下界glb(C,T)是T的一个子集，满足：1.对于任何D∈glb(C,T)，有DC；2.对于任何A∈T且AC，存在B∈glb(C,T)满足AB。"}
{"text": "找到C在T中的最大下界后，定义其中元素的析取为C在T中的一个下近似，记为下式：由于C蕴涵最大下界中的概念，可知la(C,T)C，所以la(C,T)确实是C在T中的下近似。"}
{"text": "显然，这样得到的上近似和下近似都不包含非算子（），该方法只考虑不包含非算子的近似。"}
{"text": "因为非算子可以通过将查询化为否定正规形式（NegationNormal_Form,NNF）消去[58]。"}
{"text": "任何查询都可以在线性时间内通过反复应用以下公式改写为等价的NNF在NNF中，非算子只作用于单个概念，可以将其看作一个新的概念进行处理。"}
{"text": "这样概念数目最多翻倍，但所有非算子都被消去。"}
{"text": "Akahani_J等人对定义5.10和定义5.11进行了扩展[59]，改写为T中概念D属于O1中概念C在T中最小上界lub(C,T)，当且仅当CD，且不存在A∈T满足CAD;T中概念D属于O1中概念C在T中最大下界glb(C,T)，当且仅当DC，且不存在A∈T满足DAC。"}
{"text": "上述扩展定义去除了最小上界和最大下界中的大量冗余成员，提高了效率。"}
{"text": "但由于最小上界和最大下界是T的子集，本身不会很大，效果并不明显。"}
{"text": "在生成概念的近似过程中，该方法首先找到概念在系统本体中的超类和子类，然后生成概念的最小上界和最大下界，并将上界的合取作为概念的上近似，下界的析取作为概念的下近似。"}
{"text": "但这种方法无法得到概念的最佳近似，近似的质量有时是不可接受的。"}
{"text": "如果概念远小于它的超类，那么它的上近似可能过大；最坏情况是找不到概念的超类，那么上近似的查询结果就会返回全集。"}
{"text": "同样，如果概念远大于它的子类，那么它的下近似可能过小；最坏情况是找不到概念的子类，那么下近似的查询结果就会返回空集。"}
{"text": "异构本体常常有全异的概念集合和概念层次，因此最坏的情况也时常会出现。"}
{"text": "这种现象出现的主要原因是现有方法只注意概念的超类和子类，也就是异构本体原子概念间的蕴涵关系，因而不能得到概念的最佳近似。"}
{"text": "实际上，在复杂概念，如概念的合取和析取之间，同样也存在着蕴涵关系。"}
{"text": "如果考虑这些蕴涵关系，也许可以提高近似查询的质量。"}
{"text": "例如，令O1,O2为本体，C为O1中概念，T是O2中所有概念的集合，且T中没有概念能蕴涵C或被C蕴涵，则现有方法对C求上近似会返回全集top，下近似返回空集bot。"}
{"text": "但如果T中有概念A,B满足A∧BCA∨B，则A∨B是C的一个上近似，A∧B是C的一个下近似，它们显然比现有的近似要好。"}
{"text": "显然，A,B,C之间不存在任何蕴涵关系，但有A∧BCA∨B。"}
{"text": "这个例子表明在检查蕴涵关系时考虑复杂概念A∨B（概念A和B的析取）和A∧B（概念A和B的合取）确实会得到更好的上近似和下近似。"}
{"text": "图5-11复杂蕴涵关系示例③TzitzikasY的概念近似。"}
{"text": "为获得不同本体中概念的最佳近似，TzitzikasY提出通过实例学习来进行近似查询的方法[60]。"}
{"text": "它根据每个查询结果中的实例进行查询重写：对每一个应该是原查询结果的实例，找到能返回该实例的另一个本体中的最小查询，最后把这些最小查询组合起来得到原查询的一个近似。"}
{"text": "该方法需要一个训练实例集合。"}
{"text": "令与O2中概念集合T相关的信息源S为训练集，K是S中的一个非空对象集合。"}
{"text": "在不考虑非算子的情形下，该方法定义了两个关于T的查询集合：K+={Q|K⊆QI(S)};K-={Q|QI(S)⊆K}式中，QI(S)表示查询Q对应S中对象的集合；K+表示包含K的查询集合；K-表示K包含的查询集合。"}
{"text": "这样，对于非空对象集合K，它的上界和下界可计算为：显然，由于K+和K-中的查询表达式数目可能会很多，这样的上、下界表达式长度会很长，需要一种方法计算等价的且长度有限的查询。"}
{"text": "为此，引入一个将对象映射到概念合取的函数：。"}
{"text": "可证明利用DI(o)能得到与上界和下界等价的近似表示形式，这种表示的长度是有限的：对于概念C，如果K=CI(S)，那么name+(K)是C关于T的最小上近似，name-(K)是最大下近似。"}
{"text": "对于给定的查询，只需要将其中的概念按照这种近似表示就能重写概念近似查询。"}
{"text": "遗憾的是，Tzitzikas_Y并没有提出有效发现这种概念近似的方法。"}
{"text": "与Stuckenschmidt_H的方法相比，这种表示不会造成映射结果的丢失，即能得到完备的概念间近似，但这种方法存在着明显的缺点。"}
{"text": "第一是查询效率问题。"}
{"text": "该方法需要遍历所有实例计算概念近似。"}
{"text": "得到的近似查询是由很多小查询构成的，比较冗长，但表达式的长度却没有算法来简化。"}
{"text": "第二，该方法完全基于从训练集合中学习概念间的包含关系，而没有考虑本体间的语义关系。"}
{"text": "最后，该方法得到的近似不能传递，即不能从和得到，因为它们可能是根据不同的训练集得到的结果。"}
{"text": "④基于多元界的概念近似。"}
{"text": "Kang_Dazhou、Lu_Jianjiang和Xu_Baowen等人提出一套表示和发现概念近似查询的有效方法[61-63]，该方法能有效发现异构本体间概念的近似，且这种近似是最佳的和完备的。"}
{"text": "这种方法能进一步推广到关系映射的发现。"}
{"text": "由于其他的方法要不只考虑异构本体概念间一对一的蕴涵关系，概念的上下界中只包含独立的概念，因此无法得到概念的最佳近似；或者得到了概念间的最佳近似，但近似表示的形式冗余，且没有给出有效寻找映射的算法。"}
{"text": "基于多元界的概念近似方法的创新之处是考虑概念合取和析取之间的蕴涵关系来得到概念的最佳近似。"}
{"text": "将概念的最小上界和最大下界扩展为多元界：引入概念的析取定义概念的多元最小上界，引入概念的合取定义概念的多元最大下界。"}
{"text": "证明通过概念的多元最小上界可以得到概念的最小上近似，通过概念的多元最大下界可以得到概念的最大下近似。"}
{"text": "通常多元界中可能包含大量冗余，增加了概念近似表达的复杂度，降低了查询效率。"}
{"text": "该方法又定义了概念的最简多元最小上界和最简多元最大下界去除这些冗余，并提供两个有效的算法寻找概念的最简多元界，算法被证明是正确和完备的。"}
{"text": "该方法首先结合查全率和查准率的评判标准和查询间蕴涵关系，给出概念最佳近似的定义，分别包括概念的最小上近似和最大下近似。"}
{"text": "引入复杂概念间的蕴涵关系，将概念析取扩充到概念的上界中，将概念合取扩充到概念的下界中。"}
{"text": "由于上下界中都含有多个概念组成的复杂概念，称新的上下界为概念的多元界。"}
{"text": "证明利用多元界可以求得概念的最佳近似，从而提高近似查询的质量。"}
{"text": "这是该方法的理论基础。"}
{"text": "3）FCA。"}
{"text": "Stumme_G等人提出一种自底向上的本体合并方法FCA-Merge[48,64]，它基于两本体和它们的实例，使用形式化概念分析技术FCA合并两个共享相同实例集的本体。"}
{"text": "该方法的结果是合并后的本体，但结果本体间接蕴涵着两个初始本体间的概念映射：被合并的概念可认为是等价映射，它们与对应的祖先或孩子节点之间存在包含关系的映射，与对应的兄弟概念存在着相似关系。"}
{"text": "当然，这些概念分别来自两个不同的初始本体。"}
{"text": "①形式化概念分析基础。"}
{"text": "首先介绍FCA-Merge方法采用的理论基础，即形式概念分析，也称为概念格。"}
{"text": "形式概念分析是由Wille_R于1982年首先提出的[65]，它提供了一种支持数据分析的有效工具。"}
{"text": "概念格中的每个节点是一个形式概念，由两部分组成：外延，即概念对应的实例；内涵，即概念的属性，这是该概念对应实例的共同特征。"}
{"text": "另外，概念格通过Hasse图生动和简洁地体现了这些概念之间的泛化和特化关系。"}
{"text": "因此，概念格被认为是进行数据分析的有力工具。"}
{"text": "从数据集（概念格中称为形式背景）中生成概念格的过程实质上是一种概念聚类过程；然而，概念格可以用于许多机器学习的任务。"}
{"text": "形式背景可表示为三元组形式T=(S,D,R)，其中S是实例集合，D是属性集合，R是S和D之间的一个二元关系，即R∈S×D。"}
{"text": "(s,d)∈R表示实例s有属性d。"}
{"text": "一个形式背景存在唯一的一个偏序集合与之对应，并且这个偏序集合产生一种格结构。"}
{"text": "这种由背景(S,D,R)导出的格L就称为一个概念格。"}
{"text": "格L中的每个节点是一个序偶（称为概念），记为(X,Y)，其中X∈P(S)，这里P(S)是S的幂集，称为概念的外延；Y∈P(D)，这里P(D)是D的幂集，称为概念的内涵。"}
{"text": "每一个序偶关于关系R是完备的，即有性质：1）X={x∈S|∀y∈Y,xRy}2）Y={y∈D|∀x∈X,xRy}在概念格节点间能够建立起一种偏序关系。"}
{"text": "给定H1=(X1,Y1)和H2=(X2,Y2)，则H2<H1⇔Y1<Y2，领先次序意味着H2是H1的父节点或称直接泛化。"}
{"text": "根据偏序关系可生成格的Hasse图：如果H2<H1，且不存在另一个元素H3使得H2<H3<H1，则从H1到H2就存在一条边[66]。"}
{"text": "②自底向上的FCA-Merge本体合并。"}
{"text": "该方法并不直接处理本体映射，而是使用形式化概念分析技术，以一种自底向上的方式来合并两个共享相同实例集的本体。"}
{"text": "整个本体合并的过程分三步。"}
{"text": "（a）实例提取。"}
{"text": "由于FCA-Merge方法要求两个本体具有相同的实例集合，为达到这个目的，首先从同时与两本体相关的文本集合中抽取共享实例。"}
{"text": "从相同的文本集合为两个本体提取实例能够保证两本体相关的概念具有相近的共享实例集合。"}
{"text": "而共享实例是用来识别相似概念的基础，因此，提取共享实例是该方法实现的保证，同时提取出的实例质量也决定了最后结果的质量。"}
{"text": "这一步采用自然语言处理技术，得到两本体的形式背景。"}
{"text": "每个本体的形式背景表示为一张布尔表，表的行是实例，列是本体的概念，行列对应的位置表示实例是否属于概念；FCA-Merge将每个文本视为一个实例，如果某个文档是一个概念的实例，则它们在表中对应的值为真。"}
{"text": "显然，一个文档可能是多个概念的实例。"}
{"text": "（b）概念格计算。"}
{"text": "输入第一步中得到的两张布尔表来计算概念格。"}
{"text": "FCA-Merge采用经典的形式化概念分析理论提供的算法，这些算法能根据两张形式化背景的布尔表自动生成一个剪枝的概念格[65,67,68]。"}
{"text": "（c）交互生成合并的本体。"}
{"text": "生成的概念格已经将独立的两个本体合并在一起。"}
{"text": "本体工程师根据生成的概念格，借助领域知识，通过与机器交互创建目标合并本体。"}
{"text": "显然，合并的本体实际上蕴涵了两个初始本体概念间的映射关系。"}
{"text": "②FCA总结。"}
{"text": "形式化概念分析技术基于不同本体间的共享实例解决本体映射的发现问题，并有很好的形式化理论基础作为支持。"}
{"text": "这种方法能发现异构本体概念间的等价和包含映射，这样的映射是1∶1的简单类型。"}
{"text": "FCA具有一些不足。"}
{"text": "首先，该方法并没有考虑复杂概念间的映射，而且该方法的实现原理决定着它无法生成关系间的映射。"}
{"text": "其次，映射结果质量受提取共享实例过程的影响。"}
{"text": "最后，由概念格生成合并本体的工作由于人工参与，可能产生错误的映射结果。"}
{"text": "4）IF-Map。"}
{"text": "为了弥补很多本体映射方法缺乏形式化的理论基础的问题，Kalfoglou_Y受形式化概念分析的影响，提出一个本体映射发现系统IF-Map[69,70]。"}
{"text": "该方法是一种自动的本体映射发现技术，基于信息流理论[71]。"}
{"text": "IF-Map的基本原理是寻找两个局部本体间的等价，其方法是通过查看它们与一个通用的参考本体的映射。"}
{"text": "那样的参考本体没有实例，而实例只在局部本体中才考虑。"}
{"text": "因此，IF-Map方法的核心在于生成参考本体和局部本体之间的可能映射，然后根据这些映射判断两局部本体间的等价关系。"}
{"text": "映射生成的过程包括4个阶段：①采集，即收集不同的本体；②转换，即将待映射本体转换为特定格式；③信息映射生成，即利用信息流理论生成本体间的映射；④映射投影，将生成的概念间等价映射用本体语言表示出来，如owl:sameAs等。"}
{"text": "IF-Map也只能生成异构本体概念间的简单等价映射。"}
{"text": "（3）基于实例的本体映射总结。"}
{"text": "与基于术语和结构的映射发现方法相比，基于实例的本体映射发现方法更好，在映射的质量、类型和映射的复杂程度方面都取得了不错的结果。"}
{"text": "一些基于实例的方法能较好地解决异构本体概念间的映射问题，但对本体关系间的映射还缺乏有效方法和具体的实现。"}
{"text": "此外，基于实例的方法大多要求异构本体具有相同的实例集合，有些方法采用机器学习技术来弥补这个问题，而有的方法采用人工标注共享实例来解决这个问题；前一类方法的映射结果受到机器学习精度的影响，而后一类方法耗时费力，缺乏如何有效地建立共享实例集的方法。"}
{"text": "3.综合方法不同的映射方法具有各自的优点，但仅仅使用某一种方法又都不能完善地解决映射发现的问题。"}
{"text": "因此，为了得到更好的本体映射结果，可以考虑将多种映射方法综合使用，以吸收每种方法的优势。"}
{"text": "（1）方法和工具1）QOM。"}
{"text": "QOM是采用综合方法发现本体映射的典型工作[72-75]。"}
{"text": "该方法的最大特点在于寻找映射的过程中同时考虑了映射结果的质量与发现映射的时间复杂度，它力图寻找到二者间的平衡。"}
{"text": "QOM通过合理组织各种映射发现算法，在映射质量的损失可接受的前提下，尽量提高映射发现效率，因此该方法可以处理大规模本体间的映射发现问题。"}
{"text": "①QOM的思路。"}
{"text": "大多数本体映射发现算法过于强调映射结果的质量，而往往忽略发现映射的效率。"}
{"text": "目前，绝大多数方法的时间复杂度为O(n2),n是映射对象的数目。"}
{"text": "对于大本体间的映射需求，如UMLS（107个概念）与WordNet（106个概念）之间的映射而言，很多方法由于效率太低而无法实用。"}
{"text": "与这些方法不同，QOM给出的映射发现方法同时考虑映射质量和运行时间复杂度，在提高映射发现效率的同时保证一定质量的映射结果。"}
{"text": "QOM只考虑异构本体间1∶1等价映射，映射对象包括概念、关系和实例。"}
{"text": "②QOM方法的过程。"}
{"text": "QOM处理本体映射的过程共分六步，输入异构本体，进行处理后得到本体间的映射。"}
{"text": "步骤1。"}
{"text": "特征工程：将初始的输入本体转换为相似度计算中使用的统一格式，并分析映射对象的特征。"}
{"text": "QOM使用RDF三元组形式作为统一的本体形式，其中考虑的映射对象特征包括：标识，即表示映射对象的专用字符串，如URIs或RDF标签；RDF(S)原语，如属性或子类关系；推导出的特征，由RDF(S)原语推导出的特征，如最特化的类；OWLsameAs等表示等价的原语；领域中特定的特征，例如某领域中概原语，例如考虑念“Person”的实例都有“ID”属性，可用该属性值代替实例，方便处理。"}
{"text": "步骤2。"}
{"text": "搜索步骤的选择：由于各种相似度计算方法的复杂度与待映射的对象对直接相关，为了避免比较两个本体的全部对象，保证发现映射的搜索空间在能接受的范围内，QOM使用启发式方法降低候选映射对象的数目，即它只选择那些必要的映射对象，而忽略其他不关心的映射对象。"}
{"text": "步骤3。"}
{"text": "相似度计算：对每一对候选映射对象，判断它们之间的相似度值。"}
{"text": "一个对象可被不同类型的信息描述，如URIs的标识和RDF(S)原语等。"}
{"text": "QOM定义了多种关于对象特征（包括概念、关系和实例）的相似度量公式，对于其中的每种度量，都预先分析它的时间复杂度。"}
{"text": "为了提高发现映射的效率，在选择度量公式的时候忽略那些复杂度过高的度量公式。"}
{"text": "步骤4。"}
{"text": "相似度累加：由于同时采用多种度量方法，一对候选对象通常存在多个相似度值。"}
{"text": "这些不同的相似度值需要累加，成为单个的相似度值。"}
{"text": "QOM不采用直接累加方式，它强调一些可靠的相似度，同时降低一些并不可靠的相似度。"}
{"text": "步骤5。"}
{"text": "解释：利用设定的阈值或放松标签等技术，考虑本体结构和一些相似度准则，去除一些不正确的映射结果。"}
{"text": "根据处理后的最终相似度值判断本体之间的映射。"}
{"text": "步骤6。"}
{"text": "迭代：算法过程可迭代执行，每次迭代都能提高映射结果的质量，迭代可在没有新映射生成后停止。"}
{"text": "每次迭代时可基于贪婪策略从当前相似度最高的对象开始执行。"}
{"text": "③实验评估和结果。"}
{"text": "QOM分析了几种典型的本体映射方法的时间复杂度。"}
{"text": "iPROMPT的复杂度为O(n·log(n)),AnchorPROMPT的复杂度为O(n2·log2(n)),GLUE的复杂度为O(2n)。"}
{"text": "与这些方法相比，QOM忽略一些造成较高复杂度的方法，将映射发现的时间复杂度控制为O(n·og(n))。"}
{"text": "注意，各种方法的时间复杂度并不是在同样的映射结果下给出的：iPROMPT的时间复杂度虽然低，但映射结果的质量不尽如人意；GLUE的时间复杂度虽然高，但映射结果质量却最好。"}
{"text": "试验结果表明，QOM能在保证一定映射结果质量的前提下，尽量提高发现映射的效率。"}
{"text": "2）OLA。"}
{"text": "OLA也是一种本体映射发现综合方法[76,77]，具有如下特点：①覆盖本体所有可能的特征（如术语、结构和外延）;②考虑本体结构；③明确所有的循环关系，迭代寻找最佳映射。"}
{"text": "目前，OLA实现了针对OWL-Lite描述的本体间的映射，并支持使用映射API[78]。"}
{"text": "OLA算法首先将OWL本体编码为图，图中的边为概念之间的关系。"}
{"text": "图节点之间的相似度根据两方面来度量：①根据类和它的属性将节点进行分类；②考虑分类后节点中的所有特征，如父类和属性等。"}
{"text": "实体之间的相似度被赋予权重并线性累加。"}
{"text": "OLA能发现本体概念间的等价映射。"}
{"text": "3）KRAFT。"}
{"text": "KRAFT提出了一个发现1∶1的本体映射的体系结构[79,80]。"}
{"text": "这些映射包括：①概念映射，源本体和目标本体概念间的映射；②属性映射，源本体与目标本体属性值间的映射，以及源本体属性名和目标本体属性名的映射；③关系映射，源本体和目标本体关系名间的映射；④复合映射，复合源本体表达式与复合目标本体表达式之间的映射。"}
{"text": "KRAFT并没有给出映射发现的方法。"}
{"text": "4）OntoMap。"}
{"text": "OntoMap是一个知识表示的形式化、推理和Web接口。"}
{"text": "它针对上层本体和词典[81]，提供访问大多流行的上层本体和词典资源的接口，并表示它们之间的映射。"}
{"text": "为统一表示本体和它们之间的映射，OntoMap引入相对简单的元本体OntoMapO。"}
{"text": "这个表示语言比RDF(S)复杂，与OWL_Lite相似，但它包括描述本体映射的特定原语。"}
{"text": "OntoMapO考虑的上层本体包括Cyc、WordNet和SENSUS等。"}
{"text": "映射语言中包括的映射原语有：①MuchMoreSpecific，表示两个概念的特化程度；②MuchMoreGeneral，与相反；③TopInstance，最特化的概念；④ParentAsInstance_MuchMoreSpecific_ChildAsClass。"}
{"text": "这些原语表明了OntoMapO支持的映射类型。"}
{"text": "但遗憾的是，OntoMap不能自动创建映射，它假设一个映射已存在或者能被手工创建。"}
{"text": "因此，OntoMap更多只是提供了一个映射的表示框架。"}
{"text": "和5）OBSERVER。"}
{"text": "OBSERVER系统是为了解决分布式数据库的异构问题，它通过使用组件本体和它们之间明确的映射关系解决数据库间的异构[82]，同时它能维护这些映射。"}
{"text": "OBSERVER使用基于组件的方法发现本体映射。"}
{"text": "它使用多个预先定义的本体来表示异构数据库的模式。"}
{"text": "映射建立在这些本体之间，通过一个内部管理器提供不同组件本体之间的互操作，以及维护这些映射。"}
{"text": "OBSERVER能表示两个组件本体之间的1∶1映射，包括同义、上义、下义、重叠、不交和覆盖等。"}
{"text": "但是，该方法的本体映射依靠手工建立。"}
{"text": "6）InfoSleuth。"}
{"text": "InfoSleuth是一个基于主体的系统，能够支持通过小本体组成复杂本体，因而一个小本体可以在多个应用领域使用[83,84]。"}
{"text": "本体间的映射是概念间的关系。"}
{"text": "本体的映射由一个特殊的被称为“资源主体”的类完成。"}
{"text": "一个资源主体封装了本体映射的规则集，这些规则能被其他主体使用，辅助完成主体之间的信息检索。"}
{"text": "7）基于虚拟文档的本体匹配。"}
{"text": "瞿裕忠和胡伟等研究者给出了一种基于虚拟文档的通用本体匹配方法[85]，该方法可有效地利用本体中的语义信息、文本信息和结构信息进行本体匹配，从而得到了广泛的推广和应用。"}
{"text": "本体元素使用的词汇可能是独立的单词（如Review），也可能是多个单词的组合形式（如Meta_Reviewer），还可能是某些特殊的缩写（如Stu_ID）。"}
{"text": "元素还可以通过自身注释中的简单语句，对其含义进行补充说明。"}
{"text": "此外，各种语义描述（例如概念的上下位关系等）也可转化为文本形式。"}
{"text": "因此，可以将本体中元素相关的文本组织为虚拟文档，然后用虚拟文档表示相应的元素。"}
{"text": "一个元素的虚拟文档包含3种。"}
{"text": "①元素自身的描述文本Des（e）：包括localname、rdfs:lable、rdfs:comment，以及其他的注释文本，这些不同类型的文本可赋予[0,1]区间的权重。"}
{"text": "②空节点的描述文档Des（e）：对于空节点类型的元素，虽然它没有描述自身的文本，但仍然可以根据和它相关的三元组中的其他非空节点进行描述，在这个描述过程中，如果存在其他的空节点，则这种描述迭代进行多次，直至收敛。"}
{"text": "在此过程中，越远的元素会被赋予越小的描述权重。"}
{"text": "③元素邻居的描述文本：根据三元组得到元素的邻居，并分别得到元素作为主语、谓语、宾语时的邻居文本。"}
{"text": "注意，如果这些邻居存在空节点，则采用空节点的描述方式进行描述。"}
{"text": "在上述3种文档的基础上，给定一个元素e，它对应的虚拟文档为：构造虚拟文档后，便可通过计算语义描述文档相似度来寻找异构本体元素间的映射。"}
{"text": "两元素的语义描述文档相似度越高，它们相匹配的可能性越大。"}
{"text": "描述文档根据本体对元素描述的语义特点被划分为不同的类型，所以相似度计算是在相同类型的文档中进行的。"}
{"text": "虚拟文档的表示形式为带权重的词汇集合，即DS={p1W1,p2W2,…,pxWx}，该描述形式类似于文本向量空间模型，故可利用文本向量空间的余弦相似度衡量语义描述文本间的相似度。"}
{"text": "基于虚拟文档的方法思想直观，易于实现，可用于各种包含丰富的文本信息的本体匹配情形。"}
{"text": "（2）本体映射的综合方法总结。"}
{"text": "考虑将多种映射方法综合使用，吸收每种方法的优点，能得到更好的本体映射结果。"}
{"text": "但综合使用多种方法要注意这些方法之间是否能改善映射质量，还要在映射的效率上进行权衡，因为可能引入一些方法会大大降低原有算法的效率。"}
{"text": "此外，将各种映射方法的结果进行综合也很重要。"}
{"text": "5.3.4本体映射管理映射捕获了异构本体间的关系，但仅仅有映射还不足以解决多个异构本体间的知识共享。"}
{"text": "要在多本体环境中实现知识重用和协调多本体，还需要对多本体进行有效的管理。"}
{"text": "管理多个本体的好处在于：①方便处理多个本体的维护和演化问题；②合理组织本体间的映射，方便查询、数据转移和推理等应用；③将多个本体作为一个整体来使用，能为实际应用提供更强大的功能。"}
{"text": "这里讨论如何通过组织映射来达到管理异构的多本体的目的。"}
{"text": "实际上，在数据库等领域中就有针对模式或模型管理的研究。"}
{"text": "BernsteinPA等人讨论了如何利用通用的模型管理功能降低模型间互操作的编程量[86]，这种模型管理是为了支持模型的变化以及模型之间的映射。"}
{"text": "他们指出，模型间的映射和操作是模型管理的核心问题。"}
{"text": "在本体研究领域，一些工作分析了本体管理的挑战[87,88]。"}
{"text": "这些研究将本体管理的任务分为两方面。"}
{"text": "一个方面是设计本体库系统以增强本体管理，包括存储、搜索、编辑、一致性检查、检测、映射，以及不同形式间的转换等。"}
{"text": "另一方面则包括本体版本或演化，研究如何提供相应的方法学和技术，在不同的本体版本中识别、表示或定义变化操作。"}
{"text": "Stoffel_K等人设计了一个处理大规模本体的系统，使用高效内存管理、关系数据库二级存储，以及并行处理等方法，其目的是为在短时间内给出对大规模本体的复杂查询回答[89]。"}
{"text": "Lee_J等人描述了一个企业级的本体管理系统，它提供API和查询语言来完成企业用户对本体的操作[90]，他们还提供了如何用关系数据库系统有效地直接表示和存储本体的体系结构。"}
{"text": "Stojanovic_L等人提出一个本体管理系统OntoManager[91]，它提供一种方法学，指导本体工程师更新本体，使本体与用户需求保持一致；该方法跟踪用户日志，分析最终用户和基于本体的系统间的交互。"}
{"text": "显然，这些工作都关注本体的表示、存储和维护。"}
{"text": "而且这些方法只处理单个本体，没有考虑多个本体之间的映射或演化问题。"}
{"text": "但这些工作为管理多个本体打下了基础。"}
{"text": "Noy_N_F和Musen_M提出一个处理版本管理框架，使用PROMPTDiff算法识别出一个本体不同版本在结构上的不同[25]。"}
{"text": "PROMPTDiff只使用结构不同检测两个版本的不同。"}
{"text": "而在Klein_M的方法中则有更多的选择，如日志的变化、概念化关系和传递集合等，这些都能提供更丰富的本体变化描述[92]。"}
{"text": "Maedche_A等人提出一个管理语义Web上多本体和分布式本体的继承框架[93]，它将本体演化问题分为三种情况：单个本体演化、多个相互依赖的本体演化和分布式本体演化。"}
{"text": "Klein_M分析本体演化管理的需求和问题，提出了本体演化的框架[94]，基于一些变化操作，定义了一个变化说明语言。"}
{"text": "从这些本体管理工作可以看出，目前多数本体管理工作关注本体演化或本体版本变化问题。"}
{"text": "这些工作在管理多本体的同时都忽略如何发挥多本体的潜在能量这一本质问题，即利用多本体实现更强大、灵活的、单本体无法提供的服务。"}
{"text": "与目前大多工作侧重点不同，Xu_Baowen等人从功能角度来探讨多本体管理[95]。"}
{"text": "该思想认为，管理多本体的目标不仅是为了解决本体异构和最大限度地重用本体，而且要提供基于多本体的各种服务：多本体上的查询和检索，即通过有效管理本体间的简单和复杂映射，为本体间通信服务；本体间映射的管理是多本体中查询转换的保证；跨多本体的推理，即利用多本体间的映射支持跨多个本体的推理服务；抽取子本体，即从多本体抽取语义完全且功能独立的子本体，实现知识的重用；共享本体互操作，即描述多本体间概念和实例的转换规则；协调应用多个本体，进行多本体语义标注等应用。"}
{"text": "传统的本体管理通常是二层结构：本体存储层和应用层。"}
{"text": "二层架构的多本体管理过于粗糙，提供的多本体功能嵌入具体的应用中，针对不同的应用都需要重新考虑本体间的映射，这导致大量工作的重复。"}
{"text": "Xu_Baowen等人从管理多本体的映射来处理这些问题，首先利用桥本体将本体间的映射抽取出来，映射抽取出来后并不影响每个本体的独立性，通过管理和组织本体间的映射来协调本体。"}
{"text": "这样的管理方式具有灵活的特点，适应动态Web环境。"}
{"text": "然后将多本体可提供的功能与应用分离，提供面向应用的通用功能，避免使用多本体时的大量重复工作。"}
{"text": "Xu_Baowen等人设计了一个五层体系结构的多本体管理框架。"}
{"text": "框架包括本体库层、本体表示层、描述本体间映射的桥本体层、多本体功能层和应用层。"}
{"text": "五层的多本体管理体系结构面向发挥多本体功能，它通过组织本体间的映射，将多个本体有机协调，为应用提供灵活和强大的功能。"}
{"text": "各层的具体功能如下：①本体库层。"}
{"text": "本体库层存放不同渠道获得的本体。"}
{"text": "本体由于创建者与创建时间不同，模型和本体语言上具有差异，例如DAML、RDF(S)或OWL等格式。"}
{"text": "②本体表示层。"}
{"text": "不同本体语言的语法、逻辑模型和表达能力都必然存在差异，因此需要将这些本体转换到统一的表示形式上来。"}
{"text": "这种转换会造成一些信息的损失。"}
{"text": "通常少许的非关键本体信息在转换中丢失是可容忍的。"}
{"text": "③桥本体层。"}
{"text": "多本体间常常重叠，其间往往有关联。"}
{"text": "为有效使用多本体而避免本体集成，采用生成的桥本体来描述多本体间的沟通。"}
{"text": "桥本体是一特殊的本体，可表示本体间概念和关系的12种不同映射。"}
{"text": "在这层中，利用文献[62,36]的方法生成本体间的映射。"}
{"text": "桥的生成是半自动化的，并在桥本体中组织管理。"}
{"text": "本体间映射生成过程无法避免语义冗余和冲突，有必要在使用前进行有效的化简。"}
{"text": "Xu_Baowen等人分析了引入桥后的多本体环境的语义一致性检查问题和冗余化简算法[96]。"}
{"text": "对于语义一致性问题，将引入桥后的多本体中的回路分为两种类型：良性回路和恶性回路。"}
{"text": "前者是由于引入等价桥后造成的，通过算法可消除。"}
{"text": "后者是由于原始本体中的错误或引入不当的桥造成的。"}
{"text": "算法能够找到环路，但区分恶性和良性环路需要人工参与。"}
{"text": "经过语义检查的多本体环境可当作有向无环图来处理，语义化简的目的就是要保证该图中的映射是无冗余的，同时化简操作不能改变整个多本体环境的连通性。"}
{"text": "本体间映射抽取出来，可通过桥本体进行管理。"}
{"text": "当多本体环境中添加、删除或修改本体时，为减少重新生成映射的代价，需要设计高效的增量更新算法保证映射同步更新。"}
{"text": "④多本体功能层。"}
{"text": "多本体的管理能提供满足应用需求的一些主要功能。"}
{"text": "第一，桥本体中的桥提供了大量的简单和复杂的本体映射。"}
{"text": "通过这些映射，很容易实现异构本体间的互操作问题。"}
{"text": "第二，利用多本体间的桥，能实现跨不同本体的推理。"}
{"text": "第三，能利用桥本体处理查询表达式的转换和重写，实现跨多本体的信息检索。"}
{"text": "第四，还可以从多本体中抽取满足需求的子本体。"}
{"text": "第五，还能利用多本体进行语义标注，提供比单本体更丰富的语义数据。"}
{"text": "⑤多本体应用层。"}
{"text": "在应用层上，利用多本体的功能可以开发各种不同的应用，这些应用具有通用性。"}
{"text": "5.3.5本体映射应用基于本体映射，能实现很多基于多本体的应用，例如子本体抽取与信息检索等，这里以子本体抽取为例给出本体映射在其中的应用；本体映射在信息检索中的应用将在随后的章节中详细讨论。"}
{"text": "本体建模时总希望模型建立得尽量准确和完全，这往往导致大本体，如统一医学语言系统本体包括了多达80万个概念和900万个关系。"}
{"text": "大本体难以驾驭，而且在实际应用中往往只需其中与应用需求相关的一小部分。"}
{"text": "使用整个本体会大大增加系统的复杂性和降低效率。"}
{"text": "因此，从源本体中抽取一个小的子本体能让系统更有效。"}
{"text": "子本体抽取是一个新的研究领域。"}
{"text": "Wouters_C等人提出物化本体视图抽取的顺序抽取过程[97]，通过优化模式来保证抽取质量。"}
{"text": "该方法计算代价较高。"}
{"text": "随后的研究者提出了一种分布式方法来降低从大的复杂本体中抽取子本体的代价[98]。"}
{"text": "Bhatt_M等人进一步分析了这种方法的语义完整性问题[99]。"}
{"text": "Noy_N_F等提出的PROMPTFactor本体抽取工具也支持从单个本体中获得语义独立的子本体[25]，其主要思想是通过用户选择所需要的相关术语，并与PROMPT系统进行交互抽取子本体。"}
{"text": "当前的方法都是从单个本体中抽取子本体。"}
{"text": "但多本体环境下的应用很多，多个本体的不同部分都可能是子本体需要的。"}
{"text": "从多本体中抽取子本体对于知识重用具有重要意义，目前相关的工作和工具并不多见。"}
{"text": "Kang_Dazhou等人探讨了从多本体中抽取子本体的方法[100]。"}
{"text": "抽取子本体是一种重要的知识重用手段。"}
{"text": "本体映射表示了多本体间的联系，对解决从多本体中抽取子本体具有重要的作用。"}
{"text": "在语义搜索和智能问答中，本体映射和匹配结果用于辅助查询重写，能有效地提高对用户问题的语义理解能力。"}
{"text": "5.4实例层的融合与匹配在实际应用中，由于知识图谱中的实例规模通常较大，因此针对实例层的匹配成为近年来知识融合面临的主要任务。"}
{"text": "实例匹配的过程虽然与本体匹配有相似之处，但实例匹配通常是一个大规模数据处理问题，需要在匹配过程中解决其中的时间复杂度和空间复杂度问题，其难度和挑战更大。"}
{"text": "5.4.1知识图谱中的实例匹配问题分析在过去的几十年中，本体在知识表示中起着举足轻重的作用。"}
{"text": "人们通过艰苦的努力，建立了很多描述通用知识的大规模本体，并将其应用于机器翻译、信息检索和知识推理等应用。"}
{"text": "与此同时，很多领域中的研究人员为了整合、归纳和分享领域内的专业知识，也建立了很多领域本体。"}
{"text": "这些本体的规模正随着人类知识的增长而变得越来越大。"}
{"text": "近年来，不同领域知识的交叉和基于不同大本体的系统间的交互都提出了建立大规模本体间映射的需求。"}
{"text": "然而，多数映射系统不仅无法在用户可接受的时间内给出满意的映射结果，而且还往往会由于匹配过程申请过大的内存空间而导致系统崩溃。"}
{"text": "因此，大规模本体映射问题对映射系统的时间复杂度、空间复杂度和映射结果质量都提出了严峻的考验，成为目前本体映射研究中的一个挑战性难题。"}
{"text": "本章将在分析现有几种大规模本体映射方法的基础上，提出一种新的大规模本体映射方法，该方法具有较好的时间复杂度和空间复杂度，并能保证映射结果的质量。"}
{"text": "从20世纪80年代起，人们就一直努力创建和维护很多大规模的本体，这些本体中的概念和关系规模从几千个到几十万个不等，有些本体的实例数目甚至达到亿级。"}
{"text": "这些大本体总体上可划分为三类：通用本体，即用于描述人类通用知识、语言知识和常识知识的本体，如Cyc、WordNet和SUMO等；领域本体，各个领域中的研究人员也建立了很多专业领域中的本体，如生物医学领域中的基因本体和统一医学语言系统本体UMLS；企业应用本体，为了有效管理、维护和利用拥有的大量数据，很多企业都利用本体对自身的海量数据进行重组，以便为用户提供更高效和智能的服务。"}
{"text": "出于商业保密的目的，这些企业本体通常并不公开。"}
{"text": "大规模本体在机器翻译、信息检索和集成、决策支持、知识发现等领域中都有着重要的应用。"}
{"text": "表5-4是对12个大规模知识图谱的调查结果，其中列举了各知识图谱中概念、关系、实例和公理的数目，表中横线表示没有获得对应数据；另外，由于一些本体创建时间较早，它们并没有按近年提出的本体模型来组织知识，因此只提供了所包含的术语数目。"}
{"text": "从调查结果可见，大规模知识图谱中的元素数庞大，尤其是实例数据较多。"}
{"text": "表5-4大规模知识图谱的规模调查大规模知识图谱的创建和维护仍然具有分布性和自治性的特点，知识图谱间同样存在无法避免的异构问题。"}
{"text": "基于不同大规模知识图谱的系统间可能需要进行交互。"}
{"text": "一些应用需要借助映射对多个知识图谱进行集成，如Web搜索中需要集成Yahoo_Directory和GoogleDirectory。"}
{"text": "随着不同科学研究领域的交叉和融合，不同领域知识图谱中的知识有可能产生交叉重叠，如关于解剖学的本体需要用到UMLS本体中的语义信息。"}
{"text": "总之，大规模知识图谱间的异构现象依然普遍存在。"}
{"text": "在实际应用中，为集成同一领域中不同的大规模知识图谱，或者为满足基于不同大规模知识图谱的系统间的信息交互需求，都有必要建立大规模知识图谱间的匹配。"}
{"text": "大规模知识图谱匹配是极具挑战性的任务。"}
{"text": "Reed和Lenat为将SENSUS、WordNet和UMLS等本体映射到Cyc中，通过训练本体专家和借助交互式对话工具等半自动手段，前后耗费了15年的时间才完成这项大规模本体映射项目[101]。"}
{"text": "显然，人工和半自动的方法很难处理大规模知识图谱匹配问题，因此需要寻找有效的自动化方法。"}
{"text": "传统的模式匹配工作虽然提出处理大规模模式匹配的分治法[102,103]，但数据库模式和XML模式都是树状结构，位于不同树枝的信息相对独立，适于采用分治思想处理。"}
{"text": "然而，知识图谱具有复杂的图结构，传统模式匹配的分治方法并不能直接应用于知识图谱匹配。"}
{"text": "可处理大规模知识图谱匹配的系统方法并不多。"}
{"text": "例如，在2006年的OAEI评估中，10个系统中只有4个完成了anatomy和food两个大规模本体匹配任务。"}
{"text": "在2007年的OAEI中，参与评估的18个映射系统，只有2个完成了anatomy、food、environment和library这4个大规模知识图谱匹配任务。"}
{"text": "2008年参与OAEI评估的13个映射系统，只有2个完成了anatomy、fao、mldirectory和library这4个大规模知识图谱匹配任务，而完成通用知识图谱匹配任务vlcr的系统只有1个。"}
{"text": "由此可见，大多数公开的系统仍然不能处理大规模知识图谱匹配问题。"}
{"text": "大规模知识图谱匹配问题对空间复杂度、时间复杂度和匹配结果质量都提出了严峻考验，下面给出具体分析。"}
{"text": "1.空间复杂度挑战在知识图谱匹配过程中，读入大规模知识图谱将占用相当一部分存储空间，随后的预处理、匹配计算和映射后处理均可能需要申请大量空间才能完成，这些步骤往往导致匹配系统无法得到足够的内存空间而崩溃。"}
{"text": "通常，知识图谱匹配中的主要数据结构（如相似矩阵）的空间复杂度是O(n2)，在处理大规模知识图谱匹配时，这样的空间复杂度会占用大量的存储资源。"}
{"text": "当系统申请的存储空间不能一次读入内存时，将造成操作系统不断在内存储器和虚拟存储器之间中进行数据交换；当操作系统无法满足映射系统的空间申请要求时，将导致内存不足的严重错误。"}
{"text": "很多匹配系统都采用二维数组来记录元素间的相似度矩阵，即使对于一个实例规模为5000的小型知识图谱，相似矩阵中的数值为双精度类型，则存储该矩阵所需的空间大约为200MB。"}
{"text": "因此，大规模知识图谱匹配中需要设计合理的数据结构，并利用有效的存储压缩策略，才能减小空间复杂度带来的负面影响。"}
{"text": "目前来说，只要选择合理的数据结构，并利用一些数据压缩存储技术，现有计算机存储能力基本能满足多数大规模知识图谱匹配的需求。"}
{"text": "因此，虽然空间复杂度是大规模知识图谱匹配中的一个难题，但并不是不可能克服的问题。"}
{"text": "2.时间复杂度挑战负责知识图谱读取和解析等操作的预处理过程和映射结果后处理过程一般不会成为匹配系统的时间瓶颈，知识图谱匹配系统的执行时间主要取决于匹配计算过程。"}
{"text": "为了得到最佳的映射结果，匹配过程需要计算异构实例间的相似度，早期大多数的知识图谱匹配系统的时间复杂度都是O(n2)（n为元素数目）。"}
{"text": "虽然也有研究者提出O(nlog(n))复杂度的匹配方法，但这种方法是以损失匹配质量为代价来换取匹配效率的。"}
{"text": "此外，不同匹配系统采用的匹配器在效率上差别很大，即求两个元素间的相似度这一过程所需要的时间复杂度存在差异，例如有的系统仅仅简单地计算元素标签的字符串相似度，有的则需要对知识图谱中的图做复杂的分析，二者之间的时间复杂度差别非常大；例如，我们通过实验比较发现，在本体映射系统Lily中，利用简单的编辑距离方法计算元素相似度的速度比利用语义描述文档的方法大约快1000倍。"}
{"text": "令计算两元素相似度过程的时间复杂度为t，则匹配系统的总时间复杂度可表示为O(n2t)。"}
{"text": "因此，降低大规模知识图谱匹配问题的时间复杂度除了要考虑减少匹配元素对的相似度计算次数（即n2），还需要降低每次相似度计算的时间复杂度（即t）。"}
{"text": "3.匹配结果质量挑战在降低匹配方法的时间复杂度和空间复杂度的同时，有可能造成匹配结果质量降低。"}
{"text": "很多优秀的匹配方法往往比较复杂，如果在处理大规模知识图谱匹配时用简化的快速算法来代替，或者为了提高效率设置一些不能发挥算法优势的参数，都可能得不到满意的映射结果。"}
{"text": "此外，很多有效的匹配算法需要对知识图谱进行全局分析和整理，例如采用相似度传播的结构匹配方法等。"}
{"text": "然而，这种处理对大规模知识图谱来说并不可行，尽管可以采用简化或近似处理来替代，但由此得到的映射结果可能有损失。"}
{"text": "最后，一些算法采用分治的策略，将大规模知识图谱匹配问题转换为多个小规模匹配问题，但分治的过程会将原本相邻元素分割开，破坏某些实例语义信息的完整性，因此这部分位于边界位置的实例的匹配质量无法得到保证。"}
{"text": "由于大量实际应用的需要，大规模知识图谱匹配问题备受关注。"}
{"text": "尽管目前能处理该问题的映射系统还较少，但一些研究者已进行了积极尝试，其中包括集成通用本体用于机器翻译[104]，建立Web_Directory之间的映射用于信息检索[105]，以及匹配生物医学领域的本体用于不同医学系统间信息交互[106-108]等。"}
{"text": "最近几年的OAEI评估也给出一些实际的大规模知识图谱匹配任务，虽然完成这类匹配任务的系统较少，但处理该问题的方法每年都得到改进。"}
{"text": "本文将现有的大规模知识图谱匹配方法划分为三类：基于快速相似度计算的方法、基于规则的方法和基于分治的方法。"}
{"text": "就目前来看，现有的大规模知识图谱匹配系统都能克服空间复杂度问题，因为匹配过程中需要的大量空间可以借助数据压缩技术（如将稀疏矩阵压缩存储）、外部数据库或临时文件等方式解决。"}
{"text": "因此，下面着重分析三类方法的时间复杂度。"}
{"text": "5.4.2基于快速相似度计算的实例匹配方法这类方法的思想是尽量降低每次相似度计算的时间复杂度，即降低O(n2t)中的因素t，因此映射过程只能使用简单且速度较快的匹配器，考虑的映射线索也必须尽量简单，从而保证t接近常数O(1)。"}
{"text": "基于快速相似度计算的方法使用的匹配器主要包括文本匹配器、结构匹配器和基于实例的匹配器等。"}
{"text": "很多基于文本相似的匹配算法时间复杂度都较低，但为达到快速计算元素相似度的目的，文本匹配器还应避免构造复杂的映射线索，例如映射线索只考虑元素标签和注释信息。"}
{"text": "大规模知识图谱匹配中的结构匹配器借助概念层次或元素邻居文本相似的启发式规则计算相似度，例如两个实例的父概念相似，则这两个实例也相似等；为避免匹配时间复杂度过高，这些启发式规则不能考虑太复杂的结构信息。"}
{"text": "采用上述思想的系统虽然能勉强处理一些大规模知识图谱匹配问题，但其弊端也很明显。"}
{"text": "首先，匹配器只能利用知识图谱中少量的信息构造匹配线索，得到的匹配线索不能充分反映元素语义，这会导致降低映射结果质量。"}
{"text": "其次，系统效率受相似度计算方法影响较大，即t的少量变化会给系统的效率带来较大影响。"}
{"text": "Mork和Bernstein尝试对FMA和GALEN两个大规模本体进行匹配[107]，匹配过程采用了一些通用的文本匹配器和结构匹配器，他们指出这种匹配处理的时间复杂度和空间复杂度都很高。"}
{"text": "Ichise等人实现了Web_Directory的匹配[109]，匹配方法依靠统计共享实例。"}
{"text": "此外，在相似度计算中，寻找最佳的相似函数和阈值也是一个重要问题，可采用最大可能消除匹配冗余计算的思想进行优化[110]。"}
{"text": "在OAEI2007的大规模本体匹配任务中，一些采用快速相似度计算思想的映射系统在计算时间上并没有优势，但其得到的映射结果质量却并不理想，例如，在Anatomy匹配任务中，采用简单文本匹配的Prior+、Lily1.2和DSSim等系统在运行时间和结果质量上都并不突出。"}
{"text": "5.4.3基于规则的实例匹配方法在大规模知识图谱中，为了从海量的实例数据中有效发现匹配实例对，寻找匹配规则是一条可行的思路。"}
{"text": "但由于数据源的异构性，处理不同的数据源需要的匹配规则不尽相同，规则匹配方法往往需要人类手工构建的规则来保证结果质量。"}
{"text": "为避免过多的人工参与。"}
{"text": "基于规则的方法易于扩展到处理大规模知识图谱中的实例匹配，甚至可以扩展到基于概率的方法[111]。"}
{"text": "上海交通大学的研究人员开发了一套基于EM算法的半监督学习框架以自动寻找实例匹配规则[112]，其实例匹配过程如图5-12所示。"}
{"text": "该框架以迭代的方式来自动发现匹配规则，并逐步提高匹配规则集的质量，再利用更新后的规则集来寻找高质量的匹配对。"}
{"text": "具体地，数据集中少量具有owl:sameAs属性的现存匹配对被视为种子（Seeds），匹配规则被视为似然函数中需要被估计的参数。"}
{"text": "该方法利用一种基于图的指标来度量匹配的精确度，并作为EM算法的目标似然函数。"}
{"text": "在不同的匹配规则下，同一个匹配对的匹配置信度是不一样的，如何集成不同规则的置信度是一个很重要的问题。"}
{"text": "该方法引入Dempster's_rule[1]来集成同一个匹配对的不同置信度。"}
{"text": "图5-12基于规则挖掘的实例匹配过程[112]在进一步介绍该方法之前，需要定义一些基础概念。"}
{"text": "定义5.12（实例等价）记作～I，代表了两个实例在现实世界中为同一个物体。"}
{"text": "URI不同的两个实例e1,e2是等价的，当且仅当＜e1,e2＞∈～I。"}
{"text": "定义5.13（匹配）由匹配器发现的一个匹配表示为＜e1,e2,conf＞，其中e1,e2为实例，conf为匹配的置信度，它们满足P（＜e1,e2＞∈～I）=conf。"}
{"text": "如图5-12所示，预处理完成后，实例就包含了相应的属性-值对（Property-ValuePairs）信息。"}
{"text": "然后，种子匹配对被导入系统中，用来驱动发现新的匹配，高质量的新匹配对会加入种子匹配对中以进行下一轮迭代。"}
{"text": "重复迭代步骤直至满足终止条件。"}
{"text": "前面提到，该框架通过学习规则来推导实例之间的等价关系。"}
{"text": "首先，已知匹配对中的属性等价关系（Property_Equivalence）会被挖掘；然后，这些规则被利用到未匹配实例上发现新的等价实例。"}
{"text": "一些属性等价的例子如下所示：rdfs:label≈gs:hasCommonNamefoaf:name≈gs:hsCanonicalNamedbpedia:phylum≈gs:inPhylum在dbpedia.org中定义的属性dbpedia:phylum和geospecies.org中定义的属性gs:inPhylum有相同的内在含义：它们对应的值在生物分类中都属于同一个等级。"}
{"text": "实例等价和属性等价可推导出如下规则：如果两个实例e1,e2满足则有＜e1,e2＞∈～I。"}
{"text": "（p（e,o）是三元组＜e,p,o＞的函数式表示，o1≃o2表示o1和o2指向同一实例或者字面值相等）。"}
{"text": "这样的规则可以推导出大量的等价实例，从而完成实例匹配。"}
{"text": "定义5.14（属性-值对等价）给定两个隐含等价属性（p1,p2）和两个值（o1,o2），属性-值对＜p1,o1＞和＜p2,o2＞等价当且仅当＜o1,o2＞∈～I（o1,o2为实例），或者o1=o2（o1,o2为字面值），记作～P。"}
{"text": "将这种等价关系拓展到属性-值对集，给定一个实例e和属性集合P，属性-值对集定义为PVe,P={＜p,o＞|p∈P,＜e,p,o＞∈G}。"}
{"text": "定义5.15（等价属性-值对集）给定两个实例（e1,e2）和一个等价属性对集（＜P1,P2＞），两个键值对集等价当且仅当存在一个从到的双射f∈～P，记作～S。"}
{"text": "定义5.16（逆功能属性集）一个等价属性对集eps是一个逆功能属性集（InverseFunctional_Property_Suite），当且仅当其满足若，则＜e1,e2＞∈～I。"}
{"text": "定义5.17（逆功能属性集规则）逆功能属性集规则（IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞，一个IFPS规则有如下形式：定义5.18（扩展的逆功能属性集规则）与IFPS规则相似，扩展的逆功能属性集规则（Extended_IFPS_Rule）基于逆功能属性集eps。"}
{"text": "对于所有eps里的属性对＜pi1,pi2＞,EIFPS规则有如下形式：根据以上定义，该方法实现了一个基于EM算法的实例匹配框架，输入为待匹配三元组、初始匹配对阈值，输出为匹配结果集与IFPS规则集。"}
{"text": "该框架利用EM算法迭代：E步，根据已经获得的EIFPS规则计算实例对应的置信度，把置信度高于阈值的对应放到匹配结果中；M步，根据现有的匹配结果挖掘EIFPS规则，等同于最大化似然函数。"}
{"text": "这里引入匹配图来估计算法的匹配进度，匹配图是一个无向带权图，图中的每一个顶点代表一个实例，边代表两个实例匹配的置信度。"}
{"text": "根据EIPFS规则集合，可以从所有的三元组中提取出一个匹配图。"}
{"text": "EM算法中的似然函数定义为提取出的匹配图和实际匹配图的相似程度：给定一个匹配图M,EM算法中的似然函数被定义为：L（θ;M）=Pr（M|θ）。"}
{"text": "采用准确度优先策略，可以得到以下的近似公式，用精确度来代表在一个EIPFS规则集合下，提取出来的对应图和真正的对应图之间的关系：最后，求出的匹配图M的精确度等于M中被连接的成分除以M中边的数量：L（θ;M）≈Precision（M|θ）同一个匹配对可能会由不同的EIFPS规则导出，该匹配对有多个匹配置信度，因此集成两个置信度是一个很有必要的工作。"}
{"text": "传统上会选择取两者之间的较大值，但这种集成方式只利用了一次匹配的信息，我们倾向于认为利用了两次匹配的信息得出的结果更为准确。"}
{"text": "这里给出了另外的两种集成方式，具体如下：第1种是基于概率理论：conf1⊕conf2=1−（1−conf1）（1−conf2）第2种利用了一种特殊性形式下的贝叶斯理论的泛化理论（Dempster-Shafertheory）：该方法先后用在DBpedia、GeoNames、LinkedMDB、GeoSpecies等知识图谱间进行实例匹配。"}
{"text": "该方法解决了zhishi.me等知识图谱构建中的实例匹配问题[113]。"}
{"text": "5.4.4基于分治的实例匹配方法分治处理方法的思想是降低相似度计算总的时间复杂度，即降低O(n2t)中的因素n2。"}
{"text": "采用分治策略，将大规模知识图谱匹配划分为k个小规模的知识图谱匹配后，匹配的时间复杂度降为O(kn'2t')，其中t’表示计算两元素间相似度的时间复杂度，与分治前可能不同，n’为分治处理后的小本体的平均规模，即，所以分治处理的时间复杂度又可表示为。"}
{"text": "由此可见，系统效率取决于能将原有问题划分为多少个小规模。"}
{"text": "最常用的分治策略是将大规模本体划分为若干个小知识图谱，然后计算这些小知识图谱间的匹配。"}
{"text": "分治法的思想已被用于处理大规模数据库模式和XML模式匹配问题[102,114]。"}
{"text": "Rahm和Do提出一种基于模式片段（fragment）的大规模模式匹配分治解决方法，该方法包括4个步骤：①分解大模式为多个片段，每个片段为模式树中的一个带根节点的子树，若片段过大，则进一步进行分解，直到规模满足要求为止；②识别相似片段；③对相似片段进行匹配计算；④合并片段匹配结果即得到模式匹配结果。"}
{"text": "这种方法能有效处理大规模的模式匹配问题，然而由于知识图谱是图结构，模式的片段分解方法并不适用于划分大规模知识图谱。"}
{"text": "本体模块化方法是对大规模本体进行划分的一种直观手段。"}
{"text": "已有多种本体模块化方法被提出。"}
{"text": "Grau等人通过引入语义封装的概念，利用ε-connection[115]将大本体自动划分为多个模块，该模块化算法可保证每个模块都能够捕获其中全部元素含义的最小公理集。"}
{"text": "然而，这种方法在实际应用中效果并不好。"}
{"text": "例如，该算法只能将GALEN划分为2个模块，只能将NCI本体划分为17个模块，而且所得模块的规模很不均匀，即某些模块对本体映射来说还是太大了，因此该方法并不能解决将大本体划分为适当大小的问题。"}
{"text": "Grau等人还提出了其他确保局部正确性和完整性模块化算法[116]，但结果显示该算法也不能解决模块规模过大的问题。"}
{"text": "例如，该算法对NCI本体划分会得到概念数目为15254的大模块，而对GALEN本体模块化则失败。"}
{"text": "此外，一些本体模块化工作的目标是获得描述特定元素集含义的模块[117,118]，而不能将本体划分为多个不相交或只有少量重叠的模块。"}
{"text": "Stuckenschmidt和Klein通过利用概念层次结构和属性约束，给出一种本体模块化方法[119]，但结果显示该方法得到的模块规模通常太小，并且只能处理概念结构层次构成的本体。"}
{"text": "总的来说，上述模块化工作并非以服务大规模本体映射为目的，它们都强调模块语义的完备性和正确性，而忽略给模块分配适当的规模。"}
{"text": "特别是知识图谱中存在大量的实例，上述模块化方法难以对大量的实例进行有效的划分。"}
{"text": "目前采用分治思想处理大规模本体映射的典型系统有Malasco、Falcon-AO、Lily等。"}
{"text": "Malasco[2]是Paulheim提出的一种基于分治思想的大规模OWL本体映射系统[120]，该系统实际上是一个大规模本体映射框架，可重用现有的匹配器和本体模块化方法。"}
{"text": "Malasco提供了三种本体划分算法：①基于RDF声明[121]的朴素划分算法；②Stuckenschmidt和Klein的模块化算法[119];③基于Grau的ε-connection模块化算法[116]。"}
{"text": "Paulheim在大规模本体上对模块化处理前后的匹配结果进行了比较和优化处理：在不做优化处理时，映射结果的精度与不做模块化处理前相比有50%的损失；采用覆盖模块化方法进行优化后，精度损失降低到20%，覆盖模块化是为了弥补模块交界部分的信息损失；为匹配结果选取合适的相似度阈值后，精度损失降低到5%。"}
{"text": "Paulheim的工作表明了模块化方法经过适当优化，是可以处理大规模本体映射问题的。"}
{"text": "Falcon-AO中采用一种基于结构的本体划分方法解决大规模本体映射问题[122]。"}
{"text": "该方法首先通过分析概念层次、属性层次以及属性约束信息，然后利用聚类方法将本体中的元素划分为不相交的若干个集合，再利用RDF声明恢复每个集合中的语义信息，从而完成本体划分。"}
{"text": "接着，基于预先计算的参照点，对不同的本体块进行匹配，匹配计算只在具有较高相似度的块间进行。"}
{"text": "该方法的划分算法可将本体元素划分为合适大小的集合，从而能利用现有的匹配器发现映射。"}
{"text": "Falcon-AO的结果也表明该算法并未使映射结果质量有明显损失。"}
{"text": "基于本体划分的分治处理方法较为直观，但该方法存在的主要缺点在于划分后的模块边界存在信息损失，即处于模块边界的元素的语义信息有可能不完整，由此得到的映射结果必然会有损失。"}
{"text": "一般来说，划分得到的块越多，边界语义信息损失也越多，因此，模块大小和边界信息损失是不可调和的，在实际应用中需要合理权衡。"}
{"text": "Malasco中的覆盖模块优化方法是一种对该缺点的补救处理。"}
{"text": "Lily则巧妙地利用了大规模知识图谱匹配中的匹配局部性特点，不直接对知识图谱进行分块，而通过一些确定的匹配点（称为锚点）自动发现更多的潜在匹配点，从而达到实现高效实例匹配的目的且无须进行知识图谱划分。"}
{"text": "该方法的优点是实现过程简单，同时避免了划分知识图谱造成的语义信息损失。"}
{"text": "1.基于属性规则的分块方法由于在知识图谱中实例一般都有属性信息，所以根据属性来对实例进行划分，减少实例匹配中的匹配次数以提高匹配的效率，成为一种很自然的思想。"}
{"text": "类似的方法在关系数据库领域和自然语言处理领域中的实体消解中早已得到了广泛的应用。"}
{"text": "第6章知识图谱推理漆桂林东南大学，肖国辉博尔扎诺自由大学，陈华钧浙江大学知识图谱推理在一个知识图谱的发展演变过程中起着重要的作用，知识图谱推理能用来对知识图谱进行补全和质量检测等。"}
{"text": "本章将围绕知识图谱推理展开介绍，6.1节从广义的推理角度介绍什么是推理以及推理的不同类型，并附以不同推理的实例以及不同推理之间的比较，再介绍知识图谱推理的定义及包含的任务。"}
{"text": "6.2节和6.3节主要介绍知识图谱中两种最重要的推理，即基于演绎的知识图谱推理和基于归纳的知识图谱推理，并分别介绍常用的方法和思路，同时对典型的实验工具以及实验结果进行分析和展示。"}
{"text": "6.4节将介绍知识图谱推理的最新进展，分别从时序预测、强化学习、元学习以及图神经网络的角度出发，并以最新发表的论文为例进行分析。"}
{"text": "6.5节将介绍知识图谱开源工具并提供实践建议。"}
{"text": "6.6节将对本章进行总结。"}
{"text": "希望阅读本章后，读者对知识图谱推理的定义、任务、方法以及常用工具有更准确的认识，并了解到知识图谱推理的最新进展和发展方向。"}
{"text": "6.1推理概述6.1.1什么是推理推理在人类长期的社会发展和演变中扮演着重要的角色，包含了思考、认知和理解，是认知世界的重要途径。"}
{"text": "具体来说，推理是通过已有知识推断出未知知识的过程。"}
{"text": "推理的方法大致可以分为逻辑推理和非逻辑推理，其中逻辑推理的过程包含了严格的约束和推理过程，而非逻辑推理的过程相对模糊。"}
{"text": "逻辑推理由于其透明性，被广泛研究且定义比较清晰，所以本章讨论的推理主要也围绕逻辑推理展开。"}
{"text": "逻辑推理按照推理方式的不同包含两大类：演绎推理（Deductive_Reasoning）和归纳推理（Inductive_Reasoning）。"}
{"text": "其中，归纳推理又包含了溯因推理（Abductive_Reasoning）和类比推理（Analogy_Reasoning）等。"}
{"text": "下面先介绍这四种基本的推理。"}
{"text": "演绎推理[1]是一种自上而下（top-down_logic）的逻辑推理，是指在给定的一个或多个前提的情况下，推断出一个必然成立的结论的过程。"}
{"text": "典型的演绎推理有肯定前件假言推理、否定后件假言推理（Modus_Tollens）以及三段论（Law_of_Syllogism）。"}
{"text": "在假言推理中，给定的前提中一个是包含前件和后件的假言命题，一个是性质命题，假言推理根据假言命题前后件之间的逻辑关系进行推理。"}
{"text": "其中，肯定前件假言推理是指性质命题肯定了假言命题的前件，从而推理出肯定的假言后件。"}
{"text": "例如，通过假言命题“如果今天是星期二（前件）。"}
{"text": "那么小明会去上班（后件）”以及性质命题“今天是星期二”，能推理出“小明会去上班”。"}
{"text": "而否定后件假言推理是指性质命题否定了假言命题的后件，从而推理出否定的假言前件。"}
{"text": "例如，通过前文的假言命题和性质命题“小明不会去上班”，能推出“今天不是星期二”。"}
{"text": "在假言三段论中，给定两个假言命题，且第二个假言命题的前件和第一个假言命题的后件的申明内容相同，可以推理出一个新的假言命题，其前件与第一个假言命题的前件相同，其后件与第二个假言命题的后件相同。"}
{"text": "例如，给定两个假言命题“如果小明生病了，那么小明会缺席”以及“如果小明缺席了，他将错过课堂讨论”，可以推理出“如果小明生病了，他将错过课堂讨论”。"}
{"text": "从以上的例子可以看出，演绎推理是一种形式化的逻辑推理。"}
{"text": "归纳推理[2]是一种自下而上的推理，是指基于已有的部分观察得出一般结论的过程。"}
{"text": "例如，如果到目前为止我们见到的天鹅都是白色的，那么由归纳推理得出天鹅很大概率是白色的。"}
{"text": "典型的归纳推理有归纳泛化（Inductive_Generalization）、统计推理（StatisticalSyllogism）。"}
{"text": "归纳泛化是指基于对个体的观察而得出可能适用于整体的结论，即在整体的一些样本中得到的结论可以泛化到整体上。"}
{"text": "例如，有20个球，每个球不是黑色的就是白色的，要估计黑球和白球大概的个数。"}
{"text": "可以从20个球中抽样4个球，如果发现4个球中有3个白色和1个黑色，那么可以通过归纳泛化推理出这20个球中可能有15个球是白色的，5个球是黑色的。"}
{"text": "而统计推理是将整体的统计结论应用于个体。"}
{"text": "例如，经统计，90%就读于某高中的同学都上了大学，如果小明是这所高中的同学，那么可以由统计推理得出小明有90%的概率会上大学。"}
{"text": "归纳推理是一种非形式化的推理，是由具体到一般的推理过程。"}
{"text": "它和演绎推理有本质的不同，因为即便是在最理想的归纳推理中，如果作为推理前提的部分已有观察为真，也不能保证结论一定成立，即在任何情况下前提的真值都不能完全肯定结论的真值。"}
{"text": "但在演绎推理中，如果前提均为真，那么一定可以推理得到结论也为真。"}
{"text": "溯因推理[3]也是一种逻辑推理，是在给定一个或多个已有观察事实O（Observation），并根据已有的知识T（Theory）推断出对已有观察最简单且最有可能的解释的过程。"}
{"text": "例如，当一个病人显示出某种病症，而造成这个病症的原因可能有很多时，寻找在这个病人例子里最可能的原因的过程就是溯因推理。"}
{"text": "在溯因推理中，要使基于知识T而生成的对观察O的解释E是合理的，需要满足两个条件，一是E可以由T和O经过推理得出，可以是演绎、归纳推理等多种方式；二是E和T是相关且相容的。"}
{"text": "例如，我们知道下雨了马路一定会湿（T），如果观察到马路是湿的（O），可以通过溯因推理得到很大概率是因为下雨了（E）。"}
{"text": "溯因推理是归纳推理的一种，因为整个推理过程的前提和结论并没有必然的关系。"}
{"text": "类比推理[4]可以看作只基于对一个事物的观察而进行的对另一个事物的归纳推理，是通过寻找两者之间可以类比的信息，将已知事物上的结论迁移到新的事物上的过程。"}
{"text": "例如，小明和小红是同龄人，他们都喜欢歌手A和歌手B，且小明还喜欢歌手C，那么通过类比推理可以得出小红也喜欢歌手C。"}
{"text": "由于被类比的两个事物虽然有可类比的信息，却并不一定同源，而且有可能新推理出的信息和已知的可类比信息没有关系，所以类比推理常常会导致错误的结论，称为不当类比。"}
{"text": "例如在上例中，如果歌手C和歌手A、歌手B完全不是一种类型或一个领域的歌手，那么小明喜欢歌手C与他喜欢歌手A和歌手B是完全无关的，所以将“喜欢歌手C”的结论应用到小红身上不合适。"}
{"text": "造成不当类比的原因有很多，包括类比事物不相干、类比理由不充分以及类比预设不当等。"}
{"text": "尽管类比推理的结论相较于前面介绍的三种推理得到的结论错误率更高，但类比推理依然是一种普遍存在的推理方式。"}
{"text": "除了以上介绍的四种常见的逻辑推理，还有很多其他类型的推理。"}
{"text": "例如，根据不确定的观察信息以及不确定性的知识进行推理的不确定性推理，不确定性推理与前述四种推理方式的最大区别是其所能利用的推理信息都具有很大的不确定性。"}
{"text": "又例如在知识演变的过程中，根据原有的推论可否被推翻可以分为不会被推翻的单调推理以及可能会被推翻的非单调推理。"}
{"text": "从推理过程精确性来看，又可分为精确推理和模糊推理。"}
{"text": "不同的研究领域也有各自的推理问题。"}
{"text": "例如，在自然语言处理领域，典型的问题是自然语言推理（Natutal_Language_Inference)，其任务判断两个给定句子的蕴涵关系，给定的两个句子一个前提（Premise），一个是假设结论（Hypothsis），目标是判断在给定前提句子的情况下是否可以推理出假设结论的句子。"}
{"text": "答案分为三种，包括：表示假设结论句子和前提句子矛盾的“冲突（Contradiction）”、表示可以由前提句子推出假设结论句子的“蕴涵（Entailment）”以及表示前提句子和假设结论既不冲突也不蕴涵的“中立（Neutral）”。"}
{"text": "例如，前提句子“正在进行一场男子足球比赛”和假设结论句子“几个男运动员们在打比赛”应判断为“蕴涵”，而前提句子“两个小女孩在笑”和结论句子“两个小女孩因为这周末要去游乐场很开心”应判断为“中立”，将“一个男子沉睡在梦乡”和“男子眨了眨眼睛”判断为“冲突”。"}
{"text": "在计算机视觉领域也有视觉推理（Visual_Reasoning），一般任务为根据给定的图片回答特定的需要推理的问题。"}
{"text": "例如，给定一个包含多个不同色彩、不同形状的几何体图片，回答问题“图中最小的正方体右边的几何体是什么颜色”。"}
{"text": "在知识图谱相关的研究中，也有面向知识图谱的推理，下面将重点介绍面向知识图谱的推理。"}
{"text": "6.1.2面向知识图谱的推理面向知识图谱的推理主要围绕关系的推理展开，即基于图谱中已有的事实或关系推断出未知的事实或关系[5]，一般着重考察实体、关系和图谱结构三个方面的特征信息。"}
{"text": "如图6-1所示为人物关系图推理，利用推理可以得到新的事实(X,isFatherOf,M)，以及得到规则isFatherOf(x,y)<=fatherIs(y,x)等。"}
{"text": "具体来说，知识图谱推理主要能够辅助推理出新的事实、新的关系、新的公理以及新的规则等。"}
{"text": "图6-1人物关系图推理一个丰富、完整的知识图谱的形成会经历很多阶段，从知识图谱的生命周期来看，不同的阶段都涉及不同的推理任务，包括知识图谱补全[6]、不一致性检测、查询扩展等。"}
{"text": "将不同且相关的知识图谱融合为一个是一种有效地完善和扩大知识图谱的方式，而融合的过Alignment）[7]和关系对齐（Relation程包含两个重要的推理任务：有实体对齐（Entity_Alignment），关系对齐也叫作属性对齐（Property_Alignment）。"}
{"text": "即识别出分别存在两个知识图谱中的两个实体实际上表示的是同一个实体，或者两个关系是同一种语义的关系，从而在知识图谱中将其对齐，形成一个统一的实体或关系。"}
{"text": "由于现实世界的知识千千万万，想要涵盖所有的知识是很难的，所以知识图谱的不完整性很明显，在对知识图谱进行补全的过程中，链接预测是一种典型的推理任务[8]。"}
{"text": "知识图谱中的三元组可以通过人工定义得到，也可以通过文本抽取得到。"}
{"text": "由于人工知识的局限性以及算法的不确定性，一个知识图谱中不可避免地会存在冲突的信息，所以不一致性检测也是知识图谱中重要的推理任务，即检测知识图谱中有冲突或不正确的事实。"}
{"text": "存储了众多知识的知识图谱的一个重要作用是提供知识服务，为相关的查询返回正确的相关知识信息，但查询的模糊以及知识图谱本身的语义丰富性容易造成查询困难，而推理有利于查询重写，有效地提升查询结果的质量。"}
{"text": "知识图谱的推理的主要技术手段主要可以分为两大类：基于演绎的知识图谱推理，如基于描述逻辑[9]、Datalog、产生式规则等；基于归纳的知识图谱推理，如图6-1所示的路径推理[10]、表示学习[11]、规则学习[12]、基于强化学习的推理[13]等。"}
{"text": "以演绎推理为核心的知识图谱推理主要是基于描述逻辑、DataLog等进行的，而以归纳推理为核心的知识图谱推理主要是围绕对知识图谱图结构的分析、对知识图谱中元素的表示学习、利用图上搜索和分析进行规则学习以及应用强化学习方法等进行的。"}
{"text": "下面分别从这两类展开，介绍不同的推理实现方法。"}
{"text": "6.2基于演绎的知识图谱推理6.2.1本体推理1.本体与描述逻辑概述演绎推理的过程需要明确定义的先验信息，所以基于演绎的知识图谱推理多围绕本体展开。"}
{"text": "本体的一般定义为概念化的显示规约，它给不同的领域提供共享的词汇。"}
{"text": "因为共享的词汇需要赋予一定的语义，所以基于演绎的推理一般都在具有逻辑描述基础的知识图谱上展开。"}
{"text": "对于逻辑描述的规范，W3C提出了OWL。"}
{"text": "OWL按表达能力从低到高划分成OWL_Lite、OWL_DL和OWL_Full。"}
{"text": "OWL_Lite和OWL_DL在语义上等价于某些描述逻辑（Description_Logics,DLs）[14,15]，而OWL_Full没有对应的描述逻辑。"}
{"text": "2009年，为了适应更多应用的需求，W3C组织又提出了OWL的新版本OWL_2[15]。"}
{"text": "与OWL不同，OWL_2仅有对应的Full和DL层次。"}
{"text": "OWL_2_Full比OWL_Full的表达能力更强，同样没有对应的描述逻辑。"}
{"text": "而OWL_2_DL比OWL_DL的表达能力更强，仍有对应的描述逻辑[16]。"}
{"text": "为了适应高效的应用需求，W3C组织从OWL_2中分裂出三种易处理的剖面OWL_2_EL、OWL_2_QL和OWL_2RL。"}
{"text": "这些剖面都有对应的描述逻辑。"}
{"text": "表6-1总结了OWL成员与描述逻辑之间的对应关系。"}
{"text": "目前，OWL是知识图谱语言中最规范、最严谨、表达能力最强的语言，而且OWL基于RDF语法，使表示出来的文档具有语义理解的结构基础，OWL的另外一个作用是促进了统一词汇表的使用，定义了丰富的语义词汇。"}
{"text": "表6-1OWL成员与描述逻辑之间的对应关系基于OWL的模型论语义，在丰富逻辑描述的知识图谱中，除了包含实体和二元关系，还包含了许多更抽象的信息，例如描述实体类别的概念以及关系之间的从属信息等。"}
{"text": "从而有一系列实用有趣的推理问题，包括：（1）概念包含。"}
{"text": "判定概念C是否为D的子概念，即C是否被D包含。"}
{"text": "例如，在包含公理Mother⊑Women和Women⊑Person的本体中，可以判定Mother⊑Person成立。"}
{"text": "（2）概念互斥。"}
{"text": "判定两个概念C和D是否互斥，即不相交。"}
{"text": "需要判定C⊓D⊑⊥是否为给定知识库的逻辑结论。"}
{"text": "例如，在包含Man⊓Women⊑⊥的本体中，概念Man和Women是互斥的。"}
{"text": "（3）概念可满足。"}
{"text": "判定概念C是否可满足，需要找到该知识库的一个模型，使C的解释非空。"}
{"text": "例如，包含公理Eternity⊑⊥的本体中，概念Eternity是不可满足概念。"}
{"text": "（4）全局一致。"}
{"text": "判定给定的知识库是否全局一致（简称一致，Consistent），需要找到该知识库的一个模型。"}
{"text": "例如，包含公理Man⊓Women⊑⊥、Man（Allen）和Women（Allen）的本体是不一致的。"}
{"text": "（5）TBox一致。"}
{"text": "判定给定知识库的TBox是否一致，需要判定TBox中的所有原子概念是否都满足。"}
{"text": "例如，包含公理Man⊓Women⊑⊥、Professor⊑Man和Professor⊑Women的TBox是不一致的。"}
{"text": "（6）实例测试。"}
{"text": "判定个体a是否是概念C的实例，需要判定C(a)是否为给定知识库的逻辑结论。"}
{"text": "（7）实例检索。"}
{"text": "找出概念C在给定知识库中的所有实例，需要找出属于C的所有个体a，即C(a)是给定知识库的逻辑结论。"}
{"text": "2.基于Tableaux的本体推理方法基于表运算（Tableaux）的本体推理方法[20]是描述逻辑知识库一致性检测的最常用方法。"}
{"text": "基于表运算的推理方法通过一系列规则构建Abox，以检测可满足性，或者检测某一实例是否存在某概念，基本思想类似于一阶逻辑的归结反驳。"}
{"text": "以一个例子阐述该方法的基本思想。"}
{"text": "假设知识库K由以下三个声明构成：将以a作为实例的所有概念的集合记作L(a)。"}
{"text": "我们使用L←C表示通过加入C进行更新。"}
{"text": "例如，如果=｛D｝而且通过←C来对进行更新，那么将变成{C,D}。"}
{"text": "在给出的例子中，不经推导可以得到。"}
{"text": "TBox声明C⊑D与等价。"}
{"text": "因此，通过，得到，得到了矛盾，这表明K是不一致的。"}
{"text": "在上面例子中构建的东西实质上是表的一部分。"}
{"text": "表是表达知识库逻辑结论的一种结构化方法。"}
{"text": "如果在表构建过程中出现矛盾，那么知识库是不一致的。"}
{"text": "以描述逻辑为例，在初始情况下，是原始的Abox，迭代运用如下规则：其中，y是新加进来的个体。"}
{"text": "给定包含如下公理和断言的本体：Man⊓Women⊑⊥,Man(Allen)，检测实例Allen是否Woman_Woman(Allen)，根据⊓−−规则，在Man⊓Women（Allen）加入中，再通过⊑−规则得到⊥(Allen)，这样就得到了一个矛盾，中。"}
{"text": "首先，加入待反驳的结论所以拒绝现在的，即Allen不在Woman中。"}
{"text": "为了提高Tableaux算法的效率，研究者提出了不少优化技术[20-22]，使该算法对于中小型描述逻辑知识库的推理达到了实用化的程度。"}
{"text": "目前，前沿的超表运算（Hypertableau）技术[23]进一步提高了Tableaux算法的效率，并能处理表达能力很强的描述逻辑。"}
{"text": "目前，已经有不少公开的基于表运算的OWL推理系统，比较著名的包括FaCT++[1]、RacerPro[2]、Pellet[3]和HermiT[4]，其中HermiT是目前唯一实现了Hypertableaux算法[23]的开源OWL推理系统。"}
{"text": "虽然Tableaux算法是最通用的描述逻辑知识库一致性的检测方法，但是这类算法并不一定具有最优的最坏情况组合复杂度。"}
{"text": "例如，针对SHOIN知识库进行一致性检测的问题是NExpTime-完全问题，但是针对SHOIN的Tableaux算法需要非确定性的双指数级的计算空间[22]，而能处理SHOIN的Hypertableaux算法的组合复杂度也达到了2NExpTime级别[23]。"}
{"text": "因此，如何为SHOIN等强表达力的描述逻辑设计最优组合复杂度的Tableaux算法仍有待研究。"}
{"text": "3.常用本体推理工具简介（1）FaCT++。"}
{"text": "FaCT++是曼彻斯特大学开发的描述逻辑推理机，使用C++实现，且能与Protégé集成。"}
{"text": "Java版本名为Jfact，基于OWL_API。"}
{"text": "构建推理机采用下面的代码：采用以下代码对本体进行分类：（2）Racer。"}
{"text": "Racer是美国Franz_Inc.公司开发的以描述逻辑为基础的本体推理机，也可以用作语义知识库，支持OWL_DL，支持部分OWL_2_DL并且支持单机和客户端/服务器两种模式，用Allegro_Common_Lisp实现。"}
{"text": "以下代码可以进行TBox推理：以下代码可对ABox进行推理：（3）Pellet。"}
{"text": "Pellet是马里兰大学开发的本体推理机，支持OWL_DL的所有特性，包括枚举类和XML数据类型的推理，并支持OWL_API以及Jena的接口。"}
{"text": "构建推理机采用以下代码：通过查询接口进行推理，采用下面的代码：（4）HermiT。"}
{"text": "HermiT是牛津大学开发的本体推理机，基于Hypertableaux运算，比其他推理机更加高效，支持OWL_2规则。"}
{"text": "构建推理机采用以下代码：不一致推理采用以下代码：表6-2为本体推理工具总结。"}
{"text": "表6-2本体推理工具总结6.2.2基于逻辑编程的推理方法1.逻辑编程与Datalog简介逻辑编程是一族基于规则的知识表示语言。"}
{"text": "与本体推理相比，规则推理有更大的灵活性。"}
{"text": "本体推理通常仅支持预定义的本体公理上的推理，而规则推理可以根据特定的场景定制规则，以实现用户自定义的推理过程。"}
{"text": "逻辑编程是一个很大的研究领域，在工业界应用广泛。"}
{"text": "逻辑编程也可以与本体推理相结合，集合两者的优点。"}
{"text": "逻辑编程的研究始于Prolog语言[24,25]，后来由ISO标准化。"}
{"text": "Prolog在多种系统中被实现，例如SWI-Prolog、Sicstus_Prolog、GNU_Prolog和XSB。"}
{"text": "Prolog在早期的人工智能研究中应用广泛，多用于实现专家系统。"}
{"text": "在通常情况下，Prolog程序是通过SLD消解和回溯来执行的[25]。"}
{"text": "运行结果依赖对规则内部的原子顺序和规则之间的顺序，因此不是完全的声明式的（declarative）。"}
{"text": "在程序存在递归的情况下，有可能出现运行无法终止的情况。"}
{"text": "为了得到完全的声明式规则语言，研究人员开发了一系列Datalog语言。"}
{"text": "从语法上来说，Datalog程序基本上是Prolog的一个子集。"}
{"text": "它们的主要区别是在语义层面，Datalog基于完全声明式的模型论的语义，并保证可终止性。"}
{"text": "在本节中，将简要回顾Datalog语言的语法和语义，并展示如何在实践中使用它们。"}
{"text": "读者可参考文献[26]获得更多关于逻辑程序的相关介绍。"}
{"text": "2.Datalog语言Datalog语言是一种面向知识库和数据库设计的逻辑语言。"}
{"text": "便于撰写规则，实现推理。"}
{"text": "Datalog与OWL的关系如图6-2所示，其中OWL_RL和RDFS处于OWL和Datalog的交集之中。"}
{"text": "OWL_RL的设计目标之一就是找出可以用规则推理来实现的一个OWL的片段。"}
{"text": "图6-2Datalog与OWL的关系Datalog的基本符号有常量（constant）、变量（variable）和谓词（predicate）。"}
{"text": "常量通常用小写字母a、b、c表示一个具体的实例。"}
{"text": "变量用大写字母X、Y、Z表示，有时也会用问号（?）开头，例如？x、?y。"}
{"text": "项（term）包括常量和变量。"}
{"text": "原子（atom）形如p(t1,…,tn），其中p是一个谓词，t1,…,tn为项，n被称为p的元数。"}
{"text": "例如，假定has_child为一个二元谓词，原子has_child(X,Y)表示变量X和Y有has_child的关系，而原子has_child(jim,bob)表示常量jim和bob有has_child的关系。"}
{"text": "Datalog规则形如H:-B1,B2,…,Bm.其中，H,B1,B2,…,Bm为原子。"}
{"text": "H称为此规则的头部原子，B1,B2,…,Bm称为体部原子。"}
{"text": "规则的直观含义为：当体部原子都成真时，头部原子也应成真。"}
{"text": "例如，规则has_child(Y,X):-has_son(X,Y)表示当X和Y有has_son的关系时，则Y与X有has_child的关系。"}
{"text": "Datalog事实（fact）是形如F(c1,c2,…,cn):-的没有体部且没有变量的规则。"}
{"text": "事实也常写成“F(c1,c2,…,cn).”的形式。"}
{"text": "例如，规则has_child(alice,bob):-即为一个事实，表示alice和bob有has_child的关系。"}
{"text": "Datalog程序是规则的集合。"}
{"text": "例如，下面的两条规则构成了一个Datalog程序：has_child(X,Y):-has_son(X,Y).has_child(Alice,Bob).3.Datalog推理举例下面的规则集表达了给定一个图，计算所有的路径关系，即节点X、Y之间是否联通：path(X,Y):-edge(X,Y).①path(X,Y):-path(X,Z),path(Z,Y).②节点X和Y联通有两种情况：①X、Y之间通过一条边（edge）直接连接；②存在一个节点Z，使得X、Z联通并且Z、Y联通。"}
{"text": "下面的三个事实表示了一个图中的三条边。"}
{"text": "edge(a,b).edge(b,c).edge(d,e).Datalog的语义通过结果集定义，直观来讲，一个结果集是Datalog程序可以推导出的所有原子的集合。"}
{"text": "例如，上面的关于图联通的例子，结果集为{path(a,b).path(b,c).path(a,c).path(d,e).edge(a,b).edge(b,c).edge(d,e)}，如图6-3所示。"}
{"text": "图6-3Datalog推理举例4.Datalog与知识图谱Datalog程序可以应用在知识图谱中进行规则推理。"}
{"text": "一个知识图谱可以自然地被看作一个事实集。"}
{"text": "只需人为引入一个特殊的谓词triple，每一个三元组(subject,property,object)便可以作为一个事实triple(subject,property,object)。"}
{"text": "另一种方法是按照描述逻辑ABox的方式来看待，即三元组(s,rdf:type,C)看作C(s)，其他的三元组(s,p,o)看作p(s,o)。"}
{"text": "这样一来，Datalog规则就可以作用于知识图谱上。"}
{"text": "下面介绍的三种语言SWRL、OWL_RL、RDFS与Datalog密切相关。"}
{"text": "（1）SWRL（Semantic_Web_Rule_Language）。"}
{"text": "SWRL是2004年提出的一个完全基于Datalog的规则语言。"}
{"text": "SWRL规则形如Datalog，只是限制原子的谓词必须是本体中的概念或者属性。"}
{"text": "SWRL虽然不是W3C的推荐标准，但在实际中被多个推理机支持，应用广泛。"}
{"text": "（2）OWL_RL。"}
{"text": "OWL_RL是W3C定义的OWL_2的一个子语言，其设计目标为可以直接转换成Datalog程序，从而使用现有的Datalog推理机推理。"}
{"text": "（3）RDFS（RDF_Schema）。"}
{"text": "RDFS是W3C定义的一个基于RDF的轻量级的本体语言。"}
{"text": "RDFS的推理也可以用Datalog程序表示。"}
{"text": "RDFS的表达能力大体是OWL_RL的一个子集。"}
{"text": "5.基于Datalog的推理工具RDFox介绍目前，最主要的Datalog工具包括DLV[5]和Clingo[6]。"}
{"text": "这两个工具都是一般性的Datalog推理机，而不是专用于知识图谱。"}
{"text": "知识图谱领域也有多个系统，包括KAON2[7]、HermiT[8]、Pellet[9]、Stardog[10]、RDFox[11]等，支持RL或者SWRL推理。"}
{"text": "Datalog相关工具总结如表6-3所示。"}
{"text": "下面简要介绍一下RDFox。"}
{"text": "表6-3Datalog相关工具总结RDFox是由牛津大学开发的可扩展、跨平台、基于内存的RDF三元组存储系统。"}
{"text": "其最主要的特点是支持基于内存的高效并行Datalog推理，同时也支持SPARQL查询。"}
{"text": "RDFox的架构如图6-4所示。"}
{"text": "RDFox的输入包括本体（TBox）、数据（ABox）和一个自定规则集。"}
{"text": "其核心为RDFox推理机，支持增量更新。"}
{"text": "图6-4RDFox的架构1.RDFox_Java_API使用方法（1）创建本体与存储（2）导入本体进行推理2.RDFox_Java_API使用举例下面用一个具体的例子介绍RDFox。"}
{"text": "假定有如图6-5所示的某金融领域相关的图。"}
{"text": "首先把它转换成一个知识图谱。"}
{"text": "对每一个实体，要创建一个IRI。"}
{"text": "为此引入命名空间finance：来表示http://www.example.org/kse/finance#。"}
{"text": "<http://www.example.org/kse/finance#孙宏斌>这个IRI就可以使用命名空间简写为“finance：孙宏斌”。"}
{"text": "图6-5某金融领域相关的图一个三元组例子为：finance：融创中国rdf:type_finance：地产事业本体（TBox）如下：●SubClassOf(PublicCompany,Company)//类PublicCompany是Company的子类●ObjectPropertyDomain(Control,Person)//属性Control的定义域是Person●ObjectPropertyRange(Control,Company)//属性Control的值域是Company此本体用RDF/XML的格式描述如下：数据（ABox）用Triple的语法，如下所示。"}
{"text": "自定义规则如下：1）执掌一家公司就一定是这家公司的股东。"}
{"text": "2）如果某人同时是两家公司的股东，那么这两家公司一定有关联交易。"}
{"text": "用Datalog形式化，写成SWRL规则，具体如下：下面演示如何使用代码（Java）数据读取本体、数据，声明规则并进行推理。"}
{"text": "读取本体、数据，声明规则。"}
{"text": "推理，定义命名空间与查询操作（用于输出当前三元组）。"}
{"text": "将结果输出为结合规则推理的所有三元组实例化。"}
{"text": "6.2.3基于查询重写的方法本节介绍查询重写的方法实现知识图谱的查询。"}
{"text": "考虑两种情况，第一种情况是知识图谱已经存在，第二种情况是数据并不以知识图谱的形式存在，而是存在外部的数据库中（例如关系数据库）。"}
{"text": "第一种情况直接在知识图谱之上的查询称为本体介导的查询回答（Ontology-MediatedQuery_Answering,OMQ）[27]。"}
{"text": "在OMQ下，查询重写的任务是将一个本体TBoxT上的查询q重写为查询qT，使得对于任意的ABoxA,qT在A上的执行结果等价于q在(T,A)上的执行结果。"}
{"text": "第二种情况称为基于本体的数据访问（Ontology-Based_Data_Access,OBDA）[28,29]。"}
{"text": "在OBDA的情况下，数据存放在一个或多个数据库中，由映射（Mapping）将数据库的数据映射为一个知识图谱。"}
{"text": "映射的标准语言为W3C的R2RML语言。"}
{"text": "OMQ可以看作OBDA的特殊情况，即每个本体中谓词的实例都存储在一个特定的对应表中，而映射只是一个简单的同构关系。"}
{"text": "以下着重介绍OBDA。"}
{"text": "1.OBDA框架OBDA框架包含外延（extensional）和内涵（intensional）两个部分。"}
{"text": "外延层为符合某个数据库架构（schema）S的一个源数据库D,S通常包括数据库表的定义和完整性约束。"}
{"text": "内涵层为一个OBDA规范P=（T,M,S），其中T是本体，S是数据源模式，M是从S到T的映射。"}
{"text": "这样OBDA的实例定义为外延层和内涵层的一个对I=(P,D)，其中P=(T,M,S)，且D符合S。"}
{"text": "用M(D)表示将映射M作用于数据库D上生成的知识图谱。"}
{"text": "给定这样一个OBDA实例I,OBDA的语义即定义为一个知识库(T,M(D))。"}
{"text": "OBDA的主要推理任务为查询。"}
{"text": "当查询时，本体T为用户提供了一个高级概念视图数据和方便的查询词汇，用户只针对T查询，而数据库存储层和映射层对用户完全透明。"}
{"text": "这样OBDA可以将底层的数据库呈现为一个知识图谱，从而掩盖了底层存储的细节。"}
{"text": "OBDA有多种实现方式，最直接的方式是生成映射得到的知识图谱M(D)，然后保存到一个三元组存储库中，这种方式也称作ETL（Extract_Transform_Load)，优点是实现简单直接。"}
{"text": "但是当底层数据量特别大或者数据经常变化时，或者映射规则需要修改时，ETL的成本可能很高，也需要额外的存储空间。"}
{"text": "在此，我们更感兴趣的是虚拟OBDA的方式，此方式下的三元组并不需要被真正生成，而通过查询重写的方式来实现，OBDA将在本体层面的SPARQL查询重写为在原始数据库上的SQL查询。"}
{"text": "相比于ELT的方式，虚拟OBDA方式更轻量化、更灵活，也不需要额外的硬件。"}
{"text": "为了保证可重写性，本体语言通常使用轻量级的本体语言DL-Lite，被W3C标准化为OWL_2_QL。"}
{"text": "OBDA查询重写的流程如图6-6所示。"}
{"text": "给定一个OBDA实例I=(P,D)、P=(T,S,M)以及一个SPARQL查询q，通过重写回答查询的具体步骤为：（1）查询重写。"}
{"text": "对于OMQ的情况，利用本体T将输入的SPARQLq重写为另一个SPARQL。"}
{"text": "（2）查询展开。"}
{"text": "将SPARQL利用映射M展开，把每一个查询中的谓词替换成映射中的定义，生成SQL语句查询[30]。"}
{"text": "（3）查询执行。"}
{"text": "将生成的SQL语句交给数据库引擎并执行。"}
{"text": "（4）结果转换。"}
{"text": "SQL语句查询的结果做一些简单的转换，变换成SPARQL的查询结果。"}
{"text": "为了实现更好的性能，实际使用的OBDA系统做了非常多的优化，实际的流程更加复杂[29]。"}
{"text": "图6-6OBDA查询重写的流程2.查询重写举例（OMQ）假定有如下一个关于学校信息系统的本体T：查询q1=SELECT?teacherWHERE{?teacheraTeacher}试图查询所有的教师。"}
{"text": "通过层次关系和定义域可以被重写为q1'=请注意q1’包括了所有的已知教师和所有有教学任务的人。"}
{"text": "查询q2=SELECT?teacherWHERE{?teacheraTeacher.?teacherteaches?course.?courseaCourse.}查询所有的教师和讲授的课程。"}
{"text": "可以先利用teaches的定义域和值域将q2优化为SELECT?teacher?courseWHERE{?teacherteaches?course}然后重写为q2'：注意q2’只包括有教学任务的人。"}
{"text": "可以重写为：3.查询重写举例（OBDA）现在假设数据实际是存在于一个关系数据库中。"}
{"text": "此数据库包含以下三个数据库表，其中下画线的列构成数据表的主键：同时，假设有如下的映射规则：利用这些映射，q1’可以被展开为：并进一步简化为：查询q2’可以展开为：并进一步简化为：查询q3’可以展开为：并进一步简化为：这些生成的SQL语句可以直接在原始的数据库上运行。"}
{"text": "4.相关工具介绍基于查询重写的推理机有多个，例如Ontop[12]Mastro[13]、Stardog[14]、Ultrawrap[15]、Morph[16]。"}
{"text": "这些工具的功能对比如表6-4所示。"}
{"text": "表6-4基于查询重写的推理机工具的功能对比Ontop是由意大利博尔扎诺自由大学开发的一个开源的（Apache_License_2.0）OBDA系统，现在由Ontopic公司提供技术支持。"}
{"text": "Ontop兼容RDFS、OWL_2_QL、R2RML、SPARQL标准，并支持主流关系数据库，如Oracle、MySQL、SQL_Server、PostgreSQL。"}
{"text": "Ontop的Protégé插件可以用于编辑映射和测试查询。"}
{"text": "RDF4J插件可以将编辑好的OBDA系统发布为一个SPARQL_endpoint。"}
{"text": "Ontop也提供Java_API。"}
{"text": "Mastro最初是由意大利罗马大学开发的OBDA系统，现在由OBDA_Systems商业化运行。"}
{"text": "此系统支持对OWL2_QL本体的推理。"}
{"text": "与此处提到的其他OBDA系统不同，它仅支持与合取查询相对应的SPARQL的受限片段。"}
{"text": "Ultrawrap是由Capsenta公司商业化的OBDA系统。"}
{"text": "它被扩展为支持对具有反向和传递属性的RDFS扩展的推断。"}
{"text": "Morph-RDB是西班牙马德里工业大学开发的开源OBDA系统，不支持本体层面的推理能力。"}
{"text": "Stardog原本是由Stardog_Union开发的商业化的Triple存储工具。"}
{"text": "Stardogv4版中集成了Ontop代码以支持虚拟RDF图上的SPARQL查询。"}
{"text": "因此，它现在也可以归为OBDA系统。"}
{"text": "在v5版本中有了自己的OBDA实现。"}
{"text": "5.OBDA的应用OBDA在学术界和工业级有着广泛的应用，如石油与天然气领域，挪威国家石油公司[31]；涡轮发电机故障诊断，西门子[32]；数据集成解决方案，SIRIS_Academic_SLBarcellona[33]；日志流程挖掘，KAOS项目[34]；文化遗产，EPNet项目[35]；海事安全，EMSec项目[36]；制造业，工业4.0[37]；医疗保健，电子健康记录[38]；政务信息，意大利公共债务[39]；智慧城市，IBM爱尔兰[40]。"}
{"text": "限于篇幅，不展开讲解，有兴趣的读者可以查阅参考文献[41]。"}
{"text": "6.2.4基于产生式规则的方法1.产生式系统产生式系统是一种前向推理系统，可以按照一定机制执行规则并达到某些目标，与一阶逻辑类似，也有区别。"}
{"text": "产生式系统可以应用于自动规划和专家系统等领域。"}
{"text": "一个产生式系统由事实集合、产生式集合和推理引擎三部分组成。"}
{"text": "（1）事实集合。"}
{"text": "事实集合是运行内存（Working_Memory,WM）为事实（WME）的集合，用于存储当前系统中的所有事实。"}
{"text": "事实可描述对象，形如(typeattr_1:val_1attr_2:val_2…attr_n:val_n），其中type、attr_i、val_i均为原子（常量）。"}
{"text": "例如，(studentage:24)表示一个学生，姓名为Alice，年龄为24。"}
{"text": "事实也可描述关系name:\"Alice\"（Refication）。"}
{"text": "例如，(basicFactrelation:olderThanfirstArg:JohnsecondArg:Alice)表示John比Alice的年纪大，此事实也可简记为(olderThanJohnAlice)。"}
{"text": "（2）产生式集合。"}
{"text": "产生式集合（ProductionMemory,PM）由一系列的产生式组成。"}
{"text": "产生式形如：●IFconditionsTHENactions其中，conditions是由条件组成的集合，又称为LHS;actions是由动作组成的序列，又称为RHS。"}
{"text": "LHS是conditions的集合，各条件之间为且的关系。"}
{"text": "当LHS中所有条件均被满足时，触发规则。"}
{"text": "每个条件形如(typeattr_1:spec_1attr_2:spec_2…attr_n:spec_n）。"}
{"text": "其中，spec_i表示对attr_i的约束，形式可取下列中的一种：●原子，如：Alice(personname:Alice)●变量，如：x(personname:x)●表达式，如：[n+4](personage:[n+4])●布尔测试，如：{>10}(personage:{>10})●约束的与、或、非操作RHS是action的序列，执行时依次执行。"}
{"text": "动作的种类有如下三种：●ADDpattern。"}
{"text": "向WM中加入形如pattern的WME。"}
{"text": "●REMOVEi。"}
{"text": "从WM中移除当前规则第i个条件匹配的WME。"}
{"text": "●MODIFYi(attrspec)。"}
{"text": "对于当前规则第i个条件匹配的WME，将其对应于attr属性的值改为spec。"}
{"text": "例如，产生式IF(Studentname:)ThenADD(Personname:)表示如果有一个学生名为？x，则向事实集加入一个事实，表示有一个名为？x的人。"}
{"text": "产生式具体语法因不同系统而异，某些系统中此产生式亦可写作(Studentname:x)⇒ADD(Personname:x)。"}
{"text": "（3）推理引擎。"}
{"text": "推理引擎用于控制系统的执行。"}
{"text": "产生式系统执行流程如图6-7所示。"}
{"text": "图6-7产生式系统执行流程产生式系统主要有三个部分：●模式匹配。"}
{"text": "用规则的条件部分匹配事实集中的事实，整个LHS都被满足的规则被触发，并被加入议程（Agenda）。"}
{"text": "●选择规则。"}
{"text": "按一定的策略从被触发的多条规则中选择一条。"}
{"text": "●执行规则。"}
{"text": "执行被选择出来的规则的RHS，从而操作WM。"}
{"text": "模式匹配用每条规则的条件部分匹配当前的WM，如图6-8所示为匹配规则过程。"}
{"text": "规则为：（typexy）,(subClassOfyz)⇒ADD(typexz)。"}
{"text": "图6-8匹配规则过程高效的模式匹配算法是产生式规则引擎的核心。"}
{"text": "目前，最流行的算法是Rete算法，在1979年由CharlesForgy提出[42]。"}
{"text": "其主要的想法为将产生式的LHS组织成判别网络形式，以实现用空间换时间的效果。"}
{"text": "下面用图6-9和图6-10解释Rete算法的形状。"}
{"text": "最主要的部分为α网络和β网络。"}
{"text": "α和β的名字来源于产生式规则常写成α⇒β的形式。"}
{"text": "α网络对应条件，检验并保存各个条件对应的WME集合。"}
{"text": "β网络对应结果，用于保存join的中间结果。"}
{"text": "图6-9Rete网络图6-10Rete算法的匹配过程选择规则从被触发的多条规则中选择一条执行，常用的策略有：●随机选择。"}
{"text": "从被触发的规则中随机选择一条执行。"}
{"text": "注意在推理的场景下，被触发的多条规则可全被执行。"}
{"text": "●具体性（specificity）。"}
{"text": "选择最具体的规则，例如下面的第二条规则比第一条更具体，故当同时满足时触发第二条：(Studentname:)⇒…(Studentname:age:20)⇒…●新近程度（recency）。"}
{"text": "选择最近没有被触发的规则执行动作。"}
{"text": "4.相关工具介绍表6-5为三个基于产生式规则的系统，它们都是基于Rete算法或其改进的。"}
{"text": "表6-5三个基于产生式规则的系统（1）Drools。"}
{"text": "Drools是一个商用规则管理系统，提供了一个规则推理引擎。"}
{"text": "核心算法是基于Rete算法的改进。"}
{"text": "提供规则定义语言，支持嵌入Java代码。"}
{"text": "Drools使用举例：创建容器与会话，如下：触发规则，如下：（2）Jena。"}
{"text": "Jena是一个用于构建语义网应用的Java框架。"}
{"text": "提供了处理RDF、RDFS、OWL数据的接口，还提供了一个规则引擎。"}
{"text": "提供三元组的内存存储于SPARQL、查询。"}
{"text": "Jena使用举例：创建模型，如下：创建规则推理机，如下：（3）GraphDB。"}
{"text": "GraphDB（原OWLIM）是一个可扩展的语义数据存储系统（基于RDF4J），其功能包含三元组存储、推理引擎、查询引擎，支持RDFS、OWL_DLP、OWL_Horst、OWL_2_RL等多种语言。"}
{"text": "6.3基于归纳的知识图谱推理随着技术的发展，越来越多的知识图谱自动化构建方法被提出来，例如利用算法对文本进行三元组抽取，这使得大规模知识图谱能够迅速被建立起来，例如NELL。"}
{"text": "但这类知识图谱的信息准确度稍差于利用专家知识人工构建的知识图谱，且冗余度较大。"}
{"text": "在这种自动化构建的大规模知识图谱上进行推理，知识的不精确性以及巨大的规模对演绎推理来说是很大的挑战，而归纳推理却很适用。"}
{"text": "基于归纳的知识图谱推理主要是通过对知识图谱已有信息的分析和挖掘进行推理的，最常用的信息为已有的三元组。"}
{"text": "按照推理要素的不同，基于归纳的知识图谱推理可以分为以下几类：基于图结构的推理、基于规则学习的推理和基于表示学习的推理。"}
{"text": "下面分别介绍这三类推理的主要方法和现有进展。"}
{"text": "6.3.1基于图结构的推理1.方法概述对于那些自底向上构建的知识图谱，图谱中大部分信息都是表示两个实体之间拥有某种关系的事实三元组。"}
{"text": "对于这些三元组，从图的角度来看，可以看作是标签的有向图，有向图以实体为节点，以关系为有向边，并且每个关系边从头实体的节点指向尾实体的节点，如图6-11所示。"}
{"text": "图6-11知识图谱中的实体关系图有向图中丰富的图结构反映了知识图谱丰富的语义信息，在知识图谱中典型的图结构是两个实体之间的路径。"}
{"text": "例如，上面的示例中描述了不同人物之间的关系以及人物的职业信息，包含了如下的路径：这是一条从实体小明到实体小小的路径，表述的信息是小明的妻子是小红，小红的孩子有小小。"}
{"text": "从语义角度来看，这条由关系“妻子是”和“孩子有”组成的路径揭示了小明和小小之间的父子关系，这条路径蕴涵着三元组：而这个推理过程不仅仅存在于这个包含小明、小红和小小的子图中，同样也存在于建国、秀娟和小明的子图中，而路径和三元组是常常同时出现在知识图谱中的。"}
{"text": "其中A、B、C是三个代表关系的变量，由“妻子是”和“孩子有”两种关系组成的路径与关系“孩子有”在图谱中是经常共现的，且其共现与A、B、C具体是什么实体没有关系。"}
{"text": "这说明了路径是一种重要的进行关系推理的信息，也是一种重要的图结构。"}
{"text": "除了路径，实体的邻居节点以及它们之间的关系也是刻画和描述一个实体的重要信息，例如在上例中的关于“小明”的7个三元组鲜明地描述了小明这个人物，包括（小明，父亲是，建国）、（小明，获得奖项，最佳男主角）以及（小明，妻子是，小红）等。"}
{"text": "一般而言，离实体越近的节点对描述这个实体的贡献越大，在知识图谱推理的研究中，常考虑的是实体一跳和两跳范围内的节点和关系。"}
{"text": "当把知识图谱看作是有向图时，往往强调的是在知识图谱中的事实三元组，即表示两个实体之间拥有某种关系的三元组，而对于知识图谱的本体和上层的schema则关注较少，因为本体中许多含有丰富逻辑描述的信息并不能简单地转化为图的结构。"}
{"text": "下面将介绍常见的基于图结构的知识图谱推理算法。"}
{"text": "2.常见算法简介典型的基于图结构的推理方法有PRA（Path_Ranking_Algorithm）[10]利用了实体节点之间的路径当作特征从而进行链接预测推理。"}
{"text": "（1）基于知识图谱路径特征的PRA算法。"}
{"text": "PRA处理的推理问题是关系推理，其中包含了两个任务，一个是给定关系r和头实体h预测可能的尾实体t是什么，即在给定h,r的情况下，预测哪个三元组（h,r,t）成立的可能性比较大，叫作尾实体链接预测；另一个是在给定r,t的情况下，预测可能的头实体h是什么，叫作头实体链接预测。"}
{"text": "PRA针对的知识图谱主要是自底向上自动化构建的含有较多噪声的图谱，例如NELL，并将关系推理的问题形式化为一个排序问题，对每个关系的头实体预测和尾实体预测都单独训练一条排序模型。"}
{"text": "PRA将存在于知识图谱中的路径当作特征，并通过图上的计算对每个路径赋予相应的特征值，然后利用这些特征学习一个逻辑斯蒂回归分类器完成关系推理。"}
{"text": "在PRA中，每一个路径可以当作对当前关系判断的一个专家，不同的路径从不同的角度说明了当前关系的存在与否。"}
{"text": "在PRA中，利用随机游走的路径排序算法首先需要生成一些路径特征，一个路径P是由一系列关系组成的，即：式中，Tn为关系rn的作用域（range)以及关系rn−1的值域（domian)，即Tn=range（rn）=domain（rn−1），关系的值域和作用域通常指的是实体的类型。"}
{"text": "基于路径的随机游走定义了一个关系路径的分布，并得到每条路径的特征值sℎ,P（t）,sℎ,P（t）可以理解为沿着路径P从h开始能够到达t的概率。"}
{"text": "具体操作为，在随机游走的初始阶段，sℎ,P（e）初始化为1，如果e=s，否则初始化为0。"}
{"text": "在随机游走的过程中，sℎ,P（e）的更新原则如下：式中表示从节点e′出发沿着关系rl通过一步的游走能够到达节点e的概率。"}
{"text": "对于关系r，在通过随机游走得到一系列路径特征Pr={P1,⋯,Pn}之后，PRA利用这些路径特征为关系r训练一个线性的预测实体排序模型，其中关系r下的每个训练样本，即一个头实体和尾实体的组合的得分计算方法如下：基于每个样本的得分，通过一个逻辑斯蒂函数得到每个样本的概率，即：再通过一个线性变化加上最大似然估计，设计损失函数如下：li（θ）=wi[yilnpi+（1−yi）ln（1−pi）].式中，yi为训练样本（hi,ti）是否具有关系r的标记，如果（hi,r,ti）存在，则标记为1；如果不存在，则标记为0。"}
{"text": "在路径特征搜索的过程中，PRA增加了对有效路径特征的约束，来有效减小搜索空间：路径在图谱中的支持度（support）应大于某设定的比例α；路径的长度小于或等于某设定的长度；每条路径至少有一个正样本在训练集中。"}
{"text": "采集路径随机游走过程采用了LVS（Low-Variance_Sampling）的方法。"}
{"text": "结合了有效采样和随机有走的PRA能够快速有效地利用知识图谱的路径结构对知识图谱进行关系推理，是典型的基于图结构的知识图谱推理算法。"}
{"text": "（2）PRA的演化算法。"}
{"text": "在PRA中的路径是连续的且在路径中的关系是同向的，这种路径特征可以理解为一种简单的霍恩规则（Hornrule），但是在知识图谱中，有很多种路径是含有常量的：由这个路径可以推理出三元组小明，这种有明显语义的含有常量的且不是收尾闭合的路径特征是不能被PRA捕捉到的，又例如由t=NFL直接推理ex，即将NFL直接设置为关系“服役于运动队”的值域，这种很明显的推理特征也是PRA无法捕捉的。"}
{"text": "所以，CoR-PRA（Constant_and_Reversed_Path_RankingAlgorithm）[43]通过改变PRA的路径特征搜索策略，促使其能够涵盖更多种语义信息的特征，主要是包含常量的图结构特征。"}
{"text": "给定关系r下的训练样本（h,t）,Co-PRA中搜索图结构特征的步骤如下：1）生成初步的路径。"}
{"text": "通过路径搜索算法生成以h为起点的小于长度l的路径集合Pℎ；通过路径搜索算法生成以t为起点的小于长度l的路径集合Pt。"}
{"text": "2）通过PRA计算路径特征的概率。"}
{"text": "对于路径πℎ∈Pℎ，计算沿着路径πℎ正向地由h到达x的概率P（h→x;πℎ），以及沿着路径πℎ逆向地由h到达x的概率；同理，对路径πt∈Pt，计算沿着路径πt正向地由t到达x的概率P（t→x;πt），以及沿着路径πt逆向地由t到达x的概率；并将所有的x放入常量候选集N中。"}
{"text": "3）生成候选的常量路径。"}
{"text": "对每一个（x∈N,πϵPt）的组合，如果P（t→x|πt）＞0，那么生成路径特征，其中c=x，并且将路径特征对应的覆盖度值（coverage）加1，即；同理，对每一个（x∈N,πϵPt）的组合，如果，那么生成路径特征P（c→t;πt），其中c=x，并且将路径特征对应的覆盖度值加1，即coverage（P（c→t;πt））+=1。"}
{"text": "4）生成更长的路径特征候选集（LongConcatenatedPathCandidates）。"}
{"text": "对每一个可，就生成路能的组合（x∈N,πℎ∈Pℎ,πt∈Pt），如果P（s←x|πs）＞0且径并且更新其覆盖度，即，同时更新其准确度，即。"}
{"text": "反向同理。"}
{"text": "从路径搜索过程可以看出，相比PRA,CoR-PRA最重要的不同有两方面，一是增加了带有常量的路径特征的搜索，二是搜索过程由单项搜索变成了双向搜索。"}
{"text": "尽管采用了随机游走策略来降低搜索空间，当PRA应用在关系丰富且连接稠密的知识图谱上时，依然会面临路径特征爆炸的问题。"}
{"text": "为了提高PRA的路径搜索效率以及路径特征的丰富度，Gardner[44]提出了SFE（Subgraph_Feature_Extraction）模型，改变了PRA的路径特征搜索过程。"}
{"text": "为了提升路径搜索的效率，SFE去除了路径特征的概率计算这个需要较大计算量的过程，而是直接保留二值特征，仅记录此路径是否在两个实体之间存在，SFE首先通过随机游走采集每个实体的制定步数以内的子图特征，并记录下子图中所有的结束节点实体e，对于某个关系的训练样本实体对（h,t），如果实体ei同时存在于实体h和t的结束实体集中，那么就以ei为链接节点，将h和t对应子图中的结构生成一条h和t之间的路径。"}
{"text": "为了进一步提升路径搜索效率，降低无意义的路径特征，对于图中的一个节点，如果这个节点有很多相同关系边ri连接着不同的实体节点，那么沿着这个关系继续搜索路径会急剧增加子图大小的量级。"}
{"text": "为了进一步提升搜索效率，在SFE中，这个关系ri将不会作为当前深度优先搜索路径中的一个关系，从而停止搜索，并把当前节点当作实体子图中的一个结束节点。"}
{"text": "为了增加子图特征的丰富性，除了PRA中用到的路径特征，SFE还增加了二元路径特征，类似自然语言处理中的bigram，即将两个具有连接的关系组成一个新的关系，例如“BIGRAM：对齐实体/妻子是”，除了二元路径特征，SFE还增加了one-sided_feature,one-sided_path指的是一个存在在给定两个节点之间的路径的，是从起始节点开始，但不一定由另一个节点结束，类似Co-PRA中的带有常量的路径特征。"}
{"text": "SFE还会对给定的两个节点进行one-sided_feature的比较，如果两个节点都具有相同的关系ri，例如“性别是”，那么将会把两个节点的ri以及连接的实体记录下来。"}
{"text": "如果两个节点在关系ri下连接的节点是一样的，那么这个特征是可以被PRA路径特征捕捉到的，但是如果取值不一样就只有SFE能捕捉到。"}
{"text": "SFE同时还利用了关系的向量表示，通过训练好的关系的表示，将已有路径特征中的关系替换为向量空间中比较相似的关系。"}
{"text": "SFE还增加了一个表示任意关系的关系ANYREL来增加路径特征的丰富性。"}
{"text": "总体来说，SFE在PRA的路径特征搜索的效率和特征的丰富性方面做了比较大的提升。"}
{"text": "从基于图结构的PRA系列研究可以看出，被研究得比较多的图结构是与路径相关的结构特征，在利用路径特征的过程中，一个重要的问题是如何有效地搜索到路径，涌现出了很多提升路径搜索效率的研究工作。"}
{"text": "但路径相关的特征还不能覆盖知识图谱中包含的所有语义信息，因而由相关工作通过引入带有实例的路径来丰富图特征所包含的语义信息的类型。"}
{"text": "但是，不是路径形式的图结构特征依然有待挖掘和分析。"}
{"text": "2.典型工具简介或实验对比分析PRA的提出主要是针对很不完整的知识图谱，所以论文中的实验是在知识图谱NELL上进行试验的，图6-12展示了PRA中在预测某一关系时权重最高的两个路径特征，可以看出，这些高权重的路径特征可以看作是预测当前关系的一条置信度较高的规则，具有明显的语义含义。"}
{"text": "PRA在链接预测上与N-FOIL的对比结果如图6-13所示，从结果中可以看出，p@10方面PRA和N-FOIL效果差不多，但是在p@100和p@1000方面，PRA的结果明显优于N-FOIL。"}
{"text": "图6-12PRA关系预测路径图6-13PRA在链接预测上与N-FOIL的对比结果图6-14展示了CoR-PRA在知识图谱推理和命名实体抽取上的实验比较，从实验结果可以看出，CoR-PRA由于提升了路径特征的丰富性，其结果明显优于PRA，但计算效率不及PRA。"}
{"text": "图6-14知识图谱推理及命名实体抽取结果对比图6-15展示了SFE和PRA的性能比较，左边是在同样的拥有10个关系的NELL数据集上PRA和SFE的MAP（Mean_Average_Precision）结果、平均抽取的特征数量以及运行时间的比较。"}
{"text": "从实验预测结果来看，用深度优先搜索策略（BFS）代替了随机游走（RW）的SFE表现最好，并且能够抽取到更多样的特征，且总耗时更短，效率提升明显。"}
{"text": "图6-15SFE和PRA的性能比较典型的PRA系列工具可以参考https://github.com/noon99jaki/pra，集成了PRA以及CoR-PRA算法。"}
{"text": "6.3.2基于规则学习的推理1.方法概述基于规则的推理具有精确且可解释的特性，规则在学术界和工业界的推理场景都有重要的应用。"}
{"text": "规则是基于规则推理的核心，所以规则获取是一个重要的任务。"}
{"text": "在小型的领域知识图谱上，规则可以由领域专家提供，但在大型、综合的知识图谱方面，人工提供规则的效率比较低，且很难做到全面和准确。"}
{"text": "所以，自动化的规则学习方法应运而生，旨在快速有效地从大规模知识图谱上学习置信度较高的规则，并服务于关系推理任务。"}
{"text": "规则一般包含了两个部分，分别为规则头（head）和规则主体（body），其一般形式为rule:head←body.解读为有规则主体的信息可推出规则头的信息。"}
{"text": "其中，规则头由一个二元的原子（atom）构成，而规则主体由一个或多个一元原子或二元原子组成。"}
{"text": "原子（atom）是指包含了变量的元组，例如isLocation(X)是一个一元原子表示实体变量X是一个位置实体；hasWife(X,Y)是一个二元原子，表示实体变量X的妻子是实体变量Y。"}
{"text": "二元原子可以包含两个或一个，例如liveIn(X,Hangzhou)是一个指含有一个实体变量X的二元原子，表示了变量X居住在杭州。"}
{"text": "在规则主体中，不同的原子是通过逻辑合取组合在一起的，且规则主体中的原子可以以肯定或否定的形式出现，例如如下规则：这里的规则示例说明了如果任意实体X的妻子是实体Y，且实体Y的孩子有Z且X和Y都不曾离婚，那么可以推出X的孩子也有Z。"}
{"text": "这条规则里的规则主体就包含了以否定形式出现的原子。"}
{"text": "所以，规则也可以表示为：rule:head←body+∧body−.其中，body+表示以肯定形式出现的原子的逻辑合取集合，而body−表示以否定形式出现的原子的逻辑合取集合。"}
{"text": "如果规则主体中只包含有肯定形式出现的原子而不包含否定形式出现的原子，称这样的规则为霍恩规则（horn规则类型，可以表示为以下形式：rules），霍恩规则是被研究得比较多的a0←a1∧a2∧…∧an.其中，每个ai都为一个原子。"}
{"text": "在知识图谱的规则学习方法中，另一种被研究得比较多的规则类型叫作路径规则（pathrules），路径规则可以表示为如下形式：r0（e1,en+1）←r1（e1,e2）∧r2（e2,e3）∧…∧rn（en,en+1）.其中，规则主体中的原子均为含有两个变量的二元原子，且规则主体的所有二元原子构成一个从规则头中的两个实体之间的路径，且整个规则在知识图谱中构成一个闭环结构。"}
{"text": "这几种不同规则的包含关系如下：路径规则∈霍恩规则∈一般规则.即路径规则是霍恩规则的一个子集，而霍恩规则又是一般规则的一个子集，从规则的表达能力来看，一般规则的表达能力最强，包含各种不同的规则类型，而霍恩规则次之，规则路径的表达能力最弱，只能表达特定类型的规则。"}
{"text": "在规则学习过程中，对于学习到的规则一般有三种评估方法，分别是支持度（support）、置信度（confidence）、规则头覆盖度（headcoverage）。"}
{"text": "下面分别介绍这三种评价指标的计算方法。"}
{"text": "对于一个规则rule，在知识图谱中，其支持度（support）指的是满足规则主体和规则头的实例个数，规则的实例化指的是将规则中的变量替换成知识图谱中真实的实体后的结果。"}
{"text": "所以，规则的支持度通常是一个大于或等于0的整数值，用support(rule)表示。"}
{"text": "一般来说，一个规则的支持度越大，说明这个规则的实例在知识图谱中存在得越多，从统计角度来看，也越可能是一个比较好的规则。"}
{"text": "规则的置信度（confidence）的计算方式为：即规则支持度和满足规则主体的实例个数的比值，即在满足规则主体的实例中，同时也能满足规则头的实例比例。"}
{"text": "一个规则的置信度越高，一般说明规则的质量也越高。"}
{"text": "由于知识图谱往往具有明显的不完整性，而前文介绍的规则置信度计算方法间接假设了不存在知识图谱中的三元组是错误的，这显然是不合理的。"}
{"text": "所以，基于部分完全假设（PartialCompleteness_Assumption,PCA）的置信度（PCA_Confidence）也是一个衡量规则质量的方法，且考虑了知识图谱的不完整性。"}
{"text": "PCA置信度的计算方法为从上面的式子可以看出，和前文介绍的置信度计算方法相比，PCA置信度最大的区别是分母中需要多考虑一个条件r0（x,y′），这里r0（x,y）是规则头，而r0（x,y′）说明在知识图谱中，只要当规则头中的头实体x通过关系r0连接到除y以外的实体时才能算进分母的计数，否则不作分母计数。"}
{"text": "这样考虑的原因是，如果头实体x和关系r0没有在知识图谱中构成相关的三元组，而通过规则主体可以推出三元组r0（x,y），那么根据知识图谱的不完全假设，r0（x,y）只是在知识图谱中缺失而不是错误的三元组，所以，不应该将这类实例化例子计算在分母中，否则会降低规则的置信度。"}
{"text": "所以，在PCA置信度中排除了来自这类实例对置信度值的负向影响。"}
{"text": "规则头覆盖度（Head_Coverage）的计算方法为即规则支持度和满足规则头的实例个数的比值，即在满足规则头的实例中，同时也满足规则主体的实例比例。"}
{"text": "一个规则的置信度越高，一般说明规则的质量也越高。"}
{"text": "规则的支持度、置信度以及头覆盖度从不同的角度反映了规则的质量，但三者之间没有必然的关联关系。"}
{"text": "例如，置信度高的规则，其头覆盖度并不一定高，所以在规则学习中通常会结合这三个评价指标综合衡量规则的质量。"}
{"text": "2.常见算法简介下面介绍具体的规则学习方法，首先介绍典型的规则学习方法AMIE[12]。"}
{"text": "AMIE能挖掘的规则形如：fatherOf（f,c）←motherOf（m,c）∧marriedTo（m,f）.AMIE是一种霍恩规则，也是一种闭环规则，即整条规则可以在图中构成一个闭环结构。"}
{"text": "在规则学习的任务中，最重要的是如何有效搜索空间，因为在大型的知识图谱上简单地遍历所有可能的规则并评估规则的质量效率很低，几乎不可行。"}
{"text": "AMIE定义了3个挖掘算子（Mining_Operators），通过不断在规则中增加挖掘算子来探索图上的搜索空间，并且融入了对应的剪枝策略。"}
{"text": "3个挖掘算子如下：●增加悬挂原子（Adding_Dangling_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个新的变量和一个已经在规则中出现的元素，可以是出现过的变量，也可以是出现过的实体。"}
{"text": "●增加实例化的原子（Adding_Instantiated_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含一个实例化的实体以及一个已经在规则中出现的元素。"}
{"text": "●增加闭合原子（Adding_Closing_Atom）。"}
{"text": "即在规则中增加一个原子，这个原子包含的两个元素都是已经出现在规则中的变量或实体。"}
{"text": "增加闭合原子之后，规则就算构建完成了。"}
{"text": "AMIE的规则学习算法如图6-16所示。"}
{"text": "图6-16AMIE的规则学习算法在探索规则结构的过程中，AMIE还引入了两个重要的剪枝策略，来有效缩小搜索空间。"}
{"text": "AMIE的剪枝策略主要包含两条：●设置最低规则头覆盖度过滤，头覆盖度很低的规则一般是一些边缘规则，可以直接过滤掉。"}
{"text": "在实践中，AMIE将头覆盖度值设为0.01。"}
{"text": "●在一条规则中，每在规则主体中增加一个原子，都应该使得规则的置信度增加，即confidence（a0←a0∧a2∧…∧an∧an+1）＞confidence（a0←a0∧a2∧…∧an）。"}
{"text": "如果在规则中增加一个新的原子an+1，但没有提升规则整体的置信度，那么就将拓展后的规则a0←a0∧a2∧…∧an∧an+1剪枝掉。"}
{"text": "在规则学习过程中，AMIE通过SPARQL在知识图谱上的查询对规则的质量进行评估。"}
{"text": "无论采用哪种挖掘算子来增加规则中的原子，每一个原子都伴随着需要选择一个知识图谱中的关系。"}
{"text": "在选择增加实例化算子时还涉及选择一个实体方面，为了满足选出来的实体和关系组成的原子，在添加到规则中以后，能够满足事先设置的头覆盖度的要求，AMIE用对知识图谱的查询来筛选合适的选项，例如：SELECT?rWHEREa0∧a1∧…∧an∧?r（X,Y）HAVVINGCOUNT（a0）≥k这样经过查询筛选得到的关系候选项满足了一定符合头覆盖度的要求。"}
{"text": "3.典型工具简介图6-17展示了AMIE在不同数据集上的运行效果，从中可以看出AMIE在大规模知识图谱上的效率较高。"}
{"text": "例如，在拥有100多万个实体以及近700万个三元组的DBpedia上，AMIE仅需不到3min就能完成规则挖掘，产生7000条规则，并帮助推理出了12万多个新的三元组。"}
{"text": "图6-17AMIE不同数据集规则挖掘结果对比规则挖掘的典型工具AMIE可参考http://www.mpi-inf.mpg.de/departments/ontologies/projects/amie/，其中包括了进一步提升AMIE效率的AMIE+[45]。"}
{"text": "6.3.3基于表示学习的推理1.方法概述基于图结构的推理和基于规则学习的推理，都显式地定义了推理学习所需的特征，而基于表示学习的推理通过将知识图谱中包括实体和关系的元素映射到一个连续的向量空间中，为每个元素学习在向量空间中表示，向量空间中的表示可以是一个或多个向量或矩阵。"}
{"text": "表示学习让算法在学习向量表示的过程中自动捕捉、推理所需的特征，通过训练学习，将知识图谱中离散符号表示的信息编码在不同的向量空间表示中，使得知识图谱的推理能够通过预设的向量空间表示之间的计算自动实现，不需要显式的推理步骤。"}
{"text": "知识图谱的表示学习受自然语言处理关于词向量研究的启发，因为在word2vec的结果中发现了一些词向量具有空间平移性，例如：vec（king）−vec（queen）≈vec（man）−vec（woman）即“king”的词向量减去“queen”的词向量的结果约等于“man”的词向量减去“woman”的词向量的结果，这说明“king”和“queen”在语义上的关系与“man”和“woman”之间的关系比较近似。"}
{"text": "而拓展到知识图谱上，就可以理解为拥有同一种关系的头实体和尾实体对，在向量空间的表示可能具有平移不变性，这启发了经典的知识图谱表示学习方法TransE的提出以及知识图谱表示学习的相关研究。"}
{"text": "2.常见算法简介首先介绍最经典的TransE[11]模型，为了方便起见，将一个三元组表示成（h,r,t），其中h表示头实体（head_entity）,r表示关系（relation），而t表示尾实体（tail_entity）。"}
{"text": "在TransE中，知识图谱中的每个实体和关系都被表示成了一个向量，按照词向量的启示，TransE将三元组中的关系看作是从头实体向量到尾实体向量的翻译（translation），并对知识图谱将要映射到的向量空间做了如下假设，即在理想情况下，对每一个存在知识图谱中的三元组都满足h+r=t.式中，h是头实体的向量表示；r是关系的向量表示；t是尾实体的向量表示。"}
{"text": "TransE假设在任意一个知识图谱中的三元组（h,r,t），头实体的向量表示h加上关系的向量表示r应该等于尾实体的向量表示t。"}
{"text": "在需要映射到的向量空间中，TransE将关系看作是从头实体向量到尾实体向量的翻译，即头实体向量通过关系向量的翻译得到尾实体，则说明这个三元组在知识图谱中成立。"}
{"text": "等式h+r=t是一个理想情况的假设，根据这个假设，TransE在训练阶段的目标是：对正样本三元组：h+r≈t；对负样本三元组：h+r≉t.h+r和t之间的近似程度可以用向量相似度衡量，TransE采用欧式计算两个向量的相似度，所以TransE的三元组得分函数设计为对于正样本三元组，得分函数值尽可能小；而对于负样本三元组，得分函数值尽可能大。"}
{"text": "然后通过一个正负样本之间最大间隔的损失函数，设计训练得到知识图谱的表示学习结果，其损失函数为式中，S表示知识图谱中正样本的集合；S（′ℎ,r,t）表示（h,r,t）的负样本，在训练过程中三元组（h,r,t）的负样本通过随机替换头实体h或者尾实体t得到；[x]+表示max（0,x）;γ表示损失函数中的间隔，是一个需要设置的大于零的超参。"}
{"text": "TransE的训练目标是最小化损失函数L，可以通过基于梯度的优化算法进行优化求解，直至训练收敛。"}
{"text": "实践证明，TransE由于其有效合理的向量空间假设，是一种简单高效的知识图谱表示学习方法，并且能够完成多种关系的链接预测任务。"}
{"text": "TransE的简单高效说明了知识图谱表示学习方法能够自动且很好地捕捉推理特征，无须人工设计，很适合在大规模复杂的知识图谱上推广，是一种有效的知识图谱推理手段。"}
{"text": "尽管有效，TransE依然存在着表达能力不足的问题，例如按照关系头尾实体个数比例划分，知识图谱中的关系可以分为四种类型，分别为一对一（1-1）、一对多（1-N）、多对一（N-1）以及多对多（N-N）,TransE能够较好地捕捉一对一（1-1）的关系，却无法很好地表示一对多（1-N）、多对一（N-1）以及多对多（N-N）的关系。"}
{"text": "例如，实体“中国”在关系“拥有省份”这个关系下有很多个尾实体，根据TransE的假设，任何一个省份的向量表示都满足v（省份x）:v（中国）+v（拥有省份）=v（省份x），这将会导致TransE无法很好地区分各个省份。"}
{"text": "所以，TransH[46]就提出了在通过关系将头实体向量翻译到尾实体向量之前，先将头实体和尾实体向量投影到一个和当前关系相关的平面上，由于向量空间中的不同向量在同一个平面上的投影可以是一样的，这就帮助TransE从理论上解决了难以处理一对多（1-N）、多对一（N-1）以及多对多（N-N）关系的问题，TransE和TransH的对比向量空间假设对比如图6-18所示。"}
{"text": "图6-18TransE和TransH对比向量空间假设对比TransH为每个关系r都设计了一个投影平面，并用投影平面的法向量wr表示这个平面，h和t的投影向量的计算方法如下：然后，利用投影向量进行三元组得分的计算，即TransH通过设计关系投影平面提升了TransE表达非一对一关系的能力，TransR[8]则通过拆分实体向量表示空间和关系表示向量空间来提升TransE的表达能力。"}
{"text": "由于实体和关系在知识图谱中是完全不同的两种概念，理应表示在不同的向量空间而不是同一个向量空间中，所以TransR拆分了实体表示空间和关系表示空间，如图6-19所示。"}
{"text": "图6-19TransR的实体表示空间和关系表示空间TransR设定所有的计算都发生在关系表示空间中，并在计算三元组得分之前首先将实体向量通过关系矩阵投影向关系表示空间，即：hr=hMr,tr=tMr.然后，利用投影到关系表示空间的头实体向量和尾实体向量进行三元组得分的计算：TransR通过区分实体和关系表示空间增加了模型的表达能力，并提升了表示学习结果，但是在TransR中，每个关系除拥有一个表示向量以外，还对应了一个d×d的矩阵，这相比起TransE增加了很多参数。"}
{"text": "为了减少TransR的参数量且同时保留其表达能力，TransD[47]提出了用一个与实体相关的向量以及一个与关系相关的向量通过外积计算，动态地得到关系投影矩阵，如图6-20所示。"}
{"text": "图6-20TransD实体表示空间和关系表示空间其动态矩阵的计算如下：式中，m,n为关系和实体的向量表示维度；m,n可以相等也可以不相等。"}
{"text": "TransD通过动态计算投影矩阵不仅可以显著减少关系数量较大且实体数量不多的知识图谱中的参数，而且增加了TransD捕捉全局特征的能力，使得其在链接预测任务上的表现比TransR更好。"}
{"text": "之前介绍了以TransE为代表的基于翻译假设的表示学习模型，而知识图谱表示学习的推理能力和采用的向量空间假设有很大关系，除了翻译假设还有其他的空间假设，DistMult[48]采用了更灵活的线性映射假设将实体表示为向量，关系表示为矩阵，并将关系当作是一种向量空间中的线性变换。"}
{"text": "对于一个正确的三元组（h,r,t），假设以下公式成立：式中，h和t分别为头实体和尾实体的向量表示；Mr为关系r的矩阵表示。"}
{"text": "上式表达的hMr=t.意思是头实体通过与关系矩阵相乘，经过空间中的线性变化以后，可以转变为尾实体向量。"}
{"text": "所以，训练目标是对正确的三元组让hMr与t尽可能接近，而错误的三元组尽可能远离。"}
{"text": "与TransE不同的是，DistMult采用向量点积衡量两个向量接近与否，故三元组的得分函数设计如下：f（h,r,t）=hMrt⊺.损失函数与TransE系列的方法相同，设计为基于最大间隔的损失函数。"}
{"text": "由于向量与矩阵的运算比向量的加法运算更灵活，所以整体来说DistMult的效果比TransE效果要好。"}
{"text": "当将关系的矩阵设计为对角矩阵时，参数量与TransE相同，且效果比普通矩阵更好。"}
{"text": "所以，在DistMult系列的方法中，常常将关系的表示设置为对角矩阵。"}
{"text": "基于TransE有很多丰富表达能力的模型，而基于DistMult也有很多提升方法。"}
{"text": "DistMult中一个比较明显的问题是，得分函数的设计使得当关系设计为对角矩阵时，无法隐含所有关系都是对称关系的结论，因为对于一个存在的三元组（h,r,t），经过模型训练以后，f（h,r,t）=hDrt⊺的值会比较大，即表示三元组（h,r,t）是正确的。"}
{"text": "所以，三元组（t,r,h）的得分f（t,r,h）=tDrh⊺的值也会比较大，因为tDrh⊺=hDrt⊺。"}
{"text": "这说明了DistMult天然地假设了所有的关系是对称关系，这显然是不合理的。"}
{"text": "从语义的角度分析，知识图谱中的关系既包含了对称关系如“配偶是”，也包含了不对称关系如“出生地”，而且非对称关系一般还多于对称关系。"}
{"text": "为了解决这个问题，ComplEx[49]将原来基于实数的表示学习拓展到了复数，因为基于复数的乘法计算是不满足交换律的，从而克服了DistMult不能很好地表示非对称关系的问题。"}
{"text": "其得分函数的计算如下：f（h,r,t）=＜Re（h）,Re（r）,Re（t）＞+＜Re（h）,Im（r）,Im（t）＞+＜Im（h）,Re（r）,Im（t）＞−＜Im（h）,Im（r）,Im（t）＞式中，Re（x）表示复数x的实部，Im（x）表示x的虚部，＜x,y,z＞=xyz。"}
{"text": "可以看出在ComplEx中，f（h,r,t）≠f（t,r,h），所以可以更灵活地表达对称与非对称关系。"}
{"text": "类比推理是一种类型重要的推理类型，一个具有良好推理的知识图谱表示学习模型理应具有这种推理的能力，所以，ANALOGY[50]对知识图谱中的类比推理的基本结构进行了分析，并通过在DistMult的学习过程增加两个对于关系矩阵表示的约束，来提升DistMult的模型的类比推理能力，使得模型的整体推理能力得到了提升。"}
{"text": "除目前提到的表示学习方法，还有很多其他思路的表示学习方法，例如纯神经网络方法NTN[51]、ConvE[52]等，这里不再赘述。"}
{"text": "3.典型工具简介或实验对比分析表6-6为常用知识图谱表示学习方法链接预测结果比较，采用的评价指标包括平均排序（Mean_Rank,MR）、倒数平均排序（Mean_Reciprocal_Rank,MRR）以及排序n以内的占比(Hit@n)。"}
{"text": "从实验结果可以看出，整体来说线性变换假设模型的表现优于翻译模型系列。"}
{"text": "表6-6常用知识图谱表示学习方法链接预测结果比较续表常用的关于知识图谱表示学习的工具包有清华开源的OpenKE，它涵盖了常见的表示学习模型，并有PyTorch、TensorFlow以及C++版本。"}
{"text": "全面的关于工具包的信息可以在网站主页获得。"}
{"text": "6.4知识图谱推理新进展6.4.1时序预测推理知识推理中的时序预测新应用以Chen等人[53]提出的模型为例。"}
{"text": "传统的数据流学习主要是从连续和快速更新的数据记录中提取知识结构。"}
{"text": "在语义网中，数据根据领域知识被建模成本体，而数据流则被表示为本体流。"}
{"text": "本文通过探索本体流，重新审视有监督的流学习与上下文的语义推理，开发一种对本体语义进行嵌入的模型，解决了时序预测推理中的概念漂移问题（即数据分布的意外变化，导致大多数模型随着时间的推移不太准确）。"}
{"text": "数据流学习中的概念漂移问题可以看成数据的语义随着时间的漂移。"}
{"text": "本体流可以看成随时间变化的本体，也就是语义增强的数据流。"}
{"text": "在描述逻辑中，本体流包含TBox（术语成分）和ABox（断言公理）。"}
{"text": "ABox_entailment（蕴涵）是基于ABox中的断言公理推理出的隐含的断言。"}
{"text": "Snapshot（快照）反映的是本体流中某一时刻的本体，用于对连续的本体流进行离散化建模，而多个随时间连续的快照构成了本体流中的滑动窗口。"}
{"text": "快照从一个时刻转变到下一个时刻可以看成断言公理的更新，这被称为一阶预测突变；两个快照对于某些蕴涵具有足够大的概率差异，这被称突发预测变化。"}
{"text": "这两种预测变化构成了语义概念漂移。"}
{"text": "蕴涵的滑动窗口之间基于规则的一致性度量和预测可以表示和推断这些本体流中的语义概念漂移。"}
{"text": "通过将传统机器学习中的特征嵌入扩展到本体语义嵌入，将语义推理和机器学习结合起来，即捕获本体流中的一致性和知识蕴涵的向量，然后在有监督的流学习的上下文中利用这种嵌入来学习模型。"}
{"text": "该模型被证明对概念漂移（即突然和不一致的预测变化）是稳健的，同时具有通用性和灵活性等特点，可用于增强基本的流学习算法。"}
{"text": "实验还表明，在模型中，编码语义是一种超越目前最先进模型的方法，具有语义嵌入的模型对知识推理和预测起到重要作用。"}
{"text": "6.4.2基于强化学习的知识图谱推理基于强化学习的知识图谱推理是新兴的处理知识图谱推理的技术手段。"}
{"text": "比较有代表性的工作有文献[13]和[54]。"}
{"text": "文献[13]将知识图谱推理简化为一个“事实判断”（Fact_Prediction）问题，提出了DeepPath模型。"}
{"text": "“事实判断”即确定一个三元组是否成立。"}
{"text": "文献作者将“事实判断”看作是这样一个问题：寻找一条能连接已知头实体h和尾实体t的路径。"}
{"text": "文献作者将此问题建模为序列决策问题，并利用基于策略梯度的强化学习方法REINFORCE求解。"}
{"text": "具体而言，强化学习中智能体的状态被定义为当前节点实体和目标节点实体的联合表示st=（et,etarget−et）.智能体的动作则是在当前节点实体的出边（Outgoing_edge）中选择一个适当的边作为组成路径的关系。"}
{"text": "在选择动作后，智能体的状态会随即更新。"}
{"text": "在奖励函数设计方面，文献作者同时考虑了准确率、路径效率和路径多样性。"}
{"text": "实验证明，DeepPath能学习到等价的推理路径，相比基于表示学习的方法，有更好的可解释性和推理效果。"}
{"text": "文献[54]考虑更有难度的“查询问答”（Query_Answering）问题，提出了MINERVA模型。"}
{"text": "与“事实判断”相比，“查询问答”无法预知答案对应的尾实体，需要从知识图谱中寻找可作为答案的尾实体。"}
{"text": "在这类知识图谱推理问题中，需要尽可能避免遍历大规模知识图谱，影响算法的效率。"}
{"text": "文献作者将这类问题建模成部分可观察的马尔科夫决策过程（POMDP）。"}
{"text": "我们可以想象一个智能体在知识图谱上游走，寻找目标尾实体。"}
{"text": "智能体的当前状态与它所处的当前实体有关，其动作即该实体可选的出边。"}
{"text": "尽管整个知识图谱中的关系总数可能繁多，但具体到某一实体，可选的出边往往减少一个或两个数量级，可大幅降低遍历的规模。"}
{"text": "实验结果表明：在这类“查询问答”的推理任务上，MINERVA模型远远超过了未使用强化学习的基于随机游走的模型。"}
{"text": "同时，当路径较长时，仍有良好的表现，具有鲁棒性。"}
{"text": "6.4.3基于元学习的少样本知识图谱推理在以往常见的基于表示学习的推理模型中，往往都会利用大量的数据对模型进行训练，并且当前大多数的研究都会假设对于其实验使用的知识库，所有的关系都有充足的三元组用来训练。"}
{"text": "但在真实的知识图谱中，有大量的关系仅仅具有非常少的三元组实例，称这种关系为长尾关系（Long-Tail_Relation），这类关系多被以往的研究忽视。"}
{"text": "但事实上，对于某一个关系，其具有的三元组实例越少，其对知识图谱的补全越有利用的价值。"}
{"text": "元学习的目的是解决“学习如何学习”（Learning_to_Learn），旨在通过少量样本迅速完成学习，其相对主要的应用是少样本学习（Few-Shot_Learning）。"}
{"text": "当前主要的元学习方法分为三类，基于度量（Metric-Based）、基于模型（Model-Based）和基于优化（Optimization-Based）的方法。"}
{"text": "关于元学习的研究，一开始主要应用于图像分类[55-57]，研究者近来尝试使用元学习的方法解决知识图谱中有关长尾关系的推理。"}
{"text": "XIONG等人[58]提出了使用基于度量的方法对长尾关系做少样本的链接预测，也就是在某一种关系的样本实例较少的情况下，通过头实体和关系对尾实体进行预测。"}
{"text": "HAN等人[59]确切地描述了关系分类的少样本学习任务，并提出了一个用于测试少样本关系分类（Few-Shot_Relation_Classification）的数据集FewRel，在将近来效果突出的少样本学习模型应用于该数据集后，对少样本知识图谱推理的难点进行了分析。"}
{"text": "把元学习应用于少样本知识图谱推理的研究还相对较少，该领域还有很多可以挖掘和研究的地方。"}
{"text": "6.4.4图神经网络与知识图谱推理近年来提出的图神经网络（Graph_Neural_Networks,GNNs）主要用于处理图结构的数据，随着信息在节点之间的传播以捕捉图中节点间的依赖关系，其图结构的表示方式使得模型可以基于图进行推理。"}
{"text": "而知识图谱作为一种典型的图结构数据，图神经网络在知识图谱的表示学习和推理方面贡献颇多，如知识库补全（链接预测、实体分类）等任务。"}
{"text": "Takuo_Hamaguchi_[60]主要针对KG中的OOKB（out-of-knowledge-base）实体进行知识库补全等任务。"}
{"text": "OOKB实体，即在训练过程中未被训练到的实体，无法得到其Embedding表示，从而无法预测其与知识库中其他实体之间的关系。"}
{"text": "而文中将知识库补全的任务定义为：基于知识库中已存在的三元组和当前出现的包含新实体的三元组，推理当前新实体与知识库中其他实体之间的关系。"}
{"text": "基于此，可以通过知识库中现有的实体表示推理得到OOKB实体表示。"}
{"text": "因此，这篇文献利用GNN中节点表示的方式，以OOKB实体分别为头实体、尾实体的三元组集合为周围邻居，对当前OOKB实体进行表示。"}
{"text": "每个实体节点经GNN的信息传播获取新的表示。"}
{"text": "基于此，通过TransE等经典模型，进行知识库补全任务。"}
{"text": "Schlichtkrull[61]利用R-GCNs（Relational_Graph_Convolutional_Networks）进行链接预测和实体发现等任务。"}
{"text": "本文的思想同样基于已知实体或关系在图结构中周围节点的结构，推理得到未知节点的表示，从而可对知识库中缺失的实体获取它们的Embedding向量。"}
{"text": "同时，结合TransE和DisMult等表示学习模型，进行知识库中缺失元素的补全任务。"}
{"text": "文献提出的R-GCNs，基于GCN进行图中节点信息的传播，同时考虑到真实知识库场景中的多关系类型数据，本文提出了两个正则化的优化方法，以此对由不同类型的关系连接的实体进行表示。"}
{"text": "实验结果证明，本文提出的方法对比传统的表示学习模型具有很大的提升。"}
{"text": "GNN模型的引入丰富了知识库中实体和关系元素的表达，尤其是在得到未知实体或关系的表示等方面具备一定的推理能力，针对目前在知识图谱表示学习和推理等方面遇到的问题，相信GNN一定能发挥出重要的作用。"}
{"text": "6.5开源工具实践：基于Jena和Drools的知识推理实践6.5.1开源工具简介Jena是一个免费且开源的支持构建语义网络和数据连接应用的Java框架，提供了处理RDF、RDFS、OWL数据的接口，一个规则引擎，用于查询的三元组的内存存储。"}
{"text": "Drools（JBoss_Rules）具有一个易于访问企业策略、易于调整以及易于管理的开源业务规则引擎，符合业内标准，具有速度快、效率高的特点。"}
{"text": "业务分析师或审核人员可以利用它轻松查看业务规则，从而检验已编码的规则是否执行了所需的业务规则。"}
{"text": "JBoss_Rules的前身是Codehaus的一个开源项目——Drools。"}
{"text": "现在被纳入JBoss门下，更名为JBoss_Rules，成为JBoss应用服务器的规则引擎。"}
{"text": "Drools是基于Charles_Forgy的RETE算法的规则引擎为Java量身定制的实现，具有OO接口的RETE，使得商业规则有了更自然的表达。"}
{"text": "6.5.2开源工具的技术架构图3-42所示为Jena框架。"}
{"text": "如图6-21所示为Drools框架。"}
{"text": "图6-21Drools框架规则引擎实现了数据同逻辑的完全解耦。"}
{"text": "规则并不能被直接调用，因为它们不是方法或函数，规则的激发是对Working_Memory中数据变化的响应。"}
{"text": "结果（Consequence，即RHS）作为LHS_events完全匹配的Listener。"}
{"text": "数据被assert进WorkingMemory后，和RuleBase中rule的LHS进行匹配，如果匹配成功，则这条rule连同和它匹配的数据（Activation）一起被放入Agenda，等待Agenda激发Activation（即执行rule的RHS）。"}
{"text": "6.6本章小结知识图谱是一种重要的组织知识的方式，知识图谱上的推理任务在其生命周期的各个阶段都存在，基于知识图谱的推理方法可大致分为基于演绎的推理和基于归纳的推理，而这两种不同的推理策略都包含了多种推理方法。"}
{"text": "（1）基于演绎的知识图谱推理可能有以下发展趋势：●演绎推理方法的效率是阻碍它们被广泛应用的瓶颈之一，通过并行技术、模块化技术、递增式推理技术和其他优化技术，实现高效推理机是演绎推理研究的趋势。"}
{"text": "●目前的演绎推理方法在处理流数据和移动数据方面还缺少完善的理论以及实用化算法，如何处理流数据的动态性以及时序性是值得研究的方向。"}
{"text": "（2）基于归纳的知识图谱推理可能有以下发展趋势：●尽管归纳推理主要是基于对已有数据的观察总结，但在归纳推理中也将逐渐融入先验的语义信息，例如规则等，使得归纳推理不仅仅是基于大量数据的观察，同时也包含先验知识的约束，从而达到更精准的推理。"}
{"text": "●不同的归纳推理方法，例如基于图结构、基于规则学习和基于表示学习的推理应该互相融合，形成优势互补，完成更智能的推理。"}
{"text": "（3）整体来说，知识图谱推理可能有以下发展趋势：●演绎和归纳两种不同的推理方式将逐渐融合，充分发挥各自的优势并互相补充，两者同时作用能完成更复杂、多样的知识图谱推理任务。"}
{"text": "●任何知识图谱都具有不完整性，仅仅基于知识图谱本身的推理无法突破不完整性的限制，因此外部信息，例如文本、图像等信息可能是很好的补充。"}
{"text": "第7章语义搜索王昊奋上海乐言信息科技有限公司，王萌东南大学知识图谱能够赋予信息明确的结构和语义，使机器不仅可以直观地显示这些信息，更能够理解、处理和整合它们。"}
{"text": "近年来，随着链接开放数据LOD（Linked_Open_Data）、OpenKG等项目的全面展开，知识图谱数据源的数量激增，大量以RDF为数据模型的图结构语义数据被发布，如DBpedia[1]、Wikidata[2]、zhishi.me[3]等。"}
{"text": "互联网从仅包含网页和网页之间超链接的文档万维网逐渐转变成包含大量描述各种实体和实体之间丰富关系的语义万维网。"}
{"text": "在这种背景下，以谷歌为代表的各大搜索引擎公司纷纷构建知识图谱来改善搜索质量，从而拉开了语义搜索的序幕。"}
{"text": "与传统互联网中的文档检索不同，语义搜索需要处理粒度更细的结构化语义数据，因此也面临着前所未有的挑战[4]。"}
{"text": "原有成熟的针对非结构化的、Web文档的存储与索引技术对知识图谱不再适用。"}
{"text": "现有的排序算法也不能直接应用到面向实体和关系的知识图谱语义搜索中。"}
{"text": "以SPARQL查询为代表的结构化查询语言的出现，为支持知识图谱的语义搜索提供了基础。"}
{"text": "此外，支持用户熟悉的关键词、自然语言查询对于知识图谱的语义搜索也至关重要。"}
{"text": "本章旨在全面系统地介绍以RDF为数据模型的知识图谱语义搜索基础技术以及面临的挑战。"}
{"text": "7.1语义搜索简介搜索也称信息检索（Information_Retrieval），是从信息资源集合获得与信息需求相关的信息资源的活动[1]。"}
{"text": "近年来，在互联网和企业应用上，搜索技术受到了广泛的关注和应用。"}
{"text": "其中，最广泛的信息检索主要是面向文档为单位的检索（Document_Retrieval）。"}
{"text": "此外，面向数据的检索（Data_Retrieval）也受到越来越多的关注，主要包括基于数据库的检索和基于知识库的检索，其特点是能够提供更精确的答案[5]。"}
{"text": "面向文档和面向数据两种模式间的技术差异大致可以分为三个部分，即对用户需求的(Query_Model）、对底层数据的表示（Data_model)和匹配技术（Matching_Technique）"}
{"text": "面向文档的信息检索主要通过轻量级的语法模型（Lightweight_Syntax-Centric_Model）表示用户的检索需求和资源的内容，即目前占主导地位的关键词模式——词袋模型（Bag-of-Words）。"}
{"text": "这种技术对主题搜索（Topic_Search）的效果很好，即给定一个主题检索相关的文档，但不能应对更加复杂的信息检索需求。"}
{"text": "相比来说，基于数据库Model）和匹配技术（Matching和基于知识库的检索系统能够通过使用表达能力更强的模型来表示用户的需求，并且利用数据内在的结构和语义关联，允许更为复杂的查询，进而提供更加精确和具体的答案。"}
{"text": "语义关注的是能用于搜索的资源的含义。"}
{"text": "这些含义是通过语义模型构建的，例如语言学模型和概念模型。"}
{"text": "其中，语言学模型主要侧重对词语级别的关系建模、分类以及构建同义词库，而概念模型主要侧重对论域中的语法元素的关系建模，以及从语法元素到论域的映射。"}
{"text": "此外，语义模型要求必须具备表达能力，即语言和建模结构的数量。"}
{"text": "同时，语义模型还必须能够形式化，即解析过程必须是可计算的。"}
{"text": "可见，不同的语义模型对应的搜索技术也不同。"}
{"text": "也就是说，并不存在单一类型的语义搜索技术，而是利用各种不同表达能力的语义模型的搜索系统。"}
{"text": "显然，基于数据库和基于知识库的检索系统属于重量级语义搜索系统，因为它们采用显式的和形式化的模型，例如关系数据库中的E-R图、RDF和OWL中的知识模型。"}
{"text": "近年来，语义数据的数量不断增加，特别是RDF数据，通过标记的方式已经嵌入在许多网页文档中，或与文档形成了关联。"}
{"text": "通过在检索过程中结合使用这些表达能力更强的类型数据，纯粹面向文档的检索系统已经包含了一定程度的语义使用，已经变成了轻量级的语义搜索系统。"}
{"text": "如图7-1所示，一个语义搜索系统的基本框架包括查询构建、查询处理、结果展示、查询优化、语义模型、资源及文档等。"}
{"text": "受益于结构化和语义数据的可用性的增加，重量级语义搜索系统的使用不再局限于专用领域，可能在更大规模的场景（例如Web）中找到其应用。"}
{"text": "目前，大量的语义网络搜索系统已经被构建，其目的是利用互联网上大量的RDF数据及表达Web上可用的OWL本体。"}
{"text": "一方面，可以采用应用于信息检索领域的方法和技术来解决可扩展性问题，以克服Web数据的质量问题，并处理与长文本描述相关的数据元素[6]。"}
{"text": "另一方面，也可以直接将数据库和语义网技术应用于信息检索问题，将丰富的结构化和高度表达的数据的可用性提高到搜索过程中。"}
{"text": "总的来说，不同的技术路线和语义搜索系统不仅在使用的数据方面存在趋同，而且在搜索中应用的技术也趋于一致。"}
{"text": "文档检索与数据检索之间逐渐因为语义搜索的出现变得没有明确的界限，语义在一定程度上始终参与检索过程。"}
{"text": "目前，最先进的语义搜索系统结合了一系列技术，包括结构化查询语言的构建、基于统计的信息检索排序方法、有效索引和查询处理的数据库方法以及复杂推理等技术。"}
{"text": "图7-1语义搜索基本框架7.2结构化的查询语言语义搜索的核心在于查询的构建和理解，本小节主要介绍面向知识图谱的标准结构化查询语言。"}
{"text": "回顾前面章节中的内容，知识图谱的数据模型为RDF，它是W3C推荐的用于表示语义信息的重要数据标准。"}
{"text": "RDF的核心思想是通过RDF三元组的形式描述事实知识。"}
{"text": "多个RDF三元组组成的集合构成了RDF数据集。"}
{"text": "目前，RDF已经成为知识图谱的主要描述格式，越来越多的知识图谱数据以RDF三元组的形式发布出来。"}
{"text": "多个知识图谱通过RDF三元组之间相互关联，形成了一个巨大的数据关联网络。"}
{"text": "以LOD为例，整个项目已经包含超过1000多亿条RDF三元组并依然在快速增加，蕴含了丰富的信息资源。"}
{"text": "精确查询并获取知识图谱中三元组中的有关信息是语义搜索的核心。"}
{"text": "SPARQL查询语言是面向RDF图的结构化查询语言，目前已被W3C推荐为RDF数据的标准查询语言[2]，其地位和查询形式都类似于关系数据库的SQL语言。"}
{"text": "W3C推荐RDF数据集的发布者在发布数据的同时，能够提供相应的SPARQL检索引擎和查询接口。"}
{"text": "以Apache软件基金会的Jena[3]项目为代表的一些SPARQL开源框架，进一步促进了组织机构和个人快速方便地搭建自己的SPARQL查询服务。"}
{"text": "SPARQL查询的核心处理单元是类似RDF三元组形式的三元组模式（TriplePattern），不同之处在于SPARQL的三元组模式中，主语、谓语或宾语可以是变量（以“?”开头标识）。"}
{"text": "例如，三元组模式<?film,director,Tim_burton>可以用来查询“蒂姆·伯顿执导的电影有哪些？”同样，类似于RDF三元组可以组成RDF图的道理，由多个SPARQL三元组模式组成的集合称作基本图模式（Basic_Graph_Pattern,BGP），基本图模式可以用来表示更为明确、复杂的查询需求。"}
{"text": "例如，基本图模式{<?film,director,Timburton>,<?film,released,?date>}可以用来查询“蒂姆·伯顿执导的电影和每部电影具体的上映时间”。"}
{"text": "除此之外，SPARQL查询还定义了多个基本图模式之间进行的运算操作，以及基本图模式与RDF图匹配完成后的结果过滤操作（Filter_Operator），如可以用？date大于1990（?date>1990）对前面一个查询例子中的电影日期进行限制。"}
{"text": "最后，在SPARQL1.1版本中，还增加了联合查询功能，即支持通过FROM和嵌套查询的方式，进>行多个数据源联合查询。"}
{"text": "据不完全统计[4]，目前互联网上1.49×1011条三元组数据可以通过总计557个SPARQL查询终端查询获取，占全部三元组的99.87%[7]。"}
{"text": "为了便于读者更好地理解SPARQL查询、三元组模式、SPARQL基本图模式以及约束条件，图7-2展示了一个有关电影信息的知识图谱和SPARQL样例。"}
{"text": "图7-2有关电影信息的知识图谱和SPARQL样例SPARQL查询包括查询、插入和删除操作。"}
{"text": "下面将以图7-2中的样例知识图谱和对应的SPARQL查询实例，分别介绍如何使用SPARQL对知识图谱进行数据查询、数据插入以及数据删除操作。"}
{"text": "注意，图中的f1342、f1336、f1333以及p2556用来代指电影节点的IRIs。"}
{"text": "7.2.1数据查询SPARQL官方标准定义了四种最终返回给用户查询结果的形式，代表着四种基本的查询功能，即SELECT、ASK、CONSTRUCT和DESCRIBE。"}
{"text": "其中，SELECT是唯一可以返回知识图谱中图模式匹配具体结果给用户的形式，也是最常用的查询语句；ASK查询语句主要用于测试知识图谱中是否存在满足给定查询约束条件的数据，结果以Yes或No的形式返回，除此之外没有额外的信息返回；CONSTRUCT查询语句主要用于将图模式匹配结果生成新的RDF图；DESCRIBE查询语句用于查询与指定IRI相关的数据，注意和SELECT有区别。"}
{"text": "下面结合实例分别对四种查询形式进行介绍。"}
{"text": "1.SELECT的基本语法其中，“SELECT”指明了查询的形式。"}
{"text": "“SELECT”后面的“变量1变量2…”表示图匹配后想要查询的具体目标。"}
{"text": "“FROM”指明了数据源，在通常情况下，在单个知识图谱中查询时，默认不指明数据集的名称，即可以省略SPARQL查询中的FROM字段（后续其他形式的查询语句介绍中将不再提及FROM部分）。"}
{"text": "“WHERE”语句后面的大括号中就是具体的基本图模式和约束条件（FILTER字段给出）。"}
{"text": "值得注意的是，“WHERE”语句后面至少应该包含一个基本图模式（在查询语法中，不同的三元组模式在大括号中用英文句点“.”间隔），而约束条件为可选项。"}
{"text": "最后的修饰符[5]（Modifier）同样是可选项，主要用于对查询的结果进行一些处理，常见的有排序操作ORDER、限制结果数量操作LIMIT等。"}
{"text": "典型的SELECT查询如图7-3所示。"}
{"text": "图7-3典型的SELECT查询2.ASK的基本语法其中，“ASK”指明了查询的形式。"}
{"text": "“ASK”后面的内容和SELECT中的“WHERE”部分类似。"}
{"text": "例如，如果想要查询图7-2中的知识图谱是否存在“Tim_Burton”这个人，那么对应的SPARQL查询语句为上述查询的结果将为“Yes”；假如图7-2中没有“Tim_Burton”节点，结果将为“No”。"}
{"text": "3.CONSTRUCT的基本语法其中，“CONSTRUCT”指明了查询的形式。"}
{"text": "“CONSTRUCT”后面的“图模板”类似于基本图模式，指明了生成的RDF应该具有的基本三元组内容。"}
{"text": "而“WHERE”语句后面的基本图模式和SELECT语句中的类似，用于图模式匹配和约束。"}
{"text": "CONSTRUCT查询的基本流程为：首先执行“WHERE”语句进行图模式匹配，从知识图谱中抽取满足条件的目标变量；随后，针对每一个目标变量，替换图模板中的对应变量，生成最终的如，在图7-2中的知识图谱上运行如下CONSTRUCT查询语句：RDF图。"}
{"text": "例将得到如下新的RDF图：4.DESCRIBE的基本语法其中，“DESCRIBE”指明了查询的形式。"}
{"text": "在“DESCRIBE”后面可以直接指明资源标识符，也可以用变量标识。"}
{"text": "“WHERE”语句后面的基本图模式和SELECT语句中的类似，用于图模式匹配和约束，不同之处在于DESCRIBE中的WHERE部分是可选项。"}
{"text": "例如，想要在图7-2的知识图谱中获取所有和“Tim_Burton”相关的信息，可以运行如下的DESCRIBE查询语句：对应的结果为：7.2.2数据插入SPARQL支持通过INSERTDATA语句，将新的RDF三元组插入已有的RDF图中。"}
{"text": "具体的基本语法为：其中，INSERT_DATA指明了查询的形式。"}
{"text": "在INSERT_DATA后面可以是单条三元组，也可以是多条三元组构成的RDF图。"}
{"text": "在查询语法中，英文分号“;”可以用来连续插入头实体相同的三元组。"}
{"text": "如果RDF图中已经存在某条将要插入的三元组，那么该条三元组将被忽略。"}
{"text": "例如，可以将如下的三元组插入图7-2的知识图谱中。"}
{"text": "对应的查询语句为：7.2.3数据删除SPARQL的删除语句支持通过DELETE_DATA语句将RDF图中已有的某些三元组删除。"}
{"text": "具体的基本语法为：其中，DELETE_DATA指明了查询的形式。"}
{"text": "与插入语句类似，在DELETE_DATA后可以是单条三元组，也可以是多条三元组构成的RDF图。"}
{"text": "如果RDF图中已经存在将要删除的三元组或RDF图，那么该条三元组或RDF图在语句执行后将被删除。"}
{"text": "例如，可以将如下的三元组从图7-3所示的知识图谱中删除：对应的查询语句为：以上主要介绍了SPARQL的查询、插入以及删除方法，这是最基本的三种查询形式。"}
{"text": "SPARQL虽然没有支持更新操作的语法，不过可以通过DELETE_DATA和INSERT_DATA结合使用来实现。"}
{"text": "此外，在SPARQL1.1版本中增加了联合查询、简单蕴涵推理等内容，感兴趣的读者可以查阅相关标准规范。"}
{"text": "7.3语义数据搜索目前，得益于W3C完成RDF语言和协议的标准化，互联网上的不同RDF数据能够以RDF链接的形式链接在一起，形成一个完整的语义链接数据网络，也称作数据Web。"}
{"text": "并且，不同的场景都能够有一个公共的术语词汇表，以及精确的术语含义说明。"}
{"text": "数据Web提供了丰富的信息，很多传统的搜索引擎都尝试将链接数据整合到其搜索结果中，如图7-4所示。"}
{"text": "图7-4基于链接数据的语义搜索然而，有效地对整个数据Web进行精准的语义搜索还面临如下挑战：●可扩展性。"}
{"text": "对数据Web的有效利用要求基础架构能在大规模和不断增长的内链数据上扩展和应用。"}
{"text": "●异构性。"}
{"text": "如图7-5所示，主要包括：如何进一步整合数据源（补充RDF链接）；如何从不同的数据源中找到与查询相关的数据；如何合并来自不同数据源的查询结果。"}
{"text": "图7-5多源知识图谱的异构性●不确定性。"}
{"text": "用户事先不能准确地了解自己的需求，所以需求的描述往往不完整。"}
{"text": "这就要求语义搜索系统支持以不精确的方式匹配需求和数据，并对结果进行排序，能够足够灵活以应对条件的变化。"}
{"text": "当前，链接数据比较成熟的语义搜索主要包括：面向本体的搜索引擎，如Swoogle[8]、Watson[9]；面向实体的搜索引擎，如Sigma_on_Sindice[10]、FalconS[11]；以及面向细粒度数据Web的搜索引擎，如SWSE[12]、Hermes（SearchWebDB）[13]。"}
{"text": "这些搜索引擎的基本组成都包括三元组存储、索引构建、查询处理及排序等，具体内容如下：1.三元组存储基于IR的存储方式，即单一的数据结构和查询算法，针对文本数据进行排序检索来优化。"}
{"text": "其优点是高度可压缩、可访问，且排序是整个存储索引的组成部分，缺点是不能处理结构化查询中简单的选择、联结等操作。"}
{"text": "基于DB的存储方式，即多种索引和查询算法，以适应各种结构化数据的复杂查询需求。"}
{"text": "其优点是能够完成复杂的选择、联结等操作，进而支持SPARQL结构化查询，并且能应对高动态场景（许多插入或删除），缺点是空间开销增大和访问有一定的局限性，并且无法集成对检索结果的排序。"}
{"text": "原生存储（Native_Stores）即直接以RDF图形式的存储方式。"}
{"text": "其优点是高度可压缩，可访问类似IR的检索排序，支持选择、联结等操作，并且可在亚秒级时间内在单台机器上完成对TB级数据的查询，以及支持高动态场景，缺点是没有事务、恢复等功能。"}
{"text": "2.索引构建目前主要的方式都是重用IR索引来索引RDF语义数据。"}
{"text": "IR索引主要包括以下几个核心概念：文档、字段（例如，标题、摘要、正文……）、词语、Posting_list和Positionlist[6]。"}
{"text": "而利用IR索引来索引RDF数据的核心思想是将RDF转换成具有fields和terms的虚拟文档，如图7-6所示。"}
{"text": "图7-6基于IR索引的RDF语义数据索引示例值得一提的是，语义Web上的链接数据规模已经非常庞大，不可能对其完全重建索引，需要采用增量索引的方法。"}
{"text": "在增量索引的过程中，因为移动大量元素非常耗时，所以还需要设计基于块的索引扩展，同时考虑块大小对索引性能的影响，最后做到权衡索引更新、搜索和索引块大小之间的平衡。"}
{"text": "3.查询处理和排序首先，查询处理的核心步骤是给定查询输入，将其构建成复杂的结构化查询。"}
{"text": "在此基础上，执行生成的结构化查询。"}
{"text": "不同拓扑结构的结构化查询的查询效率往往有很大不同[7]，如图7-7所示，从DBpedia和LUBM[14]的查询日志中抽取的5个典型的查询拓扑结构，其相应时间明显不同。"}
{"text": "所以，合理利用缓存可以大大提高效率，精心设计的查询功能的优化算法也可以缩短响应时间，效率和查询表达式的复杂程度之间总是有一个折衷点。"}
{"text": "图7-7不同拓扑结构的查询和其相应时间对于查询结果的排序，通常需要考虑以下原则：●质量传播（Quality_Propagation）。"}
{"text": "一个元素的分数可以看成是其质量的度量，质量传播即通过更新这个分数，反映该元素的相邻元素的质量。"}
{"text": "例如，当查找匹配关键字“战争”的美国总统的接班人时，肯尼迪应该排在前面，因为他的前任总统艾森豪威尔与“战争”紧密相关。"}
{"text": "●数量聚合。"}
{"text": "除质量外，还要考虑邻居的数量。"}
{"text": "因此，如果有更多的邻居，元素排名会更高。"}
{"text": "例如，在查询“找到图灵奖获得者工作的机构”,CMU、UC伯克利和IBM是排在前三名的机构，因为他们拥有最多的图灵奖获得者。"}
{"text": "并且，排序方案需要满足单调性。"}
{"text": "数据Web的查询及答案在通常情况下都涉及多个数据源，如图7-8所示。"}
{"text": "图7-8涉及多数源的查询及答案针对多数据源的情况，前提是对分布在不同数据源的数据进行融合，进而查询及处理，在多数据源、多存储的场景下进行语义数据搜索。"}
{"text": "Hermes系统[13]就是一个典型的多数据源语义数据搜索框架，如图7-9所示，包括数据源融合，用户意图理解以及搜索和优化。"}
{"text": "各个环节的详细内容感兴趣的读者可以查阅相关论文。"}
{"text": "图7-9Hermes多数据源语义数据搜索框架语义数据搜索有多种研究原型，既可以直接应用IR技术以增强原有搜索系统的扩展性，也可以直接设计支持处理复杂查询的语义搜索系统，但是数据质量依然是一个问题，如何针对多数据源进行高质量的映射、理解用户的查询意图以及集成IR和DB排序以处理复杂查询，是未来设计语义数据搜索的关键。"}
{"text": "7.4语义搜索的交互范式理解用户的查询意图在于将用户的查询输入构建成结构化的查询语言SPARQL，或者让用户直接提出结构化的查询，然而这种方式需要用户具备以下基本能力：熟悉知识图谱数据源，熟悉知识图谱的数据模式，了解知识图谱中数据大致包含哪些内容，熟练掌握结构化的查询语言。"}
{"text": "然而，大部分的情形是普通用户往往不具备以上的能力，即使是知识图谱的专家或开发者，也很难完全熟悉每一个图谱的模式和内容。"}
{"text": "所以，知识图谱的有效语义搜索需要一种简单高效的搜索范式，即允许用户以直观的、透明的、易用的方式对数据进行查询和浏览[13]。"}
{"text": "此类常见的交互范式主要包括：关键词查询、自然语言查询、分面查询、表单查询、可视化查询以及混合方式查询等[15]。"}
{"text": "目前，最先进的语义搜索系统会结合一系列技术，从基于统计的IR排序方法、有效索引和查询处理的数据库方法到推理的复杂推理技术。"}
{"text": "在设计相应的交互范式和语义搜索系统时，需要明白语义搜索的核心在于能够支持表现形式丰富的信息需求，即查询的表达能力至关重要。"}
{"text": "然而，用户需求的表示通常不完整，表现在用户事先并不能准确了解自己的信息需求，进而无法完全准确地描述查询输入。"}
{"text": "所以，需要设计一种直观且支持复杂信息需求表达的方式，以不精确的方式匹配需求和数据，并对结果进行排序，足够灵活以应对条件的变化。"}
{"text": "在此基础上，设计查询处理、结果展示以及查询优化等其他环节。"}
{"text": "7.4.1基于关键词的知识图谱语义搜索方法近年来，各大商业搜索引擎的成功表明用户使用关键字进行搜索非常舒适，这是由于关键词能够直观地表达信息需求[16]。"}
{"text": "基于关键词查询和自然语言自动问答形式的知识图谱语义搜索引起广泛关注。"}
{"text": "知识图谱上的关键词查询主要可以分为两类[17]：基于关键词直接在知识图谱上搜索答案；基于关键词生成结构化的查询，进而提交给查询引擎得到结果。"}
{"text": "1.基于关键词直接在知识图谱上搜索答案将关键词在知识图谱上直接进行搜索的方法，其核心思想是采用知识图谱子图定位的策略。"}
{"text": "基本流程是建立有效的关键词和知识图谱子图的索引，对于给定的关键字查询，首先在索引上匹配得到候选的知识图谱子图，进而实现对搜索空间的剪枝。"}
{"text": "最后，在小范围的知识图谱子图上进行搜索，找到最终的查询答案。"}
{"text": "该类方法的核心在于索引的构建，其构建方式直接决定搜索的效率和结果的质量。"}
{"text": "常见的索引方式有：（1）关键词倒排索引。"}
{"text": "通过构建索引，快速定位知识图谱中包含关键词的实体。"}
{"text": "（2）摘要索引。"}
{"text": "主要是构建一些包含结构化查询实体和关系类别的索引，在线上处理时根据类别摘要进行扩充。"}
{"text": "（3）路径索引。"}
{"text": "主要借助关键词中包含的查询起始和终止结点，在图上按路径搜索提高查询效率。"}
{"text": "基于关键词直接在知识图谱上搜索答案主要可以解决简单的语义搜索，即查询答案仅仅出现在单条知识图谱三元组中，对于复杂的语义查询往往无法适用。"}
{"text": "基于此需求，将关键词转化为结构化的查询方法应运而生。"}
{"text": "2.基于关键词生成结构化的查询将关键词集合转化为结构化的查询方法主要包括三个步骤：（1）关键词映射。"}
{"text": "进行映射的主要原因是用户输入的关键词和知识图谱上的实体关系往往存在语义鸿沟，例如，关键词“妻子”在知识图谱可能对应的是“配偶”。"}
{"text": "所以，需要将关键词映射到知识图谱上实体、关系以及文本内容等。"}
{"text": "在此过程中，需要对知识图谱进行预处理，构建关键词和知识图谱实体和边的索引，进而在知识图谱上快速定位与关键词相关的实体和关系。"}
{"text": "（2）候选结构化查询构建。"}
{"text": "映射关键词后，生成了对应的实体和关系。"}
{"text": "在知识图谱中，基于生成的实体和关系拓展，能够生成局部的知识图谱子图，就得到了结构化查询需要的查询图结构。"}
{"text": "在此基础上，根据查询意图，将局部子图中的部分实体和关系替换位变量，进而生成结构化的查询。"}
{"text": "（3）候选结构化查询排序。"}
{"text": "在关键词映射过程中，一个关键词往往会映射到知识图谱中的多个实体或关系，进而发现多个局部子图，生成多个结构化的查询。"}
{"text": "因此，需要对生成的结构化查询集合进行排序。"}
{"text": "例如，可以基于关键词搜索相似度、实体的拓扑度分布等指标来计算排序评分。"}
{"text": "值得一提的是，基于关键词的语义搜索还需要考虑对查询结果进行排序，让用户通过观察排序结果进而更新关键词。"}
{"text": "常见的TF/IDF等排序方法均可以采用，这里不再赘述。"}
{"text": "7.4.2基于分面的知识图谱语义搜索分面（Facet）概念最早是由“印度图书馆学之父”S.R.Ranganathan提出来的，用于表示图书文献的多维属性，并在此基础上提出了第一种图书分面分类法——冒号分类法（Colon_Classification)。"}
{"text": "在该分面分类法中，每一个大类图书由五个基本的分面组成：主体、物质、动力、空间和时间。"}
{"text": "此后，很多文献进一步给出分面这一概念的特性和定义。"}
{"text": "典型的定义将分面描述为属性或一组分类体系（category），或将分面定义为某个主题的维度或侧面。"}
{"text": "基于分面的语义搜索已经在工业界取得了广泛应用，如图7-10所示的是Ebay的商品分面搜索系统。"}
{"text": "图7-10Ebay的商品分面搜索系统具体到知识图谱上的分面搜索，可以根据RDF三元组定义分面和值，即分面可以被object是分面的看作一个在当前结果集中的RDF资源（实体）的属性，这些属性的值[18,19]，如图7-11所示。"}
{"text": "图7-11知识图谱分面实例图7-12展示了面向RDF数据分面搜索系统Dataplorer[18]的主要功能，可以看出构建知识图谱的分面搜索系统的主要环节包括：即时的计算生成分面、实时地计算分面的值以及根据用户的交互点击找到相关的分面。"}
{"text": "图7-12知识图谱分面搜索系统Dataplorer由于分面搜索的技术多种多样，本节不再详细展开。"}
{"text": "值得一提的是，一些高级的分面搜索系统还需要具备以下特征：（1）考虑特定领域的分面、分面值和计数。"}
{"text": "分面能够根据它们的起点进行分组。"}
{"text": "（2）支持全面的浏览。"}
{"text": "通过浏览可以达到每个分面的值，即没有值被跳过。"}
{"text": "（3）支持动态分面和值的聚类。"}
{"text": "此外，每一个当前浏览的知识图谱实体可能有大量分面，还需要对分面进行排序和分面隐藏。"}
{"text": "最终在整个分面搜索的过程中，分面应该以非常小的、相等的进度“引导”用户的，用户进而可以直观和明显地（用最少的必需知识）选择一类给定的分面。"}
{"text": "7.4.3基于表示学习的知识图谱语义搜索近年来，知识图谱表示学习技术的出现，在知识图谱存储、构建、补全以及应用层面都产生了深远的影响。"}
{"text": "利用知识图谱表示学习技术来改善语义搜索的质量，也逐渐引起学术界和工业界的兴趣。"}
{"text": "知识图谱表示学习旨在通过机器学习技术，将知识图谱中的实体和关系投射到连续低维的向量空间中，同时保持原有知识图谱的基本结构和性质[20]。"}
{"text": "在知识图谱表示学习技术出现之前，通常以图数据库的形式组织和存储知识图谱。"}
{"text": "然而，随着开放知识图谱数据规模越来越大，即使是中等规模的知识图谱也可能包含了数以千计的关系类型、数百万的实体和数亿的三元组。"}
{"text": "传统的基于图存储和图算法的知识图谱应用越来越受限于数据稀疏性和计算效率低下的问题[21]。"}
{"text": "通过知识图谱表示学习技术，将其投射到低维连续的向量空间中，对于语义搜索领域主要有两个好处。"}
{"text": "一是在连续向量空间中，可以直接进行数值型计算，对查询术语或者关键字进行扩展，效率极高。"}
{"text": "例如，衡量两个实体之间的相似度可以通过直接计算两个实体在向量空间中的欧式距离来实现。"}
{"text": "二是低维连续的知识图谱向量表示是通过机器学习技术学习得到的，其学习过程既考虑了知识图谱的局部特征，又考虑了全局特征，生成的实体和关系的向量在本质上是一种蕴涵语义更丰富的表示，可以进行高效率的简单查询推理。"}
{"text": "下面从基于表示学习的结构化语义查询和基于表示学习的自然语言语义查询两个方面，介绍知识图谱表示学习技术可以带来哪些改进。"}
{"text": "1.基于表示学习的结构化语义查询表示学习在结构化语义查询的应用主要是可以有效、高速地进行近似语义搜索。"}
{"text": "如图7-13所示[22]，初始的结构化查询可以看作是一个查询图，虽然查询图中的查询目标在数据层中不存在，但可以基于查询图，利用翻译机制等表示学习算子计算出其在向量空间中的坐标（如图7-13中点A所示），进而通过最近邻搜索找到近似结果（如图7-13中点B所示），该近似结果很可能接近用户的初始查询意图。"}
{"text": "图7-13基于表示学习的知识图谱结构化查询示意图2.基于表示学习的自然语言语义查询自然语言形式的语义查询的核心在于短语（phrase）到知识图谱上实体或边的映射，进而生成结构化的查询。"}
{"text": "在映射的过程中，主要难点在于关系（实体之间的边或实体属性）歧义的消除和查询图的构建。"}
{"text": "表示学习技术在这两个过程中都可以充分发挥作用。"}
{"text": "整个流程如图7-14中的例子所示[23]。"}
{"text": "图7-14基于表示学习的知识图谱自然语言语义查询示意图首先，在离线阶段，生成知识图谱的实值向量，并且将关系短语词典和知识图谱中的关系在向量空间中对齐。"}
{"text": "在线上阶段，将首先通过关键字检索的方式发现知识图谱中和自然语言短语对应的候选实体和边的集合。"}
{"text": "传统的语义搜索方法将对候选的实体和边进行消歧，容易出错；并且，在消歧后进行实体和边的组合，计算最优查询图，进而提交给查询引擎，效率较低。"}
{"text": "知识图谱的向量空间可以帮助模型省略消歧的过程，方法是将每一个候选实体集合中的实体平均实值向量作为查询图生成时的实体表示，进而并不需要某一个具体的实体向量。"}
{"text": "在计算查询图时，也可以利用翻译机制等原理提前预估查询图的评分好坏，提高生成效率和质量。"}
{"text": "以上两个案例在本质上是在传统语义搜索的数据和查询之间提供了全新的向量空间维度，进而利用实值向量计算的优势对查询进行改进。"}
{"text": "以近似查询来说，基于表示学习的搜索可以在不修改初始查询的前提下直接返回近似结果，极大地提高近似查询的质量，为知识图谱近似查询提供了全新的思路。"}
{"text": "值得一提的是，表示学习技术为知识图谱的语义搜索提供了新思路，但同时面临三项挑战，需要在实际使用中予以考虑：（1）最近邻搜索效率问题。"}
{"text": "无论是近似查询，还是自然语言问答中的关系拓展和候选查询图构建，在向量空间中进行最近邻搜索存在维度灾难造成的效率问题。"}
{"text": "（2）链接预测的合取问题。"}
{"text": "在向量空间中利用基于链接预测的思想，对语义搜索的目标进行预估，但是当搜索目标受多个实体和关系共同约束时，需要考虑不同链接预测的结果进行叠加时的合取问题。"}
{"text": "（3）结果可解释性问题。"}
{"text": "表示学习技术可以让语义检索绕过对查询本身的修改拓展，直接得到近似结果，在提高效率和精度的同时又带来结果的可解释问题。"}
{"text": "7.5开源工具实践本节将简述基于Elasticsearch[6]搭建一个简易实体语义搜索引擎的流程。"}
{"text": "该搜索引擎可以按照名称搜索实体、实体属性、多跳搜索以及搜索符合多对属性要求的实体。"}
{"text": "在功能逻辑完成后，可搭建网站将其可视化。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "7.5.1功能介绍1.实体搜索实体搜索即输入实体名称，返回该实体的知识卡片（实体在知识图谱中的所有属性和属性值），如图7-15所示。"}
{"text": "图7-15实体搜索功能示意图2.实体的属性搜索输入实体名称和一个属性名称，如果该实体存在该属性值，则返回该属性值，如图7-16所示。"}
{"text": "图7-16实体属性值搜索功能示意图3.多跳搜索多跳搜索可以输入多个属性，实现多跳搜索，即形如“姚明的女儿的母亲的身高”，其中“姚明：女儿”查询得到的是实体“姚明”的一个属性，但同时这个属性值也作为一个实体存在于数据集中，那么就可以接着对该实体继续查询其属性和值，如图7-17所示。"}
{"text": "图7-17多跳搜索功能示意图4.按照多种属性条件检索实体输入多对[属性名opearotr属性值]，它们之间的关系可以是AND、OR、NOT，同时属性值是等于、大于、小于一个输入值，返回满足这些属性限制的实体。"}
{"text": "例如，“职业：篮球运动员or职业：足球运动员AndNot国籍：中国And身高>=180”，如图7-18所示。"}
{"text": "第8章知识问答丁力海知智能，杨成彪南京柯基数据科技有限公司知识问答通过自然语言对话的形式帮助人们从知识库中获取知识，它不但是知识图谱的核心应用之一，也是自然语言处理的重要研究方向。"}
{"text": "随着新技术的不断涌现，知识问答技术取得了长足的进步，在工业界也有广泛的应用。"}
{"text": "本章介绍知识问答系统的基本概念、发展历史、评价体系以及最新进展。"}
{"text": "8.1知识问答概述知识问答系统是一个拟人化的智能系统，它接收使用自然语言表达的问题，理解用户的意图，获取相关的知识，最终通过推理计算形成自然语言表达的答案并反馈给用户。"}
{"text": "例如，用户想了解“特朗普是哪里人”时，可以在网上搜索关键词“特朗普”，找到相关的百科网页，进而通过阅读文章定位出“纽约”是他的出生地。"}
{"text": "如果换一种思路，用户拿这个问题问身边的人，也许直接就会听到“纽约”这个答案。"}
{"text": "8.1.1知识问答的基本要素知识问答或问答（Question_Answering,QA）是对话的一种形态。"}
{"text": "它强调以自然语言问答为交互形式从智能体获取知识，不但要求智能体能够理解问题的语义，还要求基于自身掌握的知识和推理计算能力形成答案。"}
{"text": "问答是一种典型的智能行为，例如著名的图灵测试就是考验能否通过自然语言对话的方式判定答题者是人还是机器。"}
{"text": "在采用对话方式与用户沟通时，众多问答系统都需要使用一定的知识来解答问题，所以说问答系统实质上就是知识问答，本文后续也不再区分问答系统和知识问答系统。"}
{"text": "也有工作将知识库编码到计算模型中，例如逻辑规则、机器学习模型和深度学习模型。"}
{"text": "图8-1问答系统的四大要素8.1.2知识问答的相关工作信息检索（Information_Retrieval,IR）或搜索以关键词搜索为代表，帮助用户发现包含搜索关键词的网页或文档。"}
{"text": "近来的信息检索技术也在逐步利用语义信息，例如支持查询扩展[1]、语义相似度匹配[2]以及基于知识图谱的实体识别[3]。"}
{"text": "但是搜索与知识问答有明显差异。"}
{"text": "第一，搜索以文档来承载答案，用户需要阅读搜索找到的文档来发现相关答案，而问答直接将答案交付给用户，而且答案通常来自已经结构化的数据或抽取后结构化的数据，而且结构化数据可以用列表的形式返回，也支持进一步的数据统计分析。"}
{"text": "第二，搜索侧重更简单的用户体验，用户的知识检索诉求主要通过关键词而不是完整的句子，这样需要用户掌握一定的搜索技巧。"}
{"text": "例如同一个问题，大学教授和中学生会采用不同的搜索技巧和搜索关键词组合，而他们得到的搜索结果也会不一样。"}
{"text": "问答则会尝试理解不同自然语言表达方式中固有的语义，然后形成知识查询。"}
{"text": "第三，当用户的问题比较复杂，需要通过多个页面的知识来回答时，搜索是无法完成的。"}
{"text": "例如，需要寻找“在华盛顿的数据挖掘公司”，而公司的地址信息（？公司位于华盛顿）和公司的专业信息（？公司业务数据挖掘）恰好在两个不同网页上，搜索引擎是无能为力的。"}
{"text": "数据库查询（Database_Query）同样可以帮助用户获取知识，但是知识问答和数据库查询仍然存在一定差异。"}
{"text": "第一，数据库查询通常需要用户熟悉结构化数据的组织（Schema），知道如何指代数据中的概念（包括实体名、属性名等），掌握数据库查询语言（包括使用JOIN等复杂操作逻辑），而知识问答降低了对这些知识的要求，人们可以用自然语言来查询数据。"}
{"text": "值得注意的是，自然语言查询需要处理歧义现象，例如“Listall_employees_in_the_company_with_a_driving_license”（“列举有驾照的公司的雇员”），可以是找“有驾照的公司”也可以是“有驾照的公司雇员”，从常识判断只有后者才是用户的真正意图。"}
{"text": "类似的中文歧义的现象也很多，例如“南京市长江大桥”“教育部长江学者”都需要不同的语义理解歧义消解的方案。"}
{"text": "第二，数据库对知识库有严格限制，要求数据必须结构化存储。"}
{"text": "然而，大量知识存在于文本中而非数据库中，知识问答并不限制知识库的类型。"}
{"text": "第三，数据库查询结果不一定能形成用户可使用的最终答案。"}
{"text": "例如，数据库查询可以查到城市的编码，还需要再查询编码表得到城市的名称，而知识问答则需要直接返回城市的名称。"}
{"text": "知识问答、信息检索和数据库查询的对比如表8-1所示。"}
{"text": "表8-1知识问答、信息检索和数据库查询的对比续表8.1.3知识问答应用场景2011年，IBM研发的超级计算机“沃森”在美国知识竞赛节目《危险边缘》中上演了“人机问答大战”，并一举战胜了两位顶尖的人类选手，成为人工智能发展史上又一标志性事件，如图8-2所示。"}
{"text": "自人工智能概念出现开始，问答系统的研究与应用一直在演进：20世纪60年代诞生了基于模板的问答专家系统，如ELISA、BaseBall[4]、LUNAR[5]、SHRDLU;20世纪90年代兴起了基于信息检索的问答[6]，如MASQUE、TREC；到21世纪初，伴随搜索引擎和网络社区而生的社区问答，如搜狗问问、百度知道、YAHOOanswers等；直到今日，基于结构化数据的知识图谱问答技术、基于文本理解的机器阅读理解技术均取得了长足的进展。"}
{"text": "案例1.知识问答可以直接嵌入搜索引擎的结果页面，将问答的答案与搜索的结果列表同时展示。"}
{"text": "图8-2“沃森”在《危险边缘》中获得冠军图8-3问答展示界面案例2.知识问答技术可以应用于智能对话系统、智能客服或智能助理（IntelligentAgent）[7]。"}
{"text": "除了帮助人们获取知识[8]，智能助理也可以跟人闲聊，帮助人执行任务（例如下订单、订酒店、叫外卖），将用户的问题转化为结构化查询，利用多轮对话补全用户的意图等[9]。"}
{"text": "图8-4基于不同领域知识图谱的问答系统在对话中有不同的理解案例3.知识问答应用于阅读理解。"}
{"text": "各种答题机器人和对话机器人也是知识问答的一个重要应用方向。"}
{"text": "例如，2011年，日本富士通联合日本国力信息学研究所的“多达一”考试机器人，以及国内“国家高技术研究发展计划（863计划）”基于大数据的类人智能关键技术与系统，俗称“高考机器人”，其背后均有知识图谱问答技术的支持。"}
{"text": "以阅读理解为代表的应用也可以被看作是知识问答的特例，它主要限制了知识库的边界（虽然阅读理解的主体知识是指定的章，但是实现理解仍然需要语法、常用词汇概念以及常识等辅助），而问题的形式可以是选择题（判断哪个答案正确）、填空题（直接填写答案）抑或是简答题。"}
{"text": "图8-5展示了一种阅读理解的应用场景，智能体以一段文章（passage）为知识库，针对问题从文章中寻找一段文字形成答案。"}
{"text": "图8-5SQuAD阅读理解问题示例8.2知识问答的分类体系本节围绕问答系统四大要素——问题、答案、知识库、智能体，简要梳理知识问答系统的特征并研究知识问答的分类体系。"}
{"text": "问答系统还有很多更深入的综述[10-14]。"}
{"text": "8.2.1问题类型与答案类型在知识问答中，首先可以通过对问题的类型（QuestionType）理解问答目标。"}
{"text": "问答系统可以针对问题类型，选择对应的知识库、处理逻辑来生成答案[15]。"}
{"text": "问题分类体系在很大程度上按照目标答案的差异而区分，所以这里将问题类型和答案类型合并，统一考虑为问题类型。"}
{"text": "通过对问题的类型（也就是用户问题所期望的答案的类型）的分析，问答系统可以有针对性地选择有效的知识库和处理逻辑解答一类问题。"}
{"text": "早期的工作包括TREC测试集问题分类研究[15]和ISIQA问题类型分类体系[16]，另外还有更详细的综述[17]。"}
{"text": "LI等人[15]通过观察TREC的1000个问题的数据，从答案类型出发建立了一个问题分类体系，包含6个大类和50个细分类，并对各类问题的占比进行了统计。"}
{"text": "从统计结果中可以看出，TREC中的大部分问题都集中在这几类数据，占总体问题数量的78%。"}
{"text": "其中，81个问题询问地点（LOCATION）、138个问题询问定义或描述（DESCRIPTION）、65个问题询问人物（HUMAN）、94个问题询问事物（例如动物、颜色、食品等）。"}
{"text": "可见，在知识问答中，一个合理的分类体系能够体现出问题的类型分布，从而帮助开发者有针对性地设计问答解决方案，并形成良好的问答系统。"}
{"text": "图8-6ISI_QA问题类型分类体系及实例后续也出现了基于功能的问题分类体系。"}
{"text": "例如，在英文中一个以“Why”开头的问题侧重询问原因，而以“How”开头的问题侧重询问解决方式。"}
{"text": "但是在中文里，带有“怎么样”这个词的问题，其意图有可能是询问原因，也有可能是询问解决方式。"}
{"text": "BU等人[18]根据百度知道的数据，建立了一个基于功能（Function-Based）的问题分类体系。"}
{"text": "和LI等人[15]从答案类型出发构建分类体系类似，BU等人[18]从利用功能以达成用户目标的角度来构建分类体系。"}
{"text": "相比于LI等人[15]专注于面向事实的知识问答的分类，BU等人[18]提出的分类体系更面向通用问题。"}
{"text": "表8-2展示了BU等人[18]提出的问题分类体系机制，其中的事实类别和LI等人[15]提出的分类体系中的大部分类别相对应。"}
{"text": "表8-2BU等人提出的问题分类机制[18]图8-7基于功能的问题分类体系在百度知道中的占比[18]综合分类体系的探索工作，本文从问答的功能出发，面向知识图谱问答的构建（即假定知识库的主题为知识图谱）整理出两种问题类型：事实性客观问题和主观深层次问题。"}
{"text": "（1）事实性客观问题。"}
{"text": "特点是语法结构简单（拥有明确的主谓宾结构，不包括例如并列、否定等复杂结构）、语义结构清晰（通常是关于某个事物或事件的简单描述性属性或关系型属性，可以通过简单的数据库查询解答）。"}
{"text": "事实型问题是知识问答中处理频度较高的一种问题类型，其中包含了谓词型问题（答案是一个单一的对象）、列表型问题（返回的不止一个答案，而是一列答案）。"}
{"text": "这两种主要是返回某些对象，从查询的角度来看，类似于数据库的Select操作。"}
{"text": "而对错型的问题更像SPARQL中的Ask类型的查询。"}
{"text": "实际上，这并不需要理解为一种“硬边界”的分类，也可能存在某些问题属于多个类别的情况。"}
{"text": "可以细分如下：①询问命名实体的基本定义（ENTITY）●事物的分类（IS-A），例如“热带水果有哪些？”●事物的别名（ALIASEs），例如“番茄是西红柿吗？”●事物的定义（WHAT-IS），例如“什么是西红柿？”②询问实体属性，包括描述性属性和关系性属性（PROPERTY）●人（WHO），例如“谁写了《平凡的世界》?”●地点（WHERE），例如“《平凡的世界》的主人公是哪里人？”●时间（WHEN），例如“北京奥运会是在哪一年举办的？”●属性（ATTRIBUTE），例如“西红柿是什么颜色的？”③复杂知识图谱查询●询问实体列表或统计结果，例如“唐宋八大家是哪几位？”“北京奥运会中国得了多少枚金牌？”“北京四月份的平均气温是多少？”“北京最大的公园是哪一个？”●询问实体差异，例如“颐和园和圆明园哪里相似，哪里不同？”●询问实体关系，例如“王菲和章子怡有什么关系？”“A公司和B公司有没有控制关系？”（2）主观深层次问题。"}
{"text": "包括除事实型问题之外的其他问题，例如观点型、因果型、解释型、关联型与比较型等。"}
{"text": "这一类问题本身的语法结构并不复杂，但是这些问题需要一定的专业知识和主观的推理计算才能解答，而且这一类问题有时甚至不止一个答案，需要结合用户偏好和智能体的配置找到不同的最优解。"}
{"text": "可以细分如下：①问解释（WHY），例如“为什么天空是蓝色的？”“为什么眼睛会近视？”②问方法（HOW），例如“怎么做戚风蛋糕？”“如何在Windows上创建一个文件夹？”③问专家意见（CONSULT），例如“左侧内踝骨折累及关节面多少天能下地走路？今年89岁。"}
{"text": "”④问推荐（RECOMMENDATION），例如“哪个歌手跟刘德华类似？”另外，问题类型并非问题理解中的唯一语义要素。"}
{"text": "问题焦点（Focus）指的是问句中出现的与答案实体或属性相关的元素，例如问句“In_which_city_was_Barack_Obama_born?”中的city，以及“What_is_the_population_of_Galway?”中的population。"}
{"text": "问题主题（Topic）反映问题是关于哪些主题的，例如问句“What_is_the_height_of_Mount_Everest?”询问的是关于地理及山脉的信息，而“Which_organ_is_affected_by_the_Meniere's_disease?”的问题主题则是医疗方面的内容。"}
{"text": "8.2.2知识库类型从知识库的内容边界，或者知识库覆盖了哪些领域来看，知识问答可以分两类。"}
{"text": "一是领域相关的问答系统，只回答与选定领域相关的问题。"}
{"text": "这一类系统相对专注，需要领域专家的深入参与，虽然问题覆盖面小，但是答案的正确率高。"}
{"text": "早期的成功问答系统都是与领域相关的。"}
{"text": "近年来，企业的智能客服通常采用领域相关的问答系统，并且逐步转向基于知识图谱的解决方案。"}
{"text": "二是领域无关的问答系统，基于开放知识库回答任意问题。"}
{"text": "这一类系统答案虽然覆盖面大，但答案的正确率有限。"}
{"text": "开放域问答系统经常使用万维网数据（尤其是百科网站、社区问答等）作为数据源解答用户的问题。"}
{"text": "由于用户的期望较高，开放问题结构并不总是简单，开放域知识相对稀疏等原因，实用产品的用户体验还有待提高。"}
{"text": "从知识库的信息组织格式来看，知识库可以是基于文本表示，也可以采用其他组织形式。"}
{"text": "第一，文本类知识库利用纯文本承载知识，也是最常见的知识组织形式。"}
{"text": "这类知识库不但支持基于搜索的问答系统，也可以与基于知识图谱的结构化抽取技术结合，支持基于语义查询的解决方案。"}
{"text": "另外，常见问答对（FAQ）或社区问答也是知识问答（尤其是智能客服）最容易获取的知识，可以直接通过问题匹配帮助用户获取答案。"}
{"text": "第二，半结构化或结构化的知识库。"}
{"text": "这一类知识库侧重知识的细粒度组织，利用结构体现知识的语义。"}
{"text": "电子表格、二维表或者关系数据库是最常见的结构化知识，实体和属性通过简单的二维表表示，大多数事实性客观问题都可以被此类知识解答。"}
{"text": "图数据库，例如RDF、属性图、语义网络等，将通过节点、有向边来形成基于图的知识组织，并且利用节点和边的名称与上下文对接自然语言处理并支持语义相似度计算，同时还能支持复杂的结构化图查询机制。"}
{"text": "第三，除文字外，知识也可以存储在图片、音频、视频等媒体中，这些都可以作为知识问答中答案的一部分，更有效地反馈给终端用户，从而丰富答案的表示并满足更多的交互场景需求。"}
{"text": "第四，知识库并不限定于文本、符号系统或多媒体，也可以利用可计算的机器学习模型承载。"}
{"text": "例如近年来出现的端到端的问答系统可以直接使用分布式表示模型记录习得的知识。"}
{"text": "另外，知识库的存储访问机制也是知识问答需要考虑的因素。"}
{"text": "知识问答的知识可以采用单一的集中数据存储（例如数据表、数据库），或者分布式存储（例如分布式数据、数据仓库），甚至是基于互联网的全网数据（例如Linked_Data）。"}
{"text": "8.2.3智能体类型智能体利用知识库实现推理。"}
{"text": "根据知识库表示形式的不同，目前的知识问答可以分为传统问答方法（符号表示）以及基于深度学习的问答方法（分布式表示）两种类型。"}
{"text": "传统问答方法使用的主要技术包括关键词检索、文本蕴涵推理以及逻辑表达式等，深度学习方法使用的技术主要是LSTM[19]、注意力模型[20]与记忆网络（Memory_Network）[21]等。"}
{"text": "传统的知识库问答将问答过程切分为语义解析与查询两个步骤。"}
{"text": "如图8-8所示，首先将问句“姚明的老婆出生在哪里”通过语义解析转化为SPARQL查询语句。"}
{"text": "这个例子中的难点是将问句中的“老婆”映射到知识图谱中的关系“配偶”，这也是传统的知识库问答研究的核心问题之一；再从知识库（知识图谱）中查询，得到问题的答案“上海”。"}
{"text": "不同于传统方法，基于分布式表示的知识库问答利用深度神经网络模型，将问题与知识库中的信息转化为向量表示，通过相似度匹配的方式完成问题与答案的匹配。"}
{"text": "首先，利用神经网络模型，将问题“姚明的老婆出生在哪里”表示成向量，这里使用的是一个递归神经网络的表达形式；然后取知识图谱中与实体“姚明”相关的实体向量，计算与问句向量的语义相似度，从而完成知识问答的过程。"}
{"text": "在整个过程中，并不需要确定问句中的“老婆”与知识图谱中的关系“配偶”的映射，这也是基于深度学习的问答方法的优势所在。"}
{"text": "图8-8基于符号表示（传统）的知识问答图8-9基于分布式表示的知识库问答8.3知识问答系统8.3.1NLIDB：早期的问答系统20世纪六七十年代，早期的NLIDB（Natural_Language_Interface_to_Data_Base）伴随着人工智能的研发逐步兴起[22]，以1961年的BASEBALL系统[4]和1972年的LUNAR系统[5]（Woods1973）为代表。"}
{"text": "BASEBALL系统回答了有关一年内棒球比赛的问题。"}
{"text": "LUNAR在阿波罗月球任务期间提供了岩石样本分析数据的界面。"}
{"text": "这些系统一般限定在特定领域，使用自然语言问题询问结构化知识库。"}
{"text": "这些数据库与如今讲的关系数据库不同，更像基于逻辑表达式的知识库。"}
{"text": "这一类系统通常为领域应用定制，将领域问题语义处理逻辑（自然语言问题转化为结构化数据查询）硬编码为特定的语法解析规则（例如模板或者简单的语法树），同时手工构建特定领域的词汇表，形成语法解析规则，很难转移到其他的应用领域。"}
{"text": "如图8-10所示为早期NLIDB型问答系统的设计思想。"}
{"text": "依据文献[23]的介绍，NLIDB系统大多采用的模块包括：①实体识别（Named_EntityRecognition），通过查询领域词典识别命名实体；②语义理解（Question2Query），利用语法解析（例如词性分析，Part-Of-Speech）、动词分析（包括主动和被动）以及语义映射规则等技术，将问题解析成语义查询语句；③回答问题（Answer_Processing），通常通过简单查询和其他复杂操作（例如Count）获取答案。"}
{"text": "这些工作中的语义理解部分各具特色，也就此奠定了后续问答系统中问题解析的基本套路，下面详细举例说明。"}
{"text": "图8-10早期NLIDB型问答系统的设计思想（1）基于模式匹配（Pattern-Matching）。"}
{"text": "基于模式匹配的语义理解可以直接将问题映射到查询。"}
{"text": "如图8-11所示，例子“...capital...<country>.....”中，变量“<country>”用来表示Country类型的一个实体，例如Italy，而“capital”是一个字符串。"}
{"text": "这个模板可以匹配不同的自然语言说法，例如“What_is_the_capital_of_Italy?”“Could_you_please_tell_me_what_is_thecapital_of_Italy?”，然后将问题映射到查询“Report_Capital_of_row_where_Country=Italy”（查询意大利的首都）。"}
{"text": "这种语义理解技术简便灵活且不依赖过多的语法分析工具，后来发展为KBQA中基于模板的语义理解方案。"}
{"text": "图8-11基于模板匹配的NLIDB解决方案[23]（2）基于语法解析（Syntactic-Parsing）。"}
{"text": "基于语法解析的语义理解将自然语言的复杂语义转化为逻辑表达式。"}
{"text": "如图8-12所示为展示了LUNAR系统利用语法树解析初步解析问题。"}
{"text": "句法分析器的树状结果仍然需要人工生成的语义规则和领域知识来理解，进而转化成一种中间层的逻辑表达式。"}
{"text": "通过一个简单的基于Context-Free_Grammar（CFG）的语法，主语（S）由一个名词短语（NP）加上一个动词短语（VP）组成；一个名词短语（NP）由一个确定词（Det）和一个名词（N）组成；确定词（Det）可以是“what”或“which”等。"}
{"text": "这样，“which_rock_contains_magnesium”就可以解析为后面的语法分for_every_X,“rock”映射到（is析结果，进而通过一系列转换规则，例如“which”映射到rock_X），形成最终的数据库查询。"}
{"text": "不少后来的系统也在系统的可移植性上有一些进展，包括允许为某一个新领域重新定制词典，构建通用知识表示语言来表达语义规则。"}
{"text": "有些系统甚至还可以允许用户通过交互界面添加新词汇和映射规制，包括LUNAR系统后期提出的MRL语言[23]，将自然语言问题转化为一种基于中间表示语言的逻辑查询表达式。"}
{"text": "这种中间表示语言承载了高层次世界概念以及用户问题的含义，独立于数据库存储结构，可以进一步转换成数据查询的表达式从而获取答案。"}
{"text": "这一类方案后来演进为KBQA中基于语义解析（Semantic_Parsing）的语义理解方法。"}
{"text": "语法树分析为处理更为复杂的问题以及简单问题的语法变形提供了便利，但是这也同时依赖语法分析工具的正确性（包括词性分析、语法依存分析）。"}
{"text": "另外，当词汇具有多重词性时，也存在潜在问题。"}
{"text": "所以，还需要附加一些规则调整语法解析出来的查询。"}
{"text": "图8-12LUNAR系统利用语法树解析初步解析问题[23]8.3.2IRQA：基于信息检索的问答系统基于信息检索的问答系统（Information_Retrieval_based_Question-Answering_System,IRQA）[6]的核心思想是根据用户输入的问题，结合自然语言处理以及信息检索技术，在给定文档集合或者互联网网页中筛选出相关的文档，从结果文档内容抽取关键文本作为候选答案，最后对候选答案进行排序返回最优答案。"}
{"text": "如图8-13所示，参考斯坦福IRQA的基本架构[13]，问答流程大致分三个阶段：（1）问题处理（Question_Processing）。"}
{"text": "从不同角度理解问题的语义，明确知识检索Formulation，即问句转化为关键词搜索）和答案类型判定（Answer的过滤条件（Query_Type_Detection，例如“谁发现了万有引力？”需要返回人物类实体；“中国哪个城市人口数最多？”需要返回城市类实体）。"}
{"text": "（2）段落检索与排序（Passage_Retrieval_And_Ranking）。"}
{"text": "基于提取出的关键词进行信息检索，对检索出的文档进行排序，把排序之后的文档分割成合适的段落，并对新的段落进行再排序，找到最优答案。"}
{"text": "（3）答案处理（Answer_Processing）。"}
{"text": "最后根据排序后的段落，结合问题处理阶段定义的答案类型抽取答案，形成答案候选集；最终对答案候选集排序，返回最优解。"}
{"text": "此方法以文档为知识库，没有预先的知识抽取工作。"}
{"text": "图8-13IRQA的基本架构[13]8.3.3KBQA：基于知识库的问答系统基于知识库的问答系统（Knowledge-Based_Question_Answering,KBQA)特指使用基于知识图谱解答问题的问答系统。"}
{"text": "KBQA实际上是20世纪七八十年代对NLIDB工作的延续，其中很多技术都借鉴和沿用了以前的研究成果。"}
{"text": "其中，主要的差异是采用了相对统一的基于RDF表示的知识图谱，并且把语义理解的结果映射到知识图谱的本体后生成SPARQL查询解答问题。"}
{"text": "通过本体可以将用户问题映射到基于概念拓扑图表示的查询表达式，也就对应了知识图谱中某种子图。"}
{"text": "KBQA的核心问题Question2Query是找到从用户问题到知识图谱子图的最合理映射。"}
{"text": "QALD（Question_Answering_on_Linked_Data）[38]是2011年开始针对KBQA问答系统的评测活动。"}
{"text": "文献[14]分析了参与QALD的数十个问答系统，并从问题解析、词汇关联、歧义消解、构建查询以及分布式知识库五个阶段做了对比，而前四个问题都是Question2Query的关键步骤。"}
{"text": "（1）问题分析。"}
{"text": "主要利用词典、词性分析、分词、实体识别、语法解析树分析、句法依存关系分析等传统NLP技术提取问题的结构特征，并且基于机器学习和规则提取分析句子的类型和答案类型。"}
{"text": "知识图谱通常可以为NLP工具提供领域词典，支持实体链接；同时，知识图谱的实体和关系也可以分别用于序列化标注和远程监督，支持对文本领域语料的结构化抽取，进一步增补领域知识图谱。"}
{"text": "（2）词汇关联。"}
{"text": "主要针对在问题分析阶段尚未形成实体链接的部分形成与知识库的链接，包括关系属性、描述属性、实体分类的链接。"}
{"text": "例如“cities”映射到实体分类“城市”,“is_married果）。"}
{"text": "to”映射到关系“spouse”。"}
{"text": "也包括一些多义词，例如“Apple”（公司还是水（3）歧义消解。"}
{"text": "一方面是对候选的词汇、查询表达式排序选优，一方面通过语义的容斥关系去掉不可能的组合。"}
{"text": "例如，苹果手机是不能吃的，所以吃苹果中苹果的“电器”选项应去掉。"}
{"text": "在很多系统中，歧义消解与构建查询紧密结合：先生成大量可能的查询，然后通过统计方法和机器学习选优。"}
{"text": "（4）构建查询。"}
{"text": "基于问题解析结果，可以通过自定义转化规则或者特定（语义模型+语法规则）将问题转化为查询语言表达式，形成对知识库的查询。"}
{"text": "QALD的大多系统使用SPARQL表达查询。"}
{"text": "注意查询语言不仅能表达匹配子图的语义，还能承载一些计算统计功能（average、count函数）。"}
{"text": "8.3.4CommunityQA/FAQ-QA：基于问答对匹配的问答系统基于常见问答对（Frequently_Asked_Question,FAQ-QA[24]）以及社区问答（Community_Question_Answering,CQA）[25]都依赖搜索问答FAQ库（许多问答对<Q,A>的集合）来发现以前问过的类似问题，并将找到的问答对的答案返回给用户。"}
{"text": "FAQ与CQA都是以问答对来组织知识，而且问答对的质量很高，不但已经是自然语言格式，而且受到领域专家或者社区的认可。"}
{"text": "二者的差异包括：答案的来源是领域专家还是社区志愿者，答案质量分别由专家自身的素质或者社区答案筛选机制保障。"}
{"text": "基于FAQ-QA的核心是计算问题之间的语义相似性。"}
{"text": "重复问题发现（DuplicateQuestion_Detection,DQD）仅限于疑问句，这是短文本相似度计算的一个特例。"}
{"text": "事实上，语义相似性面临两个挑战：（1）“泛化”。"}
{"text": "相同的语义在自然语言表达中有众多的表示方式，不论从词汇还是语法结构上都可以有显著差异，例如“How_do_I_add_a_vehicle_to_this_policy?”和“What_should_I_do_to_extend_this_policy_for_my_new_car?”。"}
{"text": "（2）“歧义”。"}
{"text": "两个近似的句子可以具有完全不同的语义，例如“教育部/长江学者”和“教育部长/江学者”。"}
{"text": "语义相似度计算一直是NLP研究的前沿。"}
{"text": "一种类型的方法试图通过利用语义词典（例如WordNet）计算词汇相似度，这些语义相似网络来自语言学家的经验总结，受限于特定的语言；另一种方法将此任务作为统计机器翻译问题处理，并采用平行语料学习逐字或短语翻译概率，这种方法需要大量的平行问题集学习翻译概率，通常很难或成本高昂。"}
{"text": "Rodrigues_J_A等人[26]基于两个测试数据集（AskUbnuntu领域相关问题集，和Quora领域无关）对比了基于规则（JCRD_Jacard）、基于传统机器学习以及基于深度学习的方法。"}
{"text": "发现基于深度学习的方法在领域问题上效果显著，但是开放领域问题中效果与传统方法接近（甚至有所下降）。"}
{"text": "SemEval2017年[27]评测结果指出，英文句子相似度计算的最佳结果已经达到F1=0.85。"}
{"text": "8.3.5Hybrid_QA_Framework混合问答系统框架从结构化数据出发的KBQA侧重精准的问题理解和答案查询，但是结构化的知识库总是有限；从非结构化文本出发的IRQA侧重于利用大量来自文本的答案，但是文本抽取存在精度问题且不容易支持复杂查询与推理。"}
{"text": "所以，在工业应用中，为了满足领域知识问答的体验，结合有限的高度结构化的领域数据与大量相关的文本领域知识，需要更通用的问答框架，以取长补短。"}
{"text": "1.DeepQA:IRQA主导的混合框架如图8-14所示的DeepQA[28]综合IRQA和KBQA形成混合问答系统的架构图，Watson系统的问题处理大致分成四阶段：图8-14DeepQA综合IRQA和KBQA形成混合问答系统的架构图[13]（1）问题处理（Question_Processing）。"}
{"text": "主要是理解问题的类型，解析问题语义元素等。"}
{"text": "（2）候选答案生成（Candidate_Answer_Generation）。"}
{"text": "不仅从网络上搜索相关文档并抽取答案，还从知识库直接查询答案，然后合并构成答案候选集。"}
{"text": "（3）候选答案评分（Candidate_Answer_Scoring）。"}
{"text": "针对每个候选答案选取一些重要特征，并对各个特征打分并形成答案的特征向量。"}
{"text": "Watson会利用很多信息源的佐证对候选答案进行打分，例如答案类型（Lexical_Answer_Type）、答案中的时空信息等。"}
{"text": "以答案类型的人的问答为例，如果已知每个历史人物的出生日期和去世日期（从百科知识图谱获取），同时要求查找一个历史人物并且提到时间范围，则候选答案中非同时期的人物可以被认为是无关的。"}
{"text": "（4）答案融合及排序（Confidence_Merging_And_Ranking）。"}
{"text": "首先把相同的答案进行融合（例如两个候选人名_J.F.K.和_John_F.Kemedy_会被合并成为一个候选答案），形成新的答案候选集，然后对新的答案候选集进行再排序，最终由训练好的逻辑回归分类器模型对每个候选答案计算置信度，并返回置信度最高的答案作为最终答案。"}
{"text": "总之，Watson架构的创新点是同时从IRQA和KBQA获取大量候选答案，并以大量答案佐证作为特征形成答案特征评分向量，这一点正是单独IRQA系统和KBQA系统没有做到的。"}
{"text": "2.QALD-Hybrid-QA:KBQA主导的混合框架在QALD-6启动的Hybrid_QA要求KBQA可以同时利用知识图谱数据和文本数据。"}
{"text": "自然语言先转化为SPARQL查询，但是并非所有SPARQL查询中的三元组特征（TriplePattern）都可以对应到知识图谱中的词汇，也并非所有知识都可以从掌握的知识图谱中查到，有一部分知识还需要从文档中抽取关系得到解答。"}
{"text": "这样可以避免前期过度的文本抽取工作，也能适应现实中更常见的图谱和文本混合的知识库。"}
{"text": "如图8-15所示[29]，当遇到包含“is_the_front_man_of”关系的三元组特征时，系统首先通过基于知识图谱的关系抽取技术，结合DBpedia[30]和OpenIE[31]从Wikipedia中抽取相关三元组。"}
{"text": "注意，在OpenIE抽取的三元组中，大量谓语predicate是没有经过归一融合的。"}
{"text": "然后利用平行语料模型将问句中的关系映射到抽取三元组的谓语上。"}
{"text": "例如，“front_man_of”映射到“lead_vocalist_of”上。"}
{"text": "图8-15基于SPARQL的混合问答系统的架构[29]3.Frankenstein：问答系统的流水线架构Frankenstein[32]通过对60多种KBQA系统的研究，将KBQA分成基于四类核心模块的流水线，其架构如图8-16所示。"}
{"text": "模块化的流水线设计有利于将复杂的QA系统分解为细粒度可优化的部分，而且形成了可插拔的体系，便于系统优化更新。"}
{"text": "但是这样的流水线有两点要求：尽量使用统一的知识表示，例如基于Ontology/Schema，这样才能保证各模块在接口上可以复用；模块的分解目前只考虑了Question2Query中针对结构化查询的部分，未覆盖非结构化文本的问答。"}
{"text": "这个框架首先制定了一个可配置的流水线框架，并且分解出KBQA的四个主要模块：的知识库以及通用的RDF图8-16问答系统流水线的架构[32]（1）命名实体识别与消解歧义（Named_Entity_Disambiguation,NED）。"}
{"text": "从问题的文本中标记其中涉及的实体。"}
{"text": "（2）实体关系映射（Relation_Linking,RL）。"}
{"text": "将问题文本提及的关系映射到知识库的实体属性或实体关系上。"}
{"text": "（3）实体分类映射（Class_Linking,CL）。"}
{"text": "将问题所需答案的类型映射到知识库的实体分类上。"}
{"text": "（4）构建查询（Query_Building,QB）。"}
{"text": "基于上述语义理解的结果综合后形成SPARQL查询。"}
{"text": "同时，框架也利用分类器技术（QA_Pipeline_Classifier）支持流水线自动配置，也就是说从29个不同的模块（18个NED、5个RL、2个CL、2个QB），针对每一个特定的KBQA问答系统选取最优的流水线组合。"}
{"text": "如图8-17所示，对于“What_is_the_capital_of_Canada?”，理想的NED组件应该将关键字“Canada”识别为命名实体，并将其映射到相应的DBpedia资源，即dbr:Canada。"}
{"text": "然后，RL模块需要找到知识图谱中对应的实体关系，因此“capital”映射到dbo:capital。"}
{"text": "最后，QB模块综合上述结果形成SPARQL查询SELECT_DISTINCT?uri_WHERE{dbr:Canadadbo:capital?uri.}。"}
{"text": "图8-17问答系统流水线举例说明[32]8.4知识问答的评价方法8.4.1问答系统的评价指标1.功能评价指标问答系统通常可以通过一组预定的测试问题集以及一组预定的维度来评价。"}
{"text": "问答系统的功能评价重点关注返回的答案，正确的答案应当同时具备正确度及完备度，正确但内容不完整的答案被称为不准确答案，没有足够证据及论证表明答案与问题相关性的则是无支撑答案，当答案与问题完全无关时，意味着答案是错误的。"}
{"text": "答案评价通常可以从如下角度考虑：（1）正确性。"}
{"text": "答案是否正确地回答了问题，例如问美国总统是谁，回答“女克林顿”就错了。"}
{"text": "（2）精确度。"}
{"text": "答案是否缺失信息，例如问美国总统是谁，回答“布什”可能存在二义性，到底是老布什，还是小布什；答案中是否包含了多余的信息，同样的问题，“特朗普在纽约州出生”就包含了多余的信息。"}
{"text": "（3）完整性。"}
{"text": "如果答案是一个列表，应当返回问题要求的所有答案。"}
{"text": "例如，列举美国总统，应该把所有满足条件的人都列举出来。"}
{"text": "（4）可解释性。"}
{"text": "在给出答案的同时，也给出引文或证明说明答案与问题的关联。"}
{"text": "根据TREC的测试结果，考虑与未考虑文章支持度的测试结果差距可达十几个百分点。"}
{"text": "（5）用户友好性。"}
{"text": "答案质量由人工评分，很多非事实性问题并非一个唯一的答案，所以需要人工判定答案的质量。"}
{"text": "如果答案被认为没错就按质量打分，Fair为1分、Good为2分、Excellent为3分，如果答不上来或答错则算零分。"}
{"text": "（6）额外的评价维度。"}
{"text": "当答案类型更为复杂时，例如有排序、统计、对比等更多的要求，还应该有额外的评价维度。"}
{"text": "除了上述针对答案的评价，也有针对解答过程复杂程度的评价，例如Semantic_Tractability[33]，用于反映问答之间的词表差异性；AnswerLocality[34]，答案是否零碎地分布在不同的文本或数据集录中；Derivability34，问题的答案是否是某种确定性答案，还是含蓄的、不确定的描述；Semantic_Complexity，问题涉及的语义复杂程度。"}
{"text": "常用的问答指标采用F1（综合正确率和召回率）和P@1（第一个答案是否正确的比率）。"}
{"text": "2.性能评价指标除了功能评价指标，参考UsbeckR等人[35]的评价体系，问答系统从性能角度可以考虑如下指标：（1）问答系统的响应时间（Response_Time）。"}
{"text": "问答系统对用户输入或者请求做出反应的时间。"}
{"text": "问答系统的响应时间是评价系统性能的一个非常重要的指标，如果响应时间过长，会使系统的可用性很低。"}
{"text": "一般问答系统的响应时间应控制在1s以内。"}
{"text": "（2）问答系统的故障率（Error_Rate）。"}
{"text": "在限定时间内给出答案即可，不考虑答案是否正确。"}
{"text": "系统返回错误或者系统运行过程中发生错误数的统计。"}
{"text": "8.4.2问答系统的评价数据集1.TREC_QA：评价IRQATREC_QA[36]是美国标准计量局在1999—2007年针对问答系统设定的年度评价体系，本文关注其问答的核心任务（MAIN_TASK）。"}
{"text": "此评价体系主要针对基于搜索的问答解决方案（IRQA）。"}
{"text": "问题集主要来自搜索引擎的查询日志（也有少部分问题由人工设计）。"}
{"text": "知识库主要采用跨度几年的主流媒体的新闻。"}
{"text": "问答系统返回的结果包括两部分<答案，文档ID>，前者为字符串，后者为问题答案来源的文档的ID。"}
{"text": "评价方法主要是选取大约1000个测试问题，由1～3人标注评价答案的正确性（答案是否正确回答了问题）、精准度（答案中是否包含多余的内容）以及对应文章的支持度（对应的文章是否支持该答案）。"}
{"text": "评价指标区分了单一答案和列表答案的评价方法。"}
{"text": "2.TREC_LIVE_QA：评价CQA社区问答TREC_LIVE_QA也[37]是美国标准计量局在2015—2107年从更真实的网络问答出发，主要面向CQA社区问答解决方案的评价体系。"}
{"text": "问题集主要来自Yahoo_Answer的实时新问题。"}
{"text": "知识库主要来自Yahoo_Answer的社区问答数据，以及过往标注的千余条数据。"}
{"text": "评价方法主要选取大约1000个测试问题，每个问题要求在1min内回答。"}
{"text": "由于问题类型不限于简单知识问答，所有的答案由1～3人标注并直接按答案质量打{0,1,2,3}分。"}
{"text": "另外，评价系统也针对测试问题，获取赛后的社区人工答案做类似的评价，然后对比自动生成的答案和人工产生的答案的体验差异。"}
{"text": "3.QALD：评价KBQAQALD[38]是指2011—2017年的链接数据的问答系统评测（Question_Answering_onLinked_Data），为自然语言问题转化为可用的SPARQL查询以及基于语义万维网标准的知识推理提供了一系列的评价体系和测试数据集，对QALD的工作做了详细介绍。"}
{"text": "QALD的主要任务如下：给定知识库（一个或多个RDF数据集以及其他知识源）和问题（自然语言问题或关键字），返回正确的答案或返回这些答案的SPARQL查询。"}
{"text": "这样，QALD可以利用工业相关的实际任务评价现有的系统，并且找到现有系统中的瓶颈与改进方向，进而深入了解如何开发处理海量RDF数据方法。"}
{"text": "这些海量数据分布在不同的数据集之间，并且它们是异构的、有噪声的，甚至结构是不一致的。"}
{"text": "每一年QALD通过不同的任务覆盖了众多的评价体系，包括：面向开放领域的多语种问答，例如Task1:Multilingualquestion_answering_over_Dpedia；面向专业领域的问答，例如MusicBrainz（音乐领域）、Drugbank（医药领域）；结构化数据与文本数据混合的问答，例如Task2:Hybrid_questionanswering；海量数据的问答，例如Task3:Large-Scale_Question_answering_over_RDF；新数据源的问答，例如Task4:Question_answering_over_Wikidata。"}
{"text": "4.SQuAD：评价端到端的问答系统解决方案SQuAD[39]是斯坦福大学推出的一个大规模阅读理解数据集，由众多维基百科文章中的众包工作者提出的问题构成，每个问题的答案都是相应阅读段落的一段文字或跨度。"}
{"text": "在500多篇文章中，有超过100,000个问题—答案对，SQUAD显著大于以前的阅读理解数据集。"}
{"text": "2017—2018年，国内也有不少类似的阅读理解比赛，例如搜狗问答。"}
{"text": "SQuAD评价指标主要分两部分：（1）精准匹配。"}
{"text": "正确匹配标准答案，目前效果最好的算法达到74.5%，人类表现是82.3%。"}
{"text": "这个指标准确地匹配任何一个基本事实答案的预测百分比。"}
{"text": "（2）F1值。"}
{"text": "这个指标衡量了预测和基本事实答案之间的平均重叠数。"}
{"text": "在给定问题的F1，然后对所有问题求平均值。"}
{"text": "2018年3月，谷歌公司的所有基础正确答案中取最大值QAnet[40]达到了F1=89.737，非常接近人工对比指标F1=91.221。"}
{"text": "在此之前，斯坦福大学还发布过Web_Question数据集[41]。"}
{"text": "首先通过Google_SuggestAPI获取只包含单个实体的问题，然后选取实体前面或后面的语句作为query，以此作为种子进行问题扩充，每个query大约扩充5个候选问题，形成体量大约为100万的问题集；然后随机选取10万个问题，交由众包工作者搜集答案，并对每个答案给出答案来源URL；最后，对问答对进行筛选，形成包括3778条数据的训练集以及2032条数据的测试集。"}
{"text": "在Web_Questions数据集上的F1值为31.3%，后续不少研究者在Web_Questions提出了一些新Jain提出的Factual的有效模型，F1值逐年更新。"}
{"text": "目前，效果最好的模型是Sarthak_Memory_Network模型[42]，该模型的平均精确度为55.2%，平均召回率为64.9%，平均精确度和平均召回率的F1值为59.7%，平均F1值为55.7%。"}
{"text": "5.Quora_QA：评价问题相似度计算Quora于2017年在Kaggle发布的数据集包含约40万个问题对，每个问题包含两个问题ID和原始文本，另外还有一个数字标记这两个问题是否等价，即对应到同一个意图的上。"}
{"text": "这个数据集主要用于验证社区问答或FAQ问答的语义相似度计算算法，目前在Kaggle上的竞赛结果最优者的Logloss已经达到0.11。"}
{"text": "这个数据集来自社区问答网站Quora，这种规模抽样的数据的确存在少量噪声问题且话题分布并不一定与Quora网站的问题分布一致。"}
{"text": "另外，社区问答中只有少量问题是真正等价，因此通过C(n,2)随机组合抽取两个问题，绝大多数问题对也不应该等价。"}
{"text": "这40万条数据首先加入了大量正例（等价的问题对），然后利用“related_question”关系添加了负例（相关但不等价的问题对），这样才形成一个相对平衡的训练数据集。"}
{"text": "Elkhan_Dadashov[43]在Quora_QA数据集上尝试了多种不同的LSTM模型，最好的模型的F1值达到了79.5%，准确率还到了83.8%。"}
{"text": "6.SemEval：词义消歧评测SemEval是由ACL词汇与语义小组组织的词汇与语义计算领域的国际权威技术竞赛。"}
{"text": "从1998年开始举办，竞赛包括多方面不同的词汇语义评测任务，如文本语义相似度计算、推特语义分析、空间角色标注、组合名词的自由复述、文本蕴涵识别、多语种的词义消歧等。"}
{"text": "2018的Sameval比赛包含12个任务，主要包括以下几方面的内容：（1）推特情感与创造性语句分析。"}
{"text": "该部分的处理对象来自推特的社交文本数据，其中涵盖英语、阿拉伯语以及西班牙语等多种语言的文本。"}
{"text": "分析的定位包括情感分析（情感的强弱、喜怒哀乐等类型的判断、情绪的积极消极以及识别推文中涵盖的多个情感类型）、符号预测（预测推文中可能嵌入的表情图片或颜文字）、反讽语义识别（识别推文中的讽刺表达）。"}
{"text": "（2）实体关联。"}
{"text": "该部分包含两个子任务。"}
{"text": "一个子任务是多人对话中的人物识别，目标是识别对话中提及的所有人物。"}
{"text": "值得一提的是，这些人物并不一定是对话中的某个谈话者，可能是他们提及的其他人。"}
{"text": "如图8-18所示的多人对话场景，Ross提到的“mom”并不是参与对话的某人，而是Judy。"}
{"text": "如何有效地识别出对话中提及人物的字符具体指向什么人物实体，是本任务需要解决的重要问题之一。"}
{"text": "另一个子任务则是面向事件的识别以及分析，针对给定的问题，从给定文本中找出问题相关的一个事件或多个事件，以及参与角色之间的关系。"}
{"text": "图8-18多人对话场景示例（3）信息抽取。"}
{"text": "该部分介绍的信息抽取包含关系（关系抽取与分类）、时间（基于语义分析的时间标准化）等。"}
{"text": "如图8-19所示为时间信息的语义解析示例，对于文本“metevery_other_Saturday_since_March_6”，其中的时间信息被解析为时间点与时间段并标准化表示出来。"}
{"text": "图8-19时间信息的语义解析示例（4）词汇语义学。"}
{"text": "该部分从词汇语义的角度入手，提出了用于反映词汇之间高度关系的上位调发现以及判别属性识别。"}
{"text": "与传统计算词汇语义相似不同，本任务关注词的语义相异性，目标是预测一个词是其他词的一个判别属性。"}
{"text": "例如，给定词语“香蕉”与“苹果”，词语“红色”可以作为判别属性区分两者的相异性。"}
{"text": "红色是苹果的一个颜色属性，但是与香蕉无关。"}
{"text": "（5）阅读理解与推理。"}
{"text": "该部分由两个子任务构成，一个子任务是研究任务包括如何利用常识完成文本阅读理解，另一个子任务是通过推理方式对给定的由声明和理由组成的论点，从两个候选论据中选出正确的论据。"}
{"text": "8.5KBQA前沿技术目前还存在两个很大的困难阻碍着KBQA系统被广泛应用。"}
{"text": "一个困难是现有的自然语言理解技术在处理自然语言的歧义性和复杂性方面还显得比较薄弱。"}
{"text": "例如，有时候一句话系统可以理解，但是换一个说法就不能理解了。"}
{"text": "另一个困难是此类系统需要大量的领域知识来理解自然语言问题，而这些一般都需要人工输入。"}
{"text": "一些系统需要开发一个专用于一个领域的基于句法或者语义的语法分析器。"}
{"text": "许多系统都引入了一个用户词典或者映射规则，用来将用户的词汇或说法映射到系统本体的词汇表或逻辑表达式中。"}
{"text": "通常还需要定义一个世界模型（World_Model），来指定词典或本体中词汇的上下位关系和关系参数类型的限制。"}
{"text": "这些工作都是非常消耗人力的。"}
{"text": "以下围绕KBQA的关键阶段——“构建查询”，说明KBQA面临的挑战，然后介绍几种典型的解决方案。"}
{"text": "8.5.1KBQA面临的挑战图8-20反映了KBQA中一个简化的“问题→答案”映射过程，自然语言问题在关联知识库之前，需要转换成结构化查询，利用查询从知识图谱中找到答案后，还需要考虑一个自然语言答案生成的过程。"}
{"text": "这个过程中的主要挑战在于如何将自然语言表达映射到知识库的查询，也就是Question2Query语义理解。"}
{"text": "图8-20问题到答案的映射过程1.多样的概念映射机制也就是将自然语言表达的查询语义映射知识库的原子查询。"}
{"text": "自然语言的表达的语义包罗万象，常见语义映射现象如表8-3所示。"}
{"text": "表8-3常见的语义映射现象2.不完美的知识库首先，知识库未必全都是结构化的数据，还有大量的知识存在于文本中。"}
{"text": "这需要有动态知识抽取解决方案。"}
{"text": "其次，知识库的知识组织机制各不相同，同样的知识在不同的知识库中未必会采用同样的结构，例如三元组（英国，加入欧盟的时间，1973）等价于四个三元组（事件1，加入方，英国）（事件1，被加入方，欧盟）（事件1，年份，1973）（事件1，类型，加入组织），这样也为查询制造了困难。"}
{"text": "再次，用户使用的语言以及知识库采用的工作语言也会影响语义理解，例如用中文查询英文的DBpedia，从中文的关系名称映射到英文的实体属性就不简单。"}
{"text": "最后，知识库本身并不是完整的，而用户的预期却是希望能找到答案，这样如何判定找不到答案从而避免答非所问也是很重要的。"}
{"text": "3.泛化语义理解的预期当用户使用知识问答时，常见的抱怨就是同一个问题换一种说法就无法理解了。"}
{"text": "这个问题在智能客服中尤其明显，在保障精确度的前提下智能客服应该匹配尽量可解答的问题。"}
{"text": "泛化问题通常可以从词语和句子两个层面来研究。"}
{"text": "（1）词语层面的泛化匹配[44]。"}
{"text": "①命名实体的不同说法，例如“上海”对应“沪”，需要从网络或领域专家获取背景知识，而“交通银行股份有限公司”可以通过简单的规则得到简称“交通银行”。"}
{"text": "②生成实体（日期，地址等）的不同说法。"}
{"text": "例如“2018年1月1日”和“2018年元旦”。"}
{"text": "注意，生成实体的识别和解析可以通过常规的语法分析工具达成，但是中英文数字的混合、语音识别错误等现象会令解析难度提升。"}
{"text": "③实体分类和属性或关系的不同说法。"}
{"text": "例如“还活着吗”对应“死亡日期”，这样的平行语料学习不但可以通过基于知识图谱的关系抽取结果来充实，也可以利用深度学习的分布式表示Embedding来计算。"}
{"text": "另外，这些语料的目标是建立从自然语言表示到知识图谱表示的映射，所以部分词汇还应该直接映射到知识图谱的实体分类和实体（描述或关系）属性上。"}
{"text": "还要注意对知识图谱本体的语义融合归一化处理，例如在Wikidata里没有统一的“水果”分类，这样就不能通过简单的实体分类获取完整的水果列表。"}
{"text": "（2）句子层面的泛化处理。"}
{"text": "主要是判断问题的语义相似度（Question-QuestionSimilarity）[44]，常用思路通常采用语言模型、机器翻译模型、句子主题分析模型、句子结构相似度分析模型、基于知识图谱的句子成分相似度模型等，SemEval的Task1和Task3_SubTaskB[45]都对这一方面的关键技术做了评测。"}
{"text": "句子问题相似度算法可以被封装为独立的计算模块，然后将语法分析和前面基于知识图谱的语义解析结果作为特征交给基于LSTM的模型[46]计算相似度。"}
{"text": "8.5.2基于模板的方法基于模板（Template）或模式（Pattern）的问答系统定义了一组带变量的模板，直接匹配问题文本形成查询表达式。"}
{"text": "这样简化了问题分析的步骤，并且通过预制的查询模板替代了本体映射。"}
{"text": "这样做的优势包括：简单可控，适于处理只有一个查询条件的简单问题；绕过了语法解析的脆弱性。"}
{"text": "这个方案在工业中得到广泛的应用。"}
{"text": "图8-21描述了一个TrueKnowledge[47]模板示例，其中包含了以下步骤，首先使用已知的模板成分匹配句子中的内容，包括疑问词（What、Which，反映问题的意图），以及部分已知的模板（is_a_present_central_form_of，某些固定表达词组），对于未知成分则使用变量字符加以替换（固定表达前后的a、y等），这种模板可以实现一对多的问题覆盖效果。"}
{"text": "但是其缺点也很明显：成熟的应用需要生成大量的模板，True_Knowledge就依赖手工生成了1200个模板，人工处理成本非常高昂；模板由人工生成，不易复用即一个问题可以用多个不同的模板回答，且需要通过全局排序来调优，容易发生冲突；即使生成的模板遵循知识库的Schema，但由于知识库自身的不完整性以及语义组合的多样性，这些模板也未必就能保障能在知识库中找到答案。"}
{"text": "注意，TrueKnowledge利用用户交互的界面降低人工编辑成本，让用户自己将系统无法回答的问题说法链接到一个相关的问题模板上，因此有效地减少了模板的生成数量。"}
{"text": "图8-21TrueKnolwedge的模板举例[47]TBSL[48]在QALD_2012测评任务中提出了一种联合使用语义结构分析以及自然语言词汇—URI间映射的问答方法。"}
{"text": "根据模板匹配结果生成多组可能的SPARQL查询，通过筛选这些查询，最终生成答案并返回给用户。"}
{"text": "在基于模板的知识问答框架中，模板一般没有统一的标准或格式，只需结合知识图谱的结构以及问句的句式进行构建即可。"}
{"text": "TBSL中的模板定义为SPARQL查询模板。"}
{"text": "图8-22典型的TBSL框架流程TBSL方法有两个重要的步骤：模板生成和模板实例化。"}
{"text": "模板生成步骤解析问句结构并生成对应的SPARQL查询模板，该查询模板中可能包含过滤和聚合操作。"}
{"text": "生成模板时，首先需要获取自然语言问题中每个单词的词性标签，然后基于词性标签和语法规则表示问句，接下来利用与领域相关或与领域无关的词汇辅助分析问题，最后将语义表示转化为SPARQL模板。"}
{"text": "同一条自然语言问句可能对应着不止一条查询模板。"}
{"text": "因此，TBSL就查询模板的排序也提出了一种方法：首先，每个实体根据字符串相似度以及显著度获得一个打分；其次，根据填充槽的多个实体的平均打分得到一个查询模板的分值。"}
{"text": "在此基础上，需要检查查询的实体类型。"}
{"text": "形式化来说，对于所有的三元组？xrdf:type<class>，对于查询三元组？xpe和ep?x，我们需要检查p的定义域（domain）和值域（range）是否与<class>一致。"}
{"text": "模板实例化步骤将自然语言问句与知识库中的本体概念建立映射。"}
{"text": "对于Resources和Classes，实体识别的常用方法主要有两点，一是用WordNet定义知识库中标签的同义词，二是计算字符串间的相似度。"}
{"text": "对于属性标签，还需要与存储在模式库中的自然语言表示进行比较。"}
{"text": "最高排位的实体将作为填充查询槽位的候选答案。"}
{"text": "1.问题“列举所有的电影出品人”2.模板生成3.资源绑定TBSL仍然存在的缺点是创建的模板结构未必和知识图谱中的数据契合。"}
{"text": "另外，考虑到数据建模的各种可能性，对应到一个问题的潜在模板数量会非常的多，同时手工准备海量模板的代价也非常大。"}
{"text": "针对此问题，CUI等人[49]针对简单事实问答模板的大规模生成，在自动化处理方面做了进一步优化，如图8-23所示。"}
{"text": "离线过程（Offline_Procedure）侧重基于问题生成模板。"}
{"text": "利用NER结果推算简单二元事实问题（Binary_Factorid_Question,BFQ）模板，将问题原文中的实体e替换为e的实体分类，多个实体分类可生成多个模板；基于DBpedia知识图谱和Yahoo_Answer社区问答对数据的训练数据，利用远程监督技术建立从问题到知识图谱查询的映射。"}
{"text": "模板映射支持BFQ，即询问知识图谱中的三元组，例如“how_many_people_are_there_in_Honolulu?”（实体的描述属性）或者“what_is_the_capital_of_China”（实体的关系属性）。"}
{"text": "同时，模板映射也支持有特色的问题：排序，例如“which_city_has_the_3rd_largest_population?”；对比，例如“which_city_has_more_people,Honolulu_or_New_Jersey?”；列表，例如“list_cities_ordered_by_population”。"}
{"text": "此外，复杂的问题可以利用语法分析技术，先将问题拆分为多个BFQ，然后再到本体中逐个映射到属性，最后再从这些结果中挑选合理的组合。"}
{"text": "例如，“when_was_Barack_Obama's_wifeborn?”可以拆分为who's_Barack_Obama's_wife?（Michelle_Obama）和when_was_MichelleObama_born?（1964）。"}
{"text": "离线过程采用E-M方法计算条件概率分布P（p|t）,p为属性，t为模板。"}
{"text": "在线过程（Online_Procedure）侧重模板选择。"}
{"text": "通过概率计算给定问题的最优答案。"}
{"text": "基于给定问题q0，可以提取出c1个实体，每个实体至多有c2个实体分类，因而至多有c3个模板，这些实体至多有p个属性（p为知识库里的所有属性），而每个（实体，属性）c4个值。"}
{"text": "其中，c1、c2、c3、c4都是常数，所以寻求实体的时间复杂度为对最多对应O（p），这意味每个问题都能快速得到解答，文中报告在线过程回答单个问题的平均时间为79ms。"}
{"text": "要注意的是，这里还包括高效率的内存知识图谱查询引擎。"}
{"text": "这种基于BFQ模板的解决方案提升了自动化处理程度，基于2782个意图从语料中学习生成了2700万个模板。"}
{"text": "当然，BFQ也未必能覆盖用户的所有问题。"}
{"text": "图8-23CUI等人提出的基于模板的KBQA的架构图及示例[49]为了解决人工定义模板成本高的问题，Abujabal等人[50]提出了QUINT模型，可以基于语料自动学习模板，然后基于生成的模板将自然语言查询转换成知识库查询。"}
{"text": "该方法在WebQuestions数据集上取得了接近最好成绩的效果，在Free917数据集上取得了当时最好的效果，同时人工监督的工作量也是最少的。"}
{"text": "总的来说，基于模板方法的优点是模板查询的响应速度快、准确率较高，可以回答相对复杂的复合问题，而缺点是模板结构通常无法与真实的用户问题相匹配。"}
{"text": "如果为了尽可能匹配上一个问题的多种不同表述，则需要建立庞大的模板库，耗时耗力且会降低查询效率。"}
{"text": "8.5.3基于语义解析的方法基于语义解析的方法是指通过对自然语言查询的语法分析，将查询转换成逻辑表达式，然后利用知识库的语义信息将逻辑表达式转换成知识库查询，最终通过查询知识库得到查询结果。"}
{"text": "逻辑表达式是语义解析方法与基于模板的方法的主要差异。"}
{"text": "逻辑表达式是面向知识库的结构化查询，用于查找知识库中的实体及实体关系等知识。"}
{"text": "相比于模板预先生成且固定的表达方式，逻辑表达式作为人工智能知识表示的经典传承，具备更完备、灵活的知识查询生成体系，包括带参数的原子逻辑表达式，以及基于操作组合的复杂逻辑表达式。"}
{"text": "原子级别的逻辑表达式通常可分为一元形式（unary）与二元形式（binary），其中一元形式匹配知识库中的实体，二元形式匹配实体之间的二元关系。"}
{"text": "这两种原子逻辑表达式可以利用连接（Join）、求交集（Intersection）及聚合统计（Aggregate）等操作进一步组合为复杂逻辑表达式。"}
{"text": "自然语言转化逻辑表达式需要训练一个语法分析器将过程自动化。"}
{"text": "应注意两个关键步骤：资源映射和逻辑表达式生成。"}
{"text": "资源映射即将自然语言查询中的短语映射到知识库的资源（类别、关系、实体等），根据处理难度分为简单映射和复杂映射两类。"}
{"text": "简单映射是指字符形式上比较相似的，一般可以通过字符串相似度匹配来找到映射关系，例如“出生”和“出生地”的映射。"}
{"text": "复杂映射是指无法通过字符串匹配找到对应关系的映射，例如“老婆”与“配偶”的映射，这类映射在实际问答中出现的概率更高，一般可以采用基于统计的方法来找到映射关系。"}
{"text": "逻辑表达式生成即自底向上自动地将自然语言查询解析为语法树，语法树的根节点即是最终对应的逻辑表达式。"}
{"text": "如图8-24所示，查询“where_was_Obamaborn”对应的逻辑表达式是Type.Location⊓PeopleBornHere.BarackObama，其中lexicon是指资源映射操作，PeopleBornHere和BarackObama用Join连接组合，此组合结果再与Type.Location用求交集组合成为最终的逻辑表达式。"}
{"text": "图8-24自然语言查询转换成逻辑表达式[41]训练语法分析器需要大量的标注数据，传统的方法是基于规则生成标注数据，通过手工编写规则虽然直接，但是存在较明显的局限性：一方面，规则的编写需要语言学专家完成，导致规则的建立效率低且成本高，还不具备扩展性；另一方面，这种人工规则可能仅适用于某一类语言甚至某一特定领域，泛化能力较弱。"}
{"text": "为了改进传统方法的缺陷，有大量研究工作采用弱监督或者无监督的方法来训练语法分析器，一个经典的方法是Berant[41]提出利用“问题/答案对”数据结合Freebase作为语法分析器的训练集。"}
{"text": "此方法不需要逻辑表示式的专家人工标注数据，可以低成本地获得。"}
{"text": "Berant等人[41]提出的方法重点解决了逻辑表达式生成过程中的四个问题：资源映射（Alignment）、桥接操作（Bridging）、组合操作（Composition）和候选逻辑表达式评估。"}
{"text": "（1）资源映射。"}
{"text": "自然语言实体到知识库实体的映射相对比较简单，属于简单映射，但自然语言关系短语到知识库关系的映射相对复杂，属于复杂映射。"}
{"text": "例如将“where_wasObama_born”中的实体Obama映射为知识库中的实体BarackObama,Berant在文中直接使用字符串匹配的方式实现实体的映射，但是将自然语言短语“was_also_born_in”映射到相应的知识库实体关系PlaceOfBirth则运用了基于统计的方法。"}
{"text": "首先从文本中收集了大量(Obama,_was_also_born_in,August_1961)这样的三元组，然后将三元组中的实体进行对齐和并将常量进行归一化，把三元组转换成(BarackObama,was_also_born_in,1961-08)这样的标r[t1,t2]的形式，例准形式，再通过知识库得到三元组中实体的类型，将三元组转换成如“was_also_born_in[Person,Date]”。"}
{"text": "如图8-25所示，左边的“grew_up_in”是三元组中的自然语言关系短语r1，右边的“DateOfBirth”是知识库中的关系r2。"}
{"text": "统计所有自然语言三元组中符合r1[t1,t2]的实体对，得到集合F(r1)，统计知识库中符合r2[t1,t2]的实体对，得到集合F(r2)。"}
{"text": "通过比较集合F(r1)和集合F(r2)类似Jaccard距离特征确定是否建立r1与r2的资源映射。"}
{"text": "图8-25关系短语映射到知识库关系的方法[41]（2）桥接操作。"}
{"text": "在完成资源映射后仍然存在一些问题，首先，例如go、have、do等轻动词（Light_Verb）由于在语法上使用相对自由，难以通过统计的方式直接映射到实体关系上；其次，部分知识库关系的出现频率较低，利用统计也较难找到准确的映射方式。"}
{"text": "这样就需要补充一个额外的二元关系将这些词两端的逻辑表达式连接起来，这就是桥接操作。"}
{"text": "如图8-26所示，“Obama”和“college”映射为BarackObama和Type.University，但是“goto”却难以找到一个映射，需要寻找一个二元关系Education使得查询可以被解析为Type.University⊓Education.BarackObama的逻辑表达式。"}
{"text": "由于知识库中的关系是有定义域和值域的，所以文献基于此特点在知识库中查找所有潜在的关系，例如Education的定义域和值域分别是Person和University，则Education可以是候选的桥接操作。"}
{"text": "这里针对每一种候选的桥接操作都会生成很多特征，基于这些特征训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "图8-26桥接操作示例[41]（3）组合操作。"}
{"text": "即逻辑表达式间的连接、求交集以及聚合三种操作。"}
{"text": "至于最终应该用哪种操作，作者同样通过收集大量的上下文特征，基于这些训练分类器，用于最后的候选逻辑表达式评估。"}
{"text": "（4）候选逻辑表达式评估。"}
{"text": "即训练一个分类器，计算每一种候选逻辑表达式的概率，DiscriminativeLog-Linear模型，最终实现逻辑表达式的筛选。"}
{"text": "Berant等人基于前面候选逻辑表达式生成过程中的所有特征，训练了一个8.5.4基于深度学习的传统问答模块优化基于深度学习的知识问答主要有两个方向，分别是利用深度学习对传统问答方法进行模块级的改进和基于深度学习的端到端问答模型。"}
{"text": "深度学习可以直接用于改进传统问答流程的各个模块，包括语义解析、实体识别、意图分类和实体消歧等。"}
{"text": "实体识别模块可以使用LSTM+CRF以及近来兴起的BERT提升实体识别正确率；在关系分类、意图分类模块方面，可以使用基于字符级别的文本分类深度学习方法，甚至针对语言和领域提供预训练模型；实体消歧模块也可以使用基于深度学习的排序方法判定一组概念的语义融洽度。"}
{"text": "下面通过Yih[51]的工作，说明如何使用深度神经网络来提升知识问答的效果。"}
{"text": "传统的基于语义解析的方法需要将问题转换成逻辑表达式，如图8-27所示。"}
{"text": "这类方法最大的问题是找到问题中自然语言短语与知识库的映射关系，Yih等人提出了一种语义解析的框架，首先基于问句生成对应的查询图（Query_Graph），然后用该查询图在知识库上进行子图匹配，找到最优子图即找到问题的答案。"}
{"text": "因为查询图可以直接映射到Lambda_Calculus形式的逻辑表达式，并且在语义上与λ-DCS（Lambda_Dependency-Based_CompositionalSemantics）紧密相关，因此就可以将语义解析的过程转换成查询图生成的过程。"}
{"text": "图8-27通过逻辑表达式转化成知识库查询的过程查询图由四种节点组成，包括实体（Grounded_Entity）、中间变量（ExistentialVariable）、聚合函数（Aggregation_Function）和Lambda变量（Lambda_Variable），图8-28是一个查询图示例，其中实体在图中用圆角矩形表示，中间变量在图中用白底圆圈表示，聚合函数用菱形表示，Lambda变量（即答案节点）用灰底圆圈表示。"}
{"text": "这个例子对应的问句是“Who_first_voiced_Meg_on_Family_Guy?”，在不考虑聚合操作的情况下，该查询图对应的逻辑表达式是λx.∃y.cast(FamilyGuy,y)∧actor(y,x)∧character(y,MegGriffin)。"}
{"text": "图8-28查询图示例[51]下面介绍查询图的生成过程。"}
{"text": "第一步，选择一个主题实体（Topic_Entity）作为根节点，如图8-29（a）中可以选择s1“FamilyGuy”作为根节点。"}
{"text": "第二步，确定一条从根节点到Lambda变量（答案节点）的有向路径，路径上可以有一个或者多个中间变量，这条路径被称为核心推断链（Core_Inferential_Chain），如图8-29（b）所示从三条路径s3、s4、s5中选取s3作为核心推断链。"}
{"text": "核心推断链上除了根节点为实体，其他的都只能是变量，节点间的关系都是知识库中的关系。"}
{"text": "第三步，给查询图添加约束条件和聚合函数（AugmentingConstraints&Aggregations），形式上就是把其他的实体或者聚合函数节点通过知识库中的关系与核心推断链上的变量连接起来，如图8-29（c）所示对y增加两个限制argmin和character(y,MegGriffin)。"}
{"text": "图8-29查询图的生成过程[51]对于生成查询图的第二步，需要一种从众多候选核心推断链中选出最优核心推断链的方法，针对图8-29（b）的例子，要评估{cast-actor,writer-start,genre}三个谓语序列中哪个最接近问题中“Family_Guy”和“Who”的关系，该文献使用一个CNN网络将候选序列和问题文本中的关键词向量化，CNN结构如图8-30所示，通过语义相似度计算找到最优的核心推断链。"}
{"text": "具体做法是将自然语言问题和谓语序列分别通过图8-30所示的网络得到两个300维的分布式表达，然后利用表达向量之间的相似度距离（如cosine距离）计算自然语言问题和谓语序列的语义相似度得分。"}
{"text": "该CNN网络的输入运用了词散列技术[52]，将句子中每个单词拆分成字母三元组，每个字母三元组对应一个向量，比如单词who可以拆为#-w-h,w-h-o,h-o-#，每个单词通过前后添加符号#来区分单词界限。"}
{"text": "然后通过卷积层将3个单词的上下文窗口中的字母三元组向量进行卷积运算得到局部上下文特征向量ht，通过最大池化层提取最显著的局部特征，以形成固定长度的全局特征向量v，然后将全局特征向量v输送到前馈神经网络层以输出最终的非线性语义特征y，作为自然语言问题或核心推断链的向量表示。"}
{"text": "图8-30Yih[51]中的CNN结构8.5.5基于深度学习的端到端问答模型端到端的深度学习问答模型将问题和知识库中的信息均转化为向量表示，通过向量间的相似度计算的方式完成用户问题与知识库答案的匹配。"}
{"text": "首先根据问题中的主题词在知识库中确定候选答案，然后把问题和知识库中的候选答案都通过神经网络模型映射到一个低维空间，得到它们的分布式向量（Distributed_Embedding），则可计算候选答案分布式向量与问题向量的相似度得分，找出相似度最高的候选答案作为最终答案。"}
{"text": "该神经网络模型通过标注数据对进行训练，使得问题向量与知识库中正确答案的向量在低维空间的关联得分尽量高。"}
{"text": "典型的工作有BordesA等人[53]提出的方法，为解决WebQuestions上数据量不够的问题，文献作者使用一些规则从Freebase、ClueWeb等知识库中构建了大量（问题，知识库答案）的标注数据用于训练模型。"}
{"text": "如图8-31所示，自底向上计算。"}
{"text": "第一步，利用实体链接定位问题中的核心实体，对应到Freebase的实体；第二步，找到从问题中核心实体到候选答案实体的路径；第三步，生成候选答案的子图；第四步，分别将问题和答案子图映射成Embedding向量；第五步，进行点积运算，获得候选答案和问题之间的匹配度。"}
{"text": "该方法取得了比Berant[41]更好的结果（F1=0.392,P@1=0.40）。"}
{"text": "图8-31BordesA等人提出方法的核心流程[53]另一个基于Multi-ColumnCNN[54]的工作，该工作同时训练自然语言问句词向量与知识库三元组，将问题与知识库映射到同一个语义空间。"}
{"text": "该工作针对知识库的特点，定义了答案路径（Answer_Path）、答案上下文（Answer_Context）和答案类型（Answer_Type）三类特征，每一类特征都对应一个训练好的卷积神经网络，以此计算问题和答案的相似度。"}
{"text": "这三个CNN被称为多列卷积神经网络（Multi-Column_Convolutional_Neural_Network,Multi-Column_CNN）。"}
{"text": "该方法的核心流程如图8-32所示，对于问题“when_did_Avatarrelease_in_UK”，首先通过Multi-Column卷积神经网络提取该问题的三个分布式向量。"}
{"text": "然后利用命名实体识别、实体链接等技术，从问题文本中找到能链接到知识库的实体，与该实体相关联的每一个实体都是候选答案实体；再基于候选答案实体形成三个分布式向量，包括斜线矩形（“Avatar”）对应主题词路径向量，虚线椭圆（“UnitedKingdom”“film.file_region”）对应上下文向量，“datetime”对应答案类型向量。"}
{"text": "最后，通过分别点乘运算再求和的方式得到最终的答案-问题对得分。"}
{"text": "在实验中，该方法取得了当时最好的效果（F1=0.408,P@1=0.45)。"}
{"text": "图8-32基于Multi-ColumnCNN方法的核心流程[54]8.6开源工具实践8.6.1使用Elasticsearch搭建简单知识问答系统本书第7章介绍了如何基于Elasticsearch实现简单的语义搜索，本节则基于Elasticsearch展示简单的知识问答系统。"}
{"text": "两个案例的基本框架一致，而知识问答增加了将自然语言问题转化为对应逻辑表达式以及查询语句的过程。"}
{"text": "因此，本小节通过一个简单案例介绍自然语言问题到Elasticsearch查询语句的转化，而用Elasticsearch查询语句进行查询即可得到问答结果。"}
{"text": "注意，真实的知识问答系统的语义理解远比本文方案复杂。"}
{"text": "自然语言问题对应的查询类型同本书第7章中的语义检索，如表8-4所示，主要包含四种类型的查询，即实体检索、实体属性检索、实体属性的多跳检索以及多种属性条件检索实体。"}
{"text": "表8-4自然语言问题的四种类型自然语言问题转化为逻辑表达式的过程如下：（1）定义逻辑表达式模板。"}
{"text": "如表8-5所示，逻辑表达式的基本元素是三元组的成分，包含S（Subject，主语）、P（Predicate，谓语）和O（Object，宾语）。"}
{"text": "当P是属性时，可以定义属性条件的运算，相关运算符（OP）包括“<”（小于）、“>”（大于）、“<=”（小于或等于）、“>=”（大于或等于）、“:”（属性），属性条件形式表示为“<P><O>”，例如“职业：演员”,“身高>180”。"}
{"text": "多个属性条件之间可以用逻辑链接符“And”和“Or”连接，表示条件间并且和或者的关系，例如“职业：作家And身高>180”。"}
{"text": "<OP>表8-5自然语言问题对应的逻辑表达式模板（2）解析自然语言问题。"}
{"text": "从自然语言问题中识别出实体名、属性名和属性值等三类要素，并将实体名和属性名映射到知识库中的实体和属性。"}
{"text": "首先，实体和属性的识别可以采用词典的方法，例如从知识库中抽取所有的实体名和属性名，构建分词器的自定义词典。"}
{"text": "然后，对自然语言问题进行分词，可直接识别其中的属性名和实体名。"}
{"text": "其次，属性值的识别比较困难，由于取值范围变化较大，可以采用模糊匹配的方法，也可以采用分词后n-gram检索Elasticsearch的办法。"}
{"text": "最后，查看自然语言问题中属性值和属性名的对应关系，当某属性值没有对应的属性名时，例如“（国籍是)中国(的)运动员”，缺省了“国籍”，就用该属性值对应的最频繁的属性名作为补全的属性名。"}
{"text": "例如下面的两段代码，分别实现了属性名识别和实体名识别。"}
{"text": "（3）后生成逻辑表达式。"}
{"text": "在识别出自然语言问题中所有的实体名、属性名和属性值后，依据它们的数目及位置，确定问题对应的查询类型，以便基于逻辑表达式模板生成对应的逻辑表达式。"}
{"text": "逻辑表达式生成流程如下：查询中含有实体名。"}
{"text": "如果有多个属性名，那么是属性值的多跳检索；如果有一个属性名，则需判断实体名和属性名的位置及中间的连接词(“是”“在”“的”等)，若实体名在前，则是实体的属性查询，例如“姚明的身高”，若属性名在前，则是依据属性查询实体，例如“女儿是姚沁蕾”。"}
{"text": "查询中没有实体名，则认为是依据属性查询实体，需要根据所有属性名和属性值位置的相对关系确定它们之间的对应关系。"}
{"text": "如果缺少属性名但有属性值，则需补全对应的属性名；如果缺少属性值但有属性名，例如“身高大于180cm”，则需通过正则表达式识别出范围查询的属性值。"}
{"text": "工业应用中抽取属性也会采用文法解析器、序列化标注、数字识别与解析等技术。"}
{"text": "在生成逻辑表达式之后，可基于查询的类型及要素，直接用对应的Elasticsearch查询模板将逻辑表达式翻译成Elasticsearch查询。"}
{"text": "本方法定义了一组Elasticsearch查询模板，基于该模板将逻辑表达式按照一定的层次结构自动转换成Elasticsearch查询语句。"}
{"text": "如表8-6所示，对于实体属性查询，包括多跳检索，都是先检索实体，然后获取对应的属性。"}
{"text": "如表8-7所示，对于多个属性条件检索实体，先为每种单个的属性条件创建Elasticsearch查询，最后组合成完整的查询，表中part_query表示单个属性条件对应的部分查询。"}
{"text": "表8-6查询类型与Elasticsearch查询模板的映射关系表8-7多属性条件组合与Elasticsearch查询模板的映射关系8.6.2基于gAnswer构建中英文知识问答系统本节进一步介绍一个真实的知识问答系统的架构与接口，帮助开发者理解如何使用知识问答系统。"}
{"text": "gAnswer系统[55]是一个基于海量知识库的自然语言问答系统，针对用户的自然语言问题，能够输出SPARQL格式的知识库查询表达式以及查询答案的结果。"}
{"text": "gAnswer同时支持中文问答和英文问答。"}
{"text": "gAnswer参加了QALD-9的评测比赛，并取得了第一名的成绩。"}
{"text": "对于中文问答，使用PKUBASE知识库；对于英文问答，使用DBpedia知识库。"}
{"text": "本实践的相关工具、实验数据及操作说明由OpenKG提供，地址为http://openkg.cn。"}
{"text": "此外，我们给出了一个使用gAnswer进行英文问答的示例网站http://ganswer.gstore-pku.com/。"}
{"text": "如图8-33所示为gAnswer系统处理流程。"}
{"text": "主要分为三个阶段：构建语义查询图、生成SPARQL查询和查询执行。"}
{"text": "在构建语义查询图阶段，系统借助数据集的信息以及自然语言分析工具，对问句进行实体识别和关系抽取，构建语法依存树，并用这些结果构建对应的查询图。"}
{"text": "这时，并不对其中的实体和关系做消歧处理，而是利用谓词词典，记录词或短语可能对应的谓词或实体。"}
{"text": "在生成SPARQL查询阶段，系统利用查询图生成多个SPARQL，并利用数据集中的部分信息对多个SPARQL进行过滤和优化，其中就包括歧义的消除。"}
{"text": "在查询执行阶段，借助gStore系统返回的SPARQL查询结果，返回并展示给用户。"}
{"text": "图8-33gAnswer系统处理流程1.系统配置需求读者可以使用gAnswer系统构建自己的领域知识问答。"}
{"text": "在系统配置需求方面，gAnswer系统使用RDF格式的数据集，默认的中文数据集是PKUBASE，默认的英文数据集是DBpedia2016。"}
{"text": "gAnswer系统的运行需要借助支持SPARQL查询的图数据库系统来获取最终答案。"}
{"text": "在目前的版本中，使用gStore系统（http://openkg.cn/tool/gstore）。"}
{"text": "gAnswer的部署还依赖一些外部工具包。"}
{"text": "包括Maltparser、StanfordNLP，在生成SPARQL阶段，需要借助Lucene对辅助信息进行索引。"}
{"text": "8.7本章小结本章介绍了问答系统的基本概念、主流方法以及评价体系，并详细阐述了知识图谱问答系统的主要方法与最新进展。"}
{"text": "知识问答以自然语言问答的方式简化了人们获取知识的过程，在知识检索过程中增加了泛化、联想、探索等智能化体验并拓展了知识获取的途径。"}
{"text": "KBQA作为知识问答的重要分支，一方面强化了针对结构化信息的检索能力，另一方面也可以利用知识图谱提升问题理解的准确性。"}
{"text": "深度学习技术在KBQA也起到了重要的作用，不但可以优化传统KBQA的各个模块，尤其是实体识别和语义相似度匹配，而且可以直接作为知识库表示支持端到端的知识问答。"}
{"text": "正如万维网是开放的一样，多种多样的领域知识是不可能被任何一家企业垄断的，所以知识问答应该走万维网一样的开放路线，允许不同的参与者形成生态体系。"}
{"text": "参与者可以从热门领域开始，从全局或细分覆盖不同领域的知识，提供不同特色的领域问答体验，这好比垂直领域的网站，进而组合形成跨领域的知识问答，最终通过一个开放的协作体系，完成全网的开放知识问答体验。"}
{"text": "第9章知识图谱应用案例王昊奋上海乐言信息科技有限公司，丁军华东理工大学知识图谱用以描述现实世界中的概念、实体以及它们之间丰富的关联关系。"}
{"text": "自从2012年谷歌公司利用知识图谱改善搜索体验并提高搜索质量后，引起了社会各界纷纷关注。"}
{"text": "随着知识图谱应用的深入，作为一种知识表示的新方法和知识管理的新思路，知识图谱不再局限于搜索引擎及智能问答等通用领域应用，而在越来越多的垂直应用领域开始崭露头角，扮演越来越重要的角色。"}
{"text": "通用知识图谱可以形象地看成一个面向通用领域的“结构化的百科知识库”，其中包含了现实世界中的大量常识，覆盖面极广。"}
{"text": "领域知识图谱又称为行业知识图谱或垂直知识图谱，通常面向某一特定领域。"}
{"text": "领域知识图谱基于行业数据构建，通常有着严格而丰富的数据模式，对该领域知识的深度、准确性有着更高的要求。"}
{"text": "本章重点介绍领域知识图谱的构建方法及系列应用案例。"}
{"text": "9.1领域知识图谱构建的技术流程由于现实世界的知识丰富多样且极其庞杂，通用知识图谱主要强调知识的广度，通常运用百科数据进行自底向上的方法进行构建。"}
{"text": "而领域知识图谱面向不同的领域，其数据模式不同，应用需求也各不相同，因此没有一套通用的标准和规范来指导构建，而需要基于特定行业通过工程师与业务专家的不断交互与定制来实现。"}
{"text": "虽然如此，领域知识图谱与通用知识图谱的构建与应用也并非完全没有互通之处，如图9-1所示，其从无到有的构建过程可分为六个阶段，被称为领域知识图谱的生命周期[1]。"}
{"text": "本节以生命周期为视角来阐述领域知识图谱构建过程中的关键技术流程。"}
{"text": "图9-1领域知识图谱生命周期9.1.1领域知识建模知识建模是建立知识图谱的概念模式的过程，相当于关系数据库的表结构定义。"}
{"text": "为了对知识进行合理的组织，更好地描述知识本身与知识之间的关联，需要对知识图谱的模式进行良好的定义。"}
{"text": "一般来说，相同的数据可以有若干种模式定义的方法，设计良好的模式可以减少数据的冗余，提高应用效率。"}
{"text": "因此，在进行知识建模时，需要结合数据特点与应用特点来完成模式的定义。"}
{"text": "知识建模通常采用两种方式：一种是自顶向下（Top-Down）的方法，即首先为知识图谱定义数据模式，数据模式从最顶层概念构建，逐步向下细化，形成结构良好的分类学层次，然后再将实体添加到概念中。"}
{"text": "另一种则是自底向上（Bottom-Up）的方法，即首先对实体进行归纳组织，形成底层概念，然后逐步往上抽象，形成上层概念。"}
{"text": "该方法可基于行业现有标准转换生成数据模式，也可基于高质量行业数据源映射生成。"}
{"text": "为了保证知识图谱质量，通常在建模时需要考虑以下几个关键问题：1）概念划分的合理性，如何描述知识体系及知识点之间的关联关系[1]；2）属性定义方式，如何在冗余程度最低的条件下满足应用和可视化展现；3）事件、时序等复杂知识表示，通过匿名节点的方法还是边属性的方法来进行描述，各自的优缺点是什么[2]；4）后续的知识扩展难度，能否支持概念体系的变更以及属性的调整。"}
{"text": "关于知识建模的详细知识和技术，请参考本书第2章。"}
{"text": "9.1.2知识存储知识存储，顾名思义为针对构建完成的知识图谱设计底层存储方式，完成各类知识的存储，包括基本属性知识、关联知识、事件知识、时序知识、资源类知识等。"}
{"text": "知识存储方案的优劣会直接影响查询的效率，同时也需要结合知识应用场景进行良好的设计。"}
{"text": "目前，主流的知识存储解决方案包括单一式存储和混合式存储两种。"}
{"text": "在单一式存储中，可以通过三元组、属性表或者垂直分割等方式进行知识的存储[3]。"}
{"text": "其中，三元组的存储方式较为直观，但在进行连接查询时开销巨大[4]。"}
{"text": "属性表指基于主语的类型划分数据表，其缺点是不利于缺失属性的查询[5]。"}
{"text": "垂直分割指基于谓词进行数据的划分，其缺点是数据表过多，且写操作的代价比较大[6]。"}
{"text": "对于知识存储介质的选择，可以分为原生（Neo4j、AllegroGraph等）和基于现有数据库（MySQL、Mongo等）两类。"}
{"text": "原生存储的优点是其本身已经提供了较为完善的图查询语言或算法的支持，但不支持定制，灵活程度不高，对于复杂节点等极端数据情况的表现非常差。"}
{"text": "因此，有了基于现有数据库的自定义方案，这样做的好处是自由程度高，可以根据数据特点进行知识的划分、索引的构建等，但增加了开发和维护成本。"}
{"text": "从上述介绍中可以得知，目前尚没有一个统一的可以实现所有类型知识存储的方式。"}
{"text": "因此，如何根据自身知识的特点选择知识存储方案，或者进行存储方案的结合，以满足针对知识的应用需要，是知识存储过程中需要解决的关键问题。"}
{"text": "关于知识存储的详细知识与技术，请参考本书第3章。"}
{"text": "9.1.3知识抽取知识抽取是指从不同来源、不同数据中进行知识提取，形成知识并存入知识图谱的过程。"}
{"text": "由于真实世界中的数据类型及介质多种多样，所以如何高效、稳定地从不同的数据源进行数据接入至关重要，其会直接影响到知识图谱中数据的规模、实时性及有效性。"}
{"text": "在现有的数据源中，数据大致可分为三类：一类是结构化的数据，这类数据包括以关系数据库（MySQL、Oracle等）为介质的关系型数据，以及开放链接数据，如Yago、Freebase等；第二类为半结构化数据，如百科数据（Wikipedia、百度百科等），或是垂直网站中的数据，如IMDB、丁香园等；第三类是以文本为代表的非结构化数据。"}
{"text": "结构化数据中会存在一些复杂关系，针对这类关系的抽取是此类研究的重点，主要方法包括直接映射或者映射规则定义等；半结构化数据通常采用包装器的方式对网站进行解析，包装器是一个针对目标数据源中的数据制定了抽取规则的计算机程序。"}
{"text": "包装器的定义、自动生成以及如何对包装器进行更新及维护以应对网站的变更，是当前获取需要考虑的问题；非结构化数据抽取难度最大，如何保证抽取的准确率和覆盖率是这类数据进行知识获取需要考虑的科学问题。"}
{"text": "关于知识抽取的详细知识和技术，请参考本书第4章。"}
{"text": "9.1.4知识融合知识融合指将不同来源的知识进行对齐、合并的工作，形成全局统一的知识标识和关联。"}
{"text": "知识融合是知识图谱构建中不可缺少的一环，知识融合体现了开放链接数据中互联的思想。"}
{"text": "良好的融合方法能有效地避免信息孤岛，使得知识的连接更加稠密，提升知识应用价值，因此知识融合是构建知识图谱过程中的核心工作与重点研究方向。"}
{"text": "知识图谱中的知识融合包含两个方面，即数据模式层的融合和数据层的融合。"}
{"text": "数据模式层的融合包含概念合并、概念上下位关系合并以及概念的属性定义合并，通常依靠专家人工构建或从可靠的结构化数据中映射生成。"}
{"text": "在映射的过程中，一般会通过设置融合规则确保数据的统一。"}
{"text": "数据层的融合包括实体合并、实体属性融合以及冲突检测与解决。"}
{"text": "进行知识融合时需要考虑使用什么方式实现不同来源、不同形态知识的融合；如何对海量知识进行高效融合[7]；如何对新增知识进行实时融合以及如何进行多语言融合等问题[8]。"}
{"text": "关于知识融合的详细知识和技术，请参考本书第5章。"}
{"text": "9.1.5知识计算知识计算是领域知识图谱能力输出的主要方式，通过知识图谱本身能力为传统的应用形态赋能，提升服务质量和效率。"}
{"text": "其中，图挖掘计算和知识推理是最具代表性的两种能力，如何将这两种能力与传统应用相结合是需要解决的一个关键问题。"}
{"text": "知识推理一般运用于知识发现、冲突与异常检测，是知识精细化工作和决策分析的主要实现方式。"}
{"text": "知识推理又可以分为基于本体的推理和基于规则的推理。"}
{"text": "一般需要依据行业应用的业务特征进行规则的定义，并基于本体结构与所定义的规则执行推理过程，给出推理结果。"}
{"text": "知识推理的关键问题包括：大数据量下的快速推理，记忆对于增量知识和规则的快速加载[9]。"}
{"text": "知识图谱的挖掘计算与分析指基于图论的相关算法，实现对图谱的探索与挖掘。"}
{"text": "图计算能力可辅助传统的推荐、搜索类应用。"}
{"text": "知识图谱中的图算法一般包括图遍历、最短路径、权威节点分析、族群发现最大流算法、相似节点等，大规模图上的算法效率是图算法设计与实现的主要问题。"}
{"text": "关于知识推理与分析的详细知识和技术，请参考本书的第6章。"}
{"text": "9.1.6知识应用知识应用是指将知识图谱特有的应用形态与领域数据和业务场景相结合，助力领域业务转型。"}
{"text": "知识图谱的典型应用包括语义搜索、智能问答以及可视化决策支持。"}
{"text": "如何针对业务需求设计实现知识图谱应用，并基于数据特点进行优化调整，是知识图谱应用的关键研究内容。"}
{"text": "其中，语义搜索是指基于知识图谱中的知识，解决传统搜索中遇到的关键字语义多样性及语义消歧的难题，通过实体链接实现知识与文档的混合检索。"}
{"text": "语义检索需要考虑如何解决自然语言输入带来的表达多样性问题，同时需要解决语言中实体的歧义性问题。"}
{"text": "而智能问答是指针对用户输入的自然语言进行理解，从知识图谱或目标数据中给出用户问题的答案。"}
{"text": "智能问答的关键技术及难点包括：1）准确的语义解析，如何正确理解用户的真实意图。"}
{"text": "2）对于返回的答案，如何评分以确定优先级顺序。"}
{"text": "可视化决策支持则指通过提供统一的图形接口，结合可视化、推理、检索等，为用户提供信息获取的入口。"}
{"text": "对于可视化决策支持，需要考虑的关键问题包括：如何通过可视化方式辅助用户快速发现业务模式；如何提升可视化组件的交互友好程度，例如高效地缩放和导航；大规模图环境下底层算法的效率。"}
{"text": "关于知识图谱的搜索及问答技术，请参考本书的第7章和第8章。"}
{"text": "9.2领域知识图谱构建的基本方法不同领域的数据情况不同，有的领域较为成熟，知识体系完备，涵盖面广，单单采用自顶向下的方法进行图谱的构建就足以满足领域的应用。"}
{"text": "但在一些新兴领域，知识体系欠缺完备性，一部分知识适用于自顶向下构建，但也有很大一部分数据未成体系，这时则需要通过自底向上的方式对这类知识进行基于数据驱动的方式进行构建。"}
{"text": "因此，通常在领域内，尤其新兴领域，建模时会将自顶向下和自低向上的构建方法相结合。"}
{"text": "9.2.1自顶向下的构建方法针对特定的行业内有固定知识体系或由该行业专家梳理后可定义模式的数据，大多采用自顶向下的方式构建。"}
{"text": "国内外现有可借助的建模工具以Protégé、PlantData为代表。"}
{"text": "Protégé[2]是一套基于RDF（S）、OWL等语义网规范的开源本体编辑器，拥有图形化界面，适用于原型构建场景。"}
{"text": "Protégé同时提供在线版本的WebProtégé，方便在线进行知识图谱语义本体的自动构建。"}
{"text": "PlantData[3]知识建模工具是一款商用知识图谱智能平台软件。"}
{"text": "该软件提供了本体概念类、关系、属性和实例的定义和编辑，屏蔽了具体的本体描述语言，用户只需在概念层次上进行领域本体模型的构建，使得建模更加便捷。"}
{"text": "为保证可靠性，数据模式的构建基本都经过了人工校验，因此知识融合的关键任务是数据层的融合。"}
{"text": "工业界在进行知识融合时，通常在知识抽取环节中就对数据进行控制，以减少融合过程中的难度及保证数据的质量。"}
{"text": "在这些方面，工业界均做了不同角度的尝试，如DBpedia_Mapping[4]采用属性映射的方式进行知识融合。"}
{"text": "zhishi.me采用离线融合的方式识别实体间的sameAs关系，完成知识融合[10]，并通过双语主题模型，针对中英文下知识体系进行跨语言融合[11]。"}
{"text": "接着，需要根据数据源的不同进行知识获取，其方法主要分为三种：第一种是使用D2R工具，该方法主要针对结构化数据，通过D2R工具将关系数据映射为RDF数据。"}
{"text": "常用的开源D2R工具有D2RQ[5]、D2R_Server[6]、DB2triples[7]等。"}
{"text": "D2RQ通过D2RQ_MappingLanguage将关系数据转化成RDF数据，同时支持基于该语言在关系数据上直接提供RDF形式的数据访问API;D2R_Server提供对RDF数据的查询访问接口，以供上层的RDF浏览器、SPARQL查询客户端以及传统的HTML浏览器调用；DB2triples支持基于W3C的R2RML和DM的标准将数据映射成RDF形式。"}
{"text": "第二种是使用包装器，该方法主要针对半结构化数据，通过使用构建面向站点的包装器解析特定网页、标记语言文本。"}
{"text": "包装器通常需要根据目标数据源编写特定的程序，因此学者们的研究主要集中于包装器的自动生成。"}
{"text": "Ion_Muslea等人[12]基于层次化信息抽取的思想，提出了一个包装器自动生成算法“STALKER”;Alberto为“Wargo”的半自动生成包装器的工具。"}
{"text": "Pan等人[13]开发了一个名第三种是借助信息抽取的方法，该方法主要针对非结构化的文本。"}
{"text": "按照抽取范围的不同，文本抽取可分为OpenIE和CloseIE两种。"}
{"text": "OpenIE面向开放领域抽取信息，是一种基于语言学模式的抽取，无法得知待抽取知识的关系类型，通常抽取规模大、精度较低。"}
{"text": "典型的工具有ReVerb[8]、TextRunner[9]等。"}
{"text": "CloseIE面向特定领域抽取信息，因其基于领域专业知识进行抽取，可以预先定义好抽取的关系类型，且通常规模小、精度较高。"}
{"text": "DeepDive是CloseIE场景中的典型工具，其基于联合推理的算法让用户只需要关心特征本身，让开发者更多地思考特征而不是算法。"}
{"text": "9.2.2自底向上的构建方法在领域中部分没有完整知识体系的数据需要采用自底向上的方法进行构建，这与通用知识图谱的构建方法类似，主要依赖开放链接数据集和百科，从这些结构化的知识中进行自动学习，主要分为实体与概念的学习、上下位关系的学习、数据模式的学习。"}
{"text": "开放链接数据集和百科中拥有丰富的实体和概念信息，数据通常以一定的结构组织生成，因此从这类数据源中抽取概念和实体较为容易。"}
{"text": "由于百科的分类体系都是经过了百科管理员或是高级编辑人员的校验，其分类系统中的数据可靠性非常高，因此从百科中抽取概念和实体，通常将标题作为实体的候选，而将百科中的分类系统直接作为概念的候选。"}
{"text": "对于概念的学习，关键[14]提出了一种基于语言学和基于统计学的多策略概念抽取方法，该方法提高了领域内概念抽取的效果。"}
{"text": "实体对齐的目标是将从不同百科中学习到的、描述同一目标的实体或概念进行合并，再将合并后的实体集与开放链接数据集中抽取的实体进行合并。"}
{"text": "实体对齐过程主要分为六步：●从开放链接数据集中抽取同义关系。"}
{"text": "●基于结构化的数据对百科中的实体进行实体对齐。"}
{"text": "●采用自监督的实体对齐方法对百科的文章进行对齐。"}
{"text": "●将百科中的实体与链接数据中的实体进行对齐。"}
{"text": "●基于语言学模式的方法抽取同义关系。"}
{"text": "●实体基于CRF的开放同义关系抽取方法学习同义词关系。"}
{"text": "黄峻福[15]提出了一种基于实体属性信息及上下文主题特征相结合进行实体对齐的方法。"}
{"text": "万静等人[16]提出了一种独立于模式的基于属性语义特征的实体对齐方法。"}
{"text": "对于上下位关系，开放链接数据集中拥有明确的描述机制，针对不同的数据集，编写相应的规则直接解析即可获取。"}
{"text": "百科中描述了两种上下位关系，一种是类别之间的上下位关系，对应概念的层次关系；另一种则是类别与文章之间的上下位关系，对应实体与概念之间的从属关系。"}
{"text": "实体对齐可从开放链接数据集和百科中抽取上下位关系。"}
{"text": "WANG等人[17]引入了弱监督学习框架提取来自用户生成的类别关系，并提出了一种基于模式的关系选择方法，解决学习过程中“语义漂移”问题。"}
{"text": "数据模式的学习又称为概念的属性学习，一个属性的定义包含三个部分：属性名、属性的定义域、属性的值域。"}
{"text": "但概念的属性被定义好，属于该属性的实体则默认具备此属性，填充属性的值即可。"}
{"text": "概念属性的变更会直接影响到它的实体、其子概念以及这些概念下的实体。"}
{"text": "因此概念的属性定义十分重要，通常大部分知识库中的概念属性都是采用人工定义等方式生成的，通用知识图谱则可以从开放数据集中获取概念的属性，然后从在线百科中学习实体的属性，并对实体属性进行往上规约从而生成概念的属性。"}
{"text": "在进行属性往上规约的过程中，需要通过一定的机制保证概念属性的准确性，对于那些无法自动保证准确性的属性，需要进行人工校验。"}
{"text": "SU[18]提出了一种新的半监督方法，从维基百科页面自动提取属性。"}
{"text": "Logan_I_V等人[19]提出了多模态属性提取的任务，用来提取实体的基础属性。"}
{"text": "9.3领域知识图谱的应用案例典型的通用知识图谱项目有DBpedia、WordNet、ConceptNet、YAGO、Wikidata等，本书第1章已有详细介绍。"}
{"text": "如图9-2所示，领域知识图谱常常用来辅助各种复杂的分析应用或决策支持，在多个领域均有应用，不同领域的构建方案与应用形式则有所不同，本节将以电商、图书情报（以下简称“图情”）、生活娱乐、企业商业、创投、中医临床、金融证券七个领域为例，从图谱构建与知识应用两个方面介绍领域知识图谱的技术构建应用与研究现状。"}
{"text": "图9-2行业知识图谱应用一览[10]9.3.1电商知识图谱的构建与应用[11]当下，电商的交易规模巨大，对每个人的生活都有影响。"}
{"text": "随着O2O和零售行业的发展，电商交易场景不再是单纯的线上交易场景，而是新零售、多语言、线上线下相结合的复杂购物场景，电商企业对数据互联的需求越来越强烈。"}
{"text": "在此基础上，电商交易逐渐转变为集B2C、B2B、跨境为一体，覆盖“实物+虚拟”商品，结合跨领域搜索发现、导购、交互多功能的新型电商交易。"}
{"text": "因而电商知识图谱变得非常重要。"}
{"text": "相对于通用知识图谱，它有很多不同之处。"}
{"text": "首先，电商平台是围绕着商品，买卖双方在线上进行交易的平台。"}
{"text": "故而电商知识图谱的核心是商品。"}
{"text": "整个商业活动中有品牌商、平台运营、消费者、国家机构、物流商等多角色参与，相对于网页来说，数据的产生、加工、使用、反馈控制得更加严格，约束性更强。"}
{"text": "如果电商数据以知识图谱的方法组织，可以从数据的生产端开始，就遵循顶层设计。"}
{"text": "电商数据的结构化程度相对于通用域来说做得更好。"}
{"text": "此外，面向不同的消费者和细分市场，不同角色、不同市场、不同平台对商品描述的侧重都不同，使得对同一个实体描述时会有不同的定义。"}
{"text": "知识融合就变得非常重要。"}
{"text": "最后，与通用知识图谱比较而言，电商知识图谱有大量的国家标准、行业规则、法律法规对商品描述进行着约束。"}
{"text": "存在大量的人的经验来描述商品做到跟消费者需求的匹配，知识推理显得更为重要。"}
{"text": "下面以阿里巴巴知识图谱为例，介绍电商知识图谱的相应技术模块和应用。"}
{"text": "在商品知识的表示方面，电商知识图谱以商品为核心，以人、货、场为主要框架。"}
{"text": "目前共涉及9大类一级本体和27大类二级本体。"}
{"text": "一级本体分别为人、货、场、百科知识、行业竞争对手、品质、类目、资质和舆情。"}
{"text": "人、货、场构成了商品信息流通的闭环，其他本体主要给予商品更丰富的信息描述。"}
{"text": "如图9-3所示为电商知识图谱的数据模型，数据来源包含国内—国外数据、商业—国家数据、线上—线下等多源数据。"}
{"text": "目前有百亿级的节点和百亿级的关系边。"}
{"text": "图9-3电商知识图谱的数据模型电商知识图谱主要的获取来源为知识众包，这其中的关键就是知识图谱本体设计。"}
{"text": "在设计上要考虑商品本身，又要考虑消费者需求和便于平台运营管理。"}
{"text": "另一个核心工作是要开发面向电商各种角色的数据采集工具，例如面向卖家的商品发布端。"}
{"text": "此外，电商知识的另一个来源是文本数据，例如商品标题、图片、详情、评价，舆情中的品牌、型号、卖点、场景等信息。"}
{"text": "这就要求命名识别系统具有跨越大规模实体类型的识别能力，能够支持电商域数据、人机语言交互自然语言问题以及更广泛的微博、新闻等舆情域数据的识别，并且把识别出的实体与知识图谱链接，特别是商品属性和属性值涉及上千类别的实体类型。"}
{"text": "主要包括：●商品域：类目、产品词、品牌、商品属性、属性值、标准产品。"}
{"text": "●LBS域：小区、超市、商场、写字楼、公司。"}
{"text": "●通用域：人物、数字、时间。"}
{"text": "最后，对知识图谱实体描述，除了基础的属性与属性值，很多是通过实体标签来实现的。"}
{"text": "相对来说，标签变化快、易扩展。"}
{"text": "很大一部分这类知识是通过推理获得的。"}
{"text": "例如，在食品的标签生成中，知识推理通过食品的配料表数据和国家行业标准，如：●无糖：碳水化合物含量小于或等于0.5g/100g（固体）或0.5g/100mL（液体）；●无盐：钠含量小于或等于5mg/100g或5mg/100mL。"}
{"text": "通过推理，可以把配料表数据转化为“无糖”“无盐”等知识点，从而真正地把数据变成了知识标签，并改善消费者的购物体验。"}
{"text": "大量的多源异构数据的汇集需要考虑知识的融合，主要涉及商品和产品两个核心节点知识融合。"}
{"text": "主要利用大规模聚类、大规模实体链指、大规模层次分类等技术，依据商品或产品的图片、文本、属性结构化等数据。"}
{"text": "图片涉及相似图计算、OCR等技术。"}
{"text": "大规模层次分类需要把目标商品或产品归到上千个商品1级和2级类目中去。"}
{"text": "这里面的难度在于类目的细分和混淆度，以及大规模训练数据的生成和去噪。"}
{"text": "大规模聚类的目的是把统一数据源的信息先做一次融合。"}
{"text": "大规模实体链指的核心是通过知识图谱的候选实体排序，把新的实体与知识图谱目标识别进行关联，从而把新知识融入知识图谱。"}
{"text": "在新知识融入工程中，涉及不同数据源属性名称和属性值的映射和标准化。"}
{"text": "这就需要大规模电商词林的建设和挖掘。"}
{"text": "通常来说，电商知识图谱的实体量比通用知识图谱的实体量要大很多，选择存储方案时，需要考虑很多因素，例如支持的查询方式、支持的图查询路径长度、响应时间、机器成本等。"}
{"text": "因此，存储主要采取多种存储方式混合的方案。"}
{"text": "另一方面，考虑到成本因素，全量的图谱数据通过离线关系数据库存储，共包含实体表、关系表、类目表三种表类型。"}
{"text": "为了更好地支持在线图查询和逻辑查询，与在线业务相关的知识图谱子图采用在线图数据库来存储。"}
{"text": "离线关系数据库支持向在线图数据库导入。"}
{"text": "考虑图数据的查询性能与节点路径长度关系很大，为保证毫秒级的在线响应，部分数据采用在线关系数据库支持查询。"}
{"text": "在应用方面，作为商品大脑，电商知识图谱的一个主要应用场景就是智能导购。"}
{"text": "而所谓导购，就是让消费者更容易找到他们想要的东西，例如说买家输入“我需要一件漂亮的真丝丝巾”，商品大脑会通过语法词法分析来提取语义要点“一”“漂亮”“真丝”“丝巾”这些关键词，从而帮买家搜索到合适的商品。"}
{"text": "在导购中，为了让发现更简单，商品大脑还学习了大量的行业规范与国家标准，比如说全棉、低糖、低嘌呤等。"}
{"text": "此外，商品大脑可以从公共媒体、专业社区的信息中识别出近期热词，跟踪热点词的变化，由运营确认是否成为热点词，这也是为什么买家在输入斩男色、禁忌之吻、流苏风等热词后，出现了自己想要的商品。"}
{"text": "最后，商品大脑还能通过实时学习构建出场景。"}
{"text": "例如输入“海边玩买什么”，结果中就会出现泳衣、游泳圈、防晒霜、沙滩裙等商品。"}
{"text": "再者，电商平台管控从过去的“巡检”模式升级为发布端实时逐一检查。"}
{"text": "在海量的商品发布量的挑战下，最大限度地借助大数据和人工智能阻止坏人、问题商品进入电商生态。"}
{"text": "为了最大限度地保护知识产权，保护消费者权益，电商知识图谱推理引擎技术满足了智能化、自学习、毫秒级响应、可解释等更高的技术要求。"}
{"text": "例如，上下位和等价推理，检索父类时，通过上下位推理把子类的对象召回，同时利用等价推理（实体的同义词、变异词、同款模型等）扩大召回。"}
{"text": "以拦截“产地为某核污染区域的食品”为例，推理引擎翻译为“找到产地为该区域，且属性项与‘产地’同义，属性值是该区域下位实体的食品，以及与命中的食品是同款的食品”。"}
{"text": "9.3.2图情知识图谱的构建与应用[12]图情知识图谱是指聚焦某一特定细分行业，以整合行业内图情资源为目标的知识图谱。"}
{"text": "提供知识搜索、知识标引、决策支持等形态的知识应用，服务于行业内的从业人员、科研机构及行业决策者。"}
{"text": "图情领域与知识图谱的结合由来已久。"}
{"text": "英国的大英博物馆通过结合语义技术对馆藏品各类数据资源进行语义组织，通过语义细化、多媒体资源标注等方式提供多样化的知识服务形式[13]；英国广播公司BBC[20]在其音乐、体育野生动物等板块定义了知识本体，将新/XML、JSON和XML）进行内容管理与自动生成报闻转化为机器可读的信息源（RDF道。"}
{"text": "国内图情领域也越来越重视对知识图谱技术的利用。"}
{"text": "上海图书馆[14]借鉴美国国会书目框架BibFrame[21]对家谱、名人、手稿等资源构建知识体系，打造家谱服务平台，为研究者们提供古籍循证服务；中国农业科学院[15]则聚焦于水稻细分领域，整合论文、专利、新闻等行业资源，构建水稻知识图谱，为科研工作者提供了行业专业知识服务平台。"}
{"text": "图情知识图谱的构建一般采用自顶向下的方式进行知识建模，通常从资源类型数据入手，整理出资源的发表者（人物）、发表机构（机构）、关键词（知识点）、发表载体（刊物）等类型的实体及各自之间的关系，同时通过人物、机构的主页进行实体属性的扩充。"}
{"text": "如图9-4所示为图情知识图谱Schema模型，展示了概念与概念间的关系以及部分属性。"}
{"text": "图9-4图情知识图谱Schema模型接下来分别对图情领域的数据进行获取，数据源主要包括四类。"}
{"text": "第一类是知网、专利局等文献类网站，第二类是开放通用数据，包括百科类网站以及DBpedia等的开放链接数据集，第三类是行业垂直的新闻门户，第四类是行业内企业和科研机构内部积累的既有数据。"}
{"text": "知识获取的方法视数据类型而异，具体可参考本章9.1.3节的介绍。"}
{"text": "图情领域的知识融合需要考虑实体层面的融合以及知识体系的融合。"}
{"text": "对于实体融合，主要解决不同来源实体的属性缺失、冲突等问题，一般采用多数投票的方式进行实体属性的对齐。"}
{"text": "对于多知识体系的融合，通常确定置信度最高的体系作为基准，如专利的IPC分类，继而将其他来源的知识点进行对齐。"}
{"text": "由于知识体系的质量影响到了整个知识图谱的知识描述能力与准确性，所以一般允许较多的人工介入来进行体系的融合梳理。"}
{"text": "图情知识图谱的存储设计需要兼顾实体、概念等图谱数据与论文、新闻等资源类型数据。"}
{"text": "对于图谱数据，推荐使用基于RDF的存储，如AllegroGraph、Jena等，它们对数据中的语义描述有着天然的支持，能更快地实现语义搜索等应用。"}
{"text": "对于资源数据，则可以使用面向搜索设计的数据库，如Elasticsearch、Solr等，以获得更好的搜索支持。"}
{"text": "图情领域中的知识计算主要包括图论算法、知识统计以及知识推理。"}
{"text": "通过实现基本图论算法来辅助进行各类业务分析。"}
{"text": "例如，通过图遍历算法进行机构合作的谱系分析；基于社区发现算法寻找学术研究热点；借助图排序算法进行权威分析等。"}
{"text": "通过统计学方法进行宏观层面的分析，如行业发展趋势、机构研究分布等。"}
{"text": "通过知识推理完成新知识的补充，如专家合作关系、公司上下游关系等。"}
{"text": "图情知识图谱的典型应用包括知识搜索、知识标引、决策支持等。"}
{"text": "知识搜索是图情领域的基础性服务，而知识图谱技术可以从准确性和形态上为其赋能。"}
{"text": "图谱中的实体识别技术能够提高搜索的命中率，同时允许用户通过自然语言的方式进行知识的语义搜索。"}
{"text": "而通过知识卡片、知识推荐等结果的返回也可以提升用户的交互体验。"}
{"text": "如图9-5所示为大英博物馆语义搜索。"}
{"text": "图9-5大英博馆院语义搜索知识标引指的是根据构建完成的图情知识图谱，对新闻、文献等文本的内容进行知识标注的过程。"}
{"text": "知识标引既是图谱构建过程中的重要工作，又是图谱应用的一种形态，可以依托标引技术打造在线的阅读工具，或者集成Office、PDF_reader等文档类应用，提供知识卡片、知识推荐等服务，辅助终端用户阅读，如图9-6所示。"}
{"text": "图9-6基于知识标引的辅助阅读决策支持基于路径分析、关联分析、节点聚类等图算法进行辅助分析，并通过图谱可视化的方式展示知识间的关联。"}
{"text": "可以对关联参数，如步长、过滤条件等，以及可视化的形态，如节点颜色、大小、距离等进行定制，从而为可视化决策支持赋予不同的业务含义。"}
{"text": "如图9-7和图9-8所示为典型的可视化决策支持场景。"}
{"text": "图9-7上川明经胡氏家族迁徙图图9-8专家合作分析9.3.3生活娱乐知识图谱的构建与应用：以美团为例[16][17]1.美团点评知识图谱概述海量数据和大规模分布式计算力催生了以深度学习为代表的新一代人工智能高潮。"}
{"text": "深度学习技术在语音、图像领域均取得了突破性的进展。"}
{"text": "然而，随着深度学习被广泛应用，其局限性也愈发明显。"}
{"text": "主要表现在以下四个方面：（1）缺乏可解释性。"}
{"text": "神经网络端到端学习的“黑箱”特性使得很多模型不具有可解释性，导致很多需要人去参与决策。"}
{"text": "在这些应用场景中，机器结果无法完全置信而需要谨慎使用，例如医学的疾病诊断、金融的智能投顾等。"}
{"text": "这些场景属于低容错高风险场景，必须需要显示的证据支持模型结果，从而辅助人进行决策。"}
{"text": "（2）常识缺失。"}
{"text": "人的日常活动需要大量的常识背景知识支持，数据驱动的机器学习和深度学习学习到的是样本空间的特征、表征，而大量的背景常识是隐式且模糊的，很难在样本数据中体现。"}
{"text": "例如，下雨要打伞，但打伞不一定都是下雨天。"}
{"text": "（3）缺乏语义理解。"}
{"text": "模型并不理解数据中的语义知识，缺乏推理和抽象能力，对于未见数据模型泛化能力差。"}
{"text": "（4）依赖大量样本数据。"}
{"text": "机器学习和深度学习需要大量标注样本数据去训练模型，而数据标注的成本很高，很多场景缺乏标注数据来进行冷启动。"}
{"text": "从人工智能整体发展来说，综上的局限性也是机器从感知智能向认知智能迁跃过程中必须解决的问题。"}
{"text": "认知智能需要机器具备推理和抽象能力，需要模型能够利用先验知识，总结出人可理解、模型可复用的知识。"}
{"text": "机器计算能力在整体上需要从数据计算转向知识计算，知识图谱就显得必不可少。"}
{"text": "知识图谱可以组织现实世界中的知识，描述客观概念、实体、关系。"}
{"text": "这种基于符号语义的计算模型，一方面可以促成人和机器的有效沟通，另一方面可以为深度学习模型提供先验知识，将机器学习结果转化为可复用的符号知识并累积起来。"}
{"text": "作为人工智能时代最重要的知识表示方式之一，知识图谱能够打破不同场景下的数据隔离，为搜索、推荐、问答、解释与决策等应用提供基础支撑。"}
{"text": "美团点评作为在线本地生活服务平台，覆盖了餐饮娱乐领域的众多生活场景，连接了数亿个用户和数千万家商户，积累了宝贵的业务数据，蕴含着丰富的日常生活相关知识。"}
{"text": "因此，美团点评NLP中心开始围绕吃喝玩乐等多种场景，构建了生活娱乐领域超大规模的知识图谱，为用户和商家建立起全方位的链接。"}
{"text": "通过对应用场景下的用户偏好和商家定位进行更为深度的理解，进而为大众提供更好的智能化服务。"}
{"text": "目前在建的美团大脑知识图谱有数十类概念、数十亿实体和数百亿三元组，美团大脑的知识关联数量预计在未来一年内将上涨到数千亿的规模。"}
{"text": "美团点评积累了40亿的公开评价数据、3450万全球商家数据、1.4亿店菜数据以及10万个性化标签。"}
{"text": "针对大量的数据，需要从实际业务需求出发，在现有数据表之上抽象出数据模型，以商户、商品、用户等为主要实体，其基本信息作为属性，商户与商品、与用户的关联为边，将多领域的信息关联起来，同时利用评论数据、互联网数据等，结合知识获取方法，填充图谱信息，从而提供更加多元化的知识。"}
{"text": "另一方面，则需要采用Language_Model（统计语言模型）、Topic_Model（主题生成模型）以及Deep_Learning_Model（深度学习模型）等各种模型，对商家标签、菜品标签、情感分析进行挖掘。"}
{"text": "挖掘商户标签，需要先通过机器对用户评论进行阅读，这里采用了无监督模型与有监督的深度学习模型相结合的方式。"}
{"text": "无监督模型采用了LDA，其特点是成本比较低，无须标注数据。"}
{"text": "当然，其他准确性比较不可控，同时对挖掘出来的标签还需要进行人工筛选。"}
{"text": "有监督的深度学习模型则采用了LSTM，其特点是需要大量的标注数据。"}
{"text": "通过这两种模型挖掘出来的标签，再加上知识图谱里面的一些推理，最终构建出商户的标签。"}
{"text": "其次，进行评论标签聚合，主要采用知识图谱推理技术与标签排序相结合的方式。"}
{"text": "举例来说，如果某商户的用户评价都围绕着宝宝椅、带娃吃饭、儿童套餐等话题，就可以得出很多关于这家商户的标签，如图9-9所示。"}
{"text": "例如可以知道它是一个亲子餐厅，环境比较别致，服务也比较热情等，这些新的标签可以基于知识图谱的推理来进行扩展。"}
{"text": "图9-9商户标签挖掘示意图接下来，为了更精确地匹配菜品，丰富商户信息，需要对菜品标签进行挖掘。"}
{"text": "这需要对用户评论进行分析，提取菜品的描述信息。"}
{"text": "主要采用Bi-LSTM以及CRF模型。"}
{"text": "例如从某些评论里面可以抽取出一些实体，再通过与其他的一些菜谱网站做一些关联，建立关联更加丰富的菜品知识图谱，就可以得到它的食材、烹饪方法、口味等信息，这样就为每一个店菜挖掘出了非常丰富的口味标签、食材标签等各种各样的标签，如图9-10所示。"}
{"text": "图9-10菜品标签挖掘示意图最后再对评论数据进行情感挖掘，主要采用CNN+LSTM的模型，对每一个用户的评价进行分析，分析出用户的一些情感的倾向。"}
{"text": "同时，美团也正在做细粒度的情感分析，希望能够通过用户短短的评价，分析出用户在交通、环境、卫生、菜品、口味等不同维度方面的情感分析结果，如图9-11所示。"}
{"text": "图9-11情感挖掘示意图2.美团“知识大脑”业务应用依托深度学习模型，美团大脑充分挖掘、关联美团点评各个业务场景公开数据（如用户评价、菜品、标签等），构建餐饮娱乐“知识大脑”，并且已经开始在美团的不同业务中落地，利用人工智能技术全面提升用户的生活体验。"}
{"text": "主要业务应用有智能搜索、ToB商户赋能、金融风险管理和反欺诈。"}
{"text": "（1）智能搜索：帮助用户做决策。"}
{"text": "知识图谱可以从多维度精准地刻画商家，已经在美食搜索和旅游搜索中应用，为用户搜索出更适合的店。"}
{"text": "基于知识图谱的搜索结果，不仅具有精准性，还具有多样性。"}
{"text": "如图9-12所示，当用户在美食类目下搜索关键词“鱼”时，未通过图谱搜索出来展示给用户的信息仅仅是包含关键词的“鱼”的相关结果；通过图谱可以认知到用户的搜索词是“鱼”这种“食材”。"}
{"text": "因此搜索的结果不仅有“糖醋鱼”“清蒸鱼”等精准的结果，还有“赛螃蟹”这样以鱼肉作为主食材的菜品，大大增加了搜索结果的多样性，提升用户的搜索体验。"}
{"text": "并且对于每一个推荐的商家，能够基于知识图谱找到用户最关心的因素，从而生成“千人千面”的推荐理由。"}
{"text": "例如，在浏览到大董烤鸭店的时候，偏好“无肉不欢”的用户A看到的推荐理由是“大董的烤鸭名不虚传”，而偏好“环境优雅”的用户B看到的推荐理由是“环境小资，有舞台表演”，不仅让搜索结果更具有解释性，同时也能吸引不同偏好的用户进入商家。"}
{"text": "图9-12知识图谱在点评搜索中的应用对于场景化搜索，知识图谱也具有很强的优势。"}
{"text": "以七夕节为例，通过知识图谱中的七夕特色化标签，如约会圣地、环境私密、菜品新颖、音乐餐厅、别墅餐厅等，结合商家评论中的细粒度情感分析，为美团搜索提供了更多适合情侣过七夕节的商户数据，用于七夕场景化搜索的结果召回与展示，极大地提升了用户体验和用户点击转化。"}
{"text": "（2）ToB商户赋能：商业大脑指导店老板决策。"}
{"text": "美团大脑正应用在SaaS收银系统专业版中，通过机器智能阅读每个商家的每一条评论，可以充分理解每个用户对商家的感受。"}
{"text": "将大量的用户评价进行归纳总结，从而可以发现商家在市场上的竞争力、用户对于商家的总体印象趋势、菜品的受欢迎程度变化。"}
{"text": "进一步通过细粒度用户评论全方位分析，可以细致刻画商家服务现状，以及对商家提供前瞻性经营方向。"}
{"text": "通过美团SaaS收银系统专业版，这些智能经营建议将定期触达到各个商家，智能化指导商家精准优化经营模式。"}
{"text": "在给店老板提供的传统商业分析服务中，主要聚焦于单店的现金流、客源分析。"}
{"text": "美团大脑充分挖掘了商户及顾客之间的关联关系，可以提供围绕商户到顾客，商户到所在商圈的更多维度的商业分析，在商户营业前、营业中以及经营方向，均可以提供细粒度的运营指导。"}
{"text": "在商家服务能力分析上，通过图谱中关于商家评论所挖掘的主观、客观标签，例如“服务热情”“上菜快”“停车免费”等，同时结合用户在这些标签所在维度上的Aspect细粒度情感分析，告诉商家在哪些方面做得不错，是目前的竞争优势；在哪些方面做得还不够，需要尽快改进。"}
{"text": "因而可以更准确地指导商家进行经营活动。"}
{"text": "更加智能的是，美团大脑还可以推理出顾客对商家的认可程度，是高于还是低于其所在商圈的平均情感值，让店老板一目了然地了解自己的实际竞争力。"}
{"text": "在消费用户群体分析上，美团大脑不仅能够告诉店老板顾客的年龄层、性别分布，还可以推理出顾客的消费水平，对于就餐环境的偏好，适合他们的推荐菜，让店老板有针对性地调整价格、更新菜品、优化就餐环境。"}
{"text": "（3）金融风险管理和反欺诈：从用户行为建立征信体系。"}
{"text": "知识图谱的推理能力和可解释性在金融场景中具有天然的优势，美团NLP中心和美团金融共建的金融好用户扩散以及用户反欺诈，就是利用知识图谱中的社区发现、标签传播等方法来对用户进行风险管理，能够更准确地识别逾期客户以及用户的不良行为，从而大大提升信用风险管理能力。"}
{"text": "在反欺诈场景中，知识图谱已经帮助美团金融团队在案件调查中发现并确认多起欺诈案件。"}
{"text": "由于团伙通常会存在较多关联及相似特性，关系图可以帮助识别出多层、多维度关联的欺诈团伙，能通过用户和用户、用户和设备、设备和设备之间的四度、五度甚至更深度的关联关系，发现共用设备、共用Wi-Fi来识别欺诈团伙，还可在已有的反欺诈规则上进行推理预测可疑设备、可疑用户来进行预警，从而成为案件调查的有力助手。"}
{"text": "9.3.4企业商业知识图谱的构建与应用[18]丰富多维度的企业信息在基本面分析中十分重要，中国企业数量十分庞大，数据多源，需要构建统一的企业商业知识图谱。"}
{"text": "企业商业知识图谱包含企业、人物、专利等实体类型，以及任职、股权、专利所属权等关系类型，以完善企业及个人画像，助力企业潜在客户获取、客户背景调查、多层次研究报告、风险管控；辅助发现不良资产、企业风险、非法集资等。"}
{"text": "典型的企业知识图谱，如量子魔镜[19]以全国全量企业的全景数据资源为研究基础，打造企业信用风险洞察平台；天眼查[20]、启信宝[21]则专注服务于个人与企业信息查询工具，为用户提供企业、工商、信用等相关信息的查询；企查查[22]立足于企业征信，通过深度学习、特征抽取以及知识图谱技术对相关信息进行整合，并向用户提供数据信息；中信建投将全国企业知识图谱整合进客户关系管理系统中，构建全面、清晰的客户视图，以实现高效客户关系管理。"}
{"text": "下面将企业商业知识图谱的构建方式进行梳理。"}
{"text": "构建企业商业知识图谱，通常从相应网站中抽取企业信息、人物形象、诉讼信息以及信用信息，再添加上市公司、股票等概念和相应属性。"}
{"text": "企业招投标信息、上市公司的股票信息可从相关网站进行采集。"}
{"text": "企业的竞争关系、并购事件则从百科站点中进行抽取。"}
{"text": "这些信息存在于信息框、列表、表格等半结构化数据以及无结构的纯文本中。"}
{"text": "企业商业知识图谱如图9-13所示。"}
{"text": "图9-13企业商业知识图谱企业商业知识图谱数据源主要包含两大类：1）半结构化的网页数据，其中包括全国企业信用信息公示系统、中国裁判文书网、中国执行信息公开网、国家知识产权局、商标局、版权局等。"}
{"text": "2）文本数据，如招投标信息公告、法律文书、新闻、企业年报等。"}
{"text": "通过D2R工具、包装器、文本信息抽取等方式对以上数据分别进行抽取。"}
{"text": "由于数据来源多种多样，一方面涉及人物重名现象，另一方面，企业全称和简称产生的不一致问题也非常明显。"}
{"text": "因此，公司和人物两类实体是企业知识图谱融合的主要目标。"}
{"text": "公司的融合推荐基于公司名的全称进行链接，人物实例的融合推荐使用基于启发式规则进行集成。"}
{"text": "全国企业商业知识图谱包含全国上千万家企业信息，10亿级别的三元组，形成知识图谱庞大而复杂，因此对存储方式提出了挑战，要求能够对海量的图数据进行存储，且具有良好的可伸缩性和灵活性。"}
{"text": "对此，推荐采用图数据库的方式进行存储，并可以扩展分布式存储方案以提高服务可用性与稳定性。"}
{"text": "企业商业知识图谱的应用主要集中于金融反欺诈、辅助信贷审核的功能。"}
{"text": "例如，在金融反欺诈中，多个借款人联系方式的属性相同，但地址属性不同，可通过不一致性验证的方式来判断借款人是否有欺诈风险。"}
{"text": "除此之外，通过异常关联挖掘、企业风险评估、关联探索、最终控制人和战略发展等方式，全国企业知识图谱为行业客户提供智能服务和风险管理。"}
{"text": "异常关联挖掘是通过路径分析、关联探索等操作，挖掘目标企业谱系中的异常关联。"}
{"text": "基于企业商业知识图谱从多维度构建数据模型，进行全方位的企业风险评估，有效规避潜在的经营风险与资金风险，如图9-14所示。"}
{"text": "图9-14异常关联挖掘最终控制人分析是基于股权投资关系寻找持股比例最大的股东，最终追溯至自然人或国有资产管理部门，如图9-15所示。"}
{"text": "图9-15最终控制人分析示例战略发展则以“信任圈”的展现形式，将目标企业的对外投资企业从股权上加以区分，探寻其全资、控股、合营、参股的股权结构及发展战略，从而理解竞争对手和行业企业的真实战略，发现投资行业结构、区域结构、风险结构和年龄结构等，如图9-16所示。"}
{"text": "图9-16企业社交图谱9.3.5创投知识图谱的构建与应用[23]创业投资（以下简称“创投”）知识图谱聚焦于工商知识图谱的一部分数据内容，旨在展现企业、投融资事件、投资机构之间的关系。"}
{"text": "据IT桔子的不完全统计，截至2019年2月，全国拥有初创公司超过12万家，投资机构超过7000家，有12万多名创业者，投资事件超过6万起。"}
{"text": "作为公司发展过程中的重要阶段，创投领域的发展正得到越来越多数据与技术公司的关注。"}
{"text": "2007年，在美国旧金山创立的Crunchbase[24]，其核心业务是围绕初创公司及投资机构的生态为企业提供数据服务。"}
{"text": "国内企业中TechNode于2017年发布了数据棱镜平台[25]，构建创投知识图谱，为专业人员提供创业投资数据分析工具；因果树[26]是一家人工智能股权投融资服务平台，依托大数据和人工智能技术，提升一级市场效率，推动一级市场量化。"}
{"text": "创投知识图谱的核心是投资，主要描述创业企业与投资机构之间以投资为主线的多种关系。"}
{"text": "因此，首先要理解创投领域的相关概念与关系。"}
{"text": "创投领域Schema中涉及的概念主要包括初创公司、投资机构、投资人、公司高管、行业以及投融资事件等。"}
{"text": "融资事件是创投领域的核心，不同于实体节点，融资事件描述的是一个事实，具有抽象性。"}
{"text": "典型的创投Schema如图9-17所示。"}
{"text": "图9-17典型的创投Schema创投数据主要来源于虎嗅、IT桔子、36Kr等科技型媒体网站。"}
{"text": "IT桔子是结构化的公司数据库和商业信息服务提供商，以融资事件为核心，关注IT互联网行业，其中包含了各类结构化的投资机构库和融资信息。"}
{"text": "虎嗅和36Kr则主要是以商业科技资讯为主的新闻数据来源网站。"}
{"text": "构建创投知识图谱时，同样需要考虑数据融合的问题，典型问题包括：1）数值属性表示不一致，例如金额的阿拉伯数字与中文写法的区别；2）实体同义，例如企业的全称与简称；3）不同数据源中的数据冲突。"}
{"text": "一般采用先实体对齐后属性对齐的方法来进行融合操作。"}
{"text": "创投知识图谱的存储主要考虑融资事件的存储设计，通常采用两种方式对此类信息进行存储。"}
{"text": "第一种是在传统三元组的基础上加入其他描述字段，存储时间、轮次等信息；第二种方式是通过匿名节点存储事件，把时间、地点等相关信息作为事件节点的属性。"}
{"text": "对于融资事件来说，虽然它不是客观世界中一个具体的事物，但它包含了丰富的属性信息，如融资时间、融资轮次、融资额等。"}
{"text": "因此比较适合单独引入一类节点来进行存储和表示。"}
{"text": "对于创投知识图谱的知识计算，主要通过使用社区发现、基于图的排序、最短路径等图算法，对合作分析、时序、相似公司等应用进行能力输出。"}
{"text": "例如，通过最短路径算法辅助合作分析，基于社区发现算法寻找行业研究热点，利用图排序算法进行权威分析等，通过分析展现公司的发展情况。"}
{"text": "创投领域知识图谱主要的应用形态包括知识检索以及可视化决策支持。"}
{"text": "依托创投知识图谱，知识检索可以在原有知识全文搜索的基础上实现语义搜索与智能问答的应用形态。"}
{"text": "其中，语义搜索提供自然语言式的搜索方式，由机器完成用户搜索意图识别，如图9-18所示为语义搜索示例。"}
{"text": "而作为知识搜索的终极形态，智能问答允许用户通过对话的方式对领域内知识进行问答交互，同时通过配置问题模板实现复杂业务问题的回答，如图9-19所示为智能问答示例。"}
{"text": "图9-18语义搜索示例图9-19智能问答示例通过图谱可视化技术，决策支持可对创投图谱中的初创公司发展情况、投资机构投资偏好等进行解读。"}
{"text": "通过节点探索、路径发现、关联探寻等可视化分析技术，展示公司的全方位信息；通过知识地图、时序图谱等形态，对地理分布、发展趋势等进行解读，为投融资决策提供支持。"}
{"text": "如图9-20～图9-22所示分别为投融资知识图谱示例。"}
{"text": "图9-20路径分析图9-21时序分析图9-22自然语言BI9.3.6中医临床领域知识图谱的构建与应用[27]中医药学是一门古老的医学，历代医家在数千年的实践中积累了丰富的临床经验，形成了完整的知识体系，产生了海量的临床文献。"}
{"text": "利用信息技术手段开展中医临床知识的管理和服务是一项开创性的探索，在临床上具有极大的应用价值。"}
{"text": "知识图谱有助于实现临床指南、中医医案以及方剂知识等各类知识的关联与整合，挖掘整理中医临证经验与学术思想，实现智能化、个性化的中医药知识服务，因此在中医临床领域具有广阔的应用前景。"}
{"text": "中医临床领域有其自身的特点和需求，需要专门研究中医临床知识建模方法，以解决中医临床知识的获取、分类、表达、组织、存储等核心问题。"}
{"text": "只有采集加工高质量的中医临床知识，才能建立准确、实用、完整的中医临床知识图谱。"}
{"text": "中国中医科学院中医药信息研究所相关学者以“证、治、效”为中心，对中医临床领域庞大的知识内容进行系统梳理，初步建立了一个中医临床知识图谱系统。"}
{"text": "该系统以中医临床领域本体作为骨架，集成了名医经验、临床指南、中医医案、中医文献和方剂知识等多种知识资源，并实现了各类知识点之间的知识关联。"}
{"text": "知识图谱为中医临床知识体系的系统梳理和深度挖掘提供了新颖的方法，有助于实现中医临床知识的关联、整合与可视化，促进中医临床研究，辅助中医临床决策。"}
{"text": "中医临床知识是解决中医临床实际过程中特定问题的结合，主要包括：看创指南、名医经验、临床术语、古籍和期刊文献资源（包括RCT文献质量评价结果）、中药方剂等。"}
{"text": "这些信息分散于不同的组织机构和信息系统之中，形成一个个“知识孤岛”，尚未得到有效整合，严重影响了临床应用的效果。"}
{"text": "但通过疾病、症状、方剂、中药等核心概念构成的中医临床知识图谱，可在这些“知识孤岛”之间建立联系，增强中医药知识资源的连通性，面向中医药工作者提供临床知识的完整视图，如图9-23所示为中医临床知识图谱示意图。"}
{"text": "图9-23中医临床知识图谱示意图中医临床知识图谱的构建包括以下三个部分：首先，基于领域专家设计中医临床领域的顶层本体，形成业界公认的技术规范。"}
{"text": "知识工程师们都可依据该规范进行知识图谱的加工，所产生的知识图谱互相兼容并能最终融合在一起。"}
{"text": "其次，构建目标领域的语义网络，作为知识图谱的骨架。"}
{"text": "例如，中医临床术语系统（Traditional_Chinese_Medicine_Clinical_Terminology_System,TCMCTS）就是一个专门面向中医临床的大型语义网络，共收录约11万个概念、27万个术语以及100多万条语义关系。"}
{"text": "[28]在建立语义网络之后，就可以进行领域知识的填充工作了。"}
{"text": "最后，从术语系统、数据库和文本等知识源获取知识，对知识图谱内容进行填充。"}
{"text": "可将本领域中已有的术语系统和数据库的内容转换为知识图谱，从而避免知识资源的重复建设。"}
{"text": "针对自由文本，可采用自然语言处理和机器学习等方法，从古今中外的各类中医药文献中自动发现实体和语义关系，以自动或半自动的方式填充知识图谱。"}
{"text": "在中医临床领域，构建知识图谱的一个核心的知识源是中医医案。"}
{"text": "中医医案是中医临床思维活动和辨证论治过程的记录，是中医理法方药综合应用的具体反映形式[29]。"}
{"text": "特别是名老中医的医案，对于中医理论和方法的传承具有重要意义。"}
{"text": "中医临床知识以医案形式分散于文献之中，这不利于知识检索以及临床数据的分析与挖掘。"}
{"text": "从中医医案到知识图谱的知识转换是中医临床知识图谱构建中的核心任务。"}
{"text": "通过探索医案文本语义分析与知识获取的方法，中国中医科学院中医药信息研究所的学者们研发了中医医案语义分析与挖掘工具，实现医案文本预处理、分词、语义标注、语义检索、医案文本浏览等功能。"}
{"text": "通过这套工具，从中医古代医案中抽取结构化的中医临床知识，填入中医临床知识图谱。"}
{"text": "所产生的知识图谱主要包括：名医（如“施今墨”）的擅长疾病、经验方以及弟子等信息；方剂（如“竹叶石膏汤”）的作用、操作方法，以及相关疾病、症状等信息；疾病（如“肺胀”）的临床表现、治疗方法以及相关病症、养生方法、名医等信息；中药（如“杏仁”）所治疗的疾病以及相关方剂、名医等信息。"}
{"text": "从知识学的角度分析，中医临床知识从低到高可分为“事实性知识”“概念性知识”“策略性知识”等多个层次。"}
{"text": "中医医案属于基础性的“事实型知识”，它直接记录中医临床活动中发生的事实。"}
{"text": "中医临床知识图谱则属于“概念性知识”，它用于梳理概念体系以及表示概念之间的关系。"}
{"text": "从医案知识向知识图谱的转换过程，实质上是一个知识抽象和归纳的过程。"}
{"text": "在这个过程中，一方面要完成知识抽取：对海量医案文本进行分析和标注，从中抽取中医知识；另一方面，要实现知识的结构化表示，也就是从医案文本到结构化知识的转换。"}
{"text": "在最高层则是问题求解和过程控制所需的“策略性知识”（通常用规则、过程等表示），它们是临床决策支持系统的基础。"}
{"text": "可见，知识图谱处于中间层，在多维度、多层次、多主题的知识点之间建立关联，在中医临床知识系统中起到重要的“粘合剂”作用。"}
{"text": "知识图谱有助于对中医临床知识进行分类整理和规范化表达，促进中医临床知识的共享、传播与利用，在临床诊疗、临床研究、教育、培训等方面都具有应用价值。"}
{"text": "特别是可以将中医临床知识图谱集成到知识服务系统之中，用于改进知识检索、知识问答、决策支持和知识可视化等多种服务的效果，从而提升知识服务能力。"}
{"text": "如图9-24所示，知识图谱系统以图形化的方式呈现中医名家、疾病、特色疗法、方药、养生方法等概念之间的相互关系，实现中医临床知识体系可视化。"}
{"text": "系统提供检索框，用于检索知识图谱中的概念。"}
{"text": "图9-24中医临床知识图谱界面示意图知识图谱系统以图形化的方式呈现中医名家、疾病、特色疗法、方药、养生方法等概念之间的相互关系，实现中医临床知识体系可视化。"}
{"text": "系统提供检索框，用于检索知识图谱中的概念。"}
{"text": "使用知识图谱，用户可快速找到与当前研究主题相关的医案、指南和知识库内容，辅助用户进行决策。"}
{"text": "系统协助用户在概念层次上浏览中医临床知识，发现概念或知识点之间的潜在联系，从而更好地驾驭复杂的中医药知识体系。"}
{"text": "中医临床知识图谱分析和揭示“证、治、效”之间的相关关系，提供了新颖的理念和方法。"}
{"text": "“证、治、效”是中医临床的灵魂，揭示三者之间的关联关系对于提高中医临床疗效具有重要意义。"}
{"text": "由于中医疗效的判断十分复杂，加入疗效这个因素后，使得三者关系的维度过高，目前的计算机模型很难处理，但可以选择验案作为研究方证对应关系的数据资源，因为验案本身都具有良好疗效。"}
{"text": "可在验案的基础上构建中医临床知识图谱，全面收集中医临床中与“证、治、效”相关的信息，从而再现中医验案中蕴涵的相关关系（如方剂与证候的相关关系、症状组合与证候的相关关系、药物组合与方剂的相关关系等），揭示症状组合规律、方剂配伍规律以及基于药物组合和症状组合的方证对应规律等。"}
{"text": "最后，可将这些相关关系和规律提供给临床医生，作为支持临床决策的参考性依据。"}
{"text": "知识图谱是在“大数据”时代背景下出现的一项新颖的知识管理技术。"}
{"text": "在“大数据”时代，不再热衷于寻找因果关系，转而将注意力放在相关关系的发现和使用上。"}
{"text": "知识图谱从多个维度来描述中医药领域对象，反映中医药事物之间的相关关系，它将是中医药大数据方法学体系中的核心组成部分。"}
{"text": "大数据通过识别有用的关联关系来分析一个现象，而不是揭示其内部的运作机制。"}
{"text": "基于相关关系分析的预测是大数据的核心。"}
{"text": "中医的思想方法不是严格的逻辑推理，而是一种关联式的思考。"}
{"text": "这种理念上的相似性，使得中医药工作者更易接受并使用“大数据”的方法与技术。"}
{"text": "利用中医临床知识图谱，能够发现中医药概念之间的相关关系，揭示各种临床规律，从而不断完善中医临床知识体系，直接推动中医临床研究的快速发展。"}
{"text": "9.3.7金融证券行业知识图谱应用实践[30]金融证券行业正面临着数据爆炸的问题。"}
{"text": "传统的金融数据服务商历时数十年，已收集整理了大量高质量的结构化数据，并分门别类地展示给用户。"}
{"text": "如何有效地使用这些数据，需要用户具备专业的金融经济知识，深刻理解某个数据的变动可能引发的关联、传导效应，从而帮助用户做出各种投资决策。"}
{"text": "金融行业的研究人员相当于在大脑里存储或训练了一个知识图谱，将相关的行业、产品、公司等因素联系在一起，当观察到某个数据变量发生变化时，可以分析推理出各种观点并进行预测。"}
{"text": "然而，一个人的脑容量或记忆是有限的，一位专业的行业分析师通常只能对几个行业了如指掌。"}
{"text": "因此，对市场进行全行业的分析服务需要一支分析师团队。"}
{"text": "通过人与人之间的交流，以及研报与研报之间的关联和对接，来实现整个经济金融体系的传导与联系。"}
{"text": "近年来，非结构化数据的井喷式涌现给这种传统的运作方式带来了挑战。"}
{"text": "财经新闻、经济产业信息每时每秒都在更新；上市公司的数目众多，所涉及的定期报告、临时报告数量巨大；基于互联网平台的股吧、论坛、门户网站、微信、微博等每时每刻也在产生着大量的资讯，上述信息都将可能对证券市场产生各种各样的影响。"}
{"text": "这使得从海量资讯触发源上，以及分析数据所需的知识的广度、深度上，均对传统的资讯处理模式提出了极大的挑战。"}
{"text": "现代信息技术人工智能的发展已经可以在很多方面提高信息分析和利用的效率。"}
{"text": "对结构化数据的分析挖掘已经取得了很多进展，很多成熟的分析预测算法还是针对结构化、关系数据的。"}
{"text": "然而，非结构化数据的分析挖掘和利用尚处于起步阶段。"}
{"text": "领域知识建模在方法论上的正确性，是决定人工智能应用成功与否的关键因素。"}
{"text": "当前，“知识图谱”作为领域知识建模的工具正在受到越来越多的重视。"}
{"text": "基于知识图谱的领域建模、基于规模化大数据的处理能力、针对半结构化标签型数据的分析预测算法三者的结合，是人工智能的优势所在。"}
{"text": "构建金融证券领域知识图谱作为金融证券文本语义理解和知识搜索的关键基础技术，为未来金融证券领域文本分析、舆情监控、知识发现、模式挖掘、推理决策等提供了坚实支撑。"}
{"text": "金融领域的知识图谱与其他专业领域图谱相比有着很大的不同。"}
{"text": "金融领域本就是连接各行各业、世间万物的，因此金融知识图谱涉及经济、投资、产业、公司等相关的知识，其实是覆盖全行业的。"}
{"text": "但金融领域知识图谱与通用或百科类知识图谱不同，其行业、产业链知识，经济金融重要指标等大多是以投资的视角来筛选和组织的。"}
{"text": "金融知识图谱常见的实体包括：公司、产品、证券、人等。"}
{"text": "实体间的关系，如公司-人之间，主要有股权关系和任职关系；公司-公司间关系，有股权关系、供应商关系、竞争关系等；公司-产品间关系，有生产关系、采购关系等；产品-产品间关系，主要有上下游关系等。"}
{"text": "有些实体和关系可以自动抽取生成，如公司-公司间的股权关系、公司-人之间的股权关系和任职关系，均可来源于工商局注册登记公开信息，其结构化程度很高，实体、关系抽取难度不大。"}
{"text": "而对于产品-产品间上下游关系，则很难有系统性的半结构化数据源，其实体和关系呈碎片化分散在百科类网站、研究报告、专家资料等文本或图像中，这给抽取和甄别带来了很大挑战。"}
{"text": "如图9-25所示为金融知识图谱示例。"}
{"text": "金融知识图谱的建立可以分为以下三个部分：从海量异构非结构化数据中辨别金融实体；定义并挖掘金融实体之间的各种关系，从而生成知识图谱；定义并表达业务逻辑，在知识图谱上实现各种具体任务，如推理等。"}
{"text": "本书对构建过程中主要用的关键技术进行简单的梳理：1.实体-关系抽取从海量异构非结构化数据中辨别金融实体，主要采用实体-关系抽取技术，即从文本中抽取出特定的实体信息，如时间、人物、地点、公司、产品等；以及实体间的各种关系，如地理位置关系、雇佣关系、股权关系等。"}
{"text": "实体确定了知识图谱中的点，而关系则确定了点与点之间的边。"}
{"text": "图9-25金融知识图谱示例常用的实体关系抽取方法有基于专家知识库的方法和基于机器学习的方法等。"}
{"text": "基于专家知识库的方法需要专家构筑大规模的领域知识库，需要大量的专家劳动。"}
{"text": "机器学习方法需要构造特征向量形式的训练数据，然后使用各种机器学习算法，如支持向量机等作为学习机构造分类器。"}
{"text": "这种方法被称作基于特征向量的学习算法。"}
{"text": "通常来说，构造领域知识图谱会从大量特定类型的文本（尤其是高质量、模板化的专业资料）中提取实体关系。"}
{"text": "这类文本，或者是半结构化，或者是模块格式相对明确固定的，例如上市公司公告的XBRL格式数据。"}
{"text": "这类规范化数据源降低了信息提取的难度，大大提高了知识提取的准确度和效率。"}
{"text": "对于非结构化文本，实体识别和关系抽取需要基于NLP算法，以及深度学习算法（例如，用词向量的方式寻找近义词，提高实体模糊识别的准确度），是一个反复迭代、不断精进的过程。"}
{"text": "其中，关系抽取可以划分为确定类型的关系抽取和不确定类型的关系抽取。"}
{"text": "确定类型的关系抽取，例如“is-a”关系，可使用语法模式抽取固定模式，使用迭代方法扩展“is-a”关系，并对生成的“is-a”进行清洗。"}
{"text": "不确定类型的关系抽取常基于NLP将目标实体间的谓词提取出来作为候选关系，再进行下一步的筛选鉴别。"}
{"text": "2.定义并挖掘金融实体间的各种关系，从而生成知识图谱基于领域知识图谱的推理与业务场景息息相关。"}
{"text": "基于通用知识图谱的推理沿边的传递性并不强，例如精准搜索常常只用到一步到二步的推理，再往下传递时，其可信程度将会大大降低。"}
{"text": "而金融知识图谱在与领域知识充分结合的前提下，是可以实现长链推理的。"}
{"text": "下面列举几个推理案例：（1）关联关系推理。"}
{"text": "基于知识图谱中公司和人之间的股东、任职等关系，可以基于聚类算法发现利益相关团体。"}
{"text": "此时，当其中若干节点发生变动或大的事件时，可以通过沿知识图谱路径查询或子图发现等方法计算并绘制发生变动的实体间的关联情况，帮助监管层发掘潜在的关联或违规行为，大大提高关联发现的效率。"}
{"text": "如图9-26所示，该图为一个以某公司为核心的股权关系结构图，当该公司出现异常风险时，会影响到其核心关联节点。"}
{"text": "图9-26关联关系推理示意图（2）产业链关系推理。"}
{"text": "基于产业链知识图谱，可模拟经济学的涟漪效应：某产业链下游销量大涨，对整个产业链中游、上游的拉动是非常显著的，且可以沿图谱用量化的方式建模并形成自动化推理传导模型。"}
{"text": "同样的，上游原材料成本的上涨对于产业链中下游也可能形成链状的传导效应。"}
{"text": "这将帮助判断事件的重要程度，并即时给出事件的影响范围和程度，为各类投资决策做数据支持。"}
{"text": "如图9-27所示，某一稀有原材料上涨，其产业链中下游的产品可能因为成本上涨导致产品价格上涨等。"}
{"text": "图9-27产业链关系推理示意图3.领域知识图谱数据库选型构建领域知识图谱底层数据库有非常多的选择。"}
{"text": "从传统的关系数据库到NoSQL，再到图数据库；不论是采用一种数据库还是多种数据库相结合的方式，都是研发领域知识图谱前需要反复斟酌和考虑的问题。"}
{"text": "数据库的选型需要充分考虑领域数据自身的特点（以结构化数据为主，还是非结构化数据为主），以及如何使用这些数据（例如，是否经常需要沿图谱进行推理，推理路径长短等）。"}
{"text": "通常来说，Neo4j等图数据库擅长长链推理，但对单位基础数据的日常维护较弱；MongoDB、HBase等NoSQL数据库擅长处理文本类非结构化数据，对于传统数值型数据的很多处理则需要额外写代码维护；MySQL等传统数据库擅长处理和维护结构化数据，在面对沿图谱进行推理等应用时则需要比图数据库更多的代码量。"}
{"text": "从工程实现上来看，图数据库的使用频率和相关人才储备远低于关系数据库，如果选用图数据库作为主要的底层数据库，研发团队可能经常需要面临无人可招和遇到问题搜遍网络都无帖可解的窘境，即整个系统工期规划会难以预估。"}
{"text": "构筑金融领域的知识图谱是一个既有着大量结构化数据，又需要整合非结构化文本数据信息，同时需要沿图谱进行推理的综合性项目。"}
{"text": "传统的金融数据供应商长期积累了大量结构化数据，例如价格、营收、利润、销量等数据，均为长时期时间序列格式。"}
{"text": "这与通用知识图谱相比，呈现出很大的不同。"}
{"text": "因此，在具体的数据库选型时，需要充分考虑未来的应用将以何种方式、何种频率使用数据，从而打造出因地制宜的高效底层数据库。"}
{"text": "在知识图谱在金融证券行业应用方面，目前国内尚处于起步阶段。"}
{"text": "如果能基于知识图谱技术框架，建立起一个全谱系的上市公司关联图，并将其直接关联、间接关联的各种实体、概念相联系，将极大地帮助证券行业监管层、投资者及其他各种参与者了解并把握市场的脉搏。"}
{"text": "而在具体业务应用方面，当监控到市场价格出现波动时，可以就股价出现异动的股票在知识图谱中追溯其异动产生的根源；挖掘学习实体之间的隐含关系，来发现潜在的关联与协同动作，以预防并打击违法、违规行为；自动学习并抽取公告摘要，快速传递并汇总全市场披露的动态信息，以减少信息不对称性并加强证券市场的透明度。"}
{"text": "基于金融证券知识图谱可在多个智能金融应用场景中得到应用，这些应用场景包括：智能投研、智能投顾、智能风控、智能客服、智能监管、智能运营等。"}
{"text": "智能投研专注于对基本面等信息的采集和分析。"}
{"text": "对智能投研技术的实用化来说，自然语言处理和产业链、作用链的知识图谱建模是最关键的技术。"}
{"text": "具体而言，通过构造上下游产业链知识图谱，基于经济基本面建立传导模型。"}
{"text": "当产业链中重要节点的状态发生变化时，将启动沿产业链传导推理引擎，自动给出影响范围、对象和程度，为事件引发的基本面分析做支持。"}
{"text": "不同于技术分析，基本面分析本身是一个非结构化的方式，无论是数据，还是市场逻辑。"}
{"text": "基于金融知识图谱和推理逻辑，把这些基础数据进行整合加工，从而找到未来趋势的变化或者解释已经发生过的事情。"}
{"text": "从局部来看，产业链知识图谱里面各种实体、属性、关系就像活细胞一样，相互关联、影响、作用着。"}
{"text": "这是“金融知识图谱+推理链”的共同作用结果。"}
{"text": "如图9-28所示为橡胶-轮胎-重卡产业链知识图谱局部示意图。"}
{"text": "当发生“重卡销量大增”事件时，可沿产业链向上游进行传导推理，并生成分析影响报告。"}
{"text": "基于金融知识图谱，还可在风险评估与反欺诈方面展开应用。"}
{"text": "风险评估是大数据、互联网时代的传统应用场景，应用时间较早，应用行业广泛。"}
{"text": "它是通过大数据、机器学习技术分析用户行为数据后，进行用户画像，并进行信用评估和风险评估。"}
{"text": "图9-28橡胶-轮胎-重卡产业链知识图谱局部示例NLP技术在风控场景中的作用是理解分析相关文本内容，为待评估对象打标签，为风控模型增加更多的评估因子。"}
{"text": "引入知识图谱技术后，可以通过人员关系图谱的分析，发现人员关系的不一致性或者短时间内变动较大，从而侦测欺诈行为。"}
{"text": "利用大数据风控技术，在事前能够预警，过滤掉带恶意欺诈目的人群；在事中进行监控，及时发现欺诈攻击；在事后进行分析，挖掘欺诈者的关联信息，降低以后的风险。"}
{"text": "在金融行业中，风险评估与反欺诈的应用场景首先是智能风控。"}
{"text": "利用NLP和知识图谱技术改善风险模型以减少模型风险，提高欺诈监测能力。"}
{"text": "其次，还可以应用在智能监管领域，以加强监管者和各部门的信息交流，跟踪合规需求变化。"}
{"text": "通过对通信、邮件、会议记录、电话的文本进行分析，发现不一致和欺诈文本。"}
{"text": "例如，欺诈文本有些固定模式：如用负面情感词，减少第一人称使用等。"}
{"text": "通过有效的数据聚合分析，可大大减少风险报告和审计过程的资源成本。"}
{"text": "从事此类业务的金融科技公司很多，如Palantir最初从事的金融业务就是反欺诈。"}
{"text": "其他如Digital_Reasoning、RapidMiner、Lexalytics、Prattle等。"}
{"text": "另一方面，金融知识图谱还可以用在客户洞察方面。"}
{"text": "客户关系管理（CRM）也是在互联网和大数据时代中发展起来，市场相对成熟，应用比较广泛，许多金融科技公司都以此为主要业务方向。"}
{"text": "现代交易越来越多是在线上而不是线下当面完成，因此如何掌握客户兴趣和客户情绪，越来越需要通过分析客户行为数据来完成。"}
{"text": "NLP技术在客户关系管理中的应用，是通过把客户的文本类数据（客服反馈信息、社交媒体上的客户评价、客户调查反馈等）解析文本语义内涵，打上客户标签，建立用户画像。"}
{"text": "同时，结合知识图谱技术，通过建立客户关系图谱，以获得更好的客户洞察。"}
{"text": "这包括客户兴趣洞察（产品兴趣），以进行个性化产品推荐、精准营销等，以及客户态度洞察（对公司和服务满意度、改进意见等），以快速响应客户问题，改善客户体验，加强客户联系，提高客户忠诚度。"}
{"text": "客户洞察在金融行业的应用场景主要包括智能客服和智能运营。"}
{"text": "例如在智能客服中，通过客户洞察分析，可以改善客户服务质量，实现智能质检。"}
{"text": "在智能运营（智能CRM）中，根据客户兴趣洞察，实现个性化精准营销。"}
{"text": "国外从事这个业务方向的金融科技公司有Inmoment、Medallia、NetBase等。"}
{"text": "[31]总体来说，基于金融知识图谱的应用，有如下三大特点：（1）广覆盖。"}
{"text": "广泛覆盖全量信息源，覆盖宏观、中观、微观各维度信息，覆盖上市公司及非上市公司，以方便后续算法拓展所有可能的深度关联关系。"}
{"text": "（2）深加工。"}
{"text": "基于知识图谱与智能推理链，实现从数据到智慧的深加工。"}
{"text": "（3）浅表达。"}
{"text": "以可视化的方式和自然语言与用户交互，一目了然，受众更广。"}
{"text": "然而，领域知识图谱对专业知识的基础需求，远远大于通用知识图谱。"}
{"text": "在建设初期需要大量的专家工作。"}
{"text": "基于此，可以尝试从两个方面入手来构筑大型领域知识图谱。"}
{"text": "一方面，开启知识众包时代，建立新的协作方式。"}
{"text": "构建用户友好的知识众包协作平台，使得专家能很方便地利用碎片化时间在平台上贡献自己的知识，同时设计相应的知识回报模式。"}
{"text": "就平台自身而言，如何设计自动内容校验和精华内容提取算法，从大量专家碎片化知识中提取重要内容以添加到“主图谱”中，是一个需要长期不断探索的课题。"}
{"text": "另一方面，通过知识自动抽取、自动生长构建“活”的知识图谱。"}
{"text": "这意味着需要有新的知识持续不断地输入知识图谱中；通过知识图谱定义的作用链进行自动推理；知识图谱自身可以备靠大数据，在“人工+自动”模式下自我生长。"}
{"text": "通过这两方面的相辅相成、交叉验证，以真正将海量非结构化信息自动化利用起来，成为领域应用决策的坚实支撑。"}
{"text": "9.4本章小结结合知识图谱研究发展态势，并结合当前知识图谱的构建与应用未来现状，对知识图谱未来技术发展及趋势发展做一个展望。"}
{"text": "1.知识图谱构建现阶段，基于本体工程的知识描述和表示仍是知识图谱建模的主流方法，而且仅仅用到一些RDFS及OWL中定义的基础元属性来完成知识图谱模式层构建，知识图谱所关注的重点也仍然是数据中的概念、实体、属性等。"}
{"text": "随着人们对知识的认知层次的提升，势必会对现有的知识表示方法进行扩展，逐步扩充对于时序知识、空间知识[22]、事件知识[23]等的表示。"}
{"text": "而知识图谱本身也会逐步将关注重点转移到时序、位置、事件等动态知识中去，来更有效地描述事物发展的变化，为预测类的应用形态提供支持。"}
{"text": "其次，对于知识图谱构建任务来说，最困难、最无法标准化实现的一个环节就是对于文本数据的信息抽取。"}
{"text": "知识图谱面向开放领域的信息抽取普遍存在着召回率低、算法准确性低、限制条件多、拓展性差等问题。"}
{"text": "随着计算机计算能力的日益提高与深度学习技术不断研究发展，NLP领域发生了翻天覆地的变化，CNN、RNN等经典神经网络结构已经被应用于NLP中，尝试完成机器翻译、命名实体识别任务。"}
{"text": "未来，深度学习的思想和方法会越来越多地应用于文本信息抽取中，优化抽取方式，提高知识的覆盖率与准确率[24-25]。"}
{"text": "其他如跨语言知识融合[26]、知识嵌入[27]等方向也会在深度学习技术的加持下激起新的研究浪潮。"}
{"text": "2.知识图谱应用在知识图谱应用方面，未来将会出现更多的应用形态，如基于知识图谱的智能文本编制，通过知识图谱将行业中的业务知识与文档相结合，在文档编制过程中进行实时的智能提示、知识校验、知识生产等，辅助文档编制。"}
{"text": "又如基于知识图谱的自然语言理解与自然语言生成，通过知识图谱对知识的建模能力，结合深度学习对知识的学习与抽象能力，实现以自然语言形式进行输入和输出的下一代问答系统。"}
{"text": "随着知识表示技术和推理技术的发展，结合一些新型的可视化方法，还可以展望一些预测分析类的应用形态，如疾病预测、行情预测、政治意识形态检测[28]、城市人流动线分析[22]。"}
{"text": "除此之外，知识图谱在辅助多媒体数据处理方面也是一个有待深入研究的方向，如物体检测[29]、图像理解[30]等。"}
{"text": "总之，知识图谱作为人工智能技术中的知识容器和孵化器，会对未来AI领域的发展起到关键性的作用。"}
{"text": "无论是通用知识图谱还是领域知识图谱，其构建技术的发展和对应用场景的探索仍然会不断地持续下去。"}
{"text": "知识图谱技术不单指某一项具体的技术，而是知识表示、抽取、存储、计算、应用等一系列技术的集合。"}
{"text": "随着这些相关技术的发展，我们有理由相信，知识图谱构建技术会朝着越来越自动化方向前进，同时知识图谱也会在越来越多的领域找到能够真正落地的应用场景，在各行各业中解放生产力，助力业务转型。"}
